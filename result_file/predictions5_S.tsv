task	label	predict1	predict2	predict
task5	"<line3>        LOG.debug(""Initializing XRay tracer"");"	<line5>	"LOG.warn(""Error while adding service: {}"", this, e)"	"<line5> LOG.warn(""Error while adding service: {}"", this, e)"
task5	"<line5>      LOGGER.warn(""Unable to transform geometry"", e);"	<line5>	"LOGGER.error(""Error transforming feature iterator"", e)"	"<line5> LOGGER.error(""Error transforming feature iterator"", e)"
task5	"<line1>    log.debug(""client [container: {}] disconnected"", con.getRemoteContainer());"	<line1>	"log.info(""Remote connection closed: {}"", con.getRemoteContainer())"	"<line1> log.info(""Remote connection closed: {}"", con.getRemoteContainer())"
task5	"<line2>    log.info(""get ["" + keys + ""]"");"	<line2>	"log.debug(""Getting multiple keys: "" + keys)"	"<line2> log.debug(""Getting multiple keys: "" + keys)"
task5	"<line9>        log.warn(""Missing />"");"	<line9>	"log.warn(""Missing </input>"")"	"<line9> log.warn(""Missing </input>"")"
task5	"<line2>    LOG.info(""Memory Difference is: "" + differenceMemoryCache);"	<line2>	"LOG.info(""Difference in memory usage: "" + differenceMemoryCache)"	"<line2> LOG.info(""Difference in memory usage: "" + differenceMemoryCache)"
task5	"<line9>      log.info(""Second holdcc() threw IllegalStateException as expected."");"	<line3>	"log.info(""apply() invoked. counter = "" + counter)"	"<line3> log.info(""apply() invoked. counter = "" + counter)"
task5	"<line7>            log.debug(""Exception in closing "" + c, e);"	<line7>	"log.debug(""Exception in closing "" + c, e)"	"<line7> log.debug(""Exception in closing "" + c, e)"
task5	<line26>      log.error(systemException, systemException);	<line26>	log.error(systemException, systemException)	<line26> log.error(systemException, systemException)
task5	"<line13>      logger.warn("" Exception while processing: ""+ belongsToClass+ "" Line: ""+ typeType.start.getLine()+ "" ""+ e.getMessage());"	<line13>	"logger.warn("" Exception while processing: "" + belongsToClass + e.getMessage())"	"<line13> logger.warn("" Exception while processing: "" + belongsToClass + e.getMessage())"
task5	<line1>    logger.info(msg);	<line2>	log.info(msg)	<line2> log.info(msg)
task5	"<line5>      logger.error(""Failed to create ssl tofu rest template"", e);"	<line5>	"logger.error(""Error while creating RestTemplate for reading linked data."", e)"	"<line5> logger.error(""Error while creating RestTemplate for reading linked data."", e)"
task5	"<line19>      logger.debug(""Since creation of parent template: ""+ templateInfo.getId()+ "" failed, delete Datadisk templates that were created as part of parent""+ "" template download"");"	<line19>	"logger.error(""Failed to create template for datadisk ""+ dataDiskTemplate.toString()+ "" from parent template: ""+ parentTemplate.getId())"	"<line19> logger.error(""Failed to create template for datadisk ""+ dataDiskTemplate.toString()+ "" from parent template: ""+ parentTemplate.getId())"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line35>      logger.trace(""Optimized query model:\n{}"", tupleExpr);"	<line38>	"log.error(""Failed to evaluate query"", e)"	"<line38> log.error(""Failed to evaluate query"", e)"
task5	"<line2>    log.trace(""#{} queue {} completed"", session.uniqueId(), var);"	<line2>	"LOG.debug(""{} completed"", this)"	"<line2> LOG.debug(""{} completed"", this)"
task5	"<line10>    log.info(""Finished request: ""+ tm+ ""ms  for ""+ request.getAbsolutePath()+ "" method=""+ request.getMethod());"	<line10>	"LOG.debug(""Request time: {} ms"", tm)"	"<line10> LOG.debug(""Request time: {} ms"", tm)"
task5	"<line7>    LOGGER.info(""doStopSelfTest() for device: {}."", deviceRequest.getDeviceIdentification());"	<line7>	"LOGGER.info(""StopSelfTest() for device: {}."", deviceRequest.getDeviceIdentification())"	"<line7> LOGGER.info(""StopSelfTest() for device: {}."", deviceRequest.getDeviceIdentification())"
task5	<line12>        log.debug(sb.toString());	<line12>	log.debug(sb.toString())	<line12> log.debug(sb.toString())
task5	"<line3>      LOG.info(""no message log replay snapshot, return empty state."");"	<line1>	"LOG.info(""Loading message checkpoint from snapshot: {}"", snapshot)"	"<line1> LOG.info(""Loading message checkpoint from snapshot: {}"", snapshot)"
task5	<line8>          log.error(e.getMessage(), e);	<line8>	log.error(e.getMessage(), e)	<line8> log.error(e.getMessage(), e)
task5	"<line5>    LOGGER.debug(""MessageLength: "" + message.getMessageLength().getValue());"	<line5>	"LOGGER.debug(""MessageLength: "" + message.getMessageLength().getValue())"	"<line5> LOGGER.debug(""MessageLength: "" + message.getMessageLength().getValue())"
task5	"<line2>    logger.debug(""Find all assets for repositoryId: {}, path: {}, deleted: {}, virtual: {}, branchId: {}"",repositoryId,path,deleted,virtual,branchId);"	<line9>	"log.debug(""all assets: {}"", all)"	"<line9> log.debug(""all assets: {}"", all)"
task5	<line16>      LOGGER.error(e);	<line16>	LOGGER.error(e)	<line16> LOGGER.error(e)
task5	"<line6>      log.info(""exceotuib reseting stats"", e);"	<line6>	"LOG.error(""Error clearing pool"", e)"	"<line6> LOG.error(""Error clearing pool"", e)"
task5	"<line2>    LOGGER.debug(""Extensions: "" + ArrayConverter.bytesToHexString(pair.getExtensions().getValue()));"	<line2>	"LOGGER.debug(""Extensions: "" + ArrayConverter.bytesToHexString(pair.getExtensions().getValue()))"	"<line2> LOGGER.debug(""Extensions: "" + ArrayConverter.bytesToHexString(pair.getExtensions().getValue()))"
task5	"<line24>      logger.error(""Exception occurred in SDNCDeactivateTasks deactivateVfModule"", ex);"	<line1>	"logger.debug(""Deactivate VfModule"")"	"<line1> logger.debug(""Deactivate VfModule"")"
task5	"<line13>      log.error(""Problem de-serializing object."", e);"	<line13>	"log.error(""Failed to de-serialize object. The ElementSerializer is null."", e)"	"<line13> log.error(""Failed to de-serialize object. The ElementSerializer is null."", e)"
task5	"<line1>    LOG.debug(""thread {}: connection stop"", Thread.currentThread().getId());"	<line4>	"logger.info(""Closing client"")"	"<line4> logger.info(""Closing client"")"
task5	"<line2>    logger.info(""Testing DB2 schema creation"");"	<line8>	logger.info(tgt.getText())	<line8> logger.info(tgt.getText())
task5	<line2>    logger.debug(Messages.STARTING_APPLICATION_0, applicationName);	<line2>	logger.debug(Messages.STARTING_APPLICATION_0, applicationName)	<line2> logger.debug(Messages.STARTING_APPLICATION_0, applicationName)
task5	"<line3>    LOG.debug(""Calling OpenstackNeutronNetworkResource.getAllShouldSucceed()"");"	<line3>	"LOG.debug(""Calling OpenstackNeutronNetworkResource.getAllShouldSucceed()"")"	"<line3> LOG.debug(""Calling OpenstackNeutronNetworkResource.getAllShouldSucceed()"")"
task5	"<line8>      logger.error(""Decode RQNT Response failed"", e);"	<line8>	"logger.info(""IOException while decoding response for TxId "" + txID, e)"	"<line8> logger.info(""IOException while decoding response for TxId "" + txID, e)"
task5	"<line2>    LOGGER.info(""Kinited user: "" + user + "" keytab: "" + KEYTAB_LOCATION + ""/"" + user + "".keytab"");"	<line1>	"LOGGER.info(""Initializing page rank data generator..."")"	"<line1> LOGGER.info(""Initializing page rank data generator..."")"
task5	"<line2>    logger.info(name.getMethodName() + "" - callback - error"");"	<line2>	"logger.info(name.getMethodName() + "" - callback - error"")"	"<line2> logger.info(name.getMethodName() + "" - callback - error"")"
task5	"<line2>    logger.debug(""Jumping from old track position {} ms to new position {} ms"",currentPosition,currentPosition + positionOffsetInMs);"	<line2>	"logger.debug(""Changing track position to {} ms"", currentPosition + positionOffsetInMs)"	"<line2> logger.debug(""Changing track position to {} ms"", currentPosition + positionOffsetInMs)"
task5	"<line15>          LOGGER.error("""", e);"	<line15>	"LOGGER.trace("""", e)"	"<line15> LOGGER.trace("""", e)"
task5	"<line11>      log.error(""Error while trying to load registry config for C-App : ""+ parentAppName+ "" artifact : ""+ artifactName,e);"	<line11>	"log.error(""Error while reading registry configuration of artifact: "" + artifactName, e)"	"<line11> log.error(""Error while reading registry configuration of artifact: "" + artifactName, e)"
task5	"<line8>      log.warn(""Inknown object invoked in surf filter ui"");"	<line8>	"log.error(""edited object filename, but not implemented"")"	"<line8> log.error(""edited object filename, but not implemented"")"
task5	"<line19>      logger.debug(""got "" + messages.size() + "" message(s): "" + messages);"	<line19>	"logger.debug(""got "" + messages.size() + "" message(s): "" + messages)"	"<line19> logger.debug(""got "" + messages.size() + "" message(s): "" + messages)"
task5	"<line6>          logger.debug(""Couldn't resolve ""+ an.desc+ "" annotation type whilst searching for hints on ""+ getName());"	<line6>	"log.warn(""Could not find annotation type for "" + annotationType)"	"<line6> log.warn(""Could not find annotation type for "" + annotationType)"
task5	"<line10>    log.info(""Starting Spark server, ignoring port and host"");"	<line20>	"log.info(""Ignite server has started: {}"", igniteConfiguration.getAddress())"	"<line20> log.info(""Ignite server has started: {}"", igniteConfiguration.getAddress())"
task5	<line7>      log.error(exception, exception);	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	"<line3>    log.debug(this.getName() + "" flushed."");"	<line1>	"log.debug(""flush()"")"	"<line1> log.debug(""flush()"")"
task5	"<line5>    LOGGER.debug(""Merging tables"");"	<line14>	"LOGGER.debug(""Merging of partitions will be done in ""+ numPartitionsToMergeSeparately+ "" steps."")"	"<line14> LOGGER.debug(""Merging of partitions will be done in ""+ numPartitionsToMergeSeparately+ "" steps."")"
task5	"<line10>          LOG.error("""", e);"	<line2>	"LOG.debug(""onEvent: {}"", event)"	"<line2> LOG.debug(""onEvent: {}"", event)"
task5	"<line8>    LOGGER.debug(""Reconstruct consumer code :""+ bill.getConsumerId()+ "", with bill reference number: ""+ billReferenceNumber+ "", for Amount Paid :""+ actualAmountPaid);"	<line10>	"if (LOGGER.isDebugEnabled()) LOGGER.debug(""Bill apportioning enabled for : "" + billID)"	"<line10> if (LOGGER.isDebugEnabled()) LOGGER.debug(""Bill apportioning enabled for : "" + billID)"
task5	"<line11>      LOG.info(""Can't create admin log and detail for logo replacement."", e);"	<line11>	"LOG.error(""Could not create logo attribute changed log for org [{}]"", orgExt.getId(), e)"	"<line11> LOG.error(""Could not create logo attribute changed log for org [{}]"", orgExt.getId(), e)"
task5	<line5>      logger.error(e, e);	<line5>	logger.error(e, e)	<line5> logger.error(e, e)
task5	"<line2>    log.debug(""exists: "" + exists);"	<line2>	"logger.debug(""clientExists? "" + demographicNo + "" : "" + exists)"	"<line2> logger.debug(""clientExists? "" + demographicNo + "" : "" + exists)"
task5	"<line1>    logger.warn(""Skipping a URL: {} which was bigger ( {} ) than max allowed size"", urlStr, pageSize);"	<line1>	"logger.info(""page {} of {} size {} is bigger than max size {}, skipping"",urlStr,pageSize)"	"<line1> logger.info(""page {} of {} size {} is bigger than max size {}, skipping"",urlStr,pageSize)"
task5	"<line4>    logger.debug(""Transaction started for window {}"", windowId);"	<line2>	"LOG.debug(""Begin window {}"", windowId)"	"<line2> LOG.debug(""Begin window {}"", windowId)"
task5	<line9>          log.error(e, e);	<line9>	"LOG.error(""wrapee class {} has no method {}"", wrapee.getCanonicalName(), method.getName())"	"<line9> LOG.error(""wrapee class {} has no method {}"", wrapee.getCanonicalName(), method.getName())"
task5	"<line5>    log.debug(""getGroups query for "" + entityId);"	<line5>	"log.info(""getGroups for "" + entityId)"	"<line5> log.info(""getGroups for "" + entityId)"
task5	"<line13>      logger.error("""", e);"	<line13>	"logger.error(""find partition group leader broker exception, topic: {}, namespace: {}"", topic, namespace)"	"<line13> logger.error(""find partition group leader broker exception, topic: {}, namespace: {}"", topic, namespace)"
task5	<line24>      LOGGER.debug(e.getMessage(), e);	<line24>	"LOG.debug(""Error while printing node: "" + e.getMessage())"	"<line24> LOG.debug(""Error while printing node: "" + e.getMessage())"
task5	<line5>    log.info(message);	<line5>	log.info(XmlHelper.formatXML(message))	<line5> log.info(XmlHelper.formatXML(message))
task5	"<line11>        LOG.error(""Unknown column "" + columnIndex);"	<line11>	"LOGGER.error(""Unknown column "" + columnIndex)"	"<line11> LOGGER.error(""Unknown column "" + columnIndex)"
task5	"<line3>      logger.debug(""Successfully connected to "" + context.getDescription());"	<line3>	"logger.debug(""Connection successful: "" + context.getDescription())"	"<line3> logger.debug(""Connection successful: "" + context.getDescription())"
task5	"<line6>      LOGGER.info(""test role doesn't exist, but it's ok"");"	<line6>	"LOGGER.info(""Failed to drop role "" + roleName + "" due to "" + ex.getMessage())"	"<line6> LOGGER.info(""Failed to drop role "" + roleName + "" due to "" + ex.getMessage())"
task5	"<line13>        log.error(""Unable to iterate on HDFS directories "" + e.getMessage());"	<line13>	"logger.error(""Error while applying policy for individual intermediate path: "" + allKyloIntermediatePath[pathCounter],e)"	"<line13> logger.error(""Error while applying policy for individual intermediate path: "" + allKyloIntermediatePath[pathCounter],e)"
task5	"<line17>      logger.error(""error tagging efs - > "" + resourceId, ase);"	<line17>	"logger.error(""error tagging resource"", ase)"	"<line17> logger.error(""error tagging resource"", ase)"
task5	<line2>    log.trace(XTCE_SEQUENCE_CONTAINER);	<line2>	log.trace(XTCE_SEQUENCE_CONTAINER)	<line2> log.trace(XTCE_SEQUENCE_CONTAINER)
task5	"<line13>      log.debug(String.format(""Use default network interface to bind %s"", address));"	<line13>	"log.debug(""createSocket(InetAddress, int, InetAddress, int) - IPv4 only"")"	"<line13> log.debug(""createSocket(InetAddress, int, InetAddress, int) - IPv4 only"")"
task5	<line5>        LOGGER.error(t.toString(), t);	<line5>	"logger.error(""Error while invoking listener "" + listener, t)"	"<line5> logger.error(""Error while invoking listener "" + listener, t)"
task5	"<line5>      LOG.info(""Creating new pool for "" + builder.getName());"	<line4>	"log.debug(""Getting pool for builder: "" + builder)"	"<line4> log.debug(""Getting pool for builder: "" + builder)"
task5	"<line13>      LOGGER.error("""", exc);"	<line13>	"LOG.error("""", exc)"	"<line13> LOG.error("""", exc)"
task5	"<line33>              LOG.warn(""Failed to delete temp file[%s]"", zippedFile);"	<line33>	"log.warn(""Failed to delete segment file at [%s]"", zippedFile)"	"<line33> log.warn(""Failed to delete segment file at [%s]"", zippedFile)"
task5	"<line5>    log.info(""Extracting "" + fileName + "" to "" + target);"	<line5>	"log.info(""Extracting file "" + fileName + "" to "" + target)"	"<line5> log.info(""Extracting file "" + fileName + "" to "" + target)"
task5	"<line3>    log.trace("">> addOrder() bidOrder={}"", order);"	<line4>	"LOG.trace(""Added bid order {}"", order)"	"<line4> LOG.trace(""Added bid order {}"", order)"
task5	"<line18>          logger.warn(String.format(""unhandled exception happened when calling %s"", task.getClass().getName()),t);"	<line18>	logger.error(t.getMessage(), t)	<line18> logger.error(t.getMessage(), t)
task5	"<line10>        LOG.info(""asyn call time "" + c);"	<line10>	"LOG.info(""Test case: "" + c)"	"<line10> LOG.info(""Test case: "" + c)"
task5	"<line6>      logger.debug(""Got response string from player: "" + getId());"	<line2>	"log.info(""Setting response string to {}"", responseString)"	"<line2> log.info(""Setting response string to {}"", responseString)"
task5	"<line1>    logger.debug(""Searching index using series query '{}'"", query);"	<line11>	"logger.error(""Failed to unmarshall series metadata"", e)"	"<line11> logger.error(""Failed to unmarshall series metadata"", e)"
task5	"<line16>      LOG.info(""BOLT ack TASK: {} TIME: {} TUPLE: {}"", taskId, delta, input);"	<line16>	"LOG.info(""Bolt acked tuple with time delta: {}"", delta)"	"<line16> LOG.info(""Bolt acked tuple with time delta: {}"", delta)"
task5	"<line17>        log.info(this,""HttpServiceComponent[""+ this.cName+ ""] for feature[""+ this.feature+ ""] started SUCCESS: port=""+ this.port);"	<line17>	"log.info(this,""HttpServiceComponent["" + this.cName + ""] for feature["" + this.feature + ""] starts OK."")"	"<line17> log.info(this,""HttpServiceComponent["" + this.cName + ""] for feature["" + this.feature + ""] starts OK."")"
task5	"<line7>        LOG.warn(""Failed to do initial update, will retry in [{}]ms, error: "",new Object[] {retryWaitMillisec, ex.getMessage(), ex});"	<line6>	"LOGGER.error(""Exception occurred during update."", ex)"	"<line6> LOGGER.error(""Exception occurred during update."", ex)"
task5	"<line3>      LOGGER.debug(""Get last commit which are given to a param map with {} elements"", param.size());"	<line14>	"LOGGER.debug(""No Result found"", ex)"	"<line14> LOGGER.debug(""No Result found"", ex)"
task5	"<line7>              LOGGER.info(""Create dir {} in hdfs"", dir);"	<line7>	"LOG.info(""Created directory "" + dir)"	"<line7> LOG.info(""Created directory "" + dir)"
task5	<line10>      LOG.info(detail.getEndpointUri());	<line10>	LOG.info(detail.getEndpointUri())	<line10> LOG.info(detail.getEndpointUri())
task5	"<line1>    log.trace(""permissionDenied"");"	<line1>	"log.debug(""Permission denied for the session: {}"", session)"	"<line1> log.debug(""Permission denied for the session: {}"", session)"
task5	"<line2>    logger.debug(""Edit tools"");"	<line4>	"logger.error(""User cancelled dialog"")"	"<line4> logger.error(""User cancelled dialog"")"
task5	<line28>      log.error(systemException, systemException);	<line28>	log.error(systemException, systemException)	<line28> log.error(systemException, systemException)
task5	"<line2>      LOG.info(""Attaching Jira {} with snapshot"", basicIssue.getKey());"	<line2>	"LOGGER.info(""Adding snapshot to {}"", basicIssue.getKey())"	"<line2> LOGGER.info(""Adding snapshot to {}"", basicIssue.getKey())"
task5	"<line33>      logger.error(""StudyController - deleteComprehensionTestQuestion - ERROR"", e);"	<line33>	"logger.error(""StudyController - deleteComprehensionTestQuestion() - Error"", e)"	"<line33> logger.error(""StudyController - deleteComprehensionTestQuestion() - Error"", e)"
task5	"<line10>      LOG.info(""Found plugin: {}"", plugin.getDescriptor().getPluginId());"	<line4>	"log.info(""Started plugins: "" + getStartedPlugins())"	"<line4> log.info(""Started plugins: "" + getStartedPlugins())"
task5	"<line3>      LOGGER.info(""setLight() successful for device : {}"", deviceResponse.getDeviceIdentification());"	<line3>	"logger.debug(""set light request sent to device accepted"")"	"<line3> logger.debug(""set light request sent to device accepted"")"
task5	"<line25>      LOG.debug(""acceptReducedValues: Accepted one set with "" + numReducers + "" aggregated values"");"	<line25>	"LOG.debug(""Master received "" + numReducers + "" reduced values"")"	"<line25> LOG.debug(""Master received "" + numReducers + "" reduced values"")"
task5	"<line6>        log.debug(""Failed to getMatching."");"	<line6>	"log.debug(""Failed to get matching elements using no wait"", ex)"	"<line6> log.debug(""Failed to get matching elements using no wait"", ex)"
task5	"<line2>    LOG.debug(""Stop counting..."");"	<line1>	"logger.info(""Stop counting"")"	"<line1> logger.info(""Stop counting"")"
task5	"<line1>    LOGGER.info(""Bind handler {} into jetty server {}:{}"",handler.getClass().getSimpleName(),jettyServerConfig.getHost(),jettyServerConfig.getPort());"	<line4>	"LOG.info(""Added handler {}"", handler)"	"<line4> LOG.info(""Added handler {}"", handler)"
task5	"<line19>    log.debug(""Number of components:""+ server.getStorageManager().getJournalSequentialFileFactory().getCriticalAnalyzer().getNumberOfComponents());"	<line19>	"log.info(""number of components in journal: "" + server.getStorageManager().getJournalSequentialFileFactory().getCriticalAnalyzer().getNumberOfComponents())"	"<line19> log.info(""number of components in journal: "" + server.getStorageManager().getJournalSequentialFileFactory().getCriticalAnalyzer().getNumberOfComponents())"
task5	"<line2>      log.info(""dimensions bad in dot()"");"	<line2>	"log.error(""dimensions bad in dot product"")"	"<line2> log.error(""dimensions bad in dot product"")"
task5	"<line7>      log.trace(""AncestorQueryIterator init()"");"	<line7>	"log.trace(""Initialising FetcherIterator"")"	"<line7> log.trace(""Initialising FetcherIterator"")"
task5	"<line5>      LOG.error(""Unable to cleanup access tracker"", e);"	<line5>	"LOG.error(""Error closing lookup"", e)"	"<line5> LOG.error(""Error closing lookup"", e)"
task5	"<line4>      LOG.info(""Unregistering webhook for endpoint: {}"", delegateEndpoint);"	<line4>	"LOG.info(""Unregistering webhook for endpoint: {}"", delegateEndpoint)"	"<line4> LOG.info(""Unregistering webhook for endpoint: {}"", delegateEndpoint)"
task5	"<line14>      LOG.error(""Insert obervations thread was interrupted!"", e);"	<line14>	"LOGGER.error(""Error while waiting for thread pool to shut down"", e)"	"<line14> LOGGER.error(""Error while waiting for thread pool to shut down"", e)"
task5	"<line8>      LOG.error(""There was an error in Git {} operation"", operation);"	<line8>	"LOG.error(""There was an error in Git {} operation"", operation)"	"<line8> LOG.error(""There was an error in Git {} operation"", operation)"
task5	<line6>        log.debug(invalidFileVersionException, invalidFileVersionException);	<line6>	log.debug(invalidFileVersionException, invalidFileVersionException)	<line6> log.debug(invalidFileVersionException, invalidFileVersionException)
task5	"<line9>    log.warn(String.format(""Unexpected value type for serialized key %s"", key));"	<line9>	"log.warn(String.format(""Unexpected value type for serialized key %s"", key))"	"<line9> log.warn(String.format(""Unexpected value type for serialized key %s"", key))"
task5	"<line14>        log.error(""Cannot set autoCommit=true"", e);"	<line14>	"log.warn(""Cannot set connection to autocommit"", e)"	"<line14> log.warn(""Cannot set connection to autocommit"", e)"
task5	"<line8>    LOG.trace(""resolveArtifacts({}) returns {}"", coords, result);"	<line1>	"log.debug(""Resolving artifacts: "" + coords)"	"<line1> log.debug(""Resolving artifacts: "" + coords)"
task5	"<line9>      logger.warn(""Exception loading public key from PEM"", e);"	<line9>	"logger.warn(""Exception loading public key from PEM "", e)"	"<line9> logger.warn(""Exception loading public key from PEM "", e)"
task5	"<line8>    log.info(""setCredential {} status for {} to {}"", credential, entityId, status);"	<line8>	"log.info(""Setting credential {} status of {} to {}"", credential, entityId, status)"	"<line8> log.info(""Setting credential {} status of {} to {}"", credential, entityId, status)"
task5	"<line5>    LOGGER.info(""WFS GetFeature&typename=gsml:MappedFeature response:\n"" + prettyString(doc));"	<line5>	"LOGGER.info(""WFS GetFeature, typename=gsml:MappedFeature response:\n"" + prettyString(doc))"	"<line5> LOGGER.info(""WFS GetFeature, typename=gsml:MappedFeature response:\n"" + prettyString(doc))"
task5	"<line1>    LOG.info(""Setting up HTTP connector for web server"");"	<line4>	"LOG.info(""Listening on port {} for HTTP requests"", httpConnector.getLocalPort())"	"<line4> LOG.info(""Listening on port {} for HTTP requests"", httpConnector.getLocalPort())"
task5	"<line2>    LOG.debug(""List status of {}"", f.toString());"	<line2>	"LOG.debug(""listStatus({})"", f)"	"<line2> LOG.debug(""listStatus({})"", f)"
task5	"<line55>      LOGGER.warn(""You can use @Route#order() to ensure the routes are not executed in random order"");"	<line55>	"LOGGER.warn(""Conflicting routes detected!"")"	"<line55> LOGGER.warn(""Conflicting routes detected!"")"
task5	"<line2>    logger.debug(""Checking if the atom container set empty: "", atomContainerCount == 0);"	<line2>	"logger.debug(""Is empty: "", atomContainerCount == 0)"	"<line2> logger.debug(""Is empty: "", atomContainerCount == 0)"
task5	"<line12>            logger.debug(""{} is a {} which is not interruptable as the thread running the session has not ""+ ""been set - please check the implementation if this is not desirable"",sessionId,this.getClass().getSimpleName());"	<line12>	"LOG.warn(""Unable to interrupt session thread {}"", sessionThread)"	"<line12> LOG.warn(""Unable to interrupt session thread {}"", sessionThread)"
task5	"<line2>    LOG.info(""Twilight plugin stopped "");"	<line2>	"LOG.debug(""SamplingProfiler {} : Stopped"", identifier)"	"<line2> LOG.debug(""SamplingProfiler {} : Stopped"", identifier)"
task5	"<line6>    log.info(""Executing command: "" + command);"	<line13>	"logger.debug(""Testing for the existence of this log message is part of the test"")"	"<line13> logger.debug(""Testing for the existence of this log message is part of the test"")"
task5	"<line7>      LOG.error(""While deleting {}"", model.getObject().getKey(), e);"	<line7>	"LOG.error(""While deleting remediation"", e)"	"<line7> LOG.error(""While deleting remediation"", e)"
task5	"<line12>    log.info(""About to run: {}"", jobName);"	<line12>	"log.info(""Running job: {}"", jobName)"	"<line12> log.info(""Running job: {}"", jobName)"
task5	"<line16>        log.error(""fieldType {} is illegal."", fieldType.toString());"	<line16>	"LOG.warn(""Type {} not supported for field {}, skipping."", fieldType, fieldName)"	"<line16> LOG.warn(""Type {} not supported for field {}, skipping."", fieldType, fieldName)"
task5	"<line3>      Log.trace(""Session {} Request ID {}, event complete: {}"", streamID, rid, asyncEvent);"	<line3>	"Log.trace(""onComplete {}"", asyncContext)"	"<line3> Log.trace(""onComplete {}"", asyncContext)"
task5	<line1>    Log.info(string);	<line1>	logger.info(string)	<line1> logger.info(string)
task5	"<line11>        logger.warn(""Slow request: {} {} ({}ms)"", req.getMethod(), getFullUrl(req), elapsedMS);"	<line11>	"LOG.warn(""Request took {} ms"", elapsedMS)"	"<line11> LOG.warn(""Request took {} ms"", elapsedMS)"
task5	<line34>      log.error(systemException, systemException);	<line34>	log.error(systemException, systemException)	<line34> log.error(systemException, systemException)
task5	"<line28>      LOGGER.debug(""Invalid spatial query type specified.  Will not apply spatial filter."");"	<line28>	"LOGGER.debug(""Could not add spatial filter"")"	"<line28> LOGGER.debug(""Could not add spatial filter"")"
task5	"<line8>      log.error(""Unable to get asset entries"", exception);"	<line8>	log.error(exception, exception)	<line8> log.error(exception, exception)
task5	"<line8>      LOGGER.warn(""Could not load class"", e);"	<line8>	"LOGGER.warn(""Error while initializing logical struct map type provider"", e)"	"<line8> LOGGER.warn(""Error while initializing logical struct map type provider"", e)"
task5	"<line2>    log.debug(""append [{}]"", path);"	<line2>	"logger.debug(""append({})"", path)"	"<line2> logger.debug(""append({})"", path)"
task5	"<line5>      LOGGER.error(""appendMessageLog schedule log error,log:{} {},code:{}"",event.getSubject(),event.getMessageId(),code);"	<line5>	"LOGGER.error(""appendScheduleLogError"", result.getAdditional())"	"<line5> LOGGER.error(""appendScheduleLogError"", result.getAdditional())"
task5	"<line17>        log.error(""Can't watch env.properties file for changes"", e);"	<line17>	"LOGGER.error(""Cannot watch for file changes in the configuration directory"", e)"	"<line17> LOGGER.error(""Cannot watch for file changes in the configuration directory"", e)"
task5	"<line10>            log.info(""Re-indexing of ""+ size+ "" objects done after updating ""+ obj.getClass().getName()+ "":""+ obj.getId());"	<line10>	"log.info(""Reindexed {} dependents of object {}"", size, obj)"	"<line10> log.info(""Reindexed {} dependents of object {}"", size, obj)"
task5	"<line4>      log.error(""Error in printing AST."", e);"	<line4>	"log.error(""Could not print AST"", e)"	"<line4> log.error(""Could not print AST"", e)"
task5	"<line4>    LOGGER.info(""Time range between : "" + startTime + "" and "" + endTime);"	<line12>	"LOGGER.info(""Cluster Name: "" + clusterName)"	"<line12> LOGGER.info(""Cluster Name: "" + clusterName)"
task5	"<line8>      logger.info(""ElasticsearchPlugin config:{}"", elasticsearchPluginConfig);"	<line8>	"logger.info(""ElasticsearchPlugin config:{}"", elasticsearchPluginConfig)"	"<line8> logger.info(""ElasticsearchPlugin config:{}"", elasticsearchPluginConfig)"
task5	"<line13>          LOGGER.error(""Number of IO operations cannot be negative for dataset: "" + this);"	<line13>	"LOGGER.error(""waitForIO: negative numActiveIOOps="" + numActiveIOOps)"	"<line13> LOGGER.error(""waitForIO: negative numActiveIOOps="" + numActiveIOOps)"
task5	"<line31>      log.warn(""[{}] Failed to fetch device state data"", device.getId(), e);"	<line31>	"log.warn(""Can't parse device state: {}"", data, e)"	"<line31> log.warn(""Can't parse device state: {}"", data, e)"
task5	"<line9>      logger.info(""creating schema '{}'"", schemaName);"	<line9>	"LOGGER.debug(""Adding create schema statement for "" + schemaName)"	"<line9> LOGGER.debug(""Adding create schema statement for "" + schemaName)"
task5	"<line4>    log.debug(""{}"", t);"	<line41>	"LOG.info(""i: "" + i)"	"<line41> LOG.info(""i: "" + i)"
task5	"<line3>      LOGGER.info(""RTree "" + getTestOpName() + "" Test With Two Dimensions With Integer Keys."");"	<line3>	"LOGGER.info(""TESTING RTREE WITH 2 DIFFERENT INT FIELDS"")"	"<line3> LOGGER.info(""TESTING RTREE WITH 2 DIFFERENT INT FIELDS"")"
task5	"<line4>      LOGGER.warn(""could not close ZooKeeper client due to interrupt"", e);"	<line4>	"LOG.error(""Failed to close ZooKeeper connection"", e)"	"<line4> LOG.error(""Failed to close ZooKeeper connection"", e)"
task5	"<line5>    LOG.trace(""routine: {}.{} "", schemaName, routineName);"	<line5>	"LOG.info(""ROUTINE: {} {} {} {}"",schemaName,routineName,language,callingConvention.name())"	"<line5> LOG.info(""ROUTINE: {} {} {} {}"",schemaName,routineName,language,callingConvention.name())"
task5	"<line2>    LOG.info(""Adding ESB job factory for job "" + name + ""."");"	<line2>	"LOG.info(""Adding ESB job factory: "" + name)"	"<line2> LOG.info(""Adding ESB job factory: "" + name)"
task5	"<line15>        logger.error(""Error during HBase clean up"", e);"	<line15>	"logger.error(""error while trying to clean up hbase tables"", e)"	"<line15> logger.error(""error while trying to clean up hbase tables"", e)"
task5	"<line2>    log.debug(""getModuleTypes()"");"	<line2>	"logger.debug(""getModuleTypes()"")"	"<line2> logger.debug(""getModuleTypes()"")"
task5	"<line19>      logger.debug(""No bridge connected or selected. Cannot set sensor state."");"	<line19>	"logger.debug(""No bridge connected or selected. Cannot set sensor state."")"	"<line19> logger.debug(""No bridge connected or selected. Cannot set sensor state."")"
task5	"<line7>        LOGGER.trace(StringUtilities.formatTimingMessage(""Time to paint layer "" + layer.getClass().getSimpleName() + "": "",System.nanoTime() - t0));"	<line7>	"LOGGER.trace(StringUtilities.formatTimingMessage(""Time to paint layer: "", layer.getLayerName(), System.nanoTime() - t0))"	"<line7> LOGGER.trace(StringUtilities.formatTimingMessage(""Time to paint layer: "", layer.getLayerName(), System.nanoTime() - t0))"
task5	"<line6>        log.warn(""The JDBC driver does not appear to support ResultSet.absolute(). Consider""+ "" reverting to the default behavior setting the driverSupportsAbsolute to false"",e);"	<line6>	"log.warn(""Cursor does not support absolute movement, falling back to relative movement"")"	"<line6> log.warn(""Cursor does not support absolute movement, falling back to relative movement"")"
task5	"<line1>    LOG.error(""Exception calling mesos ({} so far)"", failedMesosCalls.incrementAndGet(), t);"	<line2>	"log.debug(""Checking for reconnect"", t)"	"<line2> log.debug(""Checking for reconnect"", t)"
task5	<line5>        LOGGER.error(e);	<line5>	log.error(e)	<line5> log.error(e)
task5	"<line4>      log.warn(""moveEyelids - I have a null head"");"	<line4>	"Logger.error(this, ""I have a null head, so cannot move eyelids"")"	"<line4> Logger.error(this, ""I have a null head, so cannot move eyelids"")"
task5	"<line14>      LOGGER.error(""DashboardMetaDataDao - getStatisticsType() :: ERROR"", e);"	<line14>	"LOGGER.error(""DashboardMetaDataDao - getStatisticsType() :: ERROR"", e)"	"<line14> LOGGER.error(""DashboardMetaDataDao - getStatisticsType() :: ERROR"", e)"
task5	"<line3>    logger.info(""Testing: "" + filename);"	<line3>	"logger.info(""Testing: "" + filename)"	"<line3> logger.info(""Testing: "" + filename)"
task5	"<line5>      log.warn(""Error loading {}, possibly jar was not compiled with maven."", GIT_PROPS, e);"	<line5>	"log.warn(""Unable to load git.properties from "" + loc, e)"	"<line5> log.warn(""Unable to load git.properties from "" + loc, e)"
task5	"<line5>      logger.error(""[getAlertSystemRecovertIME]"", e);"	<line5>	"logger.error(""[getAlertSystemRecoverTime]"", e)"	"<line5> logger.error(""[getAlertSystemRecoverTime]"", e)"
task5	"<line2>    log.info(""Creating k8s namespace: {}"", testNamespace);"	<line1>	"LOG.info(""Setting up Kubernetes"")"	"<line1> LOG.info(""Setting up Kubernetes"")"
task5	<line9>      log.error(e);	<line9>	log.error(e, e)	<line9> log.error(e, e)
task5	"<line2>    LOGGER.debug(""Salt: "" + ArrayConverter.bytesToHexString(msg.getSalt()));"	<line2>	"LOGGER.debug(""Salt: "" + ArrayConverter.bytesToHexString(msg.getSalt().getValue()))"	"<line2> LOGGER.debug(""Salt: "" + ArrayConverter.bytesToHexString(msg.getSalt().getValue()))"
task5	"<line6>      log.warn(""Could not find session for writable event,maybe it is closed"");"	<line6>	"LOG.warn(""Write event but no session found for key {}"", key)"	"<line6> LOG.warn(""Write event but no session found for key {}"", key)"
task5	"<line1>    logger.info(""Daten Schreiben nach: {}"", xmlFilePath.toString());"	<line1>	"log.info(""writing configuration file {}"", xmlFilePath)"	"<line1> log.info(""writing configuration file {}"", xmlFilePath)"
task5	"<line3>      log.warn(""Adding domain when one already exists"");"	<line3>	"LOGGER.warn(""Domain already exists: {}"", domainId)"	"<line3> LOGGER.warn(""Domain already exists: {}"", domainId)"
task5	<line12>    LOGGER.debug(jsonText);	<line12>	LOGGER.info(jsonText)	<line12> LOGGER.info(jsonText)
task5	"<line9>      logger.error(""ERROR: AppUtil - httpResponseForInternalServerError()"", e);"	<line9>	"logger.error(""AppUtil - httpResponseForInternalServerError() :: ERROR"", e)"	"<line9> logger.error(""AppUtil - httpResponseForInternalServerError() :: ERROR"", e)"
task5	"<line14>      logger.warn("""", fex);"	<line14>	"logger.warn("""", fex)"	"<line14> logger.warn("""", fex)"
task5	"<line4>      LOGGER.debug(""unable to convert WKT to a Geometry object: wkt={}"", wkt, e);"	<line4>	"LOGGER.info(""Could not parse WKT: {}"", e.getMessage())"	"<line4> LOGGER.info(""Could not parse WKT: {}"", e.getMessage())"
task5	"<line6>    LOG.debug(""Remove task manager {}."", instanceId);"	<line9>	"log.info(""Removed task manager registration for {}. Total registered slots are {}."",instanceId,totalRegisteredResource)"	"<line9> log.info(""Removed task manager registration for {}. Total registered slots are {}."",instanceId,totalRegisteredResource)"
task5	"<line10>      logger.info(""Hook unregistered: {}"", hookId);"	<line9>	"logger.info(""Unbound hook: {}"", hookId)"	"<line9> logger.info(""Unbound hook: {}"", hookId)"
task5	"<line3>    logger.debug(""This is a test of the root logger"");"	<line3>	"logger.info(""This is a test of the properties feature"")"	"<line3> logger.info(""This is a test of the properties feature"")"
task5	<line4>      LOGGER.error(e.getMessage(), e);	<line2>	"LOGGER.info(""Getting replication connection URI"")"	"<line2> LOGGER.info(""Getting replication connection URI"")"
task5	<line9>      log.error(exception, exception);	<line9>	log.error(exception, exception)	<line9> log.error(exception, exception)
task5	"<line3>      LOG.warn(""RangerDefaultPolicyResourceMatcher is already initialized. init() must be done again""+ "" after updating serviceDef"");"	<line3>	"LOG.warn(""RangerDefaultService.setServiceDef: already initialized"")"	"<line3> LOG.warn(""RangerDefaultService.setServiceDef: already initialized"")"
task5	"<line28>      logger.error(""Error creating user filter"", t);"	<line28>	"logger.error(""Error creating user filter"", t)"	"<line28> logger.error(""Error creating user filter"", t)"
task5	"<line3>      logger.warn(String.format(""delete image [%s] failed after management node restarted"", msg.getResourceUuid()));"	<line3>	"logger.warn(String.format(""Failed to start management server[uuid:%s, ip:%s]"",Platform.getManagementServerId(),Platform.getManagementServerIp()))"	"<line3> logger.warn(String.format(""Failed to start management server[uuid:%s, ip:%s]"",Platform.getManagementServerId(),Platform.getManagementServerIp()))"
task5	"<line5>        log.debug(""missing time {} in [{}] --> {}"", timeField.getField(), bundle.getCount(), bundle);"	<line5>	"log.warn(""Bundle has no time field!  Using current time."")"	"<line5> log.warn(""Bundle has no time field!  Using current time."")"
task5	"<line3>      logger.trace(""xasuspend on "" + this.tx);"	<line3>	"logger.trace(""xaSuspend"")"	"<line3> logger.trace(""xaSuspend"")"
task5	"<line3>      LOGGER.warn(""preventing access to {}"", repo);"	<line3>	"LOG.debug(""Access prevention: user {} does not have propagate permission on repo {}"",user.getUserId(),repo)"	"<line3> LOG.debug(""Access prevention: user {} does not have propagate permission on repo {}"",user.getUserId(),repo)"
task5	"<line8>        log.info(""failed to parse heat parameters "");"	<line11>	"log.debug(""Failed to extract heat parameters from artifact with name {} and type {}"",artifactInfo.getArtifactName(),artifactInfo.getArtifactType())"	"<line11> log.debug(""Failed to extract heat parameters from artifact with name {} and type {}"",artifactInfo.getArtifactName(),artifactInfo.getArtifactType())"
task5	<line31>              logger.warn(reply.getError().getDetails());	<line37>	"logger.warn(String.format(""failed to create template from root volume[uuid:%s] on primary storage[uuid:%s]"",msg.getRootVolumeInventory().getUuid(),msg.getRootVolumeInventory().getPrimaryStorageUuid()))"	"<line37> logger.warn(String.format(""failed to create template from root volume[uuid:%s] on primary storage[uuid:%s]"",msg.getRootVolumeInventory().getUuid(),msg.getRootVolumeInventory().getPrimaryStorageUuid()))"
task5	<line16>                LOG.info(null, getUpdateNotification(config));	<line16>	"LOG.info(""BetonQuest is up-to-date!"")"	"<line16> LOG.info(""BetonQuest is up-to-date!"")"
task5	"<line7>        logger.info(""Updated digest file to "" + digest);"	<line7>	"logger.info(""Wrote digest file: "" + digestFile.getAbsolutePath())"	"<line7> logger.info(""Wrote digest file: "" + digestFile.getAbsolutePath())"
task5	"<line6>            logger.info(""processing message: "" + message);"	<line6>	"logger.info(""processing message: "" + message)"	"<line6> logger.info(""processing message: "" + message)"
task5	"<line5>      log.info(""Test eternalPolicy, key: "" + key);"	<line2>	"log.info(""Start testNullFactory"")"	"<line2> log.info(""Start testNullFactory"")"
task5	"<line30>    logger.trace(""ThingAction 'sendMessageToDevice' called with value(s): device='{}', message='{}',""+ "" title='{}'"",device,message,title);"	<line33>	"logger.trace(""ThingAction 'sendMessageToDevice' called with value(s): device='{}', message='{}', title='{}'"",device,message,title)"	"<line33> logger.trace(""ThingAction 'sendMessageToDevice' called with value(s): device='{}', message='{}', title='{}'"",device,message,title)"
task5	"<line36>      LOG.info(""patch skipped: typeName={}; applyToVersion={}; updateToVersion={}"",patch.getTypeName(),patch.getApplyToVersion(),patch.getUpdateToVersion());"	<line38>	"LOG.info(""patch: {}"", getPatchLog(patch))"	"<line38> LOG.info(""patch: {}"", getPatchLog(patch))"
task5	"<line13>    LOGGER.info(""JSON content\n{}"", specContent);"	<line13>	logger.debug(specContent)	<line13> logger.debug(specContent)
task5	"<line6>        LOGGER.warn(MessageFormat.format(""Could not parse date string: \""{0}\"""", dateString), e);"	<line6>	"LOGGER.warn(""Could not parse date {}"", dateString, e)"	"<line6> LOGGER.warn(""Could not parse date {}"", dateString, e)"
task5	"<line8>      log.debug(""Failed to get the component with id {} for component instance {} creation. "",componentInstance.getComponentUid(),componentInstance.getName());"	<line11>	"log.debug(""Failed to fetch component with uid {} for container component instance creation"",componentInstance.getComponentUid(),actionStatus)"	"<line11> log.debug(""Failed to fetch component with uid {} for container component instance creation"",componentInstance.getComponentUid(),actionStatus)"
task5	"<line10>      LOG.error(""While changing password for {}"",SyncopeEnduserSession.get().getSelfTO().getUsername(),e);"	<line10>	"LOG.error(""While changing password"", e)"	"<line10> LOG.error(""While changing password"", e)"
task5	"<line3>      log.debug(""Calling ConnectionsActionSetService"");"	<line3>	"log.debug(""Calling ConnectionsActionSetService"")"	"<line3> log.debug(""Calling ConnectionsActionSetService"")"
task5	"<line4>      logger.trace(""fromOid("" + internalId + "")"");"	<line4>	"logger.trace(""fromOid {}"", internalId)"	"<line4> logger.trace(""fromOid {}"", internalId)"
task5	"<line15>      log.warn(""Bind failed for dn '{}'"", dn, e);"	<line1>	"logger.debug(""LDAP authentication for user {}"", dn)"	"<line1> logger.debug(""LDAP authentication for user {}"", dn)"
task5	"<line31>      logger.info(""Error generating narrative"", e);"	<line31>	"log.warn(""Exception caught while generating narrative for measure: "" + theResource.getId(), e)"	"<line31> log.warn(""Exception caught while generating narrative for measure: "" + theResource.getId(), e)"
task5	"<line3>      logger.debug(""SBMLReader.readMathML called"");"	<line3>	"logger.debug(""Reading mathML:\n"" + mathML)"	"<line3> logger.debug(""Reading mathML:\n"" + mathML)"
task5	"<line7>      log.debug(""saveProgramAccess:"" + pa.getId());"	<line7>	"log.debug(""saveProgramAccess: "" + pa.getProgramId())"	"<line7> log.debug(""saveProgramAccess: "" + pa.getProgramId())"
task5	"<line1>    LOG.debug(""setting max tuples to {}"", maxNumbers);"	<line1>	"logger.debug(""Setting maxTuples to: {}"", maxNumbers)"	"<line1> logger.debug(""Setting maxTuples to: {}"", maxNumbers)"
task5	"<line1>    logger.info(""In postCommit with: ["" + arg0 + ""]"");"	<line1>	"logger.debug(""in postCommit"")"	"<line1> logger.debug(""in postCommit"")"
task5	<line22>          log.warn(invalidDDMStructureException.getMessage());	<line22>	log.warn(invalidDDMStructureException, invalidDDMStructureException)	<line22> log.warn(invalidDDMStructureException, invalidDDMStructureException)
task5	"<line12>      logger.error(""error in extractCategoryFormValues"", t);"	<line12>	"logger.error(""error in extractCategoryFormValues"", t)"	"<line12> logger.error(""error in extractCategoryFormValues"", t)"
task5	"<line21>        LOG.error(""Not able to instantiate pruning debug class"", e);"	<line21>	"LOG.error(""Cannot instantiate the pruning debug tool: "", e)"	"<line21> LOG.error(""Cannot instantiate the pruning debug tool: "", e)"
task5	"<line3>      LOG.debug(""Ending workitem at key "" + immutableBytesToString(currentRangeStartKey) + "" ."");"	<line9>	"LOG.debug(""startKey: {}, currentRangeStartKey: {}, hash: {}"",startKey,currentRangeStartKey,hash)"	"<line9> LOG.debug(""startKey: {}, currentRangeStartKey: {}, hash: {}"",startKey,currentRangeStartKey,hash)"
task5	"<line2>    log.debug(""Removing AuthenticatioKey with keyId {}"", keyId);"	<line2>	"log.debug(""Removing key {}"", keyId)"	"<line2> log.debug(""Removing key {}"", keyId)"
task5	"<line2>    LOGGER.trace(MessageFormat.format(""Updating ActionDesignTrace {0}."", actionDesignTrace.getMetadataKey().toString()));"	<line2>	"LOGGER.trace(MessageFormat.format(""Updating ActionDesignTrace {0}."", actionDesignTrace.toString()))"	"<line2> LOGGER.trace(MessageFormat.format(""Updating ActionDesignTrace {0}."", actionDesignTrace.toString()))"
task5	"<line13>            LOG.trace(""Check for trust status of class: {}"", clazz.getName());"	<line22>	"LOG.error(""Error: "" + ex)"	"<line22> LOG.error(""Error: "" + ex)"
task5	"<line2>    LOGGER.debug(""Finished sending ""+ (t.isFile() ? t.getFileName() : t.getObject())+ "" through connection ""+ c.hashCode());"	<line2>	"logger.debug(""Write Finished {} {}"", c, t)"	"<line2> logger.debug(""Write Finished {} {}"", c, t)"
task5	"<line12>      logger.error(""Error in buildGuiFragmentFromRes"", t);"	<line12>	"logger.error(""Error while building GuiFragment from res: {}"", res, t)"	"<line12> logger.error(""Error while building GuiFragment from res: {}"", res, t)"
task5	"<line25>        log.warn(""undefined property '""+ currentMimeTypePropName+ ""', no data will be dispatched to port '""+ portName+ ""'"");"	<line25>	"LOG.warn(""no mimeTypes defined for port '{}'!"", portName)"	"<line25> LOG.warn(""no mimeTypes defined for port '{}'!"", portName)"
task5	"<line9>    log.info(""Study with accession Id: {} found and updated"", accessionId);"	<line1>	"logger.info(""Updating study disease trait by accession id {} to {}"", accessionId, trait)"	"<line1> logger.info(""Updating study disease trait by accession id {} to {}"", accessionId, trait)"
task5	"<line4>    LOGGER.debug(""Starting "" + ActiveRequestSenderTest.testType.getName());"	<line3>	"logger.debug(""testSendProcessConfigurationRequest"")"	"<line3> logger.debug(""testSendProcessConfigurationRequest"")"
task5	"<line3>    log.info(""Creating Kafka Streams, store name: {}"", storeName);"	<line29>	"log.info(""Starting KafkaStreams pipeline"")"	"<line29> log.info(""Starting KafkaStreams pipeline"")"
task5	"<line7>        log.info(""Double-clicked on: {} Toggling filter enabled."", o);"	<line2>	"log.info(""mouseClicked {}"", mouseEvent)"	"<line2> log.info(""mouseClicked {}"", mouseEvent)"
task5	"<line23>      logger.info(""New cube "" + cubeName + "" has "" + cuboidCount + "" cuboids"");"	<line23>	"logger.info(""It is going to create "" + cuboidCount + "" cuboids in total"")"	"<line23> logger.info(""It is going to create "" + cuboidCount + "" cuboids in total"")"
task5	"<line18>      log.trace(""calculated network delay for module {} in solution {} is (numVisitsModule[i] *""+ "" sumOfDelaysSingleModule): {}"",i,bestSol.toString(),numVisitsModule[i] * sumOfDelaysSingleModule);"	<line20>	"LOGGER.debug(""Network delay: "" + networkDelay)"	"<line20> LOGGER.debug(""Network delay: "" + networkDelay)"
task5	"<line2>    logger.debug(testName + "": status = "" + statusCode);"	<line2>	"LOG.debug(testName + "": status = "" + statusCode)"	"<line2> LOG.debug(testName + "": status = "" + statusCode)"
task5	<line10>      log.error(e.getMessage(), e);	<line10>	"log.error(""Failed to create session ID cookie."", e)"	"<line10> log.error(""Failed to create session ID cookie."", e)"
task5	"<line2>    LOGGER.info(""Launching crawler for page "" + getUrl());"	<line2>	"logger.debug(""callCrawlerService"")"	"<line2> logger.debug(""callCrawlerService"")"
task5	<line30>      log.error(exception, exception);	<line30>	log.error(exception, exception)	<line30> log.error(exception, exception)
task5	"<line4>      logger.error(""Unable to instantiate converter of type {} for key {}"",new Object[] {constructor.getClass().getName(), dbName});"	<line4>	"logger.warn("""", t)"	"<line4> logger.warn("""", t)"
task5	"<line8>    log.debug(""createPageSource(transaction=%s, session=%s, split=%s, table=%s, columns=%s)"",transaction, session, split, table, columns);"	<line14>	"log.debug(""Creating page source for split %s"", split)"	"<line14> log.debug(""Creating page source for split %s"", split)"
task5	"<line14>      logger.error(""SQL Command failed: "" + sql.toString() + "":"" + e.getMessage());"	<line14>	"logger.error(""Could not execute one of the SQL commands: "" + sql.toString())"	"<line14> logger.error(""Could not execute one of the SQL commands: "" + sql.toString())"
task5	"<line5>      LOGGER.error(""Unexpected file visiting failure: "" + path, e);"	<line5>	"LOG.error(""Unexpected file visiting failure: "" + path, e)"	"<line5> LOG.error(""Unexpected file visiting failure: "" + path, e)"
task5	"<line10>      log.info(""Loaded model {} from location {}"", model.getId(), modelPath);"	<line10>	"log.info(""Deserialized model: "" + model)"	"<line10> log.info(""Deserialized model: "" + model)"
task5	"<line4>      LOG.warn(""oneside beforeDocumentChange - myChangedBlockData == null"");"	<line17>	"LOG.warn(""Couldn't find twoside line for oneside line ""+ line1+ "". Probably, this is a bug. Skipping this change."")"	"<line17> LOG.warn(""Couldn't find twoside line for oneside line ""+ line1+ "". Probably, this is a bug. Skipping this change."")"
task5	"<line7>      LOG.info(""Could not parse cleanup type from {} for {}"", statusMessage, taskId);"	<line7>	"LOG.warn(""Failed to find cleanup type in status message {}"", statusMessage)"	"<line7> LOG.warn(""Failed to find cleanup type in status message {}"", statusMessage)"
task5	"<line6>      log.warn(""Could not get method by reflection. This could happen if you are using @Parameters in""+ "" combination with annotations."",e);"	<line6>	"log.warn(""Could not find method "" + methodName + "" on test class "" + testClass.getCanonicalName())"	"<line6> log.warn(""Could not find method "" + methodName + "" on test class "" + testClass.getCanonicalName())"
task5	<line3>      log.warn(message);	<line3>	log.warn(message)	<line3> log.warn(message)
task5	"<line12>      log.error(""Exception happened while monitoring EntityId"", ex);"	<line12>	"log.error(""Exception happened while reloading application configuration"", ex)"	"<line12> log.error(""Exception happened while reloading application configuration"", ex)"
task5	<line24>    logger.debug(exception.getErrorMessage());	<line24>	logger.debug(exception.getErrorMessage())	<line24> logger.debug(exception.getErrorMessage())
task5	"<line2>      log.debug(""change max [active] semaphore with new permit {}"", maxActive);"	<line2>	"log.info(""Setting maxActive to %d"", maxActive)"	"<line2> log.info(""Setting maxActive to %d"", maxActive)"
task5	"<line4>    log.info(""Published an API {0}"", api);"	<line2>	"logger.info(""publishing api: {}"", api.getName())"	"<line2> logger.info(""publishing api: {}"", api.getName())"
task5	"<line7>        LOG.info(""Failure while notifying listener {}"", listener, x);"	<line1>	"if (LOG.isDebugEnabled()) LOG.debug(""Failure {} on {}"", frame, this)"	"<line1> if (LOG.isDebugEnabled()) LOG.debug(""Failure {} on {}"", frame, this)"
task5	"<line8>        LOG.warn(""The listenerContainer is not instantiated. Probably there was a timeout during the""+ "" Suspend operation. Please restart your consumer route."");"	<line8>	"LOG.warn(""Missing listener container to resume {}"", this)"	"<line8> LOG.warn(""Missing listener container to resume {}"", this)"
task5	"<line15>              logger.warn(""Error during doExceptionCaught service listener notifications:"", ex);"	<line15>	"logger.warn(""Error during doExceptionCaughtListeners()"", ex)"	"<line15> logger.warn(""Error during doExceptionCaughtListeners()"", ex)"
task5	"<line4>    logger.error(""{} {} An exception occured on {}: "",MessageEnum.RA_GENERAL_EXCEPTION_ARG,ErrorCode.DataError.getValue(),context,e);"	<line1>	"logger.error(""Runtime exception thrown"", e)"	"<line1> logger.error(""Runtime exception thrown"", e)"
task5	"<line2>      LOG.warn(""Notebook authorization module was called without initialization,""+ "" initializing with default configuration"");"	<line2>	"LOGGER.debug(""Notebook authorization manager created"")"	"<line2> LOGGER.debug(""Notebook authorization manager created"")"
task5	"<line8>      LOGGER.debug(""Error occurred while reconsructing the object, "" + ex.getMessage());"	<line8>	"LOGGER.error(""Cannot reconstruct object. Exiting now."", ex)"	"<line8> LOGGER.error(""Cannot reconstruct object. Exiting now."", ex)"
task5	"<line7>      logger.error(""Creating the nonProxyHosts pattern failed for http.nonProxyHosts="" + nonProxyHosts, e);"	<line7>	"logger.warn(""Invalid pattern for nonProxyHosts: "" + nonProxyHosts, e)"	"<line7> logger.warn(""Invalid pattern for nonProxyHosts: "" + nonProxyHosts, e)"
task5	"<line2>    logger.debug(""Listener: Disconnected from the ambient weather service)"");"	<line2>	"logger.info(""call {}"", args[0])"	"<line2> logger.info(""call {}"", args[0])"
task5	"<line6>        log.error(""Listener "" + listener + "" has thrown an exception"", ex);"	<line6>	"log.error(""Failed to notify expired event listener"", ex)"	"<line6> log.error(""Failed to notify expired event listener"", ex)"
task5	"<line12>      LOG.error(""error during save address: {}"", e.getLocalizedMessage(), e);"	<line12>	"LOG.error(""error during save-address: {}"", e.getLocalizedMessage(), e)"	"<line12> LOG.error(""error during save-address: {}"", e.getLocalizedMessage(), e)"
task5	<line11>      log.error(exception, exception);	<line11>	log.error(exception, exception)	<line11> log.error(exception, exception)
task5	"<line2>    this.logger.debug(""ActivityTestGPRSRequest"");"	<line2>	"this.logger.debug(""ActivityTestGPRSRequest"")"	"<line2> this.logger.debug(""ActivityTestGPRSRequest"")"
task5	"<line20>        logger.info(""{} bytes have been written."", written);"	<line20>	"logger.debug(""Written: {}"", written)"	"<line20> logger.debug(""Written: {}"", written)"
task5	"<line3>        LOG.warn(""Snapshot restore timed out, failed to restore snapshot for %s, snapshot %s"",queryId.getId(), lastTriedId.toString());"	<line8>	"logger.debug(""Resuming download"")"	"<line8> logger.debug(""Resuming download"")"
task5	"<line1>    LOGGER.info(""Teardown Keycloak in namespace: {}"", namespace);"	<line1>	"LOGGER.info(""Deleting Keycloak server from: {}"", PATH_TO_KEYCLOAK_TEARDOWN_SCRIPT)"	"<line1> LOGGER.info(""Deleting Keycloak server from: {}"", PATH_TO_KEYCLOAK_TEARDOWN_SCRIPT)"
task5	"<line12>          LOGGER.debug(""Unable to load buffer pool MBeans, possibly running on Java 6"");"	<line12>	"logger.warn(""Could not retrieve attribute {} from pool {}"", attribute, pool)"	"<line12> logger.warn(""Could not retrieve attribute {} from pool {}"", attribute, pool)"
task5	"<line9>      LOG.debug(""Setting job conf credstore location to ""+ jobKeyStoreLocation+ "" previous location was ""+ oldKeyStoreLocation);"	<line7>	"LOG.debug(""Updating jobConf credential provider path: {} -> {}"", oldKeyStoreLocation, jobKeyStoreLocation)"	"<line7> LOG.debug(""Updating jobConf credential provider path: {} -> {}"", oldKeyStoreLocation, jobKeyStoreLocation)"
task5	"<line3>      log.warn(""[TaskTrackerActor] receive ServerStopInstanceReq({}) but system can't find TaskTracker."",req);"	<line3>	"log.info(""[TaskTrackerPool] receive ServerStopInstanceReq({}) but pool has no TaskTracker for""+ "" instance"",req)"	"<line3> log.info(""[TaskTrackerPool] receive ServerStopInstanceReq({}) but pool has no TaskTracker for""+ "" instance"",req)"
task5	"<line29>    LOGGER.info(""did update the localization for pkg {} for {} natural languages"",pkg.getName(),updatePkgLocalizationRequest.pkgLocalizations.size());"	<line14>	"LOGGER.warn(""the current user does not have the correct permission to edit the localization for ""+ ""the package [{}]"",updatePkgLocalizationRequest.pkgName)"	"<line14> LOGGER.warn(""the current user does not have the correct permission to edit the localization for ""+ ""the package [{}]"",updatePkgLocalizationRequest.pkgName)"
task5	"<line17>      logger.debug(""Updating client id since the received value is null (new value {})"", clientId);"	<line19>	"logger.trace(""Converted message to kapua message: {}"", message)"	"<line19> logger.trace(""Converted message to kapua message: {}"", message)"
task5	"<line4>        log.info(""Iteration: "" + (i + 1) + '/' + ITERATIONS);"	<line3>	"log.info(""Iteration: "" + i)"	"<line3> log.info(""Iteration: "" + i)"
task5	"<line5>      log.info(""Exception caught at fault barrier while generating jobs."", e);"	<line5>	"log.error(""Unable to generate jobs"", e)"	"<line5> log.error(""Unable to generate jobs"", e)"
task5	"<line4>        logger.debug(String.format(""BroadcastServiceHandler: caught exception %s, probably because session was closed""+ "" with pending writes"",cause));"	<line4>	"logger.debug(""Ignoring exception during shutdown"", cause)"	"<line4> logger.debug(""Ignoring exception during shutdown"", cause)"
task5	"<line5>        logger.warn(""Could not delete {} from workspace: {}"", url, e.getMessage());"	<line5>	log.warn(e, e)	<line5> log.warn(e, e)
task5	"<line3>    LOG.trace(""Attempted write and flush of buffer: {}"", output);"	<line2>	"log.trace(""Attempted write of: {} bytes"", output.readableBytes())"	"<line2> log.trace(""Attempted write of: {} bytes"", output.readableBytes())"
task5	"<line7>      LOGGER.debug(""Calling before() for '{}' in processor '{}'..."",interceptor,component.getLocation().getLocation());"	<line22>	"LOG.warn(""Exception while invoking interceptor "" + interceptor, e)"	"<line22> LOG.warn(""Exception while invoking interceptor "" + interceptor, e)"
task5	"<line6>          LOGGER.debug(""Unable to find bundle {} of app {} in system."", loc, name);"	<line6>	"log.info(""Skipping inactive bundle at location: "" + loc)"	"<line6> log.info(""Skipping inactive bundle at location: "" + loc)"
task5	"<line9>      logger.error(e.toString() + "" parse "" + this);"	<line9>	"logger.error(""Error while parsing polynomial"", e)"	"<line9> logger.error(""Error while parsing polynomial"", e)"
task5	"<line2>    log.info(""[TRACKER] tenantId "" + tenantId + "" removed."");"	<line1>	"log.debug(""tenantId: "" + tenantId)"	"<line1> log.debug(""tenantId: "" + tenantId)"
task5	"<line12>          LOG.error(""While shutting down"", t);"	<line12>	"LOG.error(""Unable to stop pre-jetty server"", t)"	"<line12> LOG.error(""Unable to stop pre-jetty server"", t)"
task5	"<line7>    LOGGER.trace(""'{}' wrote '{}'."", key, value);"	<line7>	"log.info(""{} written items to {}: {}"", items.size(), key, value)"	"<line7> log.info(""{} written items to {}: {}"", items.size(), key, value)"
task5	"<line8>      LOG.error(""While deleting {}"", model.getObject().getKey(), e);"	<line9>	"LOG.error(""While deleting {}"", model.getObject().getKey(), e)"	"<line9> LOG.error(""While deleting {}"", model.getObject().getKey(), e)"
task5	"<line5>      LOG.trace(""{}: receive {}"", getName(), reply);"	<line17>	"LOG.warn(""Failed to parse RaftClientReply"", e)"	"<line17> LOG.warn(""Failed to parse RaftClientReply"", e)"
task5	"<line3>      log.debug(""Missing resource in payload. [resource=({}), issuer=({}), "" + ""messageId=({})]"",affectedResource,issuerConnector,messageId);"	<line3>	"log.debug(""Missing payload in request. [messageId=({})]"", messageId)"	"<line3> log.debug(""Missing payload in request. [messageId=({})]"", messageId)"
task5	"<line7>        logger.info(""Execute Service permitted commands: {}"", commandString);"	<line10>	"logger.info(""Activating {}"", this.getClass().getSimpleName())"	"<line10> logger.info(""Activating {}"", this.getClass().getSimpleName())"
task5	"<line2>    LOG.info(""This node elected Active Cluster Coordinator"");"	<line2>	"LOG.info(""{} has been elected the Cluster Coordinator"", participantId)"	"<line2> LOG.info(""{} has been elected the Cluster Coordinator"", participantId)"
task5	<line8>      log.error(e.getMessage(), e);	<line8>	log.error(e.getMessage(), e)	<line8> log.error(e.getMessage(), e)
task5	"<line8>        logger.error(""TableManagerImpl.userQuitTournamentSubTables table == null - userId "" + userId);"	<line8>	"logger.error(""TableController without table - userQuitTournamentSubTables()"")"	"<line8> logger.error(""TableController without table - userQuitTournamentSubTables()"")"
task5	"<line2>    logger.info(""{}"", Thread.currentThread().getStackTrace()[1].getMethodName());"	<line2>	"logger.info(""{}"", Thread.currentThread().getStackTrace()[1].getMethodName())"	"<line2> logger.info(""{}"", Thread.currentThread().getStackTrace()[1].getMethodName())"
task5	"<line6>      LOGGER.warn(""failed in parseMap: "" + ex.getMessage());"	<line6>	"LOG.error(""Exception while parsing metadata"", ex)"	"<line6> LOG.error(""Exception while parsing metadata"", ex)"
task5	<line9>        LOG.error(e);	<line9>	LOG.error(e, e)	<line9> LOG.error(e, e)
task5	"<line23>        logger.info(String.format(""Failed to soft-delete %s (transition from %s to %s): item is referenced, and will""+ "" be deprecated instead"",localItemCsid, localItemWorkflowState, sasWorkflowState));"	<line23>	"logger.debug(""DocumentReferenceException: "" + de.getMessage())"	"<line23> logger.debug(""DocumentReferenceException: "" + de.getMessage())"
task5	"<line6>      logger.error(""Error loading bpmWidgetInfo with id '{}'"", id, t);"	<line6>	"logger.error(""Error loading bpmWidgetInfo with id: {}"", id, t)"	"<line6> logger.error(""Error loading bpmWidgetInfo with id: {}"", id, t)"
task5	"<line2>    log.debug(""Getting client certificates for consumer: {}"", consumerUuid);"	<line10>	"log.debug(""Getting client certificate(s) for consumer: {}"", consumerUuid)"	"<line10> log.debug(""Getting client certificate(s) for consumer: {}"", consumerUuid)"
task5	"<line5>        logger.info(""DOCID: "" + d.getProperty(""docno""));"	<line5>	"logger.info(""***RECEIVED*** "" + d)"	"<line5> logger.info(""***RECEIVED*** "" + d)"
task5	"<line12>      logger.error(""Error occured while generating JSON!"");"	<line12>	"logger.error(""Error occurred while generating JSON!"", e)"	"<line12> logger.error(""Error occurred while generating JSON!"", e)"
task5	"<line1>    log.info(""Stopping iptables for {} at {}"", entity(), machine);"	<line1>	"LOG.info(""Stopping firewall on {}"", machine)"	"<line1> LOG.info(""Stopping firewall on {}"", machine)"
task5	"<line2>    logger.debug(""Returning XAResource [null]..."");"	<line2>	"logger.debug(""call getXAResources("" + specs + "")"")"	"<line2> logger.debug(""call getXAResources("" + specs + "")"")"
task5	"<line13>      logger.warn(""error calling {}.{}()"", method.getDeclaringClass().getName(), method.getName(), t);"	<line13>	"logger.warn(""error calling {}.{}()"", method.getDeclaringClass().getName(), method.getName(), t)"	"<line13> logger.warn(""error calling {}.{}()"", method.getDeclaringClass().getName(), method.getName(), t)"
task5	"<line11>        logger.debug(""getNextBatch returns with a buffer of "" + entries.length + "" entries."");"	<line11>	"logger.debug(""readMultiple returned ""+ entries.length+ "" entries for query: ""+ _queryPacket)"	"<line11> logger.debug(""readMultiple returned ""+ entries.length+ "" entries for query: ""+ _queryPacket)"
task5	"<line1>    log.info(""Query is Activity tab displayed"");"	<line1>	"log.info(""Query activity tab is selected"")"	"<line1> log.info(""Query activity tab is selected"")"
task5	<line12>      log.error(exception, exception);	<line12>	"log.error(""Unable to get journal service configuration"", exception)"	"<line12> log.error(""Unable to get journal service configuration"", exception)"
task5	"<line1>    log.info(""Pausing queue {}"", queueName);"	<line1>	"log.info(""Pausing queue {}"", queueName)"	"<line1> log.info(""Pausing queue {}"", queueName)"
task5	"<line2>    logger.info(""Accepting document: "" + document.getID());"	<line2>	logger.debug(document.getDocumentName())	<line2> logger.debug(document.getDocumentName())
task5	"<line8>    LOGGER.info(""ALTER charset execute result: {}"", result);"	<line8>	"logger.info(""Result: {}"", result)"	"<line8> logger.info(""Result: {}"", result)"
task5	"<line1>    log.debug(""Sending message to user "" + user);"	<line1>	"log.debug(""sendMessage: {}"", message)"	"<line1> log.debug(""sendMessage: {}"", message)"
task5	"<line11>      LOG.error(""Error while setting proxy."", t);"	<line11>	"LOG.error(""Error while setting system proxy:"", t)"	"<line11> LOG.error(""Error while setting system proxy:"", t)"
task5	<line8>      log.error(exception, exception);	<line8>	log.error(exception, exception)	<line8> log.error(exception, exception)
task5	"<line4>        LOGGER.warn(""Element definition contains a reserved property name {}. ""+ ""This may prevent some analytics from being used on this graph."",property);"	<line4>	"LOG.warn(MessageFormat.format(""The property name \""{0}\"" is a reserved property name and will be ignored"",property))"	"<line4> LOG.warn(MessageFormat.format(""The property name \""{0}\"" is a reserved property name and will be ignored"",property))"
task5	"<line11>        logger.debug(testName+ "": Created an AccountRole instance for account with knownResourceId=""+ knownResourceId);"	<line11>	"logger.debug(testName + "": knownResourceId="" + knownResourceId)"	"<line11> logger.debug(testName + "": knownResourceId="" + knownResourceId)"
task5	"<line19>      LOG.error(""Error reading metadata properties"", ex);"	<line19>	"logger.error(""Unable to retrieve metadata"", ex)"	"<line19> logger.error(""Unable to retrieve metadata"", ex)"
task5	"<line8>      LOGGER.warn(""Failed to dispose: "" + encoder.getClass().getName() + "" ("" + encoder + ')');"	<line8>	"log.debug(""Error disposing encoder"", t)"	"<line8> log.debug(""Error disposing encoder"", t)"
task5	"<line20>      LOGGER.error(""ActivityMetaDataDao - getQuestionnaireFrequencyDetailsForOneTime() :: ERROR"", e);"	<line20>	"LOGGER.error(""ActivityMetaDataDao - getQuestionnaireFrequencyDetailsForOneTime() :: ERROR"", e)"	"<line20> LOGGER.error(""ActivityMetaDataDao - getQuestionnaireFrequencyDetailsForOneTime() :: ERROR"", e)"
task5	<line9>    logger.trace(format, object1, object2, object3);	<line9>	logger.trace(format, object1, object2, object3)	<line9> logger.trace(format, object1, object2, object3)
task5	"<line2>    LOG.debug(""Channel connected {}"", e);"	<line2>	"log.info(""Connection established from {}"", ctx.getChannel().getRemoteAddress())"	"<line2> log.info(""Connection established from {}"", ctx.getChannel().getRemoteAddress())"
task5	"<line3>    LOGGER.debug(""[lastVal={}, curVal={}]"", lastVal, curVal);"	<line4>	"log.info(""changed value of "" + frag.getAlias() + "" to "" + curVal)"	"<line4> log.info(""changed value of "" + frag.getAlias() + "" to "" + curVal)"
task5	<line5>      logger.error(e.getMessage(), e);	<line5>	"logger.error(""Error while cutting text"", e)"	"<line5> logger.error(""Error while cutting text"", e)"
task5	"<line5>        LOG.debug(""appending ["" + warnings.size() + ""] warning(s)"");"	<line5>	"logger.warn(""ApplicationWarnings context was already set, ""+ ""this context will be overridden with application context ""+ springInstance.getDisplayName())"	"<line5> logger.warn(""ApplicationWarnings context was already set, ""+ ""this context will be overridden with application context ""+ springInstance.getDisplayName())"
task5	"<line6>      logger.error(""error in search groups"", t);"	<line6>	"logger.error(""error in search groups"", t)"	"<line6> logger.error(""error in search groups"", t)"
task5	"<line1>    LOG.error(""Error processing auth message, erroring connection {}"", errorCode);"	<line1>	"log.debug(""Authentication error: {}"", errorCode)"	"<line1> log.debug(""Authentication error: {}"", errorCode)"
task5	"<line2>    log.info(""Pending slot request [{}] timed out."", slotRequestId);"	<line4>	"logger.debug(""Timeout of pending slot request with slot request id {} reached."", slotRequestId)"	"<line4> logger.debug(""Timeout of pending slot request with slot request id {} reached."", slotRequestId)"
task5	<line27>      log.error(e.getMessage(), e);	<line26>	"LOGGER.error(""Error processing ServiceMeshMetric.Builder: {}"", e.getMessage(), e)"	"<line26> LOGGER.error(""Error processing ServiceMeshMetric.Builder: {}"", e.getMessage(), e)"
task5	"<line8>      LOGGER.error(""Exception launching activities to executes"", t);"	<line11>	"log.error(""Uncaught exception in orchestra module"", t)"	"<line11> log.error(""Uncaught exception in orchestra module"", t)"
task5	<line39>      log.error(systemException, systemException);	<line39>	log.error(systemException, systemException)	<line39> log.error(systemException, systemException)
task5	"<line11>            log.info(""Stopping node "" + idx);"	<line11>	"log.info(""Stop node: "" + idx)"	"<line11> log.info(""Stop node: "" + idx)"
task5	"<line1>    LOGGER.info(""Sending message to the da requests queue"");"	<line1>	"LOGGER.info(""Sending request message to distribution automation"")"	"<line1> LOGGER.info(""Sending request message to distribution automation"")"
task5	"<line12>                    logger.warn(""Exception at getOAuthRequestTokenAsync"", e);"	<line12>	"logger.warn(""Exception at getOAuthRequestTokenAsync"", e)"	"<line12> logger.warn(""Exception at getOAuthRequestTokenAsync"", e)"
task5	"<line10>    log.debug(""put {} index mapping finished, isAcknowledged: {}"", indexName, response.isAcknowledged());"	<line10>	"LOGGER.info(""Index mapping updated for index {}"", indexName)"	"<line10> LOGGER.info(""Index mapping updated for index {}"", indexName)"
task5	"<line11>        LOG.debug(taskName + "" interrupted while waiting for the writer thread to die"", e);"	<line2>	"LOG.info(""Closing reader"")"	"<line2> LOG.info(""Closing reader"")"
task5	"<line5>      LOGGER.error(""Naming health check fail."", e);"	<line5>	"log.warn(""Failed to get metrics: "", e)"	"<line5> log.warn(""Failed to get metrics: "", e)"
task5	"<line19>              log.debug(""Failed to parse META-INF/versions entry"", ex);"	<line19>	"LOGGER.info(""Ignoring invalid Java version number {} in JAR file {}"", part, file)"	"<line19> LOGGER.info(""Ignoring invalid Java version number {} in JAR file {}"", part, file)"
task5	"<line5>      logger.debug(""Failed to delete storage pool"", e);"	<line5>	"logger.error(""Delete storage pool failed, "", e)"	"<line5> logger.error(""Delete storage pool failed, "", e)"
task5	"<line17>      LOG.error(""Unable to retrieve job details for ""+ context.getWorkflowId()+ "" on cluster ""+ context.getClusterName(),e);"	<line17>	"LOG.warn(""Failed to get start and end time of workflow execution"", e)"	"<line17> LOG.warn(""Failed to get start and end time of workflow execution"", e)"
task5	"<line15>      LOGGER.error(""Exception writing to internal frame buffer"", ex);"	<line15>	"LOGGER.error(""Exception writing to internal frame buffer"", ex)"	"<line15> LOGGER.error(""Exception writing to internal frame buffer"", ex)"
task5	"<line12>      LOGGER.warn(""unhandled object to calculate size for: ""+ value.getClass().getName()+ "", defaulting to 100"");"	<line12>	"LOG.debug(""Cannot calculate size of value: "" + value + "". Returning 100 as default."")"	"<line12> LOG.debug(""Cannot calculate size of value: "" + value + "". Returning 100 as default."")"
task5	<line27>      log.error(exception, exception);	<line27>	log.error(exception, exception)	<line27> log.error(exception, exception)
task5	"<line3>    logger.debug(""Registered 'script' configuration parser"");"	<line2>	"logger.debug(""Activating {}"", this.getClass().getName())"	"<line2> logger.debug(""Activating {}"", this.getClass().getName())"
task5	"<line5>    LOG.debug(""<<<< {}"", endpoint);"	<line5>	"log.trace(""receiveNoWait({})"", endpoint)"	"<line5> log.trace(""receiveNoWait({})"", endpoint)"
task5	"<line5>      LOG.debug(""Ignored error: "", e);"	<line5>	"log.warn(""Ambiguous field name: "" + fname)"	"<line5> log.warn(""Ambiguous field name: "" + fname)"
task5	"<line25>          LOG.warn(""Deadlock detected, retrying"", exception);"	<line27>	"LOG.info(""PreparedStatement.executeBatch() failed, rolling back and retrying. {}"",exception.getMessage())"	"<line27> LOG.info(""PreparedStatement.executeBatch() failed, rolling back and retrying. {}"",exception.getMessage())"
task5	"<line11>    log.trace(""Downloaded external keys from "" + jwksUri + "", keys: "" + keys);"	<line14>	"LOG.info(""Using JWKS from "" + jwksUri)"	"<line14> LOG.info(""Using JWKS from "" + jwksUri)"
task5	"<line6>        logger.warn(""??"");"	<line6>	"logger.warn(MessageFormat.format(""Could not find quantity with unit to which the reference {0} can be made"",this.getRefId()))"	"<line6> logger.warn(MessageFormat.format(""Could not find quantity with unit to which the reference {0} can be made"",this.getRefId()))"
task5	"<line3>      LOGGER.debug(format(""unscheduling run once job: "" + LOG_SUBJECT_EXTERNAL_ID, subject, externalId));"	<line3>	"LOGGER.debug(""Unscheduling run-once job. subject: {}, externalId: {}"", subject, externalId)"	"<line3> LOGGER.debug(""Unscheduling run-once job. subject: {}, externalId: {}"", subject, externalId)"
task5	"<line6>          LOG.trace(""Removing artifact {}"", artifact);"	<line6>	"logger.info(""Removing local artifact: "" + artifact.getId())"	"<line6> logger.info(""Removing local artifact: "" + artifact.getId())"
task5	"<line2>    LOGGER.info(""Properties: {}"", getProperties());"	<line9>	"LOG.debug(""Opening SPARQL interpreter using {} engine"", engineType)"	"<line9> LOG.debug(""Opening SPARQL interpreter using {} engine"", engineType)"
task5	"<line38>        logger.error(""datenLesen"", ex);"	<line37>	"logger.error(""Error while reading configuration file {}"", xmlFilePath, ex)"	"<line37> logger.error(""Error while reading configuration file {}"", xmlFilePath, ex)"
task5	"<line7>      LOG.debug(""Updating entity reference {} for reference attribute {}"", attributeDef.getName());"	<line7>	"LOG.debug(""==> updateEdge({}, {}, {}, {})"", attributeDef, value, currentEdge, entityVertex)"	"<line7> LOG.debug(""==> updateEdge({}, {}, {}, {})"", attributeDef, value, currentEdge, entityVertex)"
task5	"<line3>    LOGGER.debug(""Check if the IP: "" + ip + "" is free. The vcpeID: "" + vcpeId);"	<line7>	"logger.error(""Error checking for free IP address"", e)"	"<line7> logger.error(""Error checking for free IP address"", e)"
task5	"<line2>    logger.info(""Obtained session"");"	<line14>	"if (LOGGER.isDebugEnabled()) LOGGER.debug(""FinancialYear ID="" + result)"	"<line14> if (LOGGER.isDebugEnabled()) LOGGER.debug(""FinancialYear ID="" + result)"
task5	"<line6>      logger.info(toString() + "" is at: "" + received);"	<line6>	"logger.info(""Received: "" + received)"	"<line6> logger.info(""Received: "" + received)"
task5	"<line1>    logger.info(""Task failed callback for taskId: "" + tg.getTaskId());"	<line1>	"logger.info(""Task failed: "" + tg)"	"<line1> logger.info(""Task failed: "" + tg)"
task5	"<line10>          log.warn(""Unable to create the partitioner for ""+ tableName+ "" despite its configuration.""+ ""Will use the default partitioner for this table."",e);"	<line10>	"log.error(""Could not find partitioner for table ""+ tableName+ "" ""+ e.getMessage()+ "" Will use default partitioner for the job."")"	"<line10> log.error(""Could not find partitioner for table ""+ tableName+ "" ""+ e.getMessage()+ "" Will use default partitioner for the job."")"
task5	<line7>      log.error(exception, exception);	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	"<line3>    LOGGER.trace(""Converting TieLine {}"", line.getId());"	<line2>	"log.debug(""Convert tie line {}"", mergedXnode.getPath())"	"<line2> log.debug(""Convert tie line {}"", mergedXnode.getPath())"
task5	"<line17>      log.debug(""loading failed."");"	<line16>	"log.error(""Error loading system data for {}"", system)"	"<line16> log.error(""Error loading system data for {}"", system)"
task5	<line5>        log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line5>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line5> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line1>    Freedomotic.logger.info(""Trying to connect to ethernet relay board on address "" + address + ':' + port);"	<line1>	"Freedomotic.logger.info(""Connecting to host "" + address + "" on port "" + port)"	"<line1> Freedomotic.logger.info(""Connecting to host "" + address + "" on port "" + port)"
task5	"<line7>      logger.error(""Error while delete on hbase for : "" + rowKey);"	<line7>	"LOG.error(""Could not perform delete. Caused by: "", e)"	"<line7> LOG.error(""Could not perform delete. Caused by: "", e)"
task5	<line7>          LOG.error(e);	<line7>	LOG.error(e)	<line7> LOG.error(e)
task5	<line17>        log.error(message, t);	<line17>	logger.error(message, t)	<line17> logger.error(message, t)
task5	"<line2>    logger.info(""Starting Source Task with properties {}"",StatelessKafkaConnectorUtil.getLoggableProperties(properties));"	<line2>	"log.info(""Starting the {} Kafka Connect Source Task"", context.getTaskName())"	"<line2> log.info(""Starting the {} Kafka Connect Source Task"", context.getTaskName())"
task5	"<line17>      this.logger.error(""Error while trying to retrieve matches for ""+ query+ "" ""+ ex.getClass().getName()+ "" ""+ ex.getMessage(),ex);"	<line17>	"logger.error(""An error occurred while trying to retrieve matches for term search: {}"",ex.getLocalizedMessage(),ex)"	"<line17> logger.error(""An error occurred while trying to retrieve matches for term search: {}"",ex.getLocalizedMessage(),ex)"
task5	<line67>      log.error(systemException, systemException);	<line67>	log.error(systemException, systemException)	<line67> log.error(systemException, systemException)
task5	"<line2>    LOG.debug(""{}: getSchemaSource for {} failed"", id, sourceIdentifier, throwable);"	<line2>	"log.error(""Failed to send value."", throwable)"	"<line2> log.error(""Failed to send value."", throwable)"
task5	"<line2>    LOG.debug(""SchemaTransaction remove vertex label '{}'"", id);"	<line2>	"LOG.debug(""=============== removeVertexLabel {}"", id)"	"<line2> LOG.debug(""=============== removeVertexLabel {}"", id)"
task5	"<line11>    LOG.info(""ZeppelinHub REST API get note {} "", noteId);"	<line6>	"LOG.debug(""Get note {} from ZeppelinHub REST API"", noteId)"	"<line6> LOG.debug(""Get note {} from ZeppelinHub REST API"", noteId)"
task5	"<line11>          LOG.warn(""Unable to close {}"", serverChannel, e);"	<line11>	"log.warn(""Exception while closing server channel"", e)"	"<line11> log.warn(""Exception while closing server channel"", e)"
task5	"<line3>      LOG.info(""reading checkpoint info for:"" + instant + "" key: "" + extraMetadataKey);"	<line9>	"LOG.error(""Unable to parse instant metadata "" + instant, e)"	"<line9> LOG.error(""Unable to parse instant metadata "" + instant, e)"
task5	"<line7>      logger.error(""Error deleting user config record by id {}"", username, t);"	<line7>	"logger.error(""Error deleting user config record by id {}"", username, t)"	"<line7> logger.error(""Error deleting user config record by id {}"", username, t)"
task5	<line19>      log.error(systemException, systemException);	<line19>	log.error(systemException, systemException)	<line19> log.error(systemException, systemException)
task5	"<line25>      logger.error(""Error extracting services"", t);"	<line25>	"logger.error(""Error getting services"", t)"	"<line25> logger.error(""Error getting services"", t)"
task5	"<line16>      log.error(""Cannot add token to db"", e);"	<line16>	"log.error(""Error adding confirmation token"", e)"	"<line16> log.error(""Error adding confirmation token"", e)"
task5	"<line18>          LOG.debug(""Failed to process request to read entry at {}:{}. Too many pending requests"",r.ledgerId,r.entryId);"	<line18>	"LOG.debug(""Rejected execution of ReadRequest {} : "", r, e)"	"<line18> LOG.debug(""Rejected execution of ReadRequest {} : "", r, e)"
task5	"<line3>      log.warn(""Too many parameters"",""Function ""+ function+ "" has more than 254 in parameters. Skipping generation of convenience method."");"	<line3>	"log.warn(String.format(""Convenience method with too many parameters: %s"", function))"	"<line3> log.warn(String.format(""Convenience method with too many parameters: %s"", function))"
task5	"<line4>      log.info(""Starting remote app entries"");"	<line4>	"log.info(""Activating "" + this.getClass().getName())"	"<line4> log.info(""Activating "" + this.getClass().getName())"
task5	"<line2>    LOG.debug(""get("" + key + "","" + fields + "")"");"	<line2>	"LOG.debug(""get("" + key + "")"")"	"<line2> LOG.debug(""get("" + key + "")"")"
task5	"<line15>      logger.error(""Unexpected error"", t);"	<line15>	log.error(cantSendEmailMsg, t)	<line15> log.error(cantSendEmailMsg, t)
task5	"<line7>      log.error(""Error getting leaderboard: {} "", usecase);"	<line7>	"log.error(""Error getting leaderboard: "" + usecase, e)"	"<line7> log.error(""Error getting leaderboard: "" + usecase, e)"
task5	"<line29>      LOGGER.error(""Could not retrieve network interface: {}"", ex.getMessage(), ex);"	<line29>	"logger.debug(""Error getting IPv4 address"", ex)"	"<line29> logger.debug(""Error getting IPv4 address"", ex)"
task5	"<line5>      log.info(""Trying request with url : "" + requestUrl);"	<line5>	"log.info(""Trying request with url : "" + requestUrl)"	"<line5> log.info(""Trying request with url : "" + requestUrl)"
task5	"<line14>      LOG.warn(""no committed message for topic {} partition {}"",topicPartition.getTopic(),topicPartition.getPartition());"	<line10>	"LOG.error(""Unable to create consumer for {}"", topicPartition)"	"<line10> LOG.error(""Unable to create consumer for {}"", topicPartition)"
task5	"<line2>    LOGGER.debug(""Adjusting EC public key in context"");"	<line2>	"LOGGER.debug(""Adjusting EC Public Key in Context to match our own Public Key"")"	"<line2> LOGGER.debug(""Adjusting EC Public Key in Context to match our own Public Key"")"
task5	"<line8>          log.warn(""Unable to parse date "" + text, exception);"	<line8>	"log.warn(""Unable to parse date "" + text, exception)"	"<line8> log.warn(""Unable to parse date "" + text, exception)"
task5	"<line7>    LOGGER.info(""Task object returned to client: {}"", task.toJsonString());"	<line7>	"LOGGER.info(""Task object returned to client : "" + task.toJsonString())"	"<line7> LOGGER.info(""Task object returned to client : "" + task.toJsonString())"
task5	<line4>    LOG.info(result);	<line4>	"log.info(""RESULT: "" + result)"	"<line4> log.info(""RESULT: "" + result)"
task5	"<line3>    logger.info(""query size: {}"", timeValues.size());"	<line2>	"LOGGER.debug(""Setting the JSON timeseries for the target: {}"", target)"	"<line2> LOGGER.debug(""Setting the JSON timeseries for the target: {}"", target)"
task5	"<line13>        logger.debug(""Set AsyncContext {}"", asyncContext);"	<line13>	"logger.debug(""Set asyncContext {}"", asyncContext)"	"<line13> logger.debug(""Set asyncContext {}"", asyncContext)"
task5	"<line6>      LOGGER.trace("""", e);"	<line6>	"LOGGER.trace("""", e)"	"<line6> LOGGER.trace("""", e)"
task5	"<line7>      logger.error(""Interrupted"", e);"	<line3>	"logger.info(""Consumer: Started"")"	"<line3> logger.info(""Consumer: Started"")"
task5	"<line1>    logger.debug(""{} stopped. Will no longer distribute FlowFiles across the cluster"", this);"	<line5>	"logger.info(""Stopping load balancing"")"	"<line5> logger.info(""Stopping load balancing"")"
task5	"<line3>    LOGGER.debug(""Running jobs: {}"", runningJobs.keySet());"	<line2>	"LOG.info(""JobContextInformation for JobId: {}"", jobId)"	"<line2> LOG.info(""JobContextInformation for JobId: {}"", jobId)"
task5	<line5>      log.error(exception, exception);	<line5>	log.error(exception, exception)	<line5> log.error(exception, exception)
task5	<line12>    logger.info(response);	<line12>	"LOG.info(""Response: {}"", response)"	"<line12> LOG.info(""Response: {}"", response)"
task5	"<line8>      LOGGER.error(""getFileDescriptor from FileImageOutputStream"", e);"	<line8>	"LOGGER.warn(""Could not get RandomAccessFile from FileImageOutputStream"", e)"	"<line8> LOGGER.warn(""Could not get RandomAccessFile from FileImageOutputStream"", e)"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line13>        log.warn(""Default credentials (jcifs.smb.client.username/password)""+ "" not specified. SMB signing may not work propertly.""+ ""  Skipping DC interrogation."");"	<line21>	"log.debug(""Failed to connect to {}"", addr, e)"	"<line21> log.debug(""Failed to connect to {}"", addr, e)"
task5	"<line6>        LOGGER.debug(String.format(""http.proxy service is upgrading session %s"", session));"	<line6>	"LOGGER.debug(""Upgrade to WebSocket for {}"", session)"	"<line6> LOGGER.debug(""Upgrade to WebSocket for {}"", session)"
task5	"<line5>      logger.warn(""Could not find existing MAC in {}. Generating new MAC. This will require re-pairing of""+ "" iOS devices."",storage.getClass().getName());"	<line1>	"logger.debug(""Initializing storage"")"	"<line1> logger.debug(""Initializing storage"")"
task5	"<line1>    LOGGER.info(MessageFormat.format(""Loading licenses into version home: {0}"", versionHome));"	<line1>	"log.info(MessageFormat.format(""Loading licenses for version {0}"", version))"	"<line1> log.info(MessageFormat.format(""Loading licenses for version {0}"", version))"
task5	"<line14>    logger.info("">> Registered new Image %s, waiting for it to become available."", newImageId);"	<line29>	"logger.info(""Image created: %s"", image.get())"	"<line29> logger.info(""Image created: %s"", image.get())"
task5	"<line12>      logger.debug(""Received exception {} when trying to parse: {}"",ex.getMessage(),serializedDistinctContinuationToken);"	<line12>	"logger.debug(""Received exception {} when trying to parse: {}"",ex.getMessage(),serializedDistinctContinuationToken)"	"<line12> logger.debug(""Received exception {} when trying to parse: {}"",ex.getMessage(),serializedDistinctContinuationToken)"
task5	"<line8>    LOG.info(""Found {} agents left in rack {}"", numInRack, lostAgent.getRackId());"	<line9>	"LOG.info(""Detected no agents left in rack {}, changing to DEAD"", lostAgent.getRackId())"	"<line9> LOG.info(""Detected no agents left in rack {}, changing to DEAD"", lostAgent.getRackId())"
task5	<line36>      logger.error(e.getMessage());	<line36>	logger.debug(e.getMessage())	<line36> logger.debug(e.getMessage())
task5	"<line7>        logger.warn(""failed to create config"");"	<line7>	"logger.error(""Error creating config"", t)"	"<line7> logger.error(""Error creating config"", t)"
task5	"<line19>      log.warn(""Got a request to the SAML Single Logout endpoint, ""+ ""with invalid request (XML is broken)"",e);"	<line23>	"log.debug(""Engine is shutting down"", e)"	"<line23> log.debug(""Engine is shutting down"", e)"
task5	"<line18>          LOG.warn(""You use localhost interface! It means that no external connections will be""+ "" available. Don't you want to use 0.0.0.0 instead (all network interfaces)?"");"	<line18>	"LOG.warn(""Cometd server is started with port: ""+ endpoint.getPort()+ "" for host: ""+ endpoint.getUri().getHost())"	"<line18> LOG.warn(""Cometd server is started with port: ""+ endpoint.getPort()+ "" for host: ""+ endpoint.getUri().getHost())"
task5	"<line2>    LOGGER.debug(""ProtocolVersion: "" + ArrayConverter.bytesToHexString(msg.getProtocolVersion().getValue()));"	<line2>	"LOGGER.debug(""ProtocolVersion: "" + ArrayConverter.bytesToHexString(msg.getProtocolVersion().getValue()))"	"<line2> LOGGER.debug(""ProtocolVersion: "" + ArrayConverter.bytesToHexString(msg.getProtocolVersion().getValue()))"
task5	"<line4>      LOG.error(""[{}] Unexpected error while failing {}"", logPrefix, callback, throwable);"	<line4>	"LOG.error(""Error notifying callback"", throwable)"	"<line4> LOG.error(""Error notifying callback"", throwable)"
task5	"<line2>    LOG.debug("">>>BasicService.list(neutralQuery)"");"	<line2>	"LOG.debug("">>>BasicService.list()"")"	"<line2> LOG.debug("">>>BasicService.list()"")"
task5	"<line10>      log.warn(""Unable to load level.dat file, attempting to load backup."");"	<line10>	"log.warn(""Failed to load level.dat from "" + levelDatPath + "" trying "" + levelDatOldPath, e)"	"<line10> log.warn(""Failed to load level.dat from "" + levelDatPath + "" trying "" + levelDatOldPath, e)"
task5	"<line4>      LOGGER.error(""IllegalStateException"");"	<line2>	"LOGGER.debug(""close()"")"	"<line2> LOGGER.debug(""close()"")"
task5	<line25>      log.error(exception, exception);	<line25>	log.error(exception, exception)	<line25> log.error(exception, exception)
task5	"<line13>      logger.warn(""Not a valid URI: {}"", service.configDescriptionURI);"	<line13>	"log.warn(""Service '{}' has an invalid config description URI: '{}'"", serviceId, service.configDescriptionURI)"	"<line13> log.warn(""Service '{}' has an invalid config description URI: '{}'"", serviceId, service.configDescriptionURI)"
task5	"<line2>    LOG.error(""Failure reading ActionDefinition {}"", id.getValue());"	<line2>	"logger.error(""Error while sending value."", arg0)"	"<line2> logger.error(""Error while sending value."", arg0)"
task5	"<line3>    logger.debug(""Set the selected object to: {}"", selObj);"	<line2>	"logger.debug(""updateSelectedObject: {}"", selectedObject)"	"<line2> logger.debug(""updateSelectedObject: {}"", selectedObject)"
task5	"<line8>      log.warn(""Error cleaning up origin for repository '{}': {}"", repository.getAlias(), e);"	<line8>	log.error(e, e)	<line8> log.error(e, e)
task5	"<line18>          LOGGER.trace(""Ignorable error"", ex);"	<line18>	"log.warn(format(""Unable to close input stream for '%s'; %s"", url.toString(), ex.getMessage()))"	"<line18> log.warn(format(""Unable to close input stream for '%s'; %s"", url.toString(), ex.getMessage()))"
task5	"<line12>        log.error(""Error"", e);"	<line12>	"logger.error(""Error while getting the configuration for person "" + person.getUuid(), e)"	"<line12> logger.error(""Error while getting the configuration for person "" + person.getUuid(), e)"
task5	"<line6>      log.info(""Finished notifying {} messages in {}"", topicMessages.size(), stopwatch);"	<line6>	"log.debug(""Batch save took {} ms"", stopwatch.elapsed(TimeUnit.MILLISECONDS))"	"<line6> log.debug(""Batch save took {} ms"", stopwatch.elapsed(TimeUnit.MILLISECONDS))"
task5	"<line6>      logger.debug(""LSHIL {}"", ex.getLocalizedMessage());"	<line6>	logger.debug(ex.getMessage())	<line6> logger.debug(ex.getMessage())
task5	"<line11>      LOGGER.error(""run() exiting due to uncaught error"", t);"	<line11>	"LOGGER.error(""run() exiting due to uncaught error"", t)"	"<line11> LOGGER.error(""run() exiting due to uncaught error"", t)"
task5	<line17>      log.error(systemException, systemException);	<line17>	log.error(systemException, systemException)	<line17> log.error(systemException, systemException)
task5	"<line49>            logger.debug(""The SQL to execute in beeline: {} \n"", hql);"	<line49>	"logger.debug(""tmpHqlPath: "" + tmpHqlPath)"	"<line49> logger.debug(""tmpHqlPath: "" + tmpHqlPath)"
task5	"<line20>          logger.error(""class: {}, invokeInfo: {}"", clazz.getName(), invokeInfo, e);"	<line20>	"logger.error(""Failed to invoke BeforeTraceable"", e)"	"<line20> logger.error(""Failed to invoke BeforeTraceable"", e)"
task5	"<line26>      logger.info(""Located function "" + function.getFunctionDefinition());"	<line26>	"logger.info(""Located function: "" + function)"	"<line26> logger.info(""Located function: "" + function)"
task5	"<line5>      log.info(""FetchResultSet: session:{} query:{}"", sessionHandle, queryHandle);"	<line5>	"log.info(""Fetch result set for query: "" + queryHandle)"	"<line5> log.info(""Fetch result set for query: "" + queryHandle)"
task5	"<line6>      LOG.fatal(""Can't access to TaskResult at "" + TaskRunner.class.getName() + ""!"");"	<line6>	"log.error(""Incompatible Hive API found!"", e)"	"<line6> log.error(""Incompatible Hive API found!"", e)"
task5	<line19>        log.debug(exception, exception);	<line19>	log.debug(exception, exception)	<line19> log.debug(exception, exception)
task5	<line20>          logger.error(ex.getMessage(), ex);	<line20>	logger.error(ex.getMessage(), ex)	<line20> logger.error(ex.getMessage(), ex)
task5	<line16>        log.warn(exception, exception);	<line16>	log.warn(exception, exception)	<line16> log.warn(exception, exception)
task5	"<line2>    logger.debug(""isSameFile({},{})"", a, b);"	<line2>	"log.debug(""isSameFile({},{})"", a, b)"	"<line2> log.debug(""isSameFile({},{})"", a, b)"
task5	<line7>        log.warn(noSuchFolderException, noSuchFolderException);	<line7>	log.warn(noSuchFolderException, noSuchFolderException)	<line7> log.warn(noSuchFolderException, noSuchFolderException)
task5	"<line10>      log.error(""Can't write to a pin in input mode. Change direction to OUTPUT ({}) with pinMode first."",OUTPUT);"	<line10>	"log.error(""pinMode is not OUTPUT"")"	"<line10> log.error(""pinMode is not OUTPUT"")"
task5	"<line9>      log.error(StringBundler.concat(""Unable to get OpenId configuration for company "",companyId,"": "",configurationException.getMessage()),configurationException);"	<line9>	"log.error(""Unable to get OpenId Connect configuration"", configurationException)"	"<line9> log.error(""Unable to get OpenId Connect configuration"", configurationException)"
task5	"<line9>        LOG.error(WAIT_QUEUE + "" does not exist."");"	<line2>	"LOG.info(""Begin run loop"")"	"<line2> LOG.info(""Begin run loop"")"
task5	"<line5>      logger.error(""Error occurred while running DataCleaner command line mode"", e);"	<line5>	"LOG.error(""Error while running command line interface."", e)"	"<line5> LOG.error(""Error while running command line interface."", e)"
task5	"<line9>        LOG.debug(""Certificate is not appropriate."" + UpdaterUtil.getStringRepresentation(certificate));"	<line9>	"LOGGER.error(""Cannot verify signature of JAR file: "" + jarFilePath, e)"	"<line9> LOGGER.error(""Cannot verify signature of JAR file: "" + jarFilePath, e)"
task5	"<line3>      LOG.debug(""sessionRemoved: ""+ session.getId()+ "" timedout:""+ timedout+ "" channels: ""+ channelsAsString(session.getSubscriptions()));"	<line3>	"LOG.debug(""sessionRemoved("" + session + "", "" + timedout + "")"")"	"<line3> LOG.debug(""sessionRemoved("" + session + "", "" + timedout + "")"")"
task5	"<line2>    logger.error(""Exception in API http handler"", cause);"	<line2>	"log.error(""Exception in REST service"", cause)"	"<line2> log.error(""Exception in REST service"", cause)"
task5	"<line1>    logger.trace(""starting modem database download"");"	<line1>	"logger.info(""Starting download"")"	"<line1> logger.info(""Starting download"")"
task5	"<line12>      LOG.debug(""Plugin metadata back-fill was completed during a previous startup, skipping back-fill""+ "" this time."");"	<line14>	"LOG.info(""Started {} backfilling for topic: {}"", this, getTopicId().getTopic())"	"<line14> LOG.info(""Started {} backfilling for topic: {}"", this, getTopicId().getTopic())"
task5	<line5>      logger.warn(null, ex);	<line5>	"logger.warn(""Unable to copy content from "" + address, ex)"	"<line5> logger.warn(""Unable to copy content from "" + address, ex)"
task5	"<line8>      LOG.error(""Group {} on node {} does not exist"", groupId, nodeId);"	<line4>	"LOG.debug(""Adding bucket {} to {}"", bucket, FlowUtils.createGroupPath(nodeId, groupId))"	"<line4> LOG.debug(""Adding bucket {} to {}"", bucket, FlowUtils.createGroupPath(nodeId, groupId))"
task5	"<line15>      logger.error(""Error during refres pages"", t);"	<line15>	"logger.error(""Error while updating from page model changed"", t)"	"<line15> logger.error(""Error while updating from page model changed"", t)"
task5	"<line1>    LOGGER.debug(""Setting sortByRelevanceFeatureProperty to: {}"", relevanceFeatureProperty);"	<line1>	"LOGGER.debug(""Setting sortByRelevanceFeatureProperty to: {}"", relevanceFeatureProperty)"	"<line1> LOGGER.debug(""Setting sortByRelevanceFeatureProperty to: {}"", relevanceFeatureProperty)"
task5	<line9>          log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line9>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line9> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line30>        logger.warn(""unable to discover the ClusterManagementService on locator "" + locator.toString());"	<line30>	"logger.debug(""Could not get ClusterManagementService info"", e)"	"<line30> logger.debug(""Could not get ClusterManagementService info"", e)"
task5	"<line15>        log.debug(""Login: adding login name to shared state."");"	<line4>	"LOG.warn(""No token provider found for login module ""+ getName()+ "" (continuing, anyway)"")"	"<line4> LOG.warn(""No token provider found for login module ""+ getName()+ "" (continuing, anyway)"")"
task5	"<line14>          log.debug(""No node found for nodeId: ""+ nodeId+ "", handling of single message will be stopped: ""+ msg);"	<line14>	"log.debug(""Node has left grid while sending cache change message [nodeId="" + nodeId + ""]"")"	"<line14> log.debug(""Node has left grid while sending cache change message [nodeId="" + nodeId + ""]"")"
task5	"<line8>      log.debug(""Unexpected node type of .tokens node {}."", nt);"	<line8>	"log.debug(""Invalid .tokens node name {}"", nt)"	"<line8> log.debug(""Invalid .tokens node name {}"", nt)"
task5	<line31>            log.info(clname);	<line39>	"log.error(""Error while searching for classes in package: "" + packageName, e)"	"<line39> log.error(""Error while searching for classes in package: "" + packageName, e)"
task5	"<line4>        log.debug(""Committing JDBC Connection ["" + connection + ""]"");"	<line4>	"log.debug(""Transaction commit"")"	"<line4> log.debug(""Transaction commit"")"
task5	"<line1>    log.info(""Administration: Database dump."");"	<line1>	"log.info(""Dumping project data"")"	"<line1> log.info(""Dumping project data"")"
task5	"<line9>    LOG.debug(""Got PullRequest ""+ pullRequest.getHtmlUrl()+ "" [""+ pullRequest.getTitle()+ ""] From ""+ pullRequestUser.getLogin());"	<line9>	"LOG.info(""Pull Request created by {} in repository {} with title {}"",pullRequestUser,in.getHeader(GitHubConstants.GITHUB_REPOSITORY),pullRequest.getTitle())"	"<line9> LOG.info(""Pull Request created by {} in repository {} with title {}"",pullRequestUser,in.getHeader(GitHubConstants.GITHUB_REPOSITORY),pullRequest.getTitle())"
task5	"<line11>    LOG.info(""Fetched {} Jira tickets using query - {}"", issues.size(), jiraQuery.toString());"	<line8>	"LOG.debug(""Executing JQL query for issues: {}"", jiraQuery)"	"<line8> LOG.debug(""Executing JQL query for issues: {}"", jiraQuery)"
task5	"<line2>    log.debug(""Application Level throttle decision is {} for key:tier {}:{}"",decision.isThrottled(),throttleKey,tier);"	<line2>	"log.debug(""App Level throttle decision is {} for key:tier {}:{}"",decision.isThrottled(),throttleKey,tier)"	"<line2> log.debug(""App Level throttle decision is {} for key:tier {}:{}"",decision.isThrottled(),throttleKey,tier)"
task5	"<line2>    LOG.info(""NoopTask.TaskSuspendHandler.send() invoked."");"	<line2>	"logger.debug(""Suspend task: {}"", NoopTask.this.taskId)"	"<line2> logger.debug(""Suspend task: {}"", NoopTask.this.taskId)"
task5	"<line2>    logger.debug(""[actionDone][already done]{}"", migrationState);"	<line2>	"logger.info(""{} action done"", this.actionType)"	"<line2> logger.info(""{} action done"", this.actionType)"
task5	"<line2>    logger.debug(""Getting bond for atoms: atom1="" + atom1, "" atom2="" + atom2);"	<line2>	"logger.debug(""Getting bond: "", atom1, atom2)"	"<line2> logger.debug(""Getting bond: "", atom1, atom2)"
task5	"<line6>      log.warn(""Missing request content in context, skipping stripWhitespaces"");"	<line6>	"log.warn(""Missing request content in context, skipping whitespace stripping"")"	"<line6> log.warn(""Missing request content in context, skipping whitespace stripping"")"
task5	"<line11>        log.error(""Unable to write portlet footer paths "" + portlet.getPortletId(), exception);"	<line11>	log.error(exception, exception)	<line11> log.error(exception, exception)
task5	"<line2>    Log.debug(""Test"");"	<line13>	"Log.info(""Total results: "" + totalResults)"	"<line13> Log.info(""Total results: "" + totalResults)"
task5	"<line5>      LOG.warn(""unexpected: taskid({}) missed."", taskid);"	<line2>	"log.debug(""Skip reporting for finished task {}"", taskid)"	"<line2> log.debug(""Skip reporting for finished task {}"", taskid)"
task5	"<line27>        LOG.info(projects.size() + "" projects: \n   "" + String.join(""\n   "", projectNameList.values()));"	<line27>	"log.info(""All projects in directory: "" + options.getDir())"	"<line27> log.info(""All projects in directory: "" + options.getDir())"
task5	"<line27>      log.error(""Unable to get field values from dynamic data mapping form ""+ ""instance record ""+ ddmFormInstanceRecord.getFormInstanceRecordId(),portalException);"	<line27>	log.error(portalException, portalException)	<line27> log.error(portalException, portalException)
task5	"<line26>      LOG.trace(""IGNORED"", e);"	<line26>	"log.error(""Cannot read jar file: "" + file, e)"	"<line26> log.error(""Cannot read jar file: "" + file, e)"
task5	<line36>      LOGGER.error(ex.getLocalizedMessage(), ex);	<line36>	"LOGGER.error(""Failed to serialize workflow trace with single custom connection."", ex)"	"<line36> LOGGER.error(""Failed to serialize workflow trace with single custom connection."", ex)"
task5	"<line9>      logger.info(""{} REQ {} {} {} {} {}"",reqId,ctx.request().remoteAddress(),tenant,ctx.request().method(),ctx.request().path(),mods);"	<line9>	"logger.info(""Request for tenant "" + tenant + "" received at "" + sample.getStartTime() + "" on module(s) "" + mods)"	"<line9> logger.info(""Request for tenant "" + tenant + "" received at "" + sample.getStartTime() + "" on module(s) "" + mods)"
task5	"<line13>      logger.info(""This is a pseudo-information message"");"	<line11>	"logger.info(""This is an informative message"")"	"<line11> logger.info(""This is an informative message"")"
task5	"<line20>      LOG.warn(""Can't update cache due to EventHub is too busy"");"	<line20>	"LOG.warn(""Failed to call event hub for cache, action: {}, type: {}, ids: {}"", action, type, ids, e)"	"<line20> LOG.warn(""Failed to call event hub for cache, action: {}, type: {}, ids: {}"", action, type, ids, e)"
task5	"<line9>      LOGGER.warn(""Line '{}' of contingency '{}' not found"", element.getId(), contingency.getId());"	<line9>	"LOGGER.warn(""Line '{}' of contingency '{}' not found"", element.getId(), contingency.getId())"	"<line9> LOGGER.warn(""Line '{}' of contingency '{}' not found"", element.getId(), contingency.getId())"
task5	"<line21>    log.debug(""Fragments for type ""+ docTypeName+ "": ""+ getTypeFragments(docTypeName)+ "", prefetch: ""+ getTypePrefetchedFragments(docTypeName));"	<line9>	"log.debug(""Prefetching fragments "" + fragment + "" for document type "" + docTypeName)"	"<line9> log.debug(""Prefetching fragments "" + fragment + "" for document type "" + docTypeName)"
task5	"<line3>    LOGGER.info(String.format(""**********DataSource %s has been closed,cost:%s ms.**********"", name, cost));"	<line3>	logger.info(LOG_COST_TIME_MILLISECONDS, dataSourceName, cost, isForceClosing, startTimeMilliseconds)	<line3> logger.info(LOG_COST_TIME_MILLISECONDS, dataSourceName, cost, isForceClosing, startTimeMilliseconds)
task5	"<line14>        logger.info(""Initializing syn1Neg..."");"	<line30>	"log.debug(""Model configured"")"	"<line30> log.debug(""Model configured"")"
task5	"<line45>        LOG.warn(""Exception raised while deleting directory {}"", stageDir, e);"	<line45>	"LOG.warn(""Failed to delete directory {}"", stageDir, e)"	"<line45> LOG.warn(""Failed to delete directory {}"", stageDir, e)"
task5	"<line9>      LOGGER.error(""The storage group of path {} doesn't exist."", path, e);"	<line9>	"logger.error(""get meta partition failed."", e)"	"<line9> logger.error(""get meta partition failed."", e)"
task5	<line18>      log.error(systemException, systemException);	<line18>	log.error(systemException, systemException)	<line18> log.error(systemException, systemException)
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	<line7>        log.debug(restoreEntryException, restoreEntryException);	<line7>	log.debug(restoreEntryException, restoreEntryException)	<line7> log.debug(restoreEntryException, restoreEntryException)
task5	"<line8>          logger.info(""Skipping sequence from queue ""+ genTree.getChanges()+ "" because it contains NO sequence""+ seq);"	<line16>	"log.warn(""Removing last generalised query tree containing no sequence. ""+ ""Returning last generalised query tree."")"	"<line16> log.warn(""Removing last generalised query tree containing no sequence. ""+ ""Returning last generalised query tree."")"
task5	"<line6>      logger.error(""Error Calling Workflow Engine"", e);"	<line6>	"logger.error(""Error Calling Workflow Engine"", e)"	"<line6> logger.error(""Error Calling Workflow Engine"", e)"
task5	"<line15>    logger.debug(""Source [{}] created. id={}, acces_token={}, key={}"",sourceName,map.get(""id""),map.get(""accessToken""),map.get(""key""));"	<line2>	"LOG.debug(""Creating custom source"")"	"<line2> LOG.debug(""Creating custom source"")"
task5	<line11>        log.debug(exception, exception);	<line11>	log.debug(exception, exception)	<line11> log.debug(exception, exception)
task5	<line5>      log.error(exception, exception);	<line5>	log.error(exception, exception)	<line5> log.error(exception, exception)
task5	"<line35>        log.error(""fail getParameter   [param]""+ param+ ""   [type]""+ paramtypes.getName()+ ""   [value]""+ PropertyUtil.reflectionToString(value));"	<line35>	"logger.warn(""Parameter {} with unexpected type {}"", param, value.getClass())"	"<line35> logger.warn(""Parameter {} with unexpected type {}"", param, value.getClass())"
task5	"<line16>      logger.warn(String.format(""Could not get database product type: %s"", e.getMessage()));"	<line16>	"logger.error(""Failed to get database scripts path: "" + e.getMessage(), e)"	"<line16> logger.error(""Failed to get database scripts path: "" + e.getMessage(), e)"
task5	"<line9>      logger.error(""Error loading disabling codes from file {}"", disablingCodesFileName, t);"	<line9>	"logger.error(""error while loading disabling codes file: "" + disablingCodesFileName, t)"	"<line9> logger.error(""error while loading disabling codes file: "" + disablingCodesFileName, t)"
task5	"<line12>        LOG.warn(""mapSoftRefValue: Was expecting AtlasObjectId, but found: {}"",ctx.getValue().getClass());"	<line12>	"LOG.warn(""mapSoftRefValue(): invalid value type: "" + ctx.getValue().getClass().getCanonicalName())"	"<line12> LOG.warn(""mapSoftRefValue(): invalid value type: "" + ctx.getValue().getClass().getCanonicalName())"
task5	"<line9>    LOGGER.info(String.format(""By default unknown fields are analyzed so here '%s' is ANALYZED."", name));"	<line9>	"log.warn(""Could not determine if ontology or vitam description is analyzed: "" + name)"	"<line9> log.warn(""Could not determine if ontology or vitam description is analyzed: "" + name)"
task5	<line8>      log.error(exception, exception);	<line8>	log.error(exception, exception)	<line8> log.error(exception, exception)
task5	"<line5>          Logger.trace(String.format(""< %02x"", d & 0xff));"	<line5>	"LOG.debug(""read - {}"", d)"	"<line5> LOG.debug(""read - {}"", d)"
task5	"<line2>    logger.error(""Default rollback method invoked on error. Error Code: "" + error.getCode());"	<line2>	"LOG.info(""Rollback message {} on error {}"", message, error)"	"<line2> LOG.info(""Rollback message {} on error {}"", message, error)"
task5	"<line5>      LOG.error(""Transforming FHIR data resulted in exception: {}"", ex.getLocalizedMessage(), ex);"	<line5>	"LOG.error(""Error transforming bundle to organization list: {}"", ex.getMessage(), ex)"	"<line5> LOG.error(""Error transforming bundle to organization list: {}"", ex.getMessage(), ex)"
task5	"<line14>          logger.error(""Error load configuration  {} "", e.getMessage());"	<line14>	"logger.error(""Failed to parse BPM configuration xml"", e)"	"<line14> logger.error(""Failed to parse BPM configuration xml"", e)"
task5	"<line2>    LOG.debug(""space "" + event.getSpace().getDisplayName() + "" was removed!"");"	<line2>	"logger.debug(""Space removed: "" + event.getSpace())"	"<line2> logger.debug(""Space removed: "" + event.getSpace())"
task5	"<line22>      log.error(""Invalid label Name "", e);"	<line22>	"log.error(""Error while parsing config details {}"", configDetails, e)"	"<line22> log.error(""Error while parsing config details {}"", configDetails, e)"
task5	"<line18>      LOG.debug(""Release Write {} lock on resource {} and {}"", resource.name, firstUser, secondUser);"	<line18>	"LOG.debug(""Released multi-user lock: "" + firstUser + "" or "" + secondUser)"	"<line18> LOG.debug(""Released multi-user lock: "" + firstUser + "" or "" + secondUser)"
task5	"<line47>                LOG.info(""inflight count: "" + coreQueue.getDeliveringCount());"	<line2>	"LOG.debug(""Starting the test"")"	"<line2> LOG.debug(""Starting the test"")"
task5	"<line3>      log.info(""here"");"	<line3>	"log.error(""port publisher not set"")"	"<line3> log.error(""port publisher not set"")"
task5	<line12>    logger.info(context_format,new Object[] {batchId, size, memsize, format.format(new Date()), startPosition, endPosition});	<line12>	"logger.info(""Batch #{}: Processed {} messages. Memory usage: {} bytes. Started: {}:{} - "",batchId,size,memsize,format.format(startPosition),format.format(endPosition))"	"<line12> logger.info(""Batch #{}: Processed {} messages. Memory usage: {} bytes. Started: {}:{} - "",batchId,size,memsize,format.format(startPosition),format.format(endPosition))"
task5	<line3>    LOGGER.info(String.format(Messages.Log.GETTING_INSTANCE_S, volumeOrder.getInstanceId()));	<line3>	LOGGER.info(String.format(Messages.Log.GETTING_INSTANCE_S, volumeOrder.getInstanceId()))	<line3> LOGGER.info(String.format(Messages.Log.GETTING_INSTANCE_S, volumeOrder.getInstanceId()))
task5	"<line1>    log.info(""Entering: focus"");"	<line4>	"log.info(""focus() failed for locator: "" + locator + "". Retrying once more."")"	"<line4> log.info(""focus() failed for locator: "" + locator + "". Retrying once more."")"
task5	"<line2>    LOGGER.info(""  test14ReadRead"");"	<line2>	"LOGGER.info(""  test14ReadRead"")"	"<line2> LOGGER.info(""  test14ReadRead"")"
task5	<line3>    LOGGER.info(String.format(Messages.Log.DELETING_INSTANCE_S, publicIpOrder.getInstanceId()));	<line3>	LOGGER.info(Messages.Log.DELETING_INSTANCE_S, publicIpOrder.getServiceOfferingName())	<line3> LOGGER.info(Messages.Log.DELETING_INSTANCE_S, publicIpOrder.getServiceOfferingName())
task5	"<line3>    LOG.info(""Received transaction end event, global tx id: {}"", request.getGlobalTxId());"	<line3>	"logger.info(""Received TccTransactionEnded event from service {} , global tx id: {}, local tx id: {}"",request.getServiceName(),request.getGlobalTxId(),request.getLocalTxId())"	"<line3> logger.info(""Received TccTransactionEnded event from service {} , global tx id: {}, local tx id: {}"",request.getServiceName(),request.getGlobalTxId(),request.getLocalTxId())"
task5	<line5>      LOGGER.warn(RelationalProviderI18n.threadAssociatedWithAnotherTransaction,Thread.currentThread().getName(),activeTx,id);	<line5>	"log.warn(""ModeShape has already started a transaction ('{0}')"", activeTx)"	"<line5> log.warn(""ModeShape has already started a transaction ('{0}')"", activeTx)"
task5	"<line2>    logger.debug(""generateConsumerInfo started..."");"	<line14>	"logger.debug(""generateConsumerInfo started..."")"	"<line14> logger.debug(""generateConsumerInfo started..."")"
task5	"<line8>      logger.info(String.format(""Took: %6.3f seconds"", (end - start) / NANOS));"	<line8>	"logger.info(String.format(""Elapsed time: %7.3f s"", (end - start) / NANOS))"	"<line8> logger.info(String.format(""Elapsed time: %7.3f s"", (end - start) / NANOS))"
task5	"<line4>      ActiveMQXARecoveryLogger.LOGGER.debug(""end "" + xaResource + "" xid "");"	<line4>	"ActiveMQXARecoveryLogger.LOGGER.debug(""end "" + xaResource + "" xid "")"	"<line4> ActiveMQXARecoveryLogger.LOGGER.debug(""end "" + xaResource + "" xid "")"
task5	"<line25>      logger.error(""Error while rendering content {}"", contentId, t);"	<line25>	"logger.error(""Error while rendering content {}"", contentId, t)"	"<line25> logger.error(""Error while rendering content {}"", contentId, t)"
task5	"<line14>      LOGGER.error(""Exception in getQualysDetail "", e);"	<line14>	"LOGGER.error(""Error in getQualysDetail "", e)"	"<line14> LOGGER.error(""Error in getQualysDetail "", e)"
task5	"<line2>      logger.debug(""Profile with id: \'"" + profileId + ""\' has been explicitly activated."");"	<line3>	"log.info(""Activated profile explicitly: "" + profileId)"	"<line3> log.info(""Activated profile explicitly: "" + profileId)"
task5	"<line27>      log.info(this, ""Will execute cmd: "" + cmd);"	<line27>	"log.info(this, ""Upgrade command: "" + cmd)"	"<line27> log.info(this, ""Upgrade command: "" + cmd)"
task5	"<line7>              logger.info(""shutdown "" + vm.getName() + "" guest OS failed, power off directly"");"	<line7>	"logger.info(""shutdown "" + vm.getName() + "" failed, power off directly."")"	"<line7> logger.info(""shutdown "" + vm.getName() + "" failed, power off directly."")"
task5	"<line4>      LOG.debug(""reload not forced and reload check disabled or check interval not yet elapsed"");"	<line10>	"log.info(""Configuration will be reloaded as per configuration provider state"")"	"<line10> log.info(""Configuration will be reloaded as per configuration provider state"")"
task5	"<line2>    LOGGER.info(""Consumer [{}] consume item [{}] produced by [{}]"", name, item.getId(), item.getProducer());"	<line2>	"log.info(""Received item: {}"", item)"	"<line2> log.info(""Received item: {}"", item)"
task5	<line5>        logger.info(factory.loadPolicy(policy).toString());	<line5>	"logger.info(""Testing policy: "" + policy.toString())"	"<line5> logger.info(""Testing policy: "" + policy.toString())"
task5	<line1>    log.trace(XTCE_ARRAY_PARAMETER_TYPE);	<line1>	log.trace(XTCE_ARRAY_PARAMETER_TYPE)	<line1> log.trace(XTCE_ARRAY_PARAMETER_TYPE)
task5	"<line7>        Logger.error(this, ""%s"", ExceptionUtils.getStackTrace(ex));"	<line8>	"Logger.error(this, ""failed to execute agent: %s"", agent.getClass().getSimpleName(), ex)"	"<line8> Logger.error(this, ""failed to execute agent: %s"", agent.getClass().getSimpleName(), ex)"
task5	<line7>      LOGGER.info(format(Messages.JOB_WITH_ID_AND_TASK_NAME_EXPIRED,jobEntity.getProcessInstanceId(),jobEntity.getElementName()));	<line7>	"log.warn(""Deleted job entity with id {} but no job found in the database"",event.getEntity().getId())"	"<line7> log.warn(""Deleted job entity with id {} but no job found in the database"",event.getEntity().getId())"
task5	"<line10>      log.error(""Error while opening editor."", e);"	<line10>	"LOG.error(""Error while opening editor for TodoViewItem"", e)"	"<line10> LOG.error(""Error while opening editor for TodoViewItem"", e)"
task5	"<line8>      logger.debug(""Jumping to page "" + getPage() + "" and index "" + current);"	<line8>	"logger.debug(""jumpToItem() - itemIndex: {}, page: {}, current: {}"",itemIndex,page,current)"	"<line8> logger.debug(""jumpToItem() - itemIndex: {}, page: {}, current: {}"",itemIndex,page,current)"
task5	"<line2>    LOG.info(""Executing operation getConceptsInDataCluster"");"	<line2>	"LOG.info(""Executing operation getConceptsInDataCluster"")"	"<line2> LOG.info(""Executing operation getConceptsInDataCluster"")"
task5	"<line11>      LOG.debug(""redirecting to login page loginPath"" + loginPath);"	<line9>	"logger.debug(""Ajax authentication failed. Sending back 401."")"	"<line9> logger.debug(""Ajax authentication failed. Sending back 401."")"
task5	"<line4>    LOG.warn(""No instance for WebSocketServer found, creating one with a fallback port: {}"",fallbackPort);"	<line4>	"log.info(""WebSocketServer not yet implemented"")"	"<line4> log.info(""WebSocketServer not yet implemented"")"
task5	"<line9>    LOG.info(""Loading service {}"", name);"	<line3>	"log.debug(""Adding global service '{}'"", name)"	"<line3> log.debug(""Adding global service '{}'"", name)"
task5	"<line5>      LOG.info(""Failure reading with GML3 parser. Trying with GML2"");"	<line5>	"LOGGER.info(""Reading Gml file failed with Gml3 configuration. Trying Gml2."", e)"	"<line5> LOGGER.info(""Reading Gml file failed with Gml3 configuration. Trying Gml2."", e)"
task5	"<line5>    logger.debug(""Deleting an alert {}."", alert);"	<line8>	"logger.debug(""Deleted alert {}."", alert)"	"<line8> logger.debug(""Deleted alert {}."", alert)"
task5	"<line7>        logger.warn(""Failed to get default properties for component: {}"", pid, e);"	<line7>	"logger.warn(""Error getting default properties for component: "" + pid, e)"	"<line7> logger.warn(""Error getting default properties for component: "" + pid, e)"
task5	"<line5>      logger.error(""Failed to retrieve server id from KieServerState"", e);"	<line5>	"LOGGER.error(""Error retrieving KieServerId from KieServerState. "", e)"	"<line5> LOGGER.error(""Error retrieving KieServerId from KieServerState. "", e)"
task5	<line16>      LOG.error(msg, e);	<line16>	LOG.error(msg, e)	<line16> LOG.error(msg, e)
task5	"<line2>    logger.debug(""Disposing weatherunderground bridge handler."");"	<line2>	"logger.debug(""Disposing Control API key manager."")"	"<line2> logger.debug(""Disposing Control API key manager."")"
task5	"<line8>      log.error(""Exception in loginProxy: "" + exception.getMessage());"	<line8>	"log.error(""Error occured while refreshing token"", exception)"	"<line8> log.error(""Error occured while refreshing token"", exception)"
task5	"<line1>    log.info(""Checking broker infra"");"	<line46>	"LOGGER.info(""Checking broker pod: {}"", broker.getMetadata().getName())"	"<line46> LOGGER.info(""Checking broker pod: {}"", broker.getMetadata().getName())"
task5	"<line1>    LOG.info(""Executing operation queryEndpoints"");"	<line1>	"log.debug(""queryEndpoints"")"	"<line1> log.debug(""queryEndpoints"")"
task5	"<line24>      log.info(""Connecting"");"	<line34>	"log.info(""Published and received {} messages"", messages.size())"	"<line34> log.info(""Published and received {} messages"", messages.size())"
task5	"<line10>      log.debug(""Monitoring thread was interrupted"", ex);"	<line10>	"log.debug(""Monitoring thread was interrupted"", ex)"	"<line10> log.debug(""Monitoring thread was interrupted"", ex)"
task5	"<line11>      LOG.error(""Error getting API Level by Service Name: {}"", ex.getLocalizedMessage(), ex);"	<line11>	"LOG.error(""Exception while retrieving api levels for service: {}"", serviceName, ex)"	"<line11> LOG.error(""Exception while retrieving api levels for service: {}"", serviceName, ex)"
task5	"<line3>      LOGGER.warn(""Get data "" + dataId + "" is null."");"	<line3>	"LOGGER.warn(""Requested data does not exist: "" + dataId)"	"<line3> LOGGER.warn(""Requested data does not exist: "" + dataId)"
task5	"<line4>      LOG.info(""Looking for SANs in cert: "" + cert.getTBSCertificate().getSubject());"	<line4>	"LOG.debug(""Checking certificate subject: {}"", cert.subjectDN())"	"<line4> LOG.debug(""Checking certificate subject: {}"", cert.subjectDN())"
task5	"<line2>      LOG.debug(""Copying folder(id={}) to destination_folder(id={}) {}"",folderId,destinationFolderId,newName == null ? """" : "" with new name '"" + newName + ""'"");"	<line2>	"LOG.debug(""Copying folder {} to {} with name {}"", folderId, destinationFolderId, newName)"	"<line2> LOG.debug(""Copying folder {} to {} with name {}"", folderId, destinationFolderId, newName)"
task5	"<line17>        Log.warn(""Unable to parse back-expiry for cache: "" + cacheInfo.getCacheName());"	<line17>	"Log.error(""Unable to parse maximum cache lifetime from property: ""+ lifetimeProp+ "". Using default value of ""+ CacheFactory.DEFAULT_MAX_CACHE_LIFETIME+ ""ms."")"	"<line17> Log.error(""Unable to parse maximum cache lifetime from property: ""+ lifetimeProp+ "". Using default value of ""+ CacheFactory.DEFAULT_MAX_CACHE_LIFETIME+ ""ms."")"
task5	"<line2>      LOGGER.info(""Skipping start controller step. Assumes controller is already started"");"	<line5>	"log.info(""Starting ZooKeeper Controller"")"	"<line5> log.info(""Starting ZooKeeper Controller"")"
task5	<line1>    logger.info(constructFormatOrMsg(eventName, format), arg);	<line1>	logger.info(constructFormatOrMsg(eventName, format), arg)	<line1> logger.info(constructFormatOrMsg(eventName, format), arg)
task5	<line6>        log.error(e, e);	<line6>	log.error(e, e)	<line6> log.error(e, e)
task5	"<line6>        logger.warn(""Interrupted while waiting for event latch."", e);"	<line6>	"logger.error(""Interrupted while waiting for index page"", e)"	"<line6> logger.error(""Interrupted while waiting for index page"", e)"
task5	<line15>      LOG.error(e);	<line15>	"LOG.error(""Error while deleting control from tree viewer"", e)"	"<line15> LOG.error(""Error while deleting control from tree viewer"", e)"
task5	<line4>    logger.debug(ExceptionUtils.getStackTrace(ex));	<line4>	"logger.debug("""", ex)"	"<line4> logger.debug("""", ex)"
task5	"<line12>                  LOG.error(""task info deserialization failed "" + e);"	<line12>	"LOG.error(""Failed to deserialize task info"", e)"	"<line12> LOG.error(""Failed to deserialize task info"", e)"
task5	"<line14>      logger.warn("""", pex);"	<line14>	"LOG.warn(""Could not parse date format: {}"", dateFormat, pex)"	"<line14> LOG.warn(""Could not parse date format: {}"", dateFormat, pex)"
task5	"<line9>      log.error(""ack {}"", evt, e);"	<line9>	"logger.error(""Error when sending ACK"", e)"	"<line9> logger.error(""Error when sending ACK"", e)"
task5	"<line8>      log.info(""Size {}: {} = {} % (diff: {}%)"", label, hist[i], format, error);"	<line8>	"log.info(String.format(""%s: %s%% (%s)"", label, format, error))"	"<line8> log.info(String.format(""%s: %s%% (%s)"", label, format, error))"
task5	"<line10>          log.debug(""Unable to parse JSON"", jsonException);"	<line10>	"log.debug(""Unable to parse JSON"", jsonException)"	"<line10> log.debug(""Unable to parse JSON"", jsonException)"
task5	"<line1>    logger.trace(""[{}] getSize() -> {}"", name, size);"	<line1>	"LOGGER.debug(""getting size = {}"", size)"	"<line1> LOGGER.debug(""getting size = {}"", size)"
task5	"<line24>                logger.error(""Error during remove repository"", e);"	<line24>	"LOGGER.error(""Error while removing repository [{}] from space [{}]"", alias, space.getName(), e)"	"<line24> LOGGER.error(""Error while removing repository [{}] from space [{}]"", alias, space.getName(), e)"
task5	"<line19>        logger.debug(""No ViewResolvers found in servlet '"" + getServletName() + ""': using default"");"	<line19>	"logger.debug(""No ViewResolvers found in servlet '"" + getServletName() + ""': using default"")"	"<line19> logger.debug(""No ViewResolvers found in servlet '"" + getServletName() + ""': using default"")"
task5	"<line10>      logger.error(""Error while updating the page metadata record for table {} and page {}"",PageMetadataDraft.TABLE_NAME,pageCode,t);"	<line10>	"logger.error(""Error while updating the page metadata record for table {} and page {}"",PageMetadataDraft.TABLE_NAME,pageCode,t)"	"<line10> logger.error(""Error while updating the page metadata record for table {} and page {}"",PageMetadataDraft.TABLE_NAME,pageCode,t)"
task5	"<line16>            log.debug(String.format(""Active instance is removed and added to the ""+ ""termination pending instance list. [Instance Id] %s"",instanceId));"	<line16>	"log.debug(""[moveActiveInstanceToTerminationPendingInstances] added active instance to the ""+ ""termination pending list: "" + activeInstance.getId())"	"<line16> log.debug(""[moveActiveInstanceToTerminationPendingInstances] added active instance to the ""+ ""termination pending list: "" + activeInstance.getId())"
task5	"<line9>          LOG.error(""Close channel for location "" + loc + "" error "", e);"	<line9>	"LOG.error(""close channel pool failed, "", e)"	"<line9> LOG.error(""close channel pool failed, "", e)"
task5	"<line15>      LOGGER.error(""error handling MQTT subscriptions"", ex);"	<line15>	"log.error(""Error handling entity changed event"", ex)"	"<line15> log.error(""Error handling entity changed event"", ex)"
task5	"<line28>      LOGGER.error(""Encrypt password in '"" + location + ""' error."", e);"	<line28>	"LOGGER.error(""Error encrypting properties file: "" + location, e)"	"<line28> LOGGER.error(""Error encrypting properties file: "" + location, e)"
task5	"<line19>        LOG.info(String.format(""psFunc: the best split after looping a split: fid[%d], fvalue[%d], loss gain[%f]""+ "", leftSumGrad[%f], leftSumHess[%f], rightSumGrad[%f], rightSumHess[%f]"",fid, splitIndex, lossGain, leftSumGrad, leftSumHess, rightSumGrad, rightSumHess));"	<line27>	"LOG.info(""merge split entry: "" + splitEntry)"	"<line27> LOG.info(""merge split entry: "" + splitEntry)"
task5	"<line22>      logger.error(""error in edit"", t);"	<line22>	"logger.error(""error in edit"", t)"	"<line22> logger.error(""error in edit"", t)"
task5	"<line14>        log.error(""Could not delete release from DB"", e);"	<line14>	"log.error(""Could not delete release with ID "" + releaseId, e)"	"<line14> log.error(""Could not delete release with ID "" + releaseId, e)"
task5	"<line4>    LOG.warn(""Featured occurrences have been removed."");"	<line4>	"log.warn(""Deprecated API used!"")"	"<line4> log.warn(""Deprecated API used!"")"
task5	"<line17>    LOG.info(""InputParallelism: ${""+ inputParallelism+ ""}, IndexParallelism: ${""+ config.getBloomIndexParallelism()+ ""}"");"	<line17>	"LOG.info(""Join Parallelism "" + joinParallelism)"	"<line17> LOG.info(""Join Parallelism "" + joinParallelism)"
task5	"<line6>    logger.error(""Cassandra schema not installed, starting administration services only"");"	<line2>	"LOG.info(""Starting Cassandra server"")"	"<line2> LOG.info(""Starting Cassandra server"")"
task5	"<line8>        this.logger.warn(""You're using the deprecated [{}] configuration property. You should instead use the ""+ ""newer [{}] one"",PROPERTY_DEPRECATED_PERMANENTDIRECTORY,""environment.permanentDirectory"");"	<line8>	"log.warn(""The use of the deprecated 'permanentdirectory' property is deprecated. ""+ ""Please use the 'application.dirs.permanent' property instead."")"	"<line8> log.warn(""The use of the deprecated 'permanentdirectory' property is deprecated. ""+ ""Please use the 'application.dirs.permanent' property instead."")"
task5	"<line3>      logger.debug(""Cache remove: "" + userCert.getSubjectDN());"	<line3>	"logger.debug(""Removing user from cache: "" + userCert.getSubjectDN())"	"<line3> logger.debug(""Removing user from cache: "" + userCert.getSubjectDN())"
task5	"<line3>      logger.trace(""addBooleanField fieldName: {}; value: {}"", fieldName, value);"	<line3>	"logger.trace(""addBooleanField fieldName: {}; value: {}"", fieldName, value)"	"<line3> logger.trace(""addBooleanField fieldName: {}; value: {}"", fieldName, value)"
task5	"<line11>      logger.error(""Some parser properties are not supported."");"	<line11>	"LOG.warn(""Failed to set secure processing to true"", e)"	"<line11> LOG.warn(""Failed to set secure processing to true"", e)"
task5	"<line10>      logger.error("""", fex);"	<line10>	"logger.error(""Error in isRegularFile() of abstract ftp file"", fex)"	"<line10> logger.error(""Error in isRegularFile() of abstract ftp file"", fex)"
task5	"<line5>      logger.error(""Exception in cache service: {} "", ex.getMessage());"	<line5>	"logger.error(""Exception in cache service: {} "", ex.getMessage())"	"<line5> logger.error(""Exception in cache service: {} "", ex.getMessage())"
task5	"<line6>    LOGGER.info(""Activate organisation: {}."", request.getOrganisationIdentification());"	<line6>	"LOGGER.info(""ActivateOrganisationRequest received from organisation: {}."",organisationIdentification)"	"<line6> LOGGER.info(""ActivateOrganisationRequest received from organisation: {}."",organisationIdentification)"
task5	"<line3>    log.trace(""[{}][{}][{}] Processing change resource"",tenantId,resource.getResourceType(),resource.getResourceKey());"	<line3>	"log.trace(""[{}] Processing resource change event: {}"", tenantId, resource)"	"<line3> log.trace(""[{}] Processing resource change event: {}"", tenantId, resource)"
task5	"<line2>    Log.debug(""Test"");"	<line2>	"logger.info(""Test"")"	"<line2> logger.info(""Test"")"
task5	"<line2>    LOG.info(""Registering the trigger named \""{}\"""", getName());"	<line1>	"log.info(""registering suspension consumer"")"	"<line1> log.info(""registering suspension consumer"")"
task5	"<line9>        logger.error(""Error while loading implementations of {}"",service.getName(),serviceConfigurationError);"	<line9>	LOGGER.error(serviceConfigurationError.getMessage(), serviceConfigurationError)	<line9> LOGGER.error(serviceConfigurationError.getMessage(), serviceConfigurationError)
task5	"<line17>    LOG.info(""Current Snapshot Index {}, takeSnapshot took {} ms"",lastAppliedIndex,Time.monotonicNow() - startTime);"	<line17>	"LOG.info(""Transaction log snapshot taken at {}"", startTime)"	"<line17> LOG.info(""Transaction log snapshot taken at {}"", startTime)"
task5	"<line10>        log.warn(""Cache Listener thread interrupted in MultiThreadedListener."", e);"	<line10>	"log.debug(""Interrupted while waiting for shutdown request."", e)"	"<line10> log.debug(""Interrupted while waiting for shutdown request."", e)"
task5	"<line9>      log.warn(""Error checking string constraint "" + this, e);"	<line9>	"log.warn(""Unable to get string value of argument "" + value, e)"	"<line9> log.warn(""Unable to get string value of argument "" + value, e)"
task5	"<line2>      logger.trace(""addNULLField fieldValue: {}"", fieldValue);"	<line2>	"logger.trace(""addNullField fieldValue: {}"", fieldValue)"	"<line2> logger.trace(""addNullField fieldValue: {}"", fieldValue)"
task5	"<line16>        logger.info(""{} {}: error: {}"", method, url, e.getMessage());"	<line16>	"logger.warn(""Failed to query {}: {}"", url, e.getMessage())"	"<line16> logger.warn(""Failed to query {}: {}"", url, e.getMessage())"
task5	"<line52>      log.info(""Using version: "" + topVer);"	<line52>	"log.info(""Topology version: "" + topVer)"	"<line52> log.info(""Topology version: "" + topVer)"
task5	"<line10>      LOG.info(""Update rows {}"", count);"	<line10>	"LOG.info(""Update rows {}"", count)"	"<line10> LOG.info(""Update rows {}"", count)"
task5	"<line7>      LOG.error(""Connector not found {}"", resourceTO.getConnector(), e);"	<line7>	"LOGGER.error(""Error while checking resource"", e)"	"<line7> LOGGER.error(""Error while checking resource"", e)"
task5	"<line9>      log.info(""Value found in SystemSettings: dataValuePageSize: "" + dataValuesPageSize);"	<line2>	"log.info(""Fetching data values page size from system settings"")"	"<line2> log.info(""Fetching data values page size from system settings"")"
task5	"<line12>    LOGGER.info(""ServerProfile object returned to client : "" + serverProfileUpdated.toJsonString());"	<line12>	"LOGGER.info(""ServerProfile object returned to client : "" + serverProfileUpdated.toJsonString())"	"<line12> LOGGER.info(""ServerProfile object returned to client : "" + serverProfileUpdated.toJsonString())"
task5	"<line4>        log.debug(""updateProcessBusinessKeyInHistory : {}"", processInstance.getId());"	<line4>	"log.debug(""Updating business key in history for process instance id "" + processInstance.getId())"	"<line4> log.debug(""Updating business key in history for process instance id "" + processInstance.getId())"
task5	"<line2>    LOG.debug(""starting {}"", getClass().getSimpleName());"	<line2>	"LOG.debug(""run with configuration {}"", conf)"	"<line2> LOG.debug(""run with configuration {}"", conf)"
task5	"<line10>            logger.error(""scan failed"", e);"	<line10>	"log.error(""Unknown error"", e)"	"<line10> log.error(""Unknown error"", e)"
task5	<line13>      logger.debug(marker, format, argArray);	<line13>	logger.debug(marker, format, argArray)	<line13> logger.debug(marker, format, argArray)
task5	"<line8>        LOGGER.info(""Loaded coverage store '""+ cs.getName()+ ""', ""+ (cs.isEnabled() ? ""enabled"" : ""disabled""));"	<line8>	"LOGGER.info(""Loaded coverage store '"" + storeResource.name() + ""'"")"	"<line8> LOGGER.info(""Loaded coverage store '"" + storeResource.name() + ""'"")"
task5	"<line11>            log.info(""Updating identity type {}, setting confirmationConfiguration to {}"",name,emailConfig.toJson());"	<line9>	"log.info(""Updating "" + name + "" identityType with email confirmation configuration."")"	"<line9> log.info(""Updating "" + name + "" identityType with email confirmation configuration."")"
task5	"<line3>      log.error(""processHandle is null when looking up elapsed time"");"	<line3>	"log.debug(""No process handle found for search index update"")"	"<line3> log.debug(""No process handle found for search index update"")"
task5	"<line4>      log.error(""Cannot save complex data where obsId=""+ obs.getObsId()+ "" because its ComplexData is null."");"	<line38>	"log.error(""Unable to close file writer"", e)"	"<line38> log.error(""Unable to close file writer"", e)"
task5	"<line1>    log.debug(""Fixing lateral caches:"");"	<line7>	"log.info(""Fixed caches"")"	"<line7> log.info(""Fixed caches"")"
task5	"<line6>    log.debug(""sparql-based matching for atom {} (found {} matches)"",atomURI,bulkHintEvent.getHintEvents().size());"	<line3>	"logger.debug(""Publishing BulkHintEvent for atom {}"", atomURI)"	"<line3> logger.debug(""Publishing BulkHintEvent for atom {}"", atomURI)"
task5	"<line14>      log.debug(""Loading artifact to the command object for editing."");"	<line6>	"log.debug(""Preparing data for form"")"	"<line6> log.debug(""Preparing data for form"")"
task5	"<line7>    LOGGER.info(""Discover Object Instance : ""+ ""Object = ""+ theObject.toString()+ "", Object class = ""+ theObjectClass.toString()+ "", Object name = ""+ objectName+ "", Producing federate = ""+ producingFederate.toString());"	<line7>	"log.info(""discoverObjectInstance()"")"	"<line7> log.info(""discoverObjectInstance()"")"
task5	<line10>      log.error(exception, exception);	<line10>	log.error(exception.getMessage(), exception)	<line10> log.error(exception.getMessage(), exception)
task5	"<line3>    LOGGER.debug(""Creating topic: ""+ topic+ "" , partitions: ""+ partitions+ "" , ""+ ""replication factor: ""+ replicationFactor+ ""."");"	<line2>	"log.info(""Creating topic {} with {} partitions and {} replication factor"",topic,partitions,replicationFactor)"	"<line2> log.info(""Creating topic {} with {} partitions and {} replication factor"",topic,partitions,replicationFactor)"
task5	"<line3>    logger.info(""Validating service name"");"	<line3>	"logger.info(""Validating service name"")"	"<line3> logger.info(""Validating service name"")"
task5	<line6>      log.error(exception, exception);	<line6>	log.error(exception, exception)	<line6> log.error(exception, exception)
task5	"<line18>            logger.warn("""", fex);"	<line18>	"logger.warn("""", fex)"	"<line18> logger.warn("""", fex)"
task5	"<line8>        logger.info(""Paused {}"", this);"	<line9>	"logger.info(""GatewaySender paused using the new API"")"	"<line9> logger.info(""GatewaySender paused using the new API"")"
task5	"<line29>    logger.info(""Setting number of cooperative threads and default parallelism to ""+ config.getInstanceConfig().getCooperativeThreadCount());"	<line38>	"logger.info(""Jet extension initialized"")"	"<line38> logger.info(""Jet extension initialized"")"
task5	"<line4>      log.debug(""key:"" + entry.getKey() + "" value:"" + entry.getValue());"	<line6>	"logger.debug(""adding boxId "" + boxId + "" to list"")"	"<line6> logger.debug(""adding boxId "" + boxId + "" to list"")"
task5	<line26>          log.debug(exception, exception);	<line26>	log.debug(exception, exception)	<line26> log.debug(exception, exception)
task5	"<line3>      ActiveMQRALogger.LOGGER.trace(""readShort()"");"	<line3>	"ActiveMQRALogger.LOGGER.trace(""readShort()"")"	"<line3> ActiveMQRALogger.LOGGER.trace(""readShort()"")"
task5	"<line8>      LOG.info(""zkclient{} watchForChilds path not existing:{} skipWatchingNodeNoteExist: {}"",_uid,path,skipWatchingNonExistNode);"	<line8>	"LOG.debug(""watching node {} failed: ZkNoNodeException"", path, e)"	"<line8> LOG.debug(""watching node {} failed: ZkNoNodeException"", path, e)"
task5	"<line37>      LOGGER.info(getClass().getSimpleName() + ""::onEntry,"" + infoLog);"	<line37>	LOGGER.info(infoLog)	<line37> LOGGER.info(infoLog)
task5	"<line14>        log.warn(""Unable to get info item field values provider for class "" + className);"	<line14>	"log.warn(""No info item field values provider was found for the class name "" + className)"	"<line14> log.warn(""No info item field values provider was found for the class name "" + className)"
task5	"<line4>        logger.info(""Shutting down the proxy..."");"	<line4>	"logger.info(""Shutting down: Clearing managed executors..."")"	"<line4> logger.info(""Shutting down: Clearing managed executors..."")"
task5	"<line2>      LOG.error(""invalid ledgerId {} < 0"", ledgerId);"	<line2>	"LOG.warn(""Ledger ID {} is negative!"", ledgerId)"	"<line2> LOG.warn(""Ledger ID {} is negative!"", ledgerId)"
task5	"<line17>            logger.debug(""Skipping value for "" + name);"	<line17>	"LOG.info(""Skipping unsupported version {}"", name)"	"<line17> LOG.info(""Skipping unsupported version {}"", name)"
task5	"<line7>                log.debug(String.format(""Incremented Redis key %s to %d"", sizeKey, incremented));"	<line7>	"log.debug(""Storage size incremented to: "" + incremented)"	"<line7> log.debug(""Storage size incremented to: "" + incremented)"
task5	<line3>    LOGGER.info(Messages.Log.REQUESTING_INSTANCE_FROM_PROVIDER);	<line4>	LOGGER.info(String.format(Messages.Log.CREATING_INSTANCE_S, resourceName))	<line4> LOGGER.info(String.format(Messages.Log.CREATING_INSTANCE_S, resourceName))
task5	"<line8>      log.warn(""Exception occurred while shutting down HSQLDB :"" + StringUtils.stringifyException(ex));"	<line8>	"log.warn(""error stopping server"", ex)"	"<line8> log.warn(""error stopping server"", ex)"
task5	"<line1>    logger.debug(""Bridge: Checking for valid Zoneminder host: {}"", host);"	<line7>	"logger.debug(""Can't get version information"")"	"<line7> logger.debug(""Can't get version information"")"
task5	"<line22>          log.error(""caught exception closing InputStream: "" + e);"	<line22>	"LOG.DEBUG(""unable to close stream for properties file '"" + getFileName() + ""'"", e)"	"<line22> LOG.DEBUG(""unable to close stream for properties file '"" + getFileName() + ""'"", e)"
task5	"<line10>                  log.info(""Client Cert SubjectDN: {}"", principal.getName());"	<line16>	"LOG.error(""Cannot start conversion without SSLSession"")"	"<line16> LOG.error(""Cannot start conversion without SSLSession"")"
task5	"<line6>      LOGGER.warn(""Cannot index null enum, skipping entry"");"	<line34>	"LOGGER.debug(""returning insertion ids for {}"", entry)"	"<line34> LOGGER.debug(""returning insertion ids for {}"", entry)"
task5	<line13>      LOG.trace(e.getMessage());	<line13>	"log.error(""Error getting core NetworkService"", e)"	"<line13> log.error(""Error getting core NetworkService"", e)"
task5	"<line6>      logger.error(""Unable to parse access policy"", e);"	<line6>	"LOG.warn(""Could not parse ACL from event"", e)"	"<line6> LOG.warn(""Could not parse ACL from event"", e)"
task5	"<line3>      log.info(""Element ["" + this + ""] set next write value to ["" + valueOpt.orElse(null) + ""]."");"	<line3>	"log.info(""Element ["" + this.name() + ""] set next write value to ["" + valueOpt.orElse(null) + ""]."")"	"<line3> log.info(""Element ["" + this.name() + ""] set next write value to ["" + valueOpt.orElse(null) + ""]."")"
task5	"<line11>      logger.debug(""No Result found: "" + e);"	<line11>	"logger.debug(""No Result found: "" + e)"	"<line11> logger.debug(""No Result found: "" + e)"
task5	"<line1>    logger.debug(""onNewConnection"");"	<line1>	"logger.info(""New filebeat connection."")"	"<line1> logger.info(""New filebeat connection."")"
task5	"<line7>        logger.warn(""Failed to insert address result in the DB "" + e.getMessage());"	<line7>	"LOGGER.error(""Could not log address"", e)"	"<line7> LOGGER.error(""Could not log address"", e)"
task5	"<line16>        Log.error(""Unable to send presence information of user '{}' to unblocked entity '{}' as local""+ "" user is not found."",user.getUsername(),recipient);"	<line16>	"Log.warn(""Recipient '{}' not found"", recipient)"	"<line16> Log.warn(""Recipient '{}' not found"", recipient)"
task5	"<line19>        log.error(""Oups, Set of task id's is not of type Set<Integer>, can't migrate this list."");"	<line13>	"log.error(""Failed to restore user preferences object: "" + userPrefs.getKey())"	"<line13> log.error(""Failed to restore user preferences object: "" + userPrefs.getKey())"
task5	"<line31>          LOGGER.warn(""Unknown parameter group. That should not happen."");"	<line31>	"LOGGER.info(""Ignoring unknown parameter type: "" + parameterGroup)"	"<line31> LOGGER.info(""Ignoring unknown parameter type: "" + parameterGroup)"
task5	"<line8>      logger.trace(""Permission denied for reading sequencing object id=""+ sf.getId()+ "" by user=""+ authentication.getName()+ "", no joined sample found."");"	<line8>	"logger.warn(""No sample found for sequencing object "" + sf.getId())"	"<line8> logger.warn(""No sample found for sequencing object "" + sf.getId())"
task5	"<line2>    log.info(""The method [ {} ] of bean [ {} ] is candidate to be overridden by plugin child contexts"",m.toString(),id);"	<line2>	"logger.debug(""Found proxy candidate {} for bean {} with id {}"",m,bean.getClass(),id)"	"<line2> logger.debug(""Found proxy candidate {} for bean {} with id {}"",m,bean.getClass(),id)"
task5	"<line13>        LOG.error(""Could not serialize new user {}"", newUser, e);"	<line13>	"LOG.error(""Could not find self-registration page for user {}"", newUser.getUsername(), e)"	"<line13> LOG.error(""Could not find self-registration page for user {}"", newUser.getUsername(), e)"
task5	<line28>        log.debug(workflowException, workflowException);	<line28>	log.debug(workflowException, workflowException)	<line28> log.debug(workflowException, workflowException)
task5	"<line4>      logger.error(""No GBIDs found in default properties: {}"", joynrDefaultProperties);"	<line4>	"logger.error(""No GBIDs found in default properties. Check your messaging properties file."")"	"<line4> logger.error(""No GBIDs found in default properties. Check your messaging properties file."")"
task5	"<line2>    LOG.info(""Removing completed compaction instant ("" + instant + "")"");"	<line12>	"LOG.info(""Removed "" + instant + "" from pending compaction instant file"")"	"<line12> LOG.info(""Removed "" + instant + "" from pending compaction instant file"")"
task5	"<line11>        LOGGER.warn(""{} does not appear in {}!"", path, mcrPath.getOwner());"	<line11>	"LOGGER.info(""File {} not in group {}"", file, fileGroup)"	"<line11> LOGGER.info(""File {} not in group {}"", file, fileGroup)"
task5	"<line3>    LOGGER.info(""actual output;\n{}"", jobSource.getByteSource().asCharSource(Charsets.UTF_8).read());"	<line2>	"log.info(""Obtaining job data for snapshot {}"", snapshot)"	"<line2> log.info(""Obtaining job data for snapshot {}"", snapshot)"
task5	"<line9>        LOG.info(""JPSONIC_HOME directory will be {}"", jpsonicHomeDirForTest.getAbsolutePath());"	<line9>	"LOG.info(""Using temporary JPSONIC_HOME directory for tests: "" + jpsonicHomeDirForTest)"	"<line9> LOG.info(""Using temporary JPSONIC_HOME directory for tests: "" + jpsonicHomeDirForTest)"
task5	"<line5>      logger.info(""Could not scan, as there is no USB-Serial discovery service configured."");"	<line5>	"logger.warn(""USB Serial Discovery service not available for this platform."")"	"<line5> logger.warn(""USB Serial Discovery service not available for this platform."")"
task5	"<line57>      logger.debug(""cuboid-{} saved dimension:{}, took: {}ms"",cuboidId,dimension.getName(),stopwatch.elapsed(MILLISECONDS));"	<line57>	"logger.debug(""persist dimension "" + dimension.getName() + "" takes "" + stopwatch.elapsed(MILLISECONDS))"	"<line57> logger.debug(""persist dimension "" + dimension.getName() + "" takes "" + stopwatch.elapsed(MILLISECONDS))"
task5	"<line23>    LOGGER.info(""Reloading only package {} took {}ms"", packageName, System.currentTimeMillis() - start);"	<line23>	"log.info(""Reload of package {} took {} ms."", packageName, System.currentTimeMillis() - start)"	"<line23> log.info(""Reload of package {} took {} ms."", packageName, System.currentTimeMillis() - start)"
task5	"<line19>        logger.debug(""Unable to createCq. Error: {}"", cqe.getMessage(), cqe);"	<line19>	"logger.debug(""Unable to createCq. Error: {}"", cqe.getMessage(), cqe)"	"<line19> logger.debug(""Unable to createCq. Error: {}"", cqe.getMessage(), cqe)"
task5	"<line7>      LOG.warn(""Exception hit while trying to recreate directory: "" + destPath.getParent().toString());"	<line7>	"logger.error(""Could not create folder for file {}"", destPath, e)"	"<line7> logger.error(""Could not create folder for file {}"", destPath, e)"
task5	"<line2>    logger.debug(""Start scan for Sensibo devices."");"	<line23>	"logger.debug(""Discovered {}"", discoveryResult)"	"<line23> logger.debug(""Discovered {}"", discoveryResult)"
task5	"<line10>          logger.fatal(""Unknown error closing streamer: {}"", e.getMessage(), e);"	<line10>	"log.warn(""Exception closing msg streamer"", e)"	"<line10> log.warn(""Exception closing msg streamer"", e)"
task5	"<line12>        logger.debug(""Error sending CQ request to peers. {}"", ex.getLocalizedMessage(), ex);"	<line12>	"logger.debug(""Exception while sending CQ profile operation : {}"", ex.getMessage(), ex)"	"<line12> logger.debug(""Exception while sending CQ profile operation : {}"", ex.getMessage(), ex)"
task5	"<line25>      LOG.error(""While exporting SAML 2.0 SP metadata"", e);"	<line25>	"LOG.error(""While downloading SAML2 SP metadata"", e)"	"<line25> LOG.error(""While downloading SAML2 SP metadata"", e)"
task5	"<line13>      logger.error(""Error extracting auths for user {}"", username, e);"	<line13>	"logger.error(""Error extracting auths for user {}"", username, e)"	"<line13> logger.error(""Error extracting auths for user {}"", username, e)"
task5	"<line5>    log.debug(""run_custom_filter"");"	<line8>	"log.debug(""running custom filter: "" + name)"	"<line8> log.debug(""running custom filter: "" + name)"
task5	"<line4>      logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Read Boolean {}"", value);"	<line4>	"logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Read Boolean {}"", value)"	"<line4> logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Read Boolean {}"", value)"
task5	"<line6>    LOGGER.info(""Get Tariff Schedule Response Request received from organisation: {} for correlationUID:""+ "" {}."",organisationIdentification,request.getAsyncRequest().getCorrelationUid());"	<line6>	"LOGGER.info(""Set Schedule Request received from organisation: {} for device: {}."",organisationIdentification,request.getDeviceIdentification())"	"<line6> LOGGER.info(""Set Schedule Request received from organisation: {} for device: {}."",organisationIdentification,request.getDeviceIdentification())"
task5	"<line23>      log.debug(""printenv({}) {}={}"", getServerChannelSession(), varName, varValue);"	<line23>	"log.debug(""printenv: variable value {} for {}"", varValue, varName)"	"<line23> log.debug(""printenv: variable value {} for {}"", varValue, varName)"
task5	<line5>      log.warn(e.getMessage(), e);	<line5>	log.error(e, e)	<line5> log.error(e, e)
task5	"<line10>          logger.warn(""Skipping entry with id ""+ entry.getId()+ "" since it has the same date as our last feed update."");"	<line10>	"LOGGER.info(""Skipping entry "" + entry.toString())"	"<line10> LOGGER.info(""Skipping entry "" + entry.toString())"
task5	"<line3>    LOG.info(""using GDAL command line to tranform the coverage"");"	<line7>	"LOGGER.info(""Reprojected file written to temporary directory "" + tmpDir)"	"<line7> LOGGER.info(""Reprojected file written to temporary directory "" + tmpDir)"
task5	"<line4>        LOGGER.trace(""Purge Occured: "" + cmd);"	<line4>	"LOGGER.trace(""Purging geometry occurrences within "" + bounds)"	"<line4> LOGGER.trace(""Purging geometry occurrences within "" + bounds)"
task5	"<line6>      LOG.error(""Failed to get user name from uid {}, fallback to {}"", uid, DEFAULT_USER_NAME);"	<line6>	"LOG.error(""Failed to load user name for uid {}: {}"", uid, e.toString())"	"<line6> LOG.error(""Failed to load user name for uid {}: {}"", uid, e.toString())"
task5	"<line10>    log.info(""{} zookeeper client register success: {}"", rpcType, metadata.toString());"	<line2>	"LOGGER.info(""persistInterface, metadata: {}"", metadata.toString())"	"<line2> LOGGER.info(""persistInterface, metadata: {}"", metadata.toString())"
task5	"<line3>    LOGGER.debug(""Setting client caching status to {}"", packet.isEnabled());"	<line3>	"LOGGER.debug(""Received client cache status packet from server: {}"", packet)"	"<line3> LOGGER.debug(""Received client cache status packet from server: {}"", packet)"
task5	<line5>      log.error(exception, exception);	<line5>	"log.error(""Unable to initialize portal"", exception)"	"<line5> log.error(""Unable to initialize portal"", exception)"
task5	<line15>        log.debug(sb.toString());	<line15>	log.debug(sb.toString())	<line15> log.debug(sb.toString())
task5	<line18>      log.error(systemException, systemException);	<line18>	log.error(systemException, systemException)	<line18> log.error(systemException, systemException)
task5	"<line6>        LOG.error(""load task meta from file failed."", e);"	<line6>	"LOG.error(""load ps meta info failed."", e)"	"<line6> LOG.error(""load ps meta info failed."", e)"
task5	"<line2>    logger.debug(""Close rocks db."");"	<line2>	"LOG.info(""Closing RocksDB instance"")"	"<line2> LOG.info(""Closing RocksDB instance"")"
task5	<line11>              logger.debug(problem.getMessage(), problem.getException());	<line11>	logger.debug(problem.getMessage(), problem.getException())	<line11> logger.debug(problem.getMessage(), problem.getException())
task5	"<line3>    LOGGER.debug(""[{}] Blocked inbound from all destinations"", address);"	<line3>	"log.debug(""blockAllInbound: all inbound ports blocked"")"	"<line3> log.debug(""blockAllInbound: all inbound ports blocked"")"
task5	"<line18>    logger.debug(""Received request to Deactivate an Operational Environment"");"	<line18>	"logger.debug(""Received request to deactivate Operational Environment"")"	"<line18> logger.debug(""Received request to deactivate Operational Environment"")"
task5	"<line3>        log.debug(""Loading font "" + ttf);"	<line3>	"log.debug(""loading font "" + ttf)"	"<line3> log.debug(""loading font "" + ttf)"
task5	"<line5>      LOGGER.error(""An exception occurred during validation of field - {}, objectName - {}, value - {}"",field,objectName,value);"	<line5>	LOGGER.error(e.getMessage(), e)	<line5> LOGGER.error(e.getMessage(), e)
task5	"<line3>    log.info(""Starting TEST optimizer for the TOSCA syntax of September 2015 Of an ""+ TEST_CHARACTERISTIC);"	<line3>	"log.info(""Starting TEST optimizer for the TOSCA syntax of September 2015"")"	"<line3> log.info(""Starting TEST optimizer for the TOSCA syntax of September 2015"")"
task5	"<line5>      logger.warn(""Instance ID has changed from "" + bootstrapId + "" to "" + id);"	<line5>	"logger.info(""Cms instance id "" + id + "" does not match bootstrap instance id "" + bootstrapId)"	"<line5> logger.info(""Cms instance id "" + id + "" does not match bootstrap instance id "" + bootstrapId)"
task5	"<line2>    log.info(""Got event PaymentError token='{}'"", event.getUserToken());"	<line2>	"LOG.info(""Got event {}"", event)"	"<line2> LOG.info(""Got event {}"", event)"
task5	<line15>      log.error(exception, exception);	<line15>	log.error(exception, exception)	<line15> log.error(exception, exception)
task5	"<line6>      logger.debug(""[{}] Websocket connection closed with code {} reason : {}"", debugId, statusCode, reason);"	<line2>	"logger.debug(""{}: onClose {}"", getThing().getUID(), reason)"	"<line2> logger.debug(""{}: onClose {}"", getThing().getUID(), reason)"
task5	"<line1>    LOGGER.info(""Channel active: {}"", ctx.channel());"	<line1>	"logger.debug(""Connection established from {}"", ctx.channel().remoteAddress())"	"<line1> logger.debug(""Connection established from {}"", ctx.channel().remoteAddress())"
task5	"<line1>    LOG.debug(""CONNECTED STATE: Cancelling Timeouts in handleError"");"	<line18>	"LOG.info(""Close channel "" + channelName + "" after error."")"	"<line18> LOG.info(""Close channel "" + channelName + "" after error."")"
task5	"<line6>      LOG.error(""Failed to send metrics: "", e);"	<line6>	"LOG.error(""Failed to register gauge "" + metricName, e)"	"<line6> LOG.error(""Failed to register gauge "" + metricName, e)"
task5	"<line21>    LOG.debug(""Parsed retry policy BoundedExponentialBackoffRetry with ""+ ""baseSleepTime:{}, maxSleepTime:{}, maxRetries:{}, maxElapsedTime:{}"",new Object[] {baseSleepTime, maxSleepTime, maxRetries, maxElapsedTime});"	<line22>	"log.error(""Invalid configuration for retry policy: {}"", boundedExponentialBackoffRetryConfig)"	"<line22> log.error(""Invalid configuration for retry policy: {}"", boundedExponentialBackoffRetryConfig)"
task5	"<line5>    LOGGER.debug(""Registering handler {} -> {}"", key, handler);"	<line12>	"logger.debug(""EventHandlerMethod added: {}"", handler.getMethodDescription())"	"<line12> logger.debug(""EventHandlerMethod added: {}"", handler.getMethodDescription())"
task5	"<line5>      logger.warn(String.format(""Unhandled exception happened when running %s"", task.getClass().getName()),t);"	<line5>	"logger.error(""Unable to execute task right now"", t)"	"<line5> logger.error(""Unable to execute task right now"", t)"
task5	"<line5>        logger.debug(format(""Channel %s removing mapping peer %s to mspid %s"", name, peer, mspid));"	<line7>	"logger.trace(""Removing peer {} from mspid map: {}"", peer, mspid)"	"<line7> logger.trace(""Removing peer {} from mspid map: {}"", peer, mspid)"
task5	<line12>      LOG.error(e.getMessage(), e);	<line12>	"LOG.warn(""Unable to read XML input source"", e)"	"<line12> LOG.warn(""Unable to read XML input source"", e)"
task5	"<line14>    LOG.debug(""Creating SaslServer for {} with mechanism {}"", kerberosName, saslMechanism);"	<line26>	"log.error(""Kafka Server failed to create a SaslServer to interact with a client during session""+ "" authentication"",e.getCause())"	"<line26> log.error(""Kafka Server failed to create a SaslServer to interact with a client during session""+ "" authentication"",e.getCause())"
task5	"<line13>      LOGGER.warn(""Something going wrong here..."");"	<line13>	"LOGGER.warn(""ArrayIndexOutOfBoundsException while preparing Cek and MacKey."")"	"<line13> LOGGER.warn(""ArrayIndexOutOfBoundsException while preparing Cek and MacKey."")"
task5	"<line6>    LOGGER.info(""Created scope object returned to client : "" + createdScope.toJsonString());"	<line6>	"LOG.info(""Created scope: {}"", createdScope.getName())"	"<line6> LOG.info(""Created scope: {}"", createdScope.getName())"
task5	"<line19>      LOGGER.error(""Cannot create folder"", e);"	<line19>	"LOGGER.error(""Cannot create folder"", e)"	"<line19> LOGGER.error(""Cannot create folder"", e)"
task5	"<line14>        logger.debug(""Scheduled strategy {} with cron expression {}"",cronStrategy.getName(),cronExpression);"	<line14>	"LOG.info(""Started timer '{}' for database '{}' on collection '{}'"",job.getName(),dbId,strategy.getCollectionId())"	"<line14> LOG.info(""Started timer '{}' for database '{}' on collection '{}'"",job.getName(),dbId,strategy.getCollectionId())"
task5	"<line5>      logger.error(""Registration resp. initialization of child '{}' of bridge '{}' has been failed: {}"",child.getUID(),bridge.getUID(),ex.getMessage(),ex);"	<line5>	"logger.warn(""Failed to initialize handler for child thing '{}'."", child.getUID().getId(), ex)"	"<line5> logger.warn(""Failed to initialize handler for child thing '{}'."", child.getUID().getId(), ex)"
task5	"<line2>      this.logger.info(""Rx :  DialogRelease="" + evt);"	<line2>	"logger.info(""DialogRelease, local tag="" + evt.getLocalTag())"	"<line2> logger.info(""DialogRelease, local tag="" + evt.getLocalTag())"
task5	"<line8>    LOG.info(""Finished deleting the ledgers contains most entries."");"	<line9>	"LOG.info(""Finished waiting for compaction to finish, waiting for the GC thread to clean up the entryLogs"")"	"<line9> LOG.info(""Finished waiting for compaction to finish, waiting for the GC thread to clean up the entryLogs"")"
task5	"<line12>    LOGGER.debug(""enqueueUpdateDeviceSslCertificationRequest called with organisation {} and device {}"",organisationIdentification,deviceIdentification);"	<line12>	"LOGGER.debug(""enqueueUpdateDeviceSslCertificationRequest called with organisation {} and device {}"",organisationIdentification,deviceIdentification)"	"<line12> LOGGER.debug(""enqueueUpdateDeviceSslCertificationRequest called with organisation {} and device {}"",organisationIdentification,deviceIdentification)"
task5	"<line4>      LOG.info(""Updated task: saved changes in element properties."");"	<line2>	"LOG.debug(""Updating task with changed element properties"")"	"<line2> LOG.debug(""Updating task with changed element properties"")"
task5	"<line2>      LOG.debug(MessageFormat.format(""Truncating Direct I/O resources: {0}:{1} (id={2})"", fullPath, resourcePattern, id));"	<line2>	"LOG.debug(""Truncating {}"", basePath)"	"<line2> LOG.debug(""Truncating {}"", basePath)"
task5	"<line53>    log.info(""Created consumer {} in group {}"", this.name, this.groupId);"	<line13>	"log.info(""A consumer instance with the specified name already exists in the Kafka Bridge."")"	"<line13> log.info(""A consumer instance with the specified name already exists in the Kafka Bridge."")"
task5	"<line11>    LOG.debug("">>>>> {}"", body);"	<line16>	"LOG.info(""Body:\n"" + body)"	"<line16> LOG.info(""Body:\n"" + body)"
task5	"<line7>      LOG.info(""Projecting fields schema : "" + projectionSchema.toString());"	<line3>	"LOG.debug(""Building ParquetIO reader for table {}"", table.getName())"	"<line3> LOG.debug(""Building ParquetIO reader for table {}"", table.getName())"
task5	"<line30>              LOG.debug("""" + index + "" "" + aField.getName() + "" "" + aField.getType());"	<line30>	"LOG.debug(""Obtained the size coefficients for ""+ cl.getName()+ "" : ""+ primitives+ ""+""+ arrays+ ""x""+ Bytes.SIZEOF_REF+ ""=""+ references+ "" bytes"")"	"<line30> LOG.debug(""Obtained the size coefficients for ""+ cl.getName()+ "" : ""+ primitives+ ""+""+ arrays+ ""x""+ Bytes.SIZEOF_REF+ ""=""+ references+ "" bytes"")"
task5	"<line28>      LOG.info(""ASYNC_PROFILER_HOME environment variable and async.profiler.home system property ""+ ""not specified. Disabling /prof endpoint."");"	<line8>	"LOG.warn(""Unable to add MetricsServlet"", e)"	"<line8> LOG.warn(""Unable to add MetricsServlet"", e)"
task5	"<line7>    log.debug(""Creating DiskCache for attributes = {0}"", idca);"	<line7>	"log.info(""Creating cache with following configuration: "" + idca)"	"<line7> log.info(""Creating cache with following configuration: "" + idca)"
task5	"<line7>      logger.debug(""Looking up endpoint for ["" + key + ""]"");"	<line7>	"logger.debug(""Looking up endpoint for key {}"", key)"	"<line7> logger.debug(""Looking up endpoint for key {}"", key)"
task5	"<line6>        log.warn(""Unable to index object entry "" + objectEntry.getObjectEntryId(), exception);"	<line6>	log.warn(exception, exception)	<line6> log.warn(exception, exception)
task5	"<line3>    logger.debug(""initializing bean "" + getClass().getName());"	<line3>	"logger.debug(""initializing bean "" + getClass().getName())"	"<line3> logger.debug(""initializing bean "" + getClass().getName())"
task5	<line15>        LOGGER.warn(UNABLE_TO_ACCESS_FIELD_ON_OBJECT, f.getName(), target);	<line15>	LOGGER.warn(UNABLE_TO_ACCESS_FIELD_ON_OBJECT, f.getName(), target)	<line15> LOGGER.warn(UNABLE_TO_ACCESS_FIELD_ON_OBJECT, f.getName(), target)
task5	"<line2>    logger.info(""bot is shutting down"");"	<line2>	"LOGGER.debug(""Cancelling scheduled execution"")"	"<line2> LOGGER.debug(""Cancelling scheduled execution"")"
task5	"<line14>    LOG.debug(""Property {} is set to value {}"", name, answer);"	<line6>	"LOG.warn(""Failed to lookup environment variable: hawtio/"" + name, e)"	"<line6> LOG.warn(""Failed to lookup environment variable: hawtio/"" + name, e)"
task5	"<line16>        LOG.error(""error while retrieving suite from mongo db: '{}', correlationId: '{}', suiteName:""+ "" '{}'"",dbKey,patternCorrelationId,patternSuiteName,se);"	<line16>	"log.error(""Correlation id not found for pattern suite: "" + patternSuiteName, se)"	"<line16> log.error(""Correlation id not found for pattern suite: "" + patternSuiteName, se)"
task5	<line4>      logger.info(e);	<line4>	"log.error(""Error getting room users for room "" + roomId, e)"	"<line4> log.error(""Error getting room users for room "" + roomId, e)"
task5	"<line19>        LOGGER.error(""Failed to remove timeline data - no data type found for "" + dataTypeKey);"	<line19>	"LOGGER.warn(""Failed to find data type for key "" + dataTypeKey)"	"<line19> LOGGER.warn(""Failed to find data type for key "" + dataTypeKey)"
task5	"<line3>    logger.trace(""onPostExecute()"");"	<line3>	"logger.debug(""key fingerprints updated"")"	"<line3> logger.debug(""key fingerprints updated"")"
task5	"<line29>                logger.debug(""Successfully recorded subscription for topic: ""+ topic.toStringUtf8()+ "" subscriberId: ""+ subscriberId.toStringUtf8()+ "" data: ""+ SubscriptionStateUtils.toString(data));"	<line29>	"logger.debug(""Successfully recorded new subscription for topic: ""+ topic.toStringUtf8()+ "" subscriberId: ""+ subscriberId.toStringUtf8())"	"<line29> logger.debug(""Successfully recorded new subscription for topic: ""+ topic.toStringUtf8()+ "" subscriberId: ""+ subscriberId.toStringUtf8())"
task5	"<line7>        log.debug(""Invalid shard ID:{}"", envVal);"	<line7>	"log.error(""Unable to parse the forced shard id: "" + envVal)"	"<line7> log.error(""Unable to parse the forced shard id: "" + envVal)"
task5	<line4>      logger.warn(msg);	<line4>	logger.warn(msg)	<line4> logger.warn(msg)
task5	"<line2>    LOG.trace(""bound {} to {}"", key.value(), value);"	<line2>	"LOG.debug(""bound {} to {}"", key.value(), value)"	"<line2> LOG.debug(""bound {} to {}"", key.value(), value)"
task5	"<line16>    logger.info(""Adding new CP member: "" + member);"	<line24>	"logger.error(""Failed to add CP member: "" + t.getMessage(), t)"	"<line24> logger.error(""Failed to add CP member: "" + t.getMessage(), t)"
task5	"<line24>      Logger.error(XmlHelper.class.getName(), ""Error loading localized file: "" + fullPath);"	<line24>	LOG.error(e.getMessage(), e)	<line24> LOG.error(e.getMessage(), e)
task5	"<line16>        logger.debug(""Check command context {}"", commandContext);"	<line16>	"logger.debug(""Redis command: {}"", commandContext)"	"<line16> logger.debug(""Redis command: {}"", commandContext)"
task5	"<line4>      LOG.error(""Can't fetch relevant Csar from storage: StorageService not available"");"	<line4>	"log.warn(""No storage defined for this manager!"")"	"<line4> log.warn(""No storage defined for this manager!"")"
task5	"<line27>          LOG.warn(""JAXB error: {}"", ex.getMessage(), ex);"	<line27>	"LOG.warn(""JAXB error: {}"", ex.getMessage(), ex)"	"<line27> LOG.warn(""JAXB error: {}"", ex.getMessage(), ex)"
task5	<line34>      log.error(e.getMessage(), e);	<line34>	"log.error(""Error extracting form data"", e)"	"<line34> log.error(""Error extracting form data"", e)"
task5	"<line3>    LOG.debug(""Raising NodeReconciliationOperationOngoing alarm, alarmText {} source {}"",alarmText,source);"	<line3>	"LOG.debug(""NodeReconciliationOperationOngoing raised by {}"", source)"	"<line3> LOG.debug(""NodeReconciliationOperationOngoing raised by {}"", source)"
task5	"<line1>    LOG.debug(""Session {} end of input detected while session was in state {}"",this,isUp() ? ""up"" : ""initialized"");"	<line2>	"logger.info(""End of input detected. Close the session."")"	"<line2> logger.info(""End of input detected. Close the session."")"
task5	<line10>      LOG.error(e);	<line10>	"log.error(""Error parsing multipart content"", e)"	"<line10> log.error(""Error parsing multipart content"", e)"
task5	"<line1>    LOG.info().$(""copying folder [from="").$(from).$("", to="").$(to).$(']').$();"	<line13>	"LOG.error(""Cannot copy file: "" + file, e)"	"<line13> LOG.error(""Cannot copy file: "" + file, e)"
task5	"<line6>      LOG.debug(""The project report cannot be found."", e);"	<line6>	"log.error(""Failed to load report"", e)"	"<line6> log.error(""Failed to load report"", e)"
task5	"<line8>      log.error(""Exception during datastore cutover"", ex);"	<line7>	"log.error(""Got exception on one of the partitions: "" + ex.getMessage(), ex)"	"<line7> log.error(""Got exception on one of the partitions: "" + ex.getMessage(), ex)"
task5	"<line17>      log.debug(""Could not determine volume for Path: {}"", path);"	<line17>	"log.debug(""No volumes configured for file system %s. Returning raw file system."", desiredFs)"	"<line17> log.debug(""No volumes configured for file system %s. Returning raw file system."", desiredFs)"
task5	"<line1>    LOG.info(""SeaCloudsInitializerPolicy is starting to enforce SLA Agreements for "" + entity.getId());"	<line1>	"LOG.info(""SeaCloudsInitializerPolicy is notifying SLA Agreeement installation to SeaCloudsInitializer"")"	"<line1> LOG.info(""SeaCloudsInitializerPolicy is notifying SLA Agreeement installation to SeaCloudsInitializer"")"
task5	<line3>    logger.trace(format, arg1, arg2);	<line3>	logger.trace(format, arg1, arg2)	<line3> logger.trace(format, arg1, arg2)
task5	"<line48>          logger.trace(""Created flight ({})."", flight);"	<line14>	"logger.info(""Creating flight list with {} flights"", flightListSize)"	"<line14> logger.info(""Creating flight list with {} flights"", flightListSize)"
task5	"<line6>      LOG.debug(""ArtifactSpecificContent specified!"");"	<line6>	"LOG.trace(""Setting specificContent {}"", specificContent)"	"<line6> LOG.trace(""Setting specificContent {}"", specificContent)"
task5	"<line3>    LOG.debug(""Creating IndexClient with given filesystem client with root path %s"", root);"	<line3>	"log.info(""Creating new HeuristicIndexClient"")"	"<line3> log.info(""Creating new HeuristicIndexClient"")"
task5	"<line23>      logger.warn(""failed to get channel for "" + operand);"	<line23>	"logger.error(""The channel returned for operand "" + operand + "" is null!"")"	"<line23> logger.error(""The channel returned for operand "" + operand + "" is null!"")"
task5	"<line13>      logger.error(""Error removing messages for user {}"", username, t);"	<line13>	"logger.error(""Error removing messages for user {}"", username, t)"	"<line13> logger.error(""Error removing messages for user {}"", username, t)"
task5	<line12>    logger.debug(sb.toString());	<line12>	logger.debug(sb.toString())	<line12> logger.debug(sb.toString())
task5	"<line25>          logger.info(""Downloading builtin template ""+ template.getUniqueName()+ "" to data center: ""+ dcId);"	<line5>	"logger.info(""No image store is configured on the zone.  Skipping the template download."")"	"<line5> logger.info(""No image store is configured on the zone.  Skipping the template download."")"
task5	"<line8>      logger.info(""dns lookup fail. host:{}"", host);"	<line8>	"LOGGER.error(""Could not resolve host \"""" + host + ""\"" returning unresolved"", e)"	"<line8> LOGGER.error(""Could not resolve host \"""" + host + ""\"" returning unresolved"", e)"
task5	"<line14>      log.error(""Error in enable rules"", e);"	<line14>	"log.error(""Failed to enable rules in AWS"", e)"	"<line14> log.error(""Failed to enable rules in AWS"", e)"
task5	<line15>      log.error(systemException, systemException);	<line15>	log.error(systemException, systemException)	<line15> log.error(systemException, systemException)
task5	"<line6>      log.debug(""Invoking the callback function for sent message, IoT Hub responded to message ({}) with""+ "" status {}"",packet.getMessage(),status);"	<line6>	"log.debug(""Invoking callback {} for packet {}"", callback, packet)"	"<line6> log.debug(""Invoking callback {} for packet {}"", callback, packet)"
task5	"<line2>      log.info(formatLogString(""sending "" + WorkerDoneEvent.class.getSimpleName() + "" to sync""));"	<line2>	"log.info(""Send event to Sync: "" + event)"	"<line2> log.info(""Send event to Sync: "" + event)"
task5	"<line5>        LOG.debug(""Thing \""{}\"" changes something in its status (eg: a behavior value)"",this.getPojo().getName());"	<line5>	"LOG.debug(""Sending event {}"", objectEvent)"	"<line5> LOG.debug(""Sending event {}"", objectEvent)"
task5	<line18>      log.error(systemException, systemException);	<line18>	log.error(systemException, systemException)	<line18> log.error(systemException, systemException)
task5	<line7>      log.error(exception, exception);	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	"<line61>      logger.debug(""handleNewPendingConnection {} myAddr={} theirAddr={}"",con,getConduit().getMemberId(),con.getRemoteAddress());"	<line61>	"logger.debug(""Handling new pending connection: {}"", con)"	"<line61> logger.debug(""Handling new pending connection: {}"", con)"
task5	<line5>      log.error(e.getMessage(), e);	<line5>	"LOG.error(""Unable to purge data"", e)"	"<line5> LOG.error(""Unable to purge data"", e)"
task5	"<line14>        log.error(""Invalid HDFS base path for vectors: "" + strBasePath, e);"	<line14>	"log.debug(""Unable to initialize base path from configuration"", e)"	"<line14> log.debug(""Unable to initialize base path from configuration"", e)"
task5	"<line4>      log.debug(""#validateAndFillPolicy - The 'type' member is not found under policy {}"",emptyPolicyDefinition.getName());"	<line3>	"log.debug(""policy type name: {}"", policyTypeName)"	"<line3> log.debug(""policy type name: {}"", policyTypeName)"
task5	"<line3>    log.info(""output specification location: "" + currentSpecLocation);"	<line11>	"log.info(""invalid field value for path: ""+ entry.getKey()+ "", expected: '""+ entry.getValue()+ ""', ""+ ""got: '""+ currentValue+ ""' Full object content: ""+ serializedAction)"	"<line11> log.info(""invalid field value for path: ""+ entry.getKey()+ "", expected: '""+ entry.getValue()+ ""', ""+ ""got: '""+ currentValue+ ""' Full object content: ""+ serializedAction)"
task5	"<line20>        LOG.debug(""Unresolved reference"", ignore);"	<line17>	"LOGGER.debug(""Unresolved reference: key={}"", key)"	"<line17> LOGGER.debug(""Unresolved reference: key={}"", key)"
task5	"<line4>      log.warn(""Argument 'bytes={}' was not a serialized HFileMeta!"", CommonUtils.hex(bytes));"	<line4>	"LOG.warn(""toAttr() failed"", internal)"	"<line4> LOG.warn(""toAttr() failed"", internal)"
task5	"<line2>    logger.info(""Using <{}> for container type <{}>"", containerClass.getName(), containerType);"	<line2>	"log.info(""Setting container type "" + containerType + "" to implementation "" + containerClass)"	"<line2> log.info(""Setting container type "" + containerType + "" to implementation "" + containerClass)"
task5	"<line5>      logger.warn(""new eps not set: "" + e);"	<line5>	"log.debug(""root is invalid boundary: "" + e1.getMessage())"	"<line5> log.debug(""root is invalid boundary: "" + e1.getMessage())"
task5	"<line7>            LOGGER.debug(""Error initializing the {}"", a.getName());"	<line7>	"logger.error(""NodeAuditAnalyzer failed to initialize"", ex)"	"<line7> logger.error(""NodeAuditAnalyzer failed to initialize"", ex)"
task5	"<line8>      LOGGER.debug(""Content-Length is "" + contentLength + "" bytes"");"	<line8>	"LOGGER.debug(""Content-Length is {} bytes"", contentLength)"	"<line8> LOGGER.debug(""Content-Length is {} bytes"", contentLength)"
task5	<line30>      log.error(systemException, systemException);	<line30>	log.error(systemException, systemException)	<line30> log.error(systemException, systemException)
task5	<line6>      log.error(exception, exception);	<line6>	log.error(exception, exception)	<line6> log.error(exception, exception)
task5	"<line1>    logger.info(""Failed "" + getProgress() + ""% -- "" + getTask() + "" ["" + getPrintable(getOwner()) + ""]"");"	<line1>	log.error(exception.getMessage())	<line1> log.error(exception.getMessage())
task5	"<line7>      log.debug(""AccessControlImporter may not be used with the WorkspaceImporter"");"	<line7>	"log.debug(""started workspace import"")"	"<line7> log.debug(""started workspace import"")"
task5	"<line37>          LOGGER.info(""https server working"");"	<line37>	"LOGGER.info(""Handling request: "" + t.getRequestURI())"	"<line37> LOGGER.info(""Handling request: "" + t.getRequestURI())"
task5	"<line15>                  log.error(""Error notifying event listener"", e);"	<line15>	"log.error(""Error while invoking onUnregister in bazaar event listener: {}"", e.getMessage())"	"<line15> log.error(""Error while invoking onUnregister in bazaar event listener: {}"", e.getMessage())"
task5	"<line15>      logger.error(""Error loading categories"", t);"	<line15>	"logger.error(""Error loading categories"", t)"	"<line15> logger.error(""Error loading categories"", t)"
task5	<line65>      log.error(exception, exception);	<line65>	log.error(exception, exception)	<line65> log.error(exception, exception)
task5	"<line7>      log.error(String.format(""Error reading file: \""%s\"""", filename), e);"	<line7>	"log.warn(""Could not read file "" + filename + "": "" + e.getMessage())"	"<line7> log.warn(""Could not read file "" + filename + "": "" + e.getMessage())"
task5	"<line18>      LOGGER.error(""Cannot check current user authorization to submit work item: {}"",ex.getLocalizedMessage(),ex);"	<line18>	"LOGGER.error(""Couldn't check authorization for delegate, skipping visibility of forward button. {}"",ex.getMessage(),ex)"	"<line18> LOGGER.error(""Couldn't check authorization for delegate, skipping visibility of forward button. {}"",ex.getMessage(),ex)"
task5	"<line34>      logger.error(""Unable to get the upcoming recording for agent '{}'"", agentId, e);"	<line34>	"logger.error(""Unable to get upcoming recording for agent '{}': {}"", agentId, e)"	"<line34> logger.error(""Unable to get upcoming recording for agent '{}': {}"", agentId, e)"
task5	"<line7>      log.warn(""Could not process request message. [exception=({}), artifact=({}), ""+ ""contract=({}), issuer=({}), messageId=({})]"",exception.getMessage(),requestedArtifact,transferContract,issuerConnector,messageId,exception);"	<line7>	"log.warn(""Could not process request message. [exception=({}), requestedArtifact=({}), transferContract=({}),""+ "" issuerConnector=({}), messageId=({})]"",exception.getMessage(),requestedArtifact,transferContract,issuerConnector,messageId)"	"<line7> log.warn(""Could not process request message. [exception=({}), requestedArtifact=({}), transferContract=({}),""+ "" issuerConnector=({}), messageId=({})]"",exception.getMessage(),requestedArtifact,transferContract,issuerConnector,messageId)"
task5	"<line3>    log.info(""Average time per run: {"" + perRun + ""} ms"");"	<line4>	"logger.info(""Measured {} runs in {} ms, factor is {}"", nRuns, duration, factor)"	"<line4> logger.info(""Measured {} runs in {} ms, factor is {}"", nRuns, duration, factor)"
task5	"<line12>          LOG.error(""Couldn't save notification: {}"", notification.getDocument(), e);"	<line12>	"LOG.error(""Can't update notification status"", e)"	"<line12> LOG.error(""Can't update notification status"", e)"
task5	"<line16>      LOG.info(""Created schema on persistent store and initialized cache for persistent bean {}."",super.getPersistentClass().getSimpleName());"	<line19>	"LOG.error(""createSchema() failed"", e)"	"<line19> LOG.error(""createSchema() failed"", e)"
task5	"<line1>    logger.debug(""validateSystemId started..."");"	<line1>	"logger.debug(""Validating system id: {}"", systemId)"	"<line1> logger.debug(""Validating system id: {}"", systemId)"
task5	"<line9>        logger.info(""Creating new manager instance of {}"", clz);"	<line13>	"logger.error(""Failed to instantiate manager "" + clz, e)"	"<line13> logger.error(""Failed to instantiate manager "" + clz, e)"
task5	"<line11>          logger.debug(""ClientHealthMonitor: Registering client with member id {}"", proxyID);"	<line11>	"logger.debug(""Registered client heartbeat from {}"", proxyID)"	"<line11> logger.debug(""Registered client heartbeat from {}"", proxyID)"
task5	"<line2>    log.info(""Map-SubKey: "" + MutableMap.copyOf(entity.getConfigMap().asMapWithStringKeys()));"	<line1>	"log.info(""TestMapSubkeyUsage"")"	"<line1> log.info(""TestMapSubkeyUsage"")"
task5	"<line23>                LOG.warn(""Error converting the json string {} to StructuredRecord"", recordString, e);"	<line23>	"LOG.error(""Error while deserializing record string {}"", recordString, e)"	"<line23> LOG.error(""Error while deserializing record string {}"", recordString, e)"
task5	"<line20>      log.info(""Subscribing to [{}] id [{}]"", eventName, id);"	<line2>	"log.info(""Subscribing to event: {}"", eventName)"	"<line2> log.info(""Subscribing to event: {}"", eventName)"
task5	"<line6>      log.trace(""Could not initialize generator "" + this, e);"	<line6>	"log.error(e, ""Can't find class "" + clazzName)"	"<line6> log.error(e, ""Can't find class "" + clazzName)"
task5	<line3>      LOG.error(cause.getMessage(), cause);	<line3>	"LOG.error(""onClose was called with an exception"", cause)"	"<line3> LOG.error(""onClose was called with an exception"", cause)"
task5	<line11>          LOG.warn(MessageFormat.format(JGitText.get().unableToReadPackfile, p.getPackFile().getAbsolutePath()),e);	<line11>	log.error(e, e)	<line11> log.error(e, e)
task5	"<line4>    LOGGER.info(""Initializing wsDistributionAutomationOutboundDomainRequestsConnectionFactory bean."");"	<line4>	"LOGGER.info(""Initializing wsDistributionAutomationOutboundDomainRequestsConnectionFactory bean."")"	"<line4> LOGGER.info(""Initializing wsDistributionAutomationOutboundDomainRequestsConnectionFactory bean."")"
task5	"<line28>          log.debug(""received "" + count);"	<line28>	"log.info(""Consumer has received "" + count + "" messages"")"	"<line28> log.info(""Consumer has received "" + count + "" messages"")"
task5	<line6>      LOG.error(e.getMessage());	<line6>	log.error(e.getMessage())	<line6> log.error(e.getMessage())
task5	"<line6>      LOGGER.info(""Processing CSR for scm {}, nodeId: {}"",scmNodeDetails.getHostName(),scmNodeDetails.getScmNodeId());"	<line3>	"LOG.info(""Processing CSR for SCM at {}"", scmNodeDetails.getNodeAddress().getHost())"	"<line3> LOG.info(""Processing CSR for SCM at {}"", scmNodeDetails.getNodeAddress().getHost())"
task5	"<line2>    logger.info("" ---> Creating a smaller file small.txt"");"	<line2>	"logger.info("" ---> Creating file smaller than the limit"")"	"<line2> logger.info("" ---> Creating file smaller than the limit"")"
task5	"<line5>    LOG.info(""Total processed: "" + processedCount);"	<line4>	"logger.info(""Processed: "" + simpleClient.getId())"	"<line4> logger.info(""Processed: "" + simpleClient.getId())"
task5	"<line2>      log.info(""[{}] ZK state changed: {}"", self.getServiceId(), newState);"	<line3>	"log.info(""Connection to the server has been lost, attempting to reconnect"")"	"<line3> log.info(""Connection to the server has been lost, attempting to reconnect"")"
task5	<line26>      LOGGER.error(e);	<line26>	LOGGER.error(e)	<line26> LOGGER.error(e)
task5	"<line2>    LOGGER.debug(""SignatureHashAlgorithms: ""+ ArrayConverter.bytesToHexString(msg.getSignatureHashAlgorithms().getValue()));"	<line2>	"LOGGER.debug(""SignatureHandshakeAlgorithms: ""+ ArrayConverter.bytesToHexString(msg.getSignatureHashAlgorithms().getValue()))"	"<line2> LOGGER.debug(""SignatureHandshakeAlgorithms: ""+ ArrayConverter.bytesToHexString(msg.getSignatureHashAlgorithms().getValue()))"
task5	"<line5>    log.info(""WRAPPED STREAM json is: "" + result);"	<line7>	"log.info(""Result: "" + result)"	"<line7> log.info(""Result: "" + result)"
task5	"<line8>      LOG.warn(""No 'quarkus.sentry.in-app-packages' was configured, this option is highly recommended as""+ "" it affects stacktrace grouping and display on Sentry. See""+ "" https://quarkus.io/guides/logging-sentry#in-app-packages"");"	<line8>	"LOG.info(""The \""quarkus.log.sentry.inAppPackages\"" configuration key is empty/missing. ""+ ""All packages are considered in-app"")"	"<line8> LOG.info(""The \""quarkus.log.sentry.inAppPackages\"" configuration key is empty/missing. ""+ ""All packages are considered in-app"")"
task5	"<line9>        LOG.debug(""Resolve name {} to rack {}."", n, rack);"	<line9>	"LOG.debug(""Resolve {} to {}"", n, rack)"	"<line9> LOG.debug(""Resolve {} to {}"", n, rack)"
task5	"<line10>      LOG.error(""getSessionStatDataList error"", e);"	<line10>	"log.error(""getSessionStatDataList error"", e)"	"<line10> log.error(""getSessionStatDataList error"", e)"
task5	<line18>      log.error(systemException, systemException);	<line18>	log.error(systemException, systemException)	<line18> log.error(systemException, systemException)
task5	"<line1>    log.info(""Click Perform Actions"");"	<line1>	"log.info(""Click Abort"")"	"<line1> log.info(""Click Abort"")"
task5	"<line1>    LOG.trace(""Emitting - {}"", id);"	<line1>	"LOG.debug(""emitting data: {}"", tuple)"	"<line1> LOG.debug(""emitting data: {}"", tuple)"
task5	"<line6>    logger.debug(""createBulkAuthorizationIntraCloudResponse started..."");"	<line6>	"logger.debug(""createBulkAuthorizationIntraCloudResponse started..."")"	"<line6> logger.debug(""createBulkAuthorizationIntraCloudResponse started..."")"
task5	"<line9>          logger.trace(""Handler for id {} not initialized"", integrationId);"	<line9>	"logger.debug(""Handler missing integration ID. {}"", e.getMessage())"	"<line9> logger.debug(""Handler missing integration ID. {}"", e.getMessage())"
task5	"<line1>    logger.debug(""obtainKeys started..."");"	<line1>	"logger.debug(""obtainKeys started..."")"	"<line1> logger.debug(""obtainKeys started..."")"
task5	"<line27>      logger.error(""Could not delete series: {}"", e.getMessage());"	<line27>	"logger.error(""Could not delete series with id '{}'"", seriesId, e)"	"<line27> logger.error(""Could not delete series with id '{}'"", seriesId, e)"
task5	<line5>        log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line5>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line5> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line2>    LOGGER.info(""generating data between ""+ formatter.print(startDate)+ "" and ""+ formatter.print(endDate));"	<line5>	"LOGGER.info(""Generating dates for {} minutes starting from {} and ending at {}"",minuteSkip,startDate,endDate)"	"<line5> LOGGER.info(""Generating dates for {} minutes starting from {} and ending at {}"",minuteSkip,startDate,endDate)"
task5	<line17>      log.error(exception, exception);	<line17>	log.error(exception, exception)	<line17> log.error(exception, exception)
task5	"<line3>    LOGGER.debug(""import agency file {}"", fileName);"	<line3>	"LOGGER.debug(""Import file {}"", fileName)"	"<line3> LOGGER.debug(""Import file {}"", fileName)"
task5	"<line5>        LOG.error(""Error closing JMS topic subscriber: "" + topicSubscriber, ignore);"	<line5>	"log.debug(""Failed to close topic subscriber"", ignore)"	"<line5> log.debug(""Failed to close topic subscriber"", ignore)"
task5	"<line4>    LOGGER.info(""Discover Object Instance : ""+ ""Object = ""+ theObject.toString()+ "", Object class = ""+ theObjectClass.toString()+ "", Object name = ""+ objectName);"	<line4>	"log.debug(""discoverObjectInstance()"")"	"<line4> log.debug(""discoverObjectInstance()"")"
task5	"<line6>      LOG.debug(""Received PubAck packageID: {}"" + packageId);"	<line6>	"LOG.debug(""processPubAck clientId: {}, packageId: {}"", clientId, packageId)"	"<line6> LOG.debug(""processPubAck clientId: {}, packageId: {}"", clientId, packageId)"
task5	"<line1>    logger.debug(""handleIncreaseDecrease called for channel: {}, command: {}"", channelUID, command);"	<line1>	"logger.debug(""Handling IncreaseDecrease command {} for channel {}"", command, channelUID.getId())"	"<line1> logger.debug(""Handling IncreaseDecrease command {} for channel {}"", command, channelUID.getId())"
task5	"<line2>    LOG.info(""AdviceWith replace input from [{}] --> [{}]"", from.getEndpointUri(), uri);"	<line4>	"log.debug(""Created route from definition: "" + route)"	"<line4> log.debug(""Created route from definition: "" + route)"
task5	"<line4>      log.debug(""ResourceUtils got error reading ""+ url+ (context == null ? """" : "" "" + context)+ "" (rethrowing): ""+ e);"	<line4>	"LOGGER.warn(""Unable to get resource from url: "" + url)"	"<line4> LOGGER.warn(""Unable to get resource from url: "" + url)"
task5	"<line4>      LOGGER.warn(MessageFormat.format(this.getActionExecution().getAction().getType()+ "" does not accept {0} as type for iterationType"",iterationType.getClass()));"	<line4>	"LOGGER.warn(MessageFormat.format(this.getActionExecution().getAction().getType()+ "" does not accept {0} as type for iteration type"",iterationType.getClass()))"	"<line4> LOGGER.warn(MessageFormat.format(this.getActionExecution().getAction().getType()+ "" does not accept {0} as type for iteration type"",iterationType.getClass()))"
task5	"<line4>      logger.error(""Current authUser is trying to access to a forbbiden api : ""+ authUser.getAccountRepresentation());"	<line4>	"logger.error(""Missing role to access this service"")"	"<line4> logger.error(""Missing role to access this service"")"
task5	<line1>    logger.info(text);	<line1>	logger.debug(text)	<line1> logger.debug(text)
task5	"<line7>      Log.debug(""CoordinateEditor: '"" + value + ""' -> "" + d);"	<line9>	"LOG.warn(""Unable to convert string value to a number"", e)"	"<line9> LOG.warn(""Unable to convert string value to a number"", e)"
task5	"<line2>    log.debug(""Invalidating collection sync root member cache for all users"");"	<line2>	"log.debug(""Invalidating collection sync root member cache"")"	"<line2> log.debug(""Invalidating collection sync root member cache"")"
task5	"<line2>    log.info(""Found {} classes annotated with {} "", (classes != null ? classes.size() : 0), clazz);"	<line2>	"log.debug(""Found {} classes annotated with @{}"", classes.size(), clazz.getSimpleName())"	"<line2> log.debug(""Found {} classes annotated with @{}"", classes.size(), clazz.getSimpleName())"
task5	<line2>      LOG.debug(I18n.msg(I18n.MSG_04102_BIND_REQUEST, name));	<line2>	"LOG.debug(""Bind request: {}"", bindRequest)"	"<line2> LOG.debug(""Bind request: {}"", bindRequest)"
task5	"<line24>      log.debug(DataFormatter.class.getName()+ "" could not apply mask to data. The original data was returned"");"	<line24>	"LOGGER.error(""Error while formatting data."", e)"	"<line24> LOGGER.error(""Error while formatting data."", e)"
task5	"<line2>    log.info(""Internal blob store set: {}"", blobStore);"	<line2>	"log.info(""Set blob store for split repository to {}"", blobStore)"	"<line2> log.info(""Set blob store for split repository to {}"", blobStore)"
task5	"<line2>      LOG.info(""Creating durable consumer"");"	<line2>	"LOG.info(""Creating durable consumer"")"	"<line2> LOG.info(""Creating durable consumer"")"
task5	"<line9>      logger.debug(""in Rule ""+ context.getRule().getName()+ "" added to context: [""+ t.toString()+ ""], deductions notified ""+ deductionsNotified);"	<line9>	"logger.debug(""Added triple "" + t + "" to context "" + context)"	"<line9> logger.debug(""Added triple "" + t + "" to context "" + context)"
task5	"<line36>      logger.error(""Error creating Entity"", t);"	<line36>	"logger.error(""Error creating Entity"", t)"	"<line36> logger.error(""Error creating Entity"", t)"
task5	"<line6>    logger.info(name + "": "" + total + "" from "" + results.size() + "" worker threads"");"	<line6>	"logger.info(""Total: "" + total + "" from "" + results.size() + "" worker threads"")"	"<line6> logger.info(""Total: "" + total + "" from "" + results.size() + "" worker threads"")"
task5	"<line36>      LOG.error(""get local address failed"", e);"	<line36>	"LOGGER.warn(""getLocalAddress error"", e)"	"<line36> LOGGER.warn(""getLocalAddress error"", e)"
task5	"<line1>    log.debug(""findAll() - pageable: {}"", pageable);"	<line1>	"log.debug(""findAll() - pageable: {}"", pageable)"	"<line1> log.debug(""findAll() - pageable: {}"", pageable)"
task5	"<line7>      LOG.error(""Unable to decode CloudEvent data to Map<""+ keyClass.getName()+ "",""+ valueClass.getName()+ "">"",e);"	<line7>	"LOGGER.error(""Failed to decode map data"", e)"	"<line7> LOGGER.error(""Failed to decode map data"", e)"
task5	"<line4>        logger.debug(""sendCommand getRevision :: {}"",SierraMc87xxAtCommands.getFirmwareVersion.getCommand());"	<line4>	"logger.debug(""sendCommand getFirmwareVersion :: {}"", SierraMc87xxAtCommands.getFirmwareVersion.getCommand())"	"<line4> logger.debug(""sendCommand getFirmwareVersion :: {}"", SierraMc87xxAtCommands.getFirmwareVersion.getCommand())"
task5	"<line3>      ActiveMQRALogger.LOGGER.trace(""setDoubleProperty("" + name + "", "" + value + "")"");"	<line3>	"ActiveMQRALogger.LOGGER.trace(""setDoubleProperty("" + name + "", "" + value + "")"")"	"<line3> ActiveMQRALogger.LOGGER.trace(""setDoubleProperty("" + name + "", "" + value + "")"")"
task5	"<line13>                log.warn(""Failed to parse UI input '{}': {}"", input, parsingError.get());"	<line13>	"log.debug(""Parsing error: {}"", parsingError.getMessage())"	"<line13> log.debug(""Parsing error: {}"", parsingError.getMessage())"
task5	"<line16>      log.warn(""Deleting submitted task before completion: ""+ removed+ ""; this task will continue to run in the background outwith ""+ this+ "", but perhaps it should have been cancelled?"");"	<line16>	"log.warn(""Deleted task that was submitted and is not done: {}"", task)"	"<line16> log.warn(""Deleted task that was submitted and is not done: {}"", task)"
task5	"<line20>      logger.error(""Unsupported physical plan: {}"", plan);"	<line20>	"logger.warn(""Unknown plan {}"", plan)"	"<line20> logger.warn(""Unknown plan {}"", plan)"
task5	"<line14>      logger.error(""Error on extracting widgetUtilizers : widget type code {}"", t);"	<line14>	"logger.error(""Error on extracting widgetUtilizers : widget type code {}"", widgetTypeCode, t)"	"<line14> logger.error(""Error on extracting widgetUtilizers : widget type code {}"", widgetTypeCode, t)"
task5	<line19>      log.error(systemException, systemException);	<line19>	log.error(systemException, systemException)	<line19> log.error(systemException, systemException)
task5	"<line14>      log.error(""Failed to reload api proxy service: {}"", e.getMessage());"	<line14>	"logger.error(""Exception while invoking API proxy to reload config"", e)"	"<line14> logger.error(""Exception while invoking API proxy to reload config"", e)"
task5	"<line10>      logger.error(""Error loading the CatalogModel"", e);"	<line10>	"log.error(""Error loading the CatalogModel"", e)"	"<line10> log.error(""Error loading the CatalogModel"", e)"
task5	"<line18>            log.error(""The latest computed high watermark {} is smaller than the current ""+ ""value {}, which suggests that one of the voters has lost committed data. ""+ ""Full voter replication state: {}"",highWatermarkUpdateOffset,currentHighWatermarkMetadata.offset,voterStates.values());"	<line15>	"log.info(""Updating high watermark to {}"", highWatermarkUpdateOffset)"	"<line15> log.info(""Updating high watermark to {}"", highWatermarkUpdateOffset)"
task5	"<line13>      LOGGER.debug(""Found match: ""+ row.get(row.getSchema().getField(""Name"").pos())+ "" id: ""+ row.get(row.getSchema().getField(""Id"").pos())+ "" shippingPostalCode: ""+ row.get(row.getSchema().getField(""ShippingPostalCode"").pos())+ "" billingPostalCode: ""+ row.get(row.getSchema().getField(""BillingPostalCode"").pos())+ "" billingStreet: ""+ row.get(row.getSchema().getField(""BillingStreet"").pos()));"	<line13>	"LOGGER.info(""Filtered row: "" + row.toString())"	"<line13> LOGGER.info(""Filtered row: "" + row.toString())"
task5	"<line3>      log.trace(""[IRAC] Topology Updated. Checking pending keys."");"	<line3>	"log.trace(""Topology update from {} to {}"", oldCacheTopology, newCacheTopology)"	"<line3> log.trace(""Topology update from {} to {}"", oldCacheTopology, newCacheTopology)"
task5	"<line2>    LOGGER.debug(""init vitam tenant is mandatory : {}"", mandatory);"	<line2>	"log.info(""Post constructing {}"", this.getClass().getSimpleName())"	"<line2> log.info(""Post constructing {}"", this.getClass().getSimpleName())"
task5	<line10>      LOGGER.error(e.toString());	<line10>	"logger.error(""Error while getting completion target"", e)"	"<line10> logger.error(""Error while getting completion target"", e)"
task5	"<line8>      LOG.warn(""Failed to cleanup states with error {}."", e.toString());"	<line8>	"LOG.warn(""Exception while handling error "" + error, e)"	"<line8> LOG.warn(""Exception while handling error "" + error, e)"
task5	"<line15>    LOG.debug(""instanceName: ""+ instanceName+ "" isLinux: ""+ isLinux+ "" guestid: ""+ configSpec.getGuestId()+ "" OS: ""+ configSpec.getGuestFullName());"	<line15>	"logger.debug(""isLinux: "" + isLinux)"	"<line15> logger.debug(""isLinux: "" + isLinux)"
task5	"<line1>    log.info(""Click Sign In"");"	<line1>	"log.info(""Click Sign In expect error"")"	"<line1> log.info(""Click Sign In expect error"")"
task5	<line2>    log.debug(format, arg1, arg2);	<line2>	logger.debug(format, arg1, arg2)	<line2> logger.debug(format, arg1, arg2)
task5	"<line19>      LOGGER.error(""[capacityManagement] do4Update "", e);"	<line19>	"LOGGER.error(""nacosDal init capacity check failed."", e)"	"<line19> LOGGER.error(""nacosDal init capacity check failed."", e)"
task5	"<line7>      log.info(""Error while receiving notification about key-value state de-registration"", e);"	<line7>	"log.info(""Flink job not found"", e)"	"<line7> log.info(""Flink job not found"", e)"
task5	"<line2>    Log.debug(""Test"");"	<line2>	"Log.debug(""Test"")"	"<line2> Log.debug(""Test"")"
task5	"<line2>    logger.info(""Reserved {} started."", ClassUtils.simpleClassName(this));"	<line3>	"LOG.info(""pull collector cluster not connected, skip retry"")"	"<line3> LOG.info(""pull collector cluster not connected, skip retry"")"
task5	"<line11>      LOGGER.warn(""Problem loading"", e);"	<line11>	"LOGGER.error(""Error while reading government body data from excel file."", e)"	"<line11> LOGGER.error(""Error while reading government body data from excel file."", e)"
task5	<line4>      LOGGER.debug(() -> new XMLOutputter(Format.getPrettyFormat()).outputString(metsDocument));	<line2>	"LOGGER.info(""Fetching manifest for id {} from {}"", id, getId())"	"<line2> LOGGER.info(""Fetching manifest for id {} from {}"", id, getId())"
task5	"<line1>    logger.error("""" + o);"	<line1>	logger.error(o.toString())	<line1> logger.error(o.toString())
task5	"<line1>    log.debug(""Loading blobs from the file system: "" + blobInfos);"	<line4>	"log.debug(""Restoring blob: {}"", blobFile.getAbsolutePath())"	"<line4> log.debug(""Restoring blob: {}"", blobFile.getAbsolutePath())"
task5	"<line5>      log.error(""Error reading message channel"", ex);"	<line5>	log.error(ex.getMessage())	<line5> log.error(ex.getMessage())
task5	"<line9>      log.error(""Failed to write meta-data file '{}'"", spMetadataFile, ex);"	<line9>	"log.error(""Failed to save meta-data file: "" + spMetadataFile, ex)"	"<line9> log.error(""Failed to save meta-data file: "" + spMetadataFile, ex)"
task5	"<line14>          LOGGER.warn(""Unable to copy {} to {} after "" + MAX_COPY_ATTEMPTS + "" attempts; skipping file"",child,destChild,e);"	<line14>	"log.error(""Failed to copy file: "" + child + "" after "" + ioException.getSuppressed().length + "" attempts."")"	"<line14> log.error(""Failed to copy file: "" + child + "" after "" + ioException.getSuppressed().length + "" attempts."")"
task5	"<line6>    LOGGER.debug(""resolveCollision: {}, {}, {}, {}"", composite, existing, added, intersect);"	<line6>	"log.debug(""Resolving collision in ""+ composite+ "" (existing=""+ existing+ "", added=""+ added+ "", intersect=""+ intersect+ "")"")"	"<line6> log.debug(""Resolving collision in ""+ composite+ "" (existing=""+ existing+ "", added=""+ added+ "", intersect=""+ intersect+ "")"")"
task5	"<line4>      LOGGER.info(""GUI created"");"	<line5>	"logger.error(""Error while creating GUI"", t)"	"<line5> logger.error(""Error while creating GUI"", t)"
task5	"<line16>      LOG.error(e, ""Error while testing"");"	<line16>	"log.error(""Failed to test SQL queries from file "" + queryFilePath)"	"<line16> log.error(""Failed to test SQL queries from file "" + queryFilePath)"
task5	"<line7>      logger.warn(""Remove keyValue by key preFix: "" + preFix);"	<line7>	"LOGGER.info(""ContextKey set removed by prefix: {}"", preFix)"	"<line7> LOGGER.info(""ContextKey set removed by prefix: {}"", preFix)"
task5	"<line10>    log.info(""Created zookeeper entry {} with data {}"", path, work);"	<line10>	"log.debug(""Queued recovery for sort {} at {}"", sortId, path)"	"<line10> log.debug(""Queued recovery for sort {} at {}"", sortId, path)"
task5	"<line10>      LOGGER.error(""An error have been encountered while watching resources - leaving the redeploy mode"", e);"	<line10>	"LOGGER.error(""An exception occurred in the file scanner"", e)"	"<line10> LOGGER.error(""An exception occurred in the file scanner"", e)"
task5	"<line1>    log.debug(""findByModuleId() - moduleId: {}"", moduleId);"	<line1>	"log.debug(""findByModuleId() - moduleId: {}"", moduleId)"	"<line1> log.debug(""findByModuleId() - moduleId: {}"", moduleId)"
task5	"<line10>      log.error(""IO exception, Caused by {}."", e);"	<line10>	"log.error(""Error converting to byte array"", e)"	"<line10> log.error(""Error converting to byte array"", e)"
task5	"<line3>    LOG.debug(""{}: Delete {} {}"", id, store, path);"	<line3>	"LOG.debug(""{}: Delete {} {}"", id, store, path)"	"<line3> LOG.debug(""{}: Delete {} {}"", id, store, path)"
task5	"<line7>      logger.info(""Channel {} only accepts StringType, RefreshType. Type was {}."",channelUID,command.getClass());"	<line7>	"logger.warn(""Command {} is not supported for channel {}. Supported commands: RefreshType, StringType"",command.getClass(),channelUID.getId())"	"<line7> logger.warn(""Command {} is not supported for channel {}. Supported commands: RefreshType, StringType"",command.getClass(),channelUID.getId())"
task5	"<line2>    LOG.info(""The following activity types were found: "" + activityTypes);"	<line1>	"logger.info(""Running scenario with "" + scenario.getFacilities().size() + "" facilities"")"	"<line1> logger.info(""Running scenario with "" + scenario.getFacilities().size() + "" facilities"")"
task5	"<line9>      log.info(""Ignoring exception, likely coming from Hadoop 1"", e);"	<line9>	"LOG.error(""Failed to merge token into jobConf"", e)"	"<line9> LOG.error(""Failed to merge token into jobConf"", e)"
task5	"<line11>    LOGGER.info(""{} device log items deleted."", size);"	<line11>	"logger.info(""Deleted {} DeviceLogItems from {} to {}"", size, fromIndex, toIndex)"	"<line11> logger.info(""Deleted {} DeviceLogItems from {} to {}"", size, fromIndex, toIndex)"
task5	"<line38>      LOG.info(""Job failed. Try cleaning up temporary directory [{}]."", src);"	<line2>	"LOG.info(""Aborting job {}"", jobContext)"	"<line2> LOG.info(""Aborting job {}"", jobContext)"
task5	"<line7>        logger.warn(""Rename directory {} failed!"", partitionBase.getAbsolutePath());"	<line7>	"logger.error(""Failed to rename partition {}"", partition)"	"<line7> logger.error(""Failed to rename partition {}"", partition)"
task5	"<line2>    log.debug("""");"	<line2>	"log.debug("""")"	"<line2> log.debug("""")"
task5	<line17>      log.error(UNEXPECTED_ERROR_OCCURRED, exception);	<line17>	log.error(UNEXPECTED_ERROR_OCCURRED, exception)	<line17> log.error(UNEXPECTED_ERROR_OCCURRED, exception)
task5	"<line10>        log.warn(""Spec "" + this + "" ignoring unknown config key "" + entry.getKey());"	<line10>	"log.warn(""Ignoring invalid configuration key: {}"", entry.getKey())"	"<line10> log.warn(""Ignoring invalid configuration key: {}"", entry.getKey())"
task5	<line40>      log.error(systemException, systemException);	<line40>	log.error(systemException, systemException)	<line40> log.error(systemException, systemException)
task5	<line7>      log.error(exception, exception);	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	"<line8>      log.error(""Request handler for path specification with prefix {} is already registered"",spec.prefix);"	<line8>	"log.error(""Prefix {} of path spec {} already registered"", spec.prefix, pathSpec)"	"<line8> log.error(""Prefix {} of path spec {} already registered"", spec.prefix, pathSpec)"
task5	"<line8>        logger.debug(""tryAfter() returns false: interceptorScopeTransaction: {}, executionPoint: {}. Skip""+ "" interceptor {}"",transaction,policy,interceptor.getClass());"	<line8>	"logger.debug(""tryAfter() returns false: interceptorScopeTransaction: {}, executionPoint: {}. Skip""+ "" interceptor {}"",transaction,policy,interceptor.getClass())"	"<line8> logger.debug(""tryAfter() returns false: interceptorScopeTransaction: {}, executionPoint: {}. Skip""+ "" interceptor {}"",transaction,policy,interceptor.getClass())"
task5	"<line3>      LOG.debug(""Testing Journal Rolling"");"	<line3>	"LOG.debug(""Ledgers created {}"", ledgerIds)"	"<line3> LOG.debug(""Ledgers created {}"", ledgerIds)"
task5	"<line2>      log.info(""Publishing application instance active event: [application] ""+ appId+ "" [instance] ""+ instanceId);"	<line2>	"log.info(""Publishing application instance activated event: [application] ""+ appId+ "" [instance] ""+ instanceId)"	"<line2> log.info(""Publishing application instance activated event: [application] ""+ appId+ "" [instance] ""+ instanceId)"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line6>    LOG.debug(""Sending empty message as there were no messages from polling: {}"", this.getEndpoint());"	<line2>	"LOG.debug(""Processing empty message"")"	"<line2> LOG.debug(""Processing empty message"")"
task5	"<line52>      LOG.error(""setup failed "", x);"	<line52>	"LOG.error(""setup failed "", x)"	"<line52> LOG.error(""setup failed "", x)"
task5	"<line5>    Log.debug(""Could not retrieve extended test db password, using default from unit tests"");"	<line5>	"log.error(""The test database password is missing!"")"	"<line5> log.error(""The test database password is missing!"")"
task5	"<line4>    LOG.info("">>>> "" + value);"	<line2>	"log.info("">>>> "" + value)"	"<line2> log.info("">>>> "" + value)"
task5	"<line3>    LOG.debug(""{} -> {}"", value, result);"	<line3>	"LOG.debug(""Transformed {} to {}"", value, result)"	"<line3> LOG.debug(""Transformed {} to {}"", value, result)"
task5	<line5>      logger.error(ex);	<line5>	"logger.info(""Expected xbooru.com URL format: ""+ getHost()+ "".com/index.php?tags=searchterm - got ""+ url+ "" instead"",ex)"	"<line5> logger.info(""Expected xbooru.com URL format: ""+ getHost()+ "".com/index.php?tags=searchterm - got ""+ url+ "" instead"",ex)"
task5	"<line12>      log.warn(""File-close threw the exception: "", continued);"	<line12>	"log.warn(""Failed to close stream: "" + continued.getMessage())"	"<line12> log.warn(""Failed to close stream: "" + continued.getMessage())"
task5	"<line19>          log.error(""SSLException during unwrap"", e);"	<line19>	"LOG.debug(""Ignoring SSLException during read"", e)"	"<line19> LOG.debug(""Ignoring SSLException during read"", e)"
task5	"<line8>      logger.debug(""Moving email, USER:{} UIDs:{} SRC:{} DST:{}"",udr.getUser().getLoginAtDomain(),messages,srcFolder,dstFolder);"	<line13>	"logger.error(""Error while moving messages"", e)"	"<line13> logger.error(""Error while moving messages"", e)"
task5	"<line17>      LOGGER.info(""We had some exception in Authentication filter"", e);"	<line17>	"LOGGER.error(""Error while filtering a request."", e)"	"<line17> LOGGER.error(""Error while filtering a request."", e)"
task5	"<line10>      logger.error(""Save failed"", ex);"	<line10>	"LOG.error(""Save failed"", ex)"	"<line10> LOG.error(""Save failed"", ex)"
task5	"<line3>      logger.error(""Cannot invoke signing without signing certificate. Add 'withSigningCertificate()' method""+ "" call or call 'withSignatureToken() instead.'"");"	<line2>	"logger.debug(""Loading data to be signed from file {}"", signatureParameters.getDataFile())"	"<line2> logger.debug(""Loading data to be signed from file {}"", signatureParameters.getDataFile())"
task5	<line19>      logger.warn(e.getMessage(), e);	<line19>	"logger.error(""Error saving attributes for org: "" + organizationId, e)"	"<line19> logger.error(""Error saving attributes for org: "" + organizationId, e)"
task5	"<line4>      logger.error(""Error in getCurrentSession()"", e);"	<line4>	"log.debug(""No Session available. Session is only available in transaction scope."")"	"<line4> log.debug(""No Session available. Session is only available in transaction scope."")"
task5	<line51>      log.error(systemException, systemException);	<line51>	log.error(systemException, systemException)	<line51> log.error(systemException, systemException)
task5	"<line6>    logger.info(""{} change logger level to DEBUG."", ctx.clazz().getName());"	<line6>	"logger.debug(""{} retry to initialize the context of this thread, the context is {}"",this,ctx)"	"<line6> logger.debug(""{} retry to initialize the context of this thread, the context is {}"",this,ctx)"
task5	"<line2>    logger.debug(""Replacing atom container at pos: "", position);"	<line2>	"logger.debug(""Replace atom container at position: "", position)"	"<line2> logger.debug(""Replace atom container at position: "", position)"
task5	"<line8>      LOG.error(""Can't connect to Solr: {}"", e);"	<line8>	"LOG.error(""Error creating Solr connection: {}"", e)"	"<line8> LOG.error(""Error creating Solr connection: {}"", e)"
task5	"<line5>        log.error(""Exception while setting ISSOUNDSTREAMING sensor {} to {}"",streamingSensor.getDisplayName(),mode);"	<line5>	"log.error(""setSensor error"", ex)"	"<line5> log.error(""setSensor error"", ex)"
task5	"<line17>      logger.error(""Error when get assignments"", e);"	<line17>	"logger.error(""Error getting all cube assignments"", e)"	"<line17> logger.error(""Error getting all cube assignments"", e)"
task5	"<line4>      logger.warn(""Linked Temperature device has no Value parameter: {}"", device);"	<line4>	"logger.warn(""Linked Temperature device has no Temperature Value parameter: {}"", device)"	"<line4> logger.warn(""Linked Temperature device has no Temperature Value parameter: {}"", device)"
task5	<line3>      logger.debug(msg);	<line3>	logger.debug(msg)	<line3> logger.debug(msg)
task5	"<line14>      LOG.warn(""Error calculating map update for enricher "" + this, t);"	<line8>	"LOG.debug(""{} - source sensor {} unchanged, so no need to update target"", this, sourceSensor)"	"<line8> LOG.debug(""{} - source sensor {} unchanged, so no need to update target"", this, sourceSensor)"
task5	<line26>      LOGGER.error(e.getMessage(), e);	<line26>	"LOG.error(""JavaScriptException in canHandle: "" + e.getMessage(), e)"	"<line26> LOG.error(""JavaScriptException in canHandle: "" + e.getMessage(), e)"
task5	"<line4>      LOG.warn(""Could not delete file '{}' from file store"", fileMeta.getId());"	<line4>	"log.error(""Could not delete file {} from file store"", fileMeta.getId(), e)"	"<line4> log.error(""Could not delete file {} from file store"", fileMeta.getId(), e)"
task5	<line1>    log.debug(format(arg0, arg1, arg2));	<line1>	logger.debug(arg0, arg1, arg2)	<line1> logger.debug(arg0, arg1, arg2)
task5	"<line2>      _Employee.LOG.debug(""updating lastName from "" + lastName() + "" to "" + value);"	<line2>	"_Employee.LOG.debug(""updating lastName from "" + lastName() + "" to "" + value)"	"<line2> _Employee.LOG.debug(""updating lastName from "" + lastName() + "" to "" + value)"
task5	"<line9>    logger.debug(LoggingMarkers.DUPLICATES, ""Same size: {}"", sameSize);"	<line9>	"logger.debug(String.format(""Comparing size for duplicates, difference = %d, average = %d, percent = %d, ""+ ""same = %b"",sizeDifference, sizeAverage, sizeDiffPercent, sameSize))"	"<line9> logger.debug(String.format(""Comparing size for duplicates, difference = %d, average = %d, percent = %d, ""+ ""same = %b"",sizeDifference, sizeAverage, sizeDiffPercent, sameSize))"
task5	"<line11>          LOG.error(""Failed to close the connection"", e);"	<line11>	"LOGGER.error(""Couldn't close statement"", e)"	"<line11> LOGGER.error(""Couldn't close statement"", e)"
task5	"<line15>          LOGGER.error(""Error while listing containers, while parsing resource "" + next, e);"	<line15>	"LOGGER.error(""Error while list path "" + basePath + "" while parsing element "" + next, e)"	"<line15> LOGGER.error(""Error while list path "" + basePath + "" while parsing element "" + next, e)"
task5	"<line10>      log.error(""Error during first step of installation"", e);"	<line10>	"log.error(""Error while removing package {}"", pkgId, e)"	"<line10> log.error(""Error while removing package {}"", pkgId, e)"
task5	"<line11>      log.error(""Warning: target extension point '""+ extension.getExtensionPoint()+ ""' of '""+ extension.getTargetComponent().getName()+ ""' is unknown. Check your extension in component ""+ extension.getComponent().getName());"	<line11>	"log.error(""Can't find the extension point "" + extension.getExtensionPoint())"	"<line11> log.error(""Can't find the extension point "" + extension.getExtensionPoint())"
task5	"<line10>      LOGGER.error(""Exception in WebDriverManager while getWebDriver "", e);"	<line10>	"LOGGER.error(""Exception in WebDriverManager while getWebDriver "", e)"	"<line10> LOGGER.error(""Exception in WebDriverManager while getWebDriver "", e)"
task5	"<line11>        LOG.warn(""Cert Container conversion failed: "" + e.getLocalizedMessage(), e);"	<line19>	"log.warn(""Data cannot be converted to a valid X.509 Certificate or IPKIX URL"", e)"	"<line19> log.warn(""Data cannot be converted to a valid X.509 Certificate or IPKIX URL"", e)"
task5	"<line11>      logger.error(""Input/Output exception while reading from a random access file. Stack trace follows"",ioe);"	<line11>	"log.error(""incrByte() threw"", ioe)"	"<line11> log.error(""incrByte() threw"", ioe)"
task5	"<line18>    LOGGER.debug(""IdentifiersMatch={} ({}, {})"",matches,dependency1.getFileName(),dependency2.getFileName());"	<line14>	"LOGGER.debug(""CPE identifiers do not match: {} and {}"", i, dependency2.getVulnerableSoftwareIdentifiers())"	"<line14> LOGGER.debug(""CPE identifiers do not match: {} and {}"", i, dependency2.getVulnerableSoftwareIdentifiers())"
task5	"<line9>      LOG.trace(""Registered service: {}..."", brokerPoolService.getClass().getSimpleName());"	<line9>	"LOG.trace(""Registered service: {}"", brokerPoolService)"	"<line9> LOG.trace(""Registered service: {}"", brokerPoolService)"
task5	"<line12>      logger.error(""error in save"", t);"	<line12>	"logger.error(""error in save"", t)"	"<line12> logger.error(""error in save"", t)"
task5	"<line4>    LOG.debug(""Loaded conf "" + conf);"	<line4>	"LOG.info(""Initialized {}"", this.getClass().getSimpleName())"	"<line4> LOG.info(""Initialized {}"", this.getClass().getSimpleName())"
task5	"<line6>      LOG.error(""Failed to get revision {} of note {}"", revId, noteId, e);"	<line6>	"LOG.error(""Fail to get note {} revision {}"", noteId, revId, e)"	"<line6> LOG.error(""Fail to get note {} revision {}"", noteId, revId, e)"
task5	"<line4>      log.debug(""logback loglevel is starting..."");"	<line3>	"log.info(""Starting loglevel configuration"")"	"<line3> log.info(""Starting loglevel configuration"")"
task5	"<line15>        LOG.debug(""UP UPDATE  \t""+ startVertex.getId()+ ""\t""+ maxVertex.getId()+ ""\t""+ startVertex.getHierarchyWeight()+ "" --> ""+ (maxVertex.getHierarchyWeight() - 1));"	<line1>	"LOGGER.debug(""updating depth values for vertex {}"", startVertex.getId())"	"<line1> LOGGER.debug(""updating depth values for vertex {}"", startVertex.getId())"
task5	"<line12>      logger.error(""Exception occurred in AAIUpdateTasks updateManagementV6AddressVnf"", ex);"	<line12>	"logger.error(""Exception occurred in AAIUpdateTasks during updateManagementV6AddressVnf"", ex)"	"<line12> logger.error(""Exception occurred in AAIUpdateTasks during updateManagementV6AddressVnf"", ex)"
task5	"<line53>              log.warn(""OrganizationPersistenceImpl.fetchByC_ERC(long, String, boolean) with parameters""+ "" (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."");"	<line53>	"log.warn(""OrganizationPersistenceImpl.fetchByC_ERC(long, String, boolean) with parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."")"	"<line53> log.warn(""OrganizationPersistenceImpl.fetchByC_ERC(long, String, boolean) with parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."")"
task5	"<line2>    logger.debug(""Adding product with coefficient: "", product, """" + coefficient);"	<line2>	"logger.debug(""Adding product: "", product, "" with coefficient: "", coefficient)"	"<line2> logger.debug(""Adding product: "", product, "" with coefficient: "", coefficient)"
task5	"<line1>    logger.debug(""getAuthorizedPublishers started..."");"	<line1>	"logger.debug(""getAuthorizedPublishers started..."")"	"<line1> logger.debug(""getAuthorizedPublishers started..."")"
task5	<line18>      logger.debug(msg);	<line18>	logger.debug(msg, e)	<line18> logger.debug(msg, e)
task5	"<line2>    LOG.debug(""KyloDatabaseConnectionInspection.inspect"");"	<line33>	"logger.info(""Established connection to database"")"	"<line33> logger.info(""Established connection to database"")"
task5	"<line6>      LOG.error(""Interrupted waiting for finish"", e);"	<line6>	"logger.error(""syncStop interrupted"", e)"	"<line6> logger.error(""syncStop interrupted"", e)"
task5	"<line19>      LOGGER.info(""Configuring jdbcloader from "" + url.toString());"	<line19>	"LOGGER.info(""Reading configuration from URL: "" + url)"	"<line19> LOGGER.info(""Reading configuration from URL: "" + url)"
task5	"<line19>      logger.error(""error in end tag"", t);"	<line19>	"logger.error(""error in doEndTag"", t)"	"<line19> logger.error(""error in doEndTag"", t)"
task5	"<line3>    logger.info(""STANDALONE mode is set..."");"	<line3>	"logger.debug(""onApplicationEvent started..."")"	"<line3> logger.debug(""onApplicationEvent started..."")"
task5	"<line4>      log.info(""Invalid map to add the entries"");"	<line10>	"log.debug(""Adding attribute "" + addAttribute.getKey() + "" to map. Overwriting existing attribute."")"	"<line10> log.debug(""Adding attribute "" + addAttribute.getKey() + "" to map. Overwriting existing attribute."")"
task5	"<line3>    LOG.debug(String.format(""started opertation %s. polling until complete."", operation.getName()));"	<line4>	"logger.info(""Waiting for operation {}"", operation.getName())"	"<line4> logger.info(""Waiting for operation {}"", operation.getName())"
task5	<line6>      logger.error(e.getMessage());	<line6>	"LOGGER.error(""Failed to apply Schematron validation transform"", e)"	"<line6> LOGGER.error(""Failed to apply Schematron validation transform"", e)"
task5	"<line53>      LOGGER.error(""Exception:"", e);"	<line53>	"LOGGER.error(""Exception:"", e)"	"<line53> LOGGER.error(""Exception:"", e)"
task5	"<line17>      LOG.error(""Failed fetching using indexQuery: "" + e.getMessage());"	<line17>	"LOG.warn(""getTypeShellCount(): Returned empty result!"", e)"	"<line17> LOG.warn(""getTypeShellCount(): Returned empty result!"", e)"
task5	"<line9>    LOGGER.info(""Created multibranch pipeline: "" + pipelineName);"	<line3>	"LOGGER.info(""Creating multi-branch pipeline {}"", pipelineName)"	"<line3> LOGGER.info(""Creating multi-branch pipeline {}"", pipelineName)"
task5	"<line18>      log.debug(""Adding object {}: {}"", i++, file.getName());"	<line2>	"log.info(""Running job to stage deposit {}"", getDepositPID().getQualifiedId())"	"<line2> log.info(""Running job to stage deposit {}"", getDepositPID().getQualifiedId())"
task5	"<line3>      LOG.warn(""{} is not configured. We recommend adding this setting. ""+ ""Falling back to {} instead."",definition.getLocationConfigKey(),HddsConfigKeys.OZONE_METADATA_DIRS);"	<line5>	"LOG.info(""Metadata directory for DB {} is {}"", definition.getDBName(), metadataDir)"	"<line5> LOG.info(""Metadata directory for DB {} is {}"", definition.getDBName(), metadataDir)"
task5	"<line2>    log.debug(""NunchukRemovedEvent {}"", arg0);"	<line2>	"logger.info(""Nunchuk removed: {}"", arg0.getNunchuk().getAddress())"	"<line2> logger.info(""Nunchuk removed: {}"", arg0.getNunchuk().getAddress())"
task5	<line13>      logger.warn(e.getMessage(), e);	<line13>	logger.debug(e.getMessage(), e)	<line13> logger.debug(e.getMessage(), e)
task5	"<line14>        log.error(""Failed to end transaction"", e);"	<line14>	"log.error(""Failed to commit/rollback transaction"", e)"	"<line14> log.error(""Failed to commit/rollback transaction"", e)"
task5	"<line2>    logger.warn(""Schema validation error parsing Flow Configuration at line {}, col {}: {}"",e.getLineNumber(),e.getColumnNumber(),e.getMessage());"	<line2>	logger.warn(getSAXErrorMessage(e), e)	<line2> logger.warn(getSAXErrorMessage(e), e)
task5	"<line22>        logger.error(""commit index exception, commitMap: {}, app: {}"", entry.getValue(), app, e);"	<line22>	"logger.error(""commitIndex exception, topic: {}, app: {}, indexes: {}, broker: {}"",topic,app,indexes,entry.getKey())"	"<line22> logger.error(""commitIndex exception, topic: {}, app: {}, indexes: {}, broker: {}"",topic,app,indexes,entry.getKey())"
task5	"<line13>      LOG.error(""Error while checking validity of the document"", e);"	<line13>	"logger.error(""Error while checking document validity"", e)"	"<line13> logger.error(""Error while checking document validity"", e)"
task5	<line40>      log.error(UNEXPECTED_ERROR_OCCURRED, exception);	<line29>	"log.error(""Unable to attach the rule with the target {}"", config.getJob().getLambda().getTargetId())"	"<line29> log.error(""Unable to attach the rule with the target {}"", config.getJob().getLambda().getTargetId())"
task5	"<line3>      logger.debug(""Client Http Session received OK"");"	<line3>	"logger.debug(""Server Http Session message received"")"	"<line3> logger.debug(""Server Http Session message received"")"
task5	"<line31>        logger.info(""Concat video job {} started on a remote composer"", r.getId());"	<line31>	"logger.info(""Started concat on a remote composer service proxy"")"	"<line31> logger.info(""Started concat on a remote composer service proxy"")"
task5	"<line4>        log.debug(""Loading "" + sourceURL);"	<line4>	"log.debug(""Reading SQL files from "" + sourceURL)"	"<line4> log.debug(""Reading SQL files from "" + sourceURL)"
task5	"<line12>      logger.debug(""Unable to find beans exposing the `BindableService` interface - not starting the gRPC""+ "" server"");"	<line12>	"LOG.info(""gRPC server will not be started in production mode"")"	"<line12> LOG.info(""gRPC server will not be started in production mode"")"
task5	"<line7>      logger.error(""Error reading the content from version {} "", versionId, e);"	<line7>	"logger.error(""Error getting content for version {}"", versionId, e)"	"<line7> logger.error(""Error getting content for version {}"", versionId, e)"
task5	"<line12>        log.error(""Cartridge group not found group-name: "" + groupCtxt.getName());"	<line10>	"log.debug(""Parsing group: {}"", groupCtxt.getName())"	"<line10> log.debug(""Parsing group: {}"", groupCtxt.getName())"
task5	"<line4>      logger.trace(""DoLock.execute() : do workaround for user agent '"" + userAgent + ""'"");"	<line21>	"logger.error(""Error: locked object not found for path: "" + path)"	"<line21> logger.error(""Error: locked object not found for path: "" + path)"
task5	"<line8>    LOG.debug(""Created cache key; {}"", cacheKey);"	<line8>	"LOG.trace(""toKey({},{})"", expression, input)"	"<line8> LOG.trace(""toKey({},{})"", expression, input)"
task5	<line6>      log.error(msg);	<line6>	log.error(msg)	<line6> log.error(msg)
task5	"<line7>      logger.info(""Processing: ["" + data + ""]"");"	<line5>	"LOGGER.info(""Failing now..."")"	"<line5> LOGGER.info(""Failing now..."")"
task5	"<line11>        logger.warn(""A lifecycle error observer threw an exception"", ex);"	<line11>	"log.error(""Could not process error event"", ex)"	"<line11> log.error(""Could not process error event"", ex)"
task5	"<line2>      logger.trace(""getDiscoveryInitialWaitTimeout()"");"	<line2>	"logger.trace(""getDiscoveryInitialWaitTimeout()"")"	"<line2> logger.trace(""getDiscoveryInitialWaitTimeout()"")"
task5	"<line7>    LOG.debug(""[testScheduleCampaign] {}"", rs);"	<line7>	"LOG.debug(""{}"", rs)"	"<line7> LOG.debug(""{}"", rs)"
task5	"<line3>      LOG.debug(""Securing route {} using Shiro policy {}"", route.getRouteId(), this);"	<line3>	"LOG.debug(""Wrapping route {} in ShiroSecurityProcessor"", route)"	"<line3> LOG.debug(""Wrapping route {} in ShiroSecurityProcessor"", route)"
task5	"<line1>    LOG.debug(""Config loaded"" + authConfig);"	<line12>	"log.error(""config load error"", e)"	"<line12> log.error(""config load error"", e)"
task5	"<line4>      log.debug(""Get {}: {} {} {}"",new String[] {o != null ? ""Hit"" : ""Miss"", getLogLayerId(layer), category.toString(), key});"	<line4>	"log.debug(""get "" + category.toString() + "" "" + key + "" -> "" + o)"	"<line4> log.debug(""get "" + category.toString() + "" "" + key + "" -> "" + o)"
task5	"<line42>      log.error(""Error during find All , Caused by: ."", ioex);"	<line42>	"log.error(""Error while finding all for entity class {}, caused by {}."", entityClass, ioex)"	"<line42> log.error(""Error while finding all for entity class {}, caused by {}."", entityClass, ioex)"
task5	"<line2>    log.info(""Setting up disk quota periodic enforcement task"");"	<line2>	"logger.info(""DiskQuota clean up executor service created with {} threads"", numCleaningThreads)"	"<line2> logger.info(""DiskQuota clean up executor service created with {} threads"", numCleaningThreads)"
task5	"<line3>    logger.info(""registered scripting gauge:"" + name);"	<line1>	"logger.debug(""newGauge(name={}, initialValue={})"", name, initialValue)"	"<line1> logger.debug(""newGauge(name={}, initialValue={})"", name, initialValue)"
task5	"<line2>    logger.debug(""Getting reactionScheme count: "", super.getReactionSchemeCount());"	<line2>	"logger.debug(""Getting reaction scheme count: "", super.getReactionSchemeCount())"	"<line2> logger.debug(""Getting reaction scheme count: "", super.getReactionSchemeCount())"
task5	<line17>      LOGGER.error(ERROR_ADDING_DATA, e);	<line17>	logger.error(e.getMessage())	<line17> logger.error(e.getMessage())
task5	"<line7>      LOGGER.warn(""No event on flow completion"", messagingException);"	<line7>	"LOG.warn(""Event is null for pipeline {}"", this.getName())"	"<line7> LOG.warn(""Event is null for pipeline {}"", this.getName())"
task5	"<line22>    logger.debug(""final cluster spec: "" + manifest);"	<line22>	"logger.info(""Cluster manifest: {}"", manifest)"	"<line22> logger.info(""Cluster manifest: {}"", manifest)"
task5	"<line1>    logger.debug(""activate()"");"	<line1>	"log.info(""Activating {}"", this.getClass().getSimpleName())"	"<line1> log.info(""Activating {}"", this.getClass().getSimpleName())"
task5	"<line39>      LOGGER.info(""discovered {} ctors, {} methods for class {}"",declaredConstructors.length,methods,clazz);"	<line39>	"LOG.info(""defined {} test methods for {}"", methods, clazz)"	"<line39> LOG.info(""defined {} test methods for {}"", methods, clazz)"
task5	<line13>        LOGGER.warn(e.toString(), e);	<line13>	"LOGGER.warn(""Unexpected exception while writing request body"", e)"	"<line13> LOGGER.warn(""Unexpected exception while writing request body"", e)"
task5	"<line3>    LOG.trace(""postNotice"");"	<line3>	"LOG.debug(""postNotice"")"	"<line3> LOG.debug(""postNotice"")"
task5	<line35>            LOGGER.warn(e.getMessage(), e);	<line35>	"log.error(""Error while trying to generate a bash example for body parameter ""+ p.name+ "" of type ""+ p.dataType+ "" with no schema example."")"	"<line35> log.error(""Error while trying to generate a bash example for body parameter ""+ p.name+ "" of type ""+ p.dataType+ "" with no schema example."")"
task5	"<line2>    log.debug(""Reading CAs for Automation document [{}] ({}) in project [{}] ({})"",aDocument.getName(),aDocument.getId(),aDocument.getProject().getName(),aDocument.getProject().getId());"	<line20>	"log.info(""Reading annotations for document ["" + aDocument.getName() + ""] ("" + aDocument.getId() + "")"")"	"<line20> log.info(""Reading annotations for document ["" + aDocument.getName() + ""] ("" + aDocument.getId() + "")"")"
task5	"<line7>      log.error(""Error while reading traits"", e);"	<line7>	"log.error(""Unable to read traits"", e)"	"<line7> log.error(""Unable to read traits"", e)"
task5	"<line8>      LOGGER.debug(""File's own path: {}"", filePath);"	<line9>	"LOGGER.debug(""Adding file: "" + filePath)"	"<line9> LOGGER.debug(""Adding file: "" + filePath)"
task5	"<line3>    log.info(""Portlet [""+ (portletName != null ? portletName : this.getClass().getSimpleName())+ ""] has been MODIFIED."");"	<line3>	"log.debug(""Portlet [""+ (portletName != null ? portletName : this.getClass().getSimpleName())+ ""] has been configured."")"	"<line3> log.debug(""Portlet [""+ (portletName != null ? portletName : this.getClass().getSimpleName())+ ""] has been configured."")"
task5	"<line5>      LOGGER.info(""Attempt to delete mailbox {} for user {} that does not exists"",mailboxPath.getName(),mailboxPath.getUser());"	<line5>	"LOGGER.info(""Mailbox not found: {}"", mailboxPath)"	"<line5> LOGGER.info(""Mailbox not found: {}"", mailboxPath)"
task5	<line2>    log.debug(event);	<line2>	LOGGER.info(event)	<line2> LOGGER.info(event)
task5	"<line10>        LOGGER.info(""Catalog sync interrupted early, exiting"");"	<line14>	"console.debug(""Adding {} results"", results.size())"	"<line14> console.debug(""Adding {} results"", results.size())"
task5	"<line4>      ActiveMQRALogger.LOGGER.trace(""createConnectionConsumer("" + destination + "", "" + pool + "", "" + maxMessages + "")"");"	<line4>	"ActiveMQRALogger.LOGGER.trace(""createConnectionConsumer("" + destination + "", "" + pool + "", "" + maxMessages + "")"")"	"<line4> ActiveMQRALogger.LOGGER.trace(""createConnectionConsumer("" + destination + "", "" + pool + "", "" + maxMessages + "")"")"
task5	"<line51>              log.warn(""ObjectFieldPersistenceImpl.fetchByODI_N(long, String, boolean) with parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."");"	<line51>	"log.warn(""ObjectFieldPersistenceImpl.fetchByODI_N(long, String, boolean) with parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."")"	"<line51> log.warn(""ObjectFieldPersistenceImpl.fetchByODI_N(long, String, boolean) with parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."")"
task5	"<line11>            LOG.info(""Model contains Equipment Core data profile in model {}"",m.get(CgmesNames.FULL_MODEL));"	<line11>	"LOG.info(""HasEquipmentCore: "" + p)"	"<line11> LOG.info(""HasEquipmentCore: "" + p)"
task5	"<line21>                    LOG.info(""File Metadata resourceId is {} "", file.getMetadata().resourceId());"	<line21>	"LOG.info(""Output filepattern {}"", file.getMetadata().getPath())"	"<line21> LOG.info(""Output filepattern {}"", file.getMetadata().getPath())"
task5	"<line29>      logger.error(""Unable to update index"", e);"	<line29>	"LOG.error(""Error updating indexes for subscriber queue {}"", subscriberQueuePath, e)"	"<line29> LOG.error(""Error updating indexes for subscriber queue {}"", subscriberQueuePath, e)"
task5	"<line31>          LOG.warn(""Ignoring unsupported Workflow node type {}"", node.getType());"	<line31>	"LOG.debug(""Ignoring node type {}"", node.getType())"	"<line31> LOG.debug(""Ignoring node type {}"", node.getType())"
task5	"<line3>      LOG.debug(""discarding unexpected response [correlation-id: {}]"", correlationId);"	<line3>	"log.error(""no result handler found for correlation id {}"", correlationId)"	"<line3> log.error(""no result handler found for correlation id {}"", correlationId)"
task5	<line19>      log.error(systemException, systemException);	<line19>	log.error(systemException, systemException)	<line19> log.error(systemException, systemException)
task5	"<line15>      logger.error(""Error skipping to: "" + pos + "": "" + e.getMessage(), e);"	<line15>	log.error(e.getMessage(), e)	<line15> log.error(e.getMessage(), e)
task5	"<line5>    LOG.info(""---------------- Response with content received from '{}' ----------------\n""+ ""---------------- START Response-Body ----------------\n""+ ""{}\n""+ ""---------------- END Response-Body ----------------"",request.getURI(),response);"	<line5>	"if (LOG.isDebugEnabled()) LOG.debug(""onData {}"", response)"	"<line5> if (LOG.isDebugEnabled()) LOG.debug(""onData {}"", response)"
task5	"<line8>    LOGGER.info(""Move paragraph {} {} {}"", noteId, paragraphId, newIndex);"	<line8>	"LOGGER.info(""Move paragraph {} in note {} to index {}"",paragraphId,noteId,Integer.parseInt(newIndex))"	"<line8> LOGGER.info(""Move paragraph {} in note {} to index {}"",paragraphId,noteId,Integer.parseInt(newIndex))"
task5	"<line2>      log.debug(""sendWindowChange({}) cols={}, lines={}, height={}, width={}"",this,columns,lines,height,width);"	<line2>	"log.debug(""sendWindowChange({}) columns={}, lines={}, height={}, width={}"", this, columns, lines, height, width)"	"<line2> log.debug(""sendWindowChange({}) columns={}, lines={}, height={}, width={}"", this, columns, lines, height, width)"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line7>        logger.warn(""Failed to stop command with pid {}"", pid.getPid());"	<line7>	"LOG.warn(""Failed to send {} to process with pid {}"", signal, pid)"	"<line7> LOG.warn(""Failed to send {} to process with pid {}"", signal, pid)"
task5	<line2>    LOGGER.debug(String.format(Messages.Log.RECEIVING_REMOTE_REQUEST_S, iq.getID()));	<line2>	LOGGER.debug(String.format(Messages.Log.RECEIVING_REMOTE_REQUEST, iq.getID()))	<line2> LOGGER.debug(String.format(Messages.Log.RECEIVING_REMOTE_REQUEST, iq.getID()))
task5	"<line11>          log.error(""Invalid Command name in SimpleCommand: {}, skipping"", cmd);"	<line11>	"LOGGER.warn(""Command {} does not match the requirements of a simple command"", cmd)"	"<line11> LOGGER.warn(""Command {} does not match the requirements of a simple command"", cmd)"
task5	"<line12>      LOG.error("""", e);"	<line12>	"LOG.error(""Exception in getInstanceCurrentState"", e)"	"<line12> LOG.error(""Exception in getInstanceCurrentState"", e)"
task5	"<line13>        logger.debug(""Failed to create snapshot for region: {}. Continuing with next region."",subRegion.getFullPath(),e);"	<line13>	"logger.error(""Error while creating snapshot for region: "" + subRegion.getFullPath(), e)"	"<line13> logger.error(""Error while creating snapshot for region: "" + subRegion.getFullPath(), e)"
task5	"<line26>      logger.error(""Error in processing input row:"", e);"	<line26>	"logger.error(""Error in processing input row:"", e)"	"<line26> logger.error(""Error in processing input row:"", e)"
task5	"<line3>      LOGGER.trace(format(""Encode raw '%s' tuple2 object %s"", fieldName, o));"	<line3>	"LOGGER.trace(format(""Encode raw '%s' tuple2 object %s"", fieldName, o))"	"<line3> LOGGER.trace(format(""Encode raw '%s' tuple2 object %s"", fieldName, o))"
task5	"<line4>      logger.debug(""writeElement: "" + sbmlElementToWrite.getClass().getSimpleName());"	<line4>	"logger.debug(MessageFormat.format(""writeElement {0}"", xmlObject.getElementName()))"	"<line4> logger.debug(MessageFormat.format(""writeElement {0}"", xmlObject.getElementName()))"
task5	<line6>      log.warn(message, e);	<line6>	LOG.error(message)	<line6> LOG.error(message)
task5	<line24>      log.error(exception.getMessage(), exception);	<line24>	"log.error(""Unable to initialize BayeuxClient"", exception)"	"<line24> log.error(""Unable to initialize BayeuxClient"", exception)"
task5	"<line4>    LOG.info(""Created new process file and writer over {} "", processFile.getAbsolutePath());"	<line1>	"log.info(""Generation of files {} and {} started"", inProcessFile, processFile)"	"<line1> log.info(""Generation of files {} and {} started"", inProcessFile, processFile)"
task5	"<line15>        LOGGER.warn(""Interrupted while requesting repository statistics."", e);"	<line15>	"log.error(""Failed to get repository statistics."", e)"	"<line15> log.error(""Failed to get repository statistics."", e)"
task5	"<line3>      ActiveMQRALogger.LOGGER.trace(""setFloat("" + name + "", "" + value + "")"");"	<line3>	"ActiveMQRALogger.LOGGER.trace(""setFloat("" + name + "", "" + value + "")"")"	"<line3> ActiveMQRALogger.LOGGER.trace(""setFloat("" + name + "", "" + value + "")"")"
task5	"<line28>          logger.warn(""unknown produce code {}"", code);"	<line28>	"logger.error(""produce code not exist, version:[{}], code:[{}]"", version, code)"	"<line28> logger.error(""produce code not exist, version:[{}], code:[{}]"", version, code)"
task5	"<line30>            log.debug(""initChannel("" + ch + "") listener="" + listener + "" ignoring abort event exception"",exc);"	<line30>	"log.debug(""initChannel() exception while invoking listener {}"", listener, exc)"	"<line30> log.debug(""initChannel() exception while invoking listener {}"", listener, exc)"
task5	"<line1>    log.info(""Sample point called "" + x + "" "" + y);"	<line1>	"log.debug(""Sample point: "" + x + "" "" + y)"	"<line1> log.debug(""Sample point: "" + x + "" "" + y)"
task5	"<line10>      LOG.info(""The amount of cpu cores must be a positive integer on Yarn. Rounding {} up to the""+ "" closest positive integer {}."",cpuCoresDouble,cpuCoresLong);"	<line10>	"LOG.warn(""The amount of cpu cores {} cannot be represented as a long: {}"",cpuCoresDouble,cpuCoresLong)"	"<line10> LOG.warn(""The amount of cpu cores {} cannot be represented as a long: {}"",cpuCoresDouble,cpuCoresLong)"
task5	"<line13>        LOG.debug(""Allocation to dirIndex {} rejected: {}"", dirIndex, dir.toBlockStoreLocation());"	<line15>	"LOG.debug(""Exhausted all dirs in the tier. Return -1"")"	"<line15> LOG.debug(""Exhausted all dirs in the tier. Return -1"")"
task5	"<line2>      LOG.trace(""clearing JMX Cache"" + StringUtils.stringifyException(new Exception()));"	<line2>	"LOG.trace(""Clearing jmx cache"")"	"<line2> LOG.trace(""Clearing jmx cache"")"
task5	"<line2>    log.error(""Request: {} raised following exception."", req.getRequestURL(), exception);"	<line2>	"logger.error(""Unable to process request"", exception)"	"<line2> logger.error(""Unable to process request"", exception)"
task5	"<line1>    log.info(""[{}] Clearing backlog for cursor {} in the topic."", topic, cursorName);"	<line9>	"log.warn(""[{}] Failed to clear backlog for cursor: {}"", topic, cursorName)"	"<line9> log.warn(""[{}] Failed to clear backlog for cursor: {}"", topic, cursorName)"
task5	"<line11>      LOGGER.warn(""Cannot find histogram for coverage '"" + coverageName + ""'"");"	<line11>	"LOGGER.info(""Unable to find histogram for "" + coverageName)"	"<line11> LOGGER.info(""Unable to find histogram for "" + coverageName)"
task5	"<line7>    logger.debug(""checkUniqueConstraintByConsumerSystemIdAndServiceIdAndProviderSystemId started..."");"	<line12>	"logger.debug(""checkUniqueConstraintByConsumerSystemIdAndServiceIdAndProviderSystemId""+ "" VIOLATES_UNIQUE_CONSTRAINT"")"	"<line12> logger.debug(""checkUniqueConstraintByConsumerSystemIdAndServiceIdAndProviderSystemId""+ "" VIOLATES_UNIQUE_CONSTRAINT"")"
task5	"<line17>              logger.error(""Error occured while generating JSON!"");"	<line17>	"logger.error(""Error occured while generating JSON!"", e)"	"<line17> logger.error(""Error occured while generating JSON!"", e)"
task5	"<line11>                LOG.error(""Null {}"", ItemTO.class.getSimpleName());"	<line41>	"LOG.error(""Invalid mapping for auth module items: {}"", scce.getMessage(), scce)"	"<line41> LOG.error(""Invalid mapping for auth module items: {}"", scce.getMessage(), scce)"
task5	<line21>        LOG.debug(e.getMessage());	<line21>	"LOG.debug(""Could not find drive title for language '{}' and title key '{}'"", lang, key)"	"<line21> LOG.debug(""Could not find drive title for language '{}' and title key '{}'"", lang, key)"
task5	"<line2>      log.warn(""Closing session for you"");"	<line6>	"log.info(""Opened session as administrator"")"	"<line6> log.info(""Opened session as administrator"")"
task5	"<line18>        LOG.error(""Suppressing exception from closing tables"", t);"	<line18>	"log.error(""Failed to close tables"", t)"	"<line18> log.error(""Failed to close tables"", t)"
task5	<line5>      log.error(msg);	<line5>	log.error(msg)	<line5> log.error(msg)
task5	"<line3>    logger.info(""Registering error: {}, code: {}, body:\n{}"", key, code, error);"	<line2>	"logger.debug(""registering error response for {} {}"", method, path)"	"<line2> logger.debug(""registering error response for {} {}"", method, path)"
task5	"<line12>      logger.debug(""Using evaluator with index {} (wnc:{}, rcs:{}, rst:{}, rs:{}) "",new Object[] {evaluatorIndex, wnc, restrictsConnectionStates, restrictsSocketTypes, restrictsSockets});"	<line12>	"logger.debug(""using evaluator {} for check {}"", evaluator, check)"	"<line12> logger.debug(""using evaluator {} for check {}"", evaluator, check)"
task5	"<line7>      log.debug(e, ""SQLException when abort"");"	<line7>	"LOG.error(""Aborting transaction failed"", e)"	"<line7> LOG.error(""Aborting transaction failed"", e)"
task5	"<line6>        logger.debug(""RowKeyComparisonFilter: "" + (this.keepRow ? ""KEEP"" : ""FILTER"") + "" row "" + inputTuple);"	<line6>	"logger.debug(""filterKeyValue(), keepRow="" + keepRow)"	"<line6> logger.debug(""filterKeyValue(), keepRow="" + keepRow)"
task5	"<line3>      logger.error(""getDoubleProperty(): argument 'name' must be non-null"");"	<line3>	"logger.warn(""getDoubleProperty(): argument 'name' must be non-null"")"	"<line3> logger.warn(""getDoubleProperty(): argument 'name' must be non-null"")"
task5	"<line2>      log.trace(""add margins to extent "" + extent);"	<line2>	"log.trace(""Adding margins of "" + extent + "" to "" + this)"	"<line2> log.trace(""Adding margins of "" + extent + "" to "" + this)"
task5	"<line5>      LOG.warn(""No state retention interval configured for a query which accumulates state. Please""+ "" provide a query configuration with valid retention interval to prevent excessive""+ "" state size. You may specify a retention time of 0 to not clean up the state."");"	<line5>	"LOG.warn(""The execution of this query will not use local grouping aggregation. ""+ ""Please consider adding a minimum idle state retention time to the table ""+ ""configuration."")"	"<line5> LOG.warn(""The execution of this query will not use local grouping aggregation. ""+ ""Please consider adding a minimum idle state retention time to the table ""+ ""configuration."")"
task5	"<line5>        LOGGER.info(""Dropped a pending dataverse: "" + dataverse.getDataverseName());"	<line5>	"LOGGER.info(""Dataverse "" + dataverse.getDataverseName() + "" was dropped and will be recreated"")"	"<line5> LOGGER.info(""Dataverse "" + dataverse.getDataverseName() + "" was dropped and will be recreated"")"
task5	"<line12>    LOGGER.debug(""Creating a Dataset<Row> from path {} with option mergeSchema=true"", store.getGraphPath());"	<line15>	"LOGGER.debug(""GetDataFrameOfElements: returning {} records"", dataframe.count())"	"<line15> LOGGER.debug(""GetDataFrameOfElements: returning {} records"", dataframe.count())"
task5	<line10>      Logger.debug(response.getBody().toString());	<line10>	Logger.debug(response.getBody().toString())	<line10> Logger.debug(response.getBody().toString())
task5	"<line10>    LOG.info(""Opening split "" + split);"	<line11>	"LOG.info(""Opening Avro data file: {}"", stream)"	"<line11> LOG.info(""Opening Avro data file: {}"", stream)"
task5	"<line2>    LOG.debug(""Client connected"");"	<line18>	"LOGGER.info(""Tracking connection to ["" + remoteSocketAddress + ""]"")"	"<line18> LOGGER.info(""Tracking connection to ["" + remoteSocketAddress + ""]"")"
task5	"<line33>      LOG.debug(""Failed to delete {} flows"", deviceFlowRegistry.size(), ex);"	<line33>	"LOG.error(""Failed to delete all flows for node: {}"", instanceIdentifier, ex)"	"<line33> LOG.error(""Failed to delete all flows for node: {}"", instanceIdentifier, ex)"
task5	"<line32>    LOG.info(""{} removed from Flow Controller"", service, this);"	<line32>	"LOG.info(""{} removed from {}"", service, this)"	"<line32> LOG.info(""{} removed from {}"", service, this)"
task5	"<line2>      log.info(""Recieved ping for [{}]"", agentId);"	<line2>	"log.info(""Successfully pinged {} after {} failures."", hostname, failures)"	"<line2> log.info(""Successfully pinged {} after {} failures."", hostname, failures)"
task5	"<line1>    logger.info(""activate..."");"	<line3>	"logger.debug(""Activating {}"", this.getClass().getName())"	"<line3> logger.debug(""Activating {}"", this.getClass().getName())"
task5	"<line7>    log.debug(""deleteLayout() - id={}"", id);"	<line7>	"log.debug(""deleteLayout() - id: {}"", id)"	"<line7> log.debug(""deleteLayout() - id: {}"", id)"
task5	"<line10>        log.info(""Expected exception: "" + e);"	<line10>	"log.info(""Expected exception: "" + e)"	"<line10> log.info(""Expected exception: "" + e)"
task5	"<line8>      logger.info(getClass().getName()+ "".freeInstance: ignoring exception ""+ e+ "" on bean instance ""+ bean);"	<line8>	"log.warn(""The bean instance "" + bean + "" threw a system exception during freeing"", e)"	"<line8> log.warn(""The bean instance "" + bean + "" threw a system exception during freeing"", e)"
task5	"<line33>      LOGGER.error(""Exception while processing message in RelayStatisticsCollectingHandler"");"	<line33>	"LOG.error(""Exception in messageReceived"", ex)"	"<line33> LOG.error(""Exception in messageReceived"", ex)"
task5	"<line8>      logger.warn(""Error shutting down user group refresh scheduler due to {}"", e.getMessage(), e);"	<line8>	"LOG.warn(""Interrupted while waiting for scheduler to terminate"", e)"	"<line8> LOG.warn(""Interrupted while waiting for scheduler to terminate"", e)"
task5	"<line9>          LOG.warn(""Invalid stream rule type. Skipping matching for this rule. "" + e.getMessage(), e);"	<line9>	"LOG.error(""Invalid stream rule type"", e)"	"<line9> LOG.error(""Invalid stream rule type"", e)"
task5	"<line23>      LOG.warn(""Unexpected key type "" + key + "" ("" + key.getClass() + "") in "" + bo + ""; ignoring value"");"	<line17>	"LOG.trace(""Resolved {} from {}"", result, container)"	"<line17> LOG.trace(""Resolved {} from {}"", result, container)"
task5	"<line3>    log.debug("">> IoT Hub responded to message {} with status {}"", msg.getMessageId(), status.name());"	<line3>	"log.debug(""Telemetry - Message Id: {}"", msg.getMessageId())"	"<line3> log.debug(""Telemetry - Message Id: {}"", msg.getMessageId())"
task5	"<line2>    LOG.info(""Enabling availability zone {} in preparation for agent {}"",availabilityZone,agent.getAgentId());"	<line2>	"LOG.info(""Enabling availability zone {} for {}"", availabilityZone, agent.getHostname())"	"<line2> LOG.info(""Enabling availability zone {} for {}"", availabilityZone, agent.getHostname())"
task5	"<line3>    log.debug(""XML export output at "" + outputFile.getAbsolutePath());"	<line3>	"log.debug(""XML digest calculation for file "" + outputFile)"	"<line3> log.debug(""XML digest calculation for file "" + outputFile)"
task5	"<line7>      log.trace(""setting sensor {}={} for {}"", new Object[] {path, newValue, entity});"	<line7>	"log.trace(""update {} {}"", path, newValue)"	"<line7> log.trace(""update {} {}"", path, newValue)"
task5	"<line14>      LOG.debug(""Exiting safe mode."");"	<line14>	"LOG.info(""{}: Failed to connect to worker at {}."", this, startTime)"	"<line14> LOG.info(""{}: Failed to connect to worker at {}."", this, startTime)"
task5	"<line39>      LOG.info(""LongHybridHashTable: Use dense mode!"");"	<line25>	"LOG.info(""Trying dense mode. range: {}, recordCount: {}, buffers: {}"", range, recordCount, buffers)"	"<line25> LOG.info(""Trying dense mode. range: {}, recordCount: {}, buffers: {}"", range, recordCount, buffers)"
task5	"<line23>        log.warn(""Abort creating a new thread pool for destination ""+ getName()+ "" and reuse previous one"");"	<line23>	"log.warn(""Shutting down old NoticeableThreadPoolExecutor "" + oldNoticeableExecutorService)"	"<line23> log.warn(""Shutting down old NoticeableThreadPoolExecutor "" + oldNoticeableExecutorService)"
task5	"<line29>          Log.warn(""An exception occurred while trying to update the identity store configuration for""+ "" connection type '""+ type+ ""'"",e);"	<line29>	"Log.warn(""An exception occurred while calling setIdentityStoreConfiguration on a ConnectionListener."",e)"	"<line29> Log.warn(""An exception occurred while calling setIdentityStoreConfiguration on a ConnectionListener."",e)"
task5	"<line1>    log.debug(""Entered WML folder"");"	<line1>	"log.info(""Changing hash of .wml files in "" + baseDir.getAbsolutePath())"	"<line1> log.info(""Changing hash of .wml files in "" + baseDir.getAbsolutePath())"
task5	"<line9>        log.error(""Error while reading authorization header from APIM configurations"", e);"	<line9>	"log.error(""Error while retrieving security header"", e)"	"<line9> log.error(""Error while retrieving security header"", e)"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line25>      logger.error(""Error while checking page for widget '{}'"", viewerWidgetCode, t);"	<line25>	"logger.error(""Error checking for free viewer page"", t)"	"<line25> logger.error(""Error checking for free viewer page"", t)"
task5	"<line3>    LOG.info(""handleNewSession. sessionId: {}."", sessionId);"	<line3>	"LOG.info(""handleNewSession. sessionId: {}."", sessionId)"	"<line3> LOG.info(""handleNewSession. sessionId: {}."", sessionId)"
task5	"<line16>      logger.error(""Unable to get the event count"", e);"	<line16>	"logger.error(""Unable to get event count"", e)"	"<line16> logger.error(""Unable to get event count"", e)"
task5	<line12>    LOGGER.info(String.format(Messages.Log.ASYNCHRONOUS_PUBLIC_IP_STATE_S,asyncRequestInstanceState.getOrderInstanceId(),AsyncRequestInstanceState.StateType.CREATING_FIREWALL_RULE));	<line12>	"logger.debug(""setAsyncRequestInstanceSecondStep: ipAddressId={}, ip={}, asyncRequestInstanceState={}"",ipAddressId,ip,asyncRequestInstanceState)"	"<line12> logger.debug(""setAsyncRequestInstanceSecondStep: ipAddressId={}, ip={}, asyncRequestInstanceState={}"",ipAddressId,ip,asyncRequestInstanceState)"
task5	"<line17>        logger.warn(""{}"", ex.getMessage());"	<line17>	"logger.debug(""Ignoring discovered device {}"", device.id, ex)"	"<line17> logger.debug(""Ignoring discovered device {}"", device.id, ex)"
task5	"<line2>    LOG.debug(""Completing session: {}"", id);"	<line2>	"log.debug(""Entry {} completed"", this)"	"<line2> log.debug(""Entry {} completed"", this)"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line7>        LOGGER.error(""Fail to reload notes from repository"", e);"	<line7>	"LOGGER.error(""Failed to reload all notes"", e)"	"<line7> LOGGER.error(""Failed to reload all notes"", e)"
task5	"<line11>    logger.debug(""Number of cell params: "", params.length);"	<line1>	"logger.debug(""Molecule has been created"")"	"<line1> logger.debug(""Molecule has been created"")"
task5	"<line11>      log.warn(""Failed to read topic policies data, will apply the namespace backlog quota:""+ "" topicName={}"",topicName,e);"	<line11>	"log.error(""Failed to get backlog quota for {}"", topicName, e)"	"<line11> log.error(""Failed to get backlog quota for {}"", topicName, e)"
task5	"<line6>      log.error(""Can't deserialize json object (may-be incompatible ProjectForge versions): ""+ ex.getMessage()+ "" json=""+ json,ex);"	<line6>	"log.error(""Error while deserializing "" + classOfT + "" from JSON: "" + json, ex)"	"<line6> log.error(""Error while deserializing "" + classOfT + "" from JSON: "" + json, ex)"
task5	"<line14>      log.debug(""The batch ID '{}' of the received reply from bitarchives does not correspond to any""+ "" pending batch job. Ignoring and deleting RemoteFile '{}'.Only knows batchjob with""+ "" IDs: {}"",bitarchiveBatchID,remoteFile,runningBatchJobs.keySet());"	<line14>	"log.warn(""No batch job found for bitarchive batch ID: {}"", bitarchiveBatchID)"	"<line14> log.warn(""No batch job found for bitarchive batch ID: {}"", bitarchiveBatchID)"
task5	"<line39>              log.warn(""AccountRolePersistenceImpl.fetchByRoleId(long, boolean) with parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."");"	<line39>	"log.warn(""AccountRolePersistenceImpl.fetchByRoleId(long, boolean) with roleId ""+ roleId+ "" and useFinderCache ""+ useFinderCache+ "" yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."")"	"<line39> log.warn(""AccountRolePersistenceImpl.fetchByRoleId(long, boolean) with roleId ""+ roleId+ "" and useFinderCache ""+ useFinderCache+ "" yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."")"
task5	<line6>    log.info(xml);	<line5>	LOG.info(xml)	<line5> LOG.info(xml)
task5	"<line2>    log.info(""In region ["" + event.getRegion().getName() + ""] destroyed key ["" + event.getKey() + ""] "");"	<line2>	"LOG.info(""afterDestroy called"")"	"<line2> LOG.info(""afterDestroy called"")"
task5	"<line4>        LOGGER.info(""Spawning member bouncing thread"");"	<line4>	"logger.info(""Starting bouncing of members"")"	"<line4> logger.info(""Starting bouncing of members"")"
task5	"<line15>        LOGGER.debug(""Exception in parsing date  "" + receiptEndDate + "" - "" + e.getMessage());"	<line3>	"if (LOGGER.isDebugEnabled()) LOGGER.debug(""BankRemittanceSearchAction | validate | start"")"	"<line3> if (LOGGER.isDebugEnabled()) LOGGER.debug(""BankRemittanceSearchAction | validate | start"")"
task5	<line16>      log.error(exception, exception);	<line16>	log.error(exception, exception)	<line16> log.error(exception, exception)
task5	<line19>        logger.error(e.getMessage());	<line19>	"LOG.error(""Failed to determine mime type for path: {}"", path, e)"	"<line19> LOG.error(""Failed to determine mime type for path: {}"", path, e)"
task5	"<line2>      LOGGER.debug(""Unbekanntes Element."");"	<line2>	"LOGGER.error(""createControl(): argument 'element' must be non-null"")"	"<line2> LOGGER.error(""createControl(): argument 'element' must be non-null"")"
task5	"<line5>    LOGGER.info(""amsPacket:\n{} has \n{}bytes\nHexDump:\n{}"",amsTCPPacket,bytes.length,amsTCPPacket.dump());"	<line5>	"log.debug(""TCP Packet: {}"", new String(bytes))"	"<line5> log.debug(""TCP Packet: {}"", new String(bytes))"
task5	"<line1>    log.info(""publish uri: {}"", registerDTOList);"	<line1>	"logger.debug(""publishRegisterURI started..."")"	"<line1> logger.debug(""publishRegisterURI started..."")"
task5	"<line2>    log.debug(""MappingAndDelegatingCommandConsumer receiver link [tenant-id: {}] closed locally"",tenantId);"	<line2>	"log.debug(""Closing consumer for tenant [{}]"", tenantId)"	"<line2> log.debug(""Closing consumer for tenant [{}]"", tenantId)"
task5	<line13>        log.debug(searchException, searchException);	<line13>	log.debug(searchException, searchException)	<line13> log.debug(searchException, searchException)
task5	"<line8>    log.info(""Job {} reached terminal state {}."",archivedExecutionGraph.getJobID(),archivedExecutionGraph.getState());"	<line8>	"log.debug(""Job %s reached terminal state %s."", archivedExecutionGraph.getJobID(), archivedExecutionGraph.getState())"	"<line8> log.debug(""Job %s reached terminal state %s."", archivedExecutionGraph.getJobID(), archivedExecutionGraph.getState())"
task5	"<line5>      log.debug(""cannot set pageType for {}"", file, ex);"	<line5>	"logger.warn(""Can't set page type attribute for file {}"", file, ex)"	"<line5> logger.warn(""Can't set page type attribute for file {}"", file, ex)"
task5	"<line1>    logger.error(""Insane record: "" + Arrays.toString(flatRow), ex);"	<line2>	"logger.error(""Error record threshold exceeded.  Skipping record: "" + Arrays.toString(flatRow), ex)"	"<line2> logger.error(""Error record threshold exceeded.  Skipping record: "" + Arrays.toString(flatRow), ex)"
task5	"<line55>    log.debug(""Type ""+ tupleExpr.getClass().getSimpleName()+ "" not supported for computing free vars. If you run into this, please report a bug."");"	<line55>	"log.debug(""No free vars in "" + tupleExpr.getClass().getSimpleName())"	"<line55> log.debug(""No free vars in "" + tupleExpr.getClass().getSimpleName())"
task5	"<line20>      logger.debug(""test case duration = "" + tc.getDuration());"	<line33>	"logger.debug(""saveResult forward: {}"", forward)"	"<line33> logger.debug(""saveResult forward: {}"", forward)"
task5	"<line25>          logger.trace(""Failed to connect to "" + possibleLive.getA());"	<line25>	"logger.debug(""scale-down connection failed"", e)"	"<line25> logger.debug(""scale-down connection failed"", e)"
task5	"<line2>      logger.warn(""resolving lock"");"	<line1>	"LOG.debug(""resolveLock: {}"", lock)"	"<line1> LOG.debug(""resolveLock: {}"", lock)"
task5	"<line26>      log.error(""Unsupported calibrator  type "" + calibrator.getClass());"	<line26>	"LOGGER.warn(""Calibrator of type "" + calibrator.getClass().getSimpleName() + "" is not supported!"")"	"<line26> LOGGER.warn(""Calibrator of type "" + calibrator.getClass().getSimpleName() + "" is not supported!"")"
task5	<line15>      logger.warn(msg, e);	<line15>	logger.error(msg, e)	<line15> logger.error(msg, e)
task5	"<line12>        logger.debug(""problem processing policy"", pdme);"	<line12>	"logger.debug(""Error while finding policy: "" + pdme.getMessage(), pdme)"	"<line12> logger.debug(""Error while finding policy: "" + pdme.getMessage(), pdme)"
task5	"<line11>      LOG.error(""Can't find ExternalizableBusinessObject implementation class for ""+ inquiryBusinessObjectClass.getName());"	<line5>	"LOG.debug(""Business object is not externalizable: "" + inquiryBusinessObjectClass.getName())"	"<line5> LOG.debug(""Business object is not externalizable: "" + inquiryBusinessObjectClass.getName())"
task5	"<line8>      log.error(""Task could not be initialized hence not be executed."", e);"	<line8>	"log.error(""Task could not be initialized hence not be executed."", e)"	"<line8> log.error(""Task could not be initialized hence not be executed."", e)"
task5	"<line5>      logger.error(""error in getWidgetTypeApiMappings"", t);"	<line5>	"logger.error(""Error extracting widget type API mappings from the catalog"", t)"	"<line5> logger.error(""Error extracting widget type API mappings from the catalog"", t)"
task5	"<line12>      LOG.warn(""Convert to CGMES a change on IIDM {}.{}"",change.getIdentifiable().getClass().getSimpleName(),change.getAttribute());"	<line12>	"log.info(""Ignoring change {}"", change)"	"<line12> log.info(""Ignoring change {}"", change)"
task5	"<line19>                log.error(""Error occurred"", e);"	<line14>	"log.info(""Started: "" + cl.name())"	"<line14> log.info(""Started: "" + cl.name())"
task5	"<line3>        Log.debug(""AuthorizationManager: Trying "" + am.name() + "".map("" + principal + "")"");"	<line3>	"Log.debug(""Mapping "" + principal + "" to "" + username)"	"<line3> Log.debug(""Mapping "" + principal + "" to "" + username)"
task5	<line23>        log.error(e);	<line23>	"logger.error(""Cannot determine connection status"", e)"	"<line23> logger.error(""Cannot determine connection status"", e)"
task5	"<line18>    LOGGER.info(""Job Return Status {} "", status);"	<line18>	"LOGGER.info(jobName + "" : "" + status.toString())"	"<line18> LOGGER.info(jobName + "" : "" + status.toString())"
task5	"<line38>      LOGGER.error(""Error in fetchVPCtoNatIPInfo"", e);"	<line38>	"LOGGER.error(""Error in fetchVPCtoNatIPInfo"", e)"	"<line38> LOGGER.error(""Error in fetchVPCtoNatIPInfo"", e)"
task5	"<line4>    LOGGER.info(instanceName + "" becomes MASTER from SLAVE for "" + partitionName);"	<line4>	"LOG.info(""Become MASTER from SLAVE for partition: {} for {}"", partitionName, instanceName)"	"<line4> LOG.info(""Become MASTER from SLAVE for partition: {} for {}"", partitionName, instanceName)"
task5	"<line1>    log.debug(""find() - username: {}"", username);"	<line1>	"log.debug(""find() - username: "" + username)"	"<line1> log.debug(""find() - username: "" + username)"
task5	<line5>        log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line5>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line5> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line7>        LOG.info(""Loaded event filter: {}"", filterClassName);"	<line8>	"log.error(""Failed to find filter class."", e.getCause())"	"<line8> log.error(""Failed to find filter class."", e.getCause())"
task5	"<line21>      LOGGER.error(""Failed to parse "" + item.getPath(), e.toString());"	<line21>	"logger.error(""Error processing iPhone simulator data file"", e)"	"<line21> logger.error(""Error processing iPhone simulator data file"", e)"
task5	"<line16>      LOGGER.error(""Error getting ancestors when creating AIP"", e);"	<line16>	"LOGGER.error(""Error indexing AIP '{}'"", aip, e)"	"<line16> LOGGER.error(""Error indexing AIP '{}'"", aip, e)"
task5	"<line18>      logger.error(""ThingHandler not found for {}"", thingTypeUID);"	<line18>	"logger.debug(""Handler for {} not found"", thingTypeUID.getId())"	"<line18> logger.debug(""Handler for {} not found"", thingTypeUID.getId())"
task5	"<line7>    log.debug(""Cleared shard records : shardRecovery - {}, shard id = {}"",shardRecoveryDeleted,shard.getShardId());"	<line4>	"log.debug(""Shard recovery deleted: {}"", shardRecoveryDeleted)"	"<line4> log.debug(""Shard recovery deleted: {}"", shardRecoveryDeleted)"
task5	<line9>      log.error(exception, exception);	<line9>	log.error(exception, exception)	<line9> log.error(exception, exception)
task5	"<line3>      logger.trace(""getXAResources("" + Arrays.toString(specs) + "")"");"	<line3>	"logger.trace(""getXAResources()"")"	"<line3> logger.trace(""getXAResources()"")"
task5	"<line2>      LOG.debug(""selectLink() called ..."");"	<line2>	"LOG.debug("""")"	"<line2> LOG.debug("""")"
task5	"<line9>      logger.info(""The index "" + indexName + "" already exists"");"	<line9>	"LOGGER.debug(""Index [{}] already exists"", indexName)"	"<line9> LOGGER.debug(""Index [{}] already exists"", indexName)"
task5	"<line35>        LOG.warn(""Error releasing exchange due to "" + e.getMessage() + "". This exception is ignored."",e);"	<line35>	"LOG.debug(""Error resetting pairs: {}"", e.getMessage(), e)"	"<line35> LOG.debug(""Error resetting pairs: {}"", e.getMessage(), e)"
task5	"<line25>        LOG.debug(""Exception: "" + e, e);"	<line24>	"LOG.warn(""Failed creating initial content for path "" + path, e)"	"<line24> LOG.warn(""Failed creating initial content for path "" + path, e)"
task5	<line3>      LOGGER.info(task);	<line3>	"LOGGER.info(""Task updated to '"" + task + ""'"")"	"<line3> LOGGER.info(""Task updated to '"" + task + ""'"")"
task5	<line18>      log.error(message, ex);	<line18>	LOG.error(message, ex)	<line18> LOG.error(message, ex)
task5	"<line5>    LOG.trace(""Adding composite phenomenons {} to procedure {}"", compositePhenomenon, procedure);"	<line5>	"LOG.trace(""Adding composite phenomenon {} to procedure {}"", compositePhenomenon, procedure)"	"<line5> LOG.trace(""Adding composite phenomenon {} to procedure {}"", compositePhenomenon, procedure)"
task5	"<line1>    logger.error(""Event Bus Exception thrown during event handling within "" + context.getSubscriberMethod(),exception);"	<line18>	log.error(message, exception)	<line18> log.error(message, exception)
task5	"<line6>      LOG.info(""starting final check"");"	<line2>	"log.info(""tearDown switch simulator after scenario"")"	"<line2> log.info(""tearDown switch simulator after scenario"")"
task5	"<line2>    logger.info(""Document servlet started"");"	<line2>	"logger.info(""Activating Maven Deployer Service"")"	"<line2> logger.info(""Activating Maven Deployer Service"")"
task5	"<line4>    logger.debug(marker, requestId + "" "" + format, arg);"	<line4>	logger.debug(marker, format, arg, new Throwable())	<line4> logger.debug(marker, format, arg, new Throwable())
task5	<line9>      log.error(exception, exception);	<line9>	log.error(exception, exception)	<line9> log.error(exception, exception)
task5	"<line1>    LOG.debug(""Received: {}"", record.value());"	<line2>	"log.error(""Checking record "" + record + "" with unexpected error."")"	"<line2> log.error(""Checking record "" + record + "" with unexpected error."")"
task5	"<line3>      log.warn(""Oups, task shouldn't be null."");"	<line3>	"LOGGER.warn(""Task with id '{}' not found"", task.getId())"	"<line3> LOGGER.warn(""Task with id '{}' not found"", task.getId())"
task5	"<line4>      log.error(""Unable to get descriptive name for group "" + group.getGroupId(), portalException);"	<line4>	log.error(portalException, portalException)	<line4> log.error(portalException, portalException)
task5	"<line2>      log.debug(""Clear local statistics [key="" + key + "", columns="" + colNames + ']');"	<line2>	"log.debug(""Clearing local statistics for "" + key)"	"<line2> log.debug(""Clearing local statistics for "" + key)"
task5	<line29>    logger.info(sql);	<line29>	"logger.debug(""sql: {}"", sql)"	"<line29> logger.debug(""sql: {}"", sql)"
task5	"<line2>    log.info(""test method: testQueryEmptyResults"");"	<line2>	"log.info(""test method: testQueryWebPageQueryEmptyResults"")"	"<line2> log.info(""test method: testQueryWebPageQueryEmptyResults"")"
task5	"<line26>    LOG.trace(""Deleting temporary file: {}"", tmpTar);"	<line7>	"LOG.debug(""Adding file to tar: {}"", tmpTar)"	"<line7> LOG.debug(""Adding file to tar: {}"", tmpTar)"
task5	"<line5>      logger.error(""Could not close the metrics service, some metrics may have not been written"", e);"	<line5>	"LOG.warn(""Error closing metadata store"", e)"	"<line5> LOG.warn(""Error closing metadata store"", e)"
task5	"<line20>        LOGGER.debug(""Error parsing Integer"");"	<line20>	"logger.debug(""SonosAlarm with ID {} is missing the 'id' field. This alarm will be ignored."", id)"	"<line20> logger.debug(""SonosAlarm with ID {} is missing the 'id' field. This alarm will be ignored."", id)"
task5	"<line3>        logger.warn(""no filters"");"	<line14>	"logger.error(""error building limit query"", t)"	"<line14> logger.error(""error building limit query"", t)"
task5	<line12>      log.error(e);	<line6>	log.debug(exception)	<line6> log.debug(exception)
task5	"<line9>    LOGGER.debug(""Connected devices: "".concat(connectedDevices.toString()));"	<line9>	"LOGGER.debug(""Connected devices: {}"", connectedDevices)"	"<line9> LOGGER.debug(""Connected devices: {}"", connectedDevices)"
task5	"<line9>    LOG.warn(""Searching for a trigger named \""{}\"" but it doesn't exist"", name);"	<line9>	"LOGGER.warn(""Trigger with name "" + name + "" not found"")"	"<line9> LOGGER.warn(""Trigger with name "" + name + "" not found"")"
task5	"<line2>      LOGGER.debug(""Reading taskana configuration from {} with separator {}"", propertiesFile, separator);"	<line2>	"LOGGER.debug(""Loading properties for Taskana Roles and Jobs"")"	"<line2> LOGGER.debug(""Loading properties for Taskana Roles and Jobs"")"
task5	"<line17>        LOG.debug(""Unresolved reference"", ignore);"	<line17>	"LOGGER.debug(""Unresolved reference"", ignore)"	"<line17> LOGGER.debug(""Unresolved reference"", ignore)"
task5	"<line5>    LOG.warn(""@@@@@@@@@@@@@@@@@@ Benchmark for student section view: {}"",(System.nanoTime() - startTime) * 1.0e-9);"	<line5>	"logger.info(""getStudentSummaries took "" + TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime) + "" ms"")"	"<line5> logger.info(""getStudentSummaries took "" + TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime) + "" ms"")"
task5	"<line4>      log.debug(""  query[""+ queryStr+ ""]  start(""+ YMD_DateFormat.format(startEndDate[0])+ "")  end(""+ YMD_DateFormat.format(startEndDate[1])+ "")"");"	<line4>	"log.debug(""Start and end date: "" + startEndDate[0] + "" , "" + startEndDate[1])"	"<line4> log.debug(""Start and end date: "" + startEndDate[0] + "" , "" + startEndDate[1])"
task5	<line32>      log.error(bundleException, bundleException);	<line2>	"log.debug(""Adding bundle "" + location)"	"<line2> log.debug(""Adding bundle "" + location)"
task5	"<line5>        LOGGER.debug(""apparentlyTo set to: {}"", (Object) internetAddresses);"	<line5>	"LOGGER.info(""Set To: {}"", Arrays.toString(internetAddresses))"	"<line5> LOGGER.info(""Set To: {}"", Arrays.toString(internetAddresses))"
task5	<line6>      log.error(e.toString());	<line6>	"logger.error(""Main threw"", e)"	"<line6> logger.error(""Main threw"", e)"
task5	"<line7>      log.warn(""documentAttribute for hitTerm:"" + hitTerm + "" is null in document:"" + document);"	<line7>	"log.warn(""Document attribute "" + hitName + "" not found."")"	"<line7> log.warn(""Document attribute "" + hitName + "" not found."")"
task5	"<line7>      logger.debug(""recording bulkOp event {} {} {} op={}"",threadID.expensiveToString(),eventID,tag,event.getOperation());"	<line7>	"logger.debug(""RegionVersionVector.recordBulkOpStarted {}"", event)"	"<line7> logger.debug(""RegionVersionVector.recordBulkOpStarted {}"", event)"
task5	"<line9>          logger.debug(""Sending my leave request to {}"", coords);"	<line3>	"log.info(""Leaving group"")"	"<line3> log.info(""Leaving group"")"
task5	"<line8>      log.debug(""Opening store directory [{}]"", path);"	<line8>	"log.debug(""Opening store directory {}"", dir)"	"<line8> log.debug(""Opening store directory {}"", dir)"
task5	<line11>      log.error(e);	<line11>	"log.error(""Unable to read configuration file: "" + resource, e)"	"<line11> log.error(""Unable to read configuration file: "" + resource, e)"
task5	<line7>    logger.info(events);	<line6>	"logger.info(""string event sent to Flume"")"	"<line6> logger.info(""string event sent to Flume"")"
task5	"<line14>      log.error(""Unable to create Output Event Adapter : "" + DeviceTypeConstants.MQTT_ADAPTER_NAME, e);"	<line14>	"log.error(""Failed to create the MQTT output event adapter"", e)"	"<line14> log.error(""Failed to create the MQTT output event adapter"", e)"
task5	"<line2>      LOG.trace(""[{}] Cancelling timeout"", logPrefix);"	<line2>	"logger.debug(""Cancelling timeout for {}"", this)"	"<line2> logger.debug(""Cancelling timeout for {}"", this)"
task5	"<line12>                    logger.warn(""Exception at getRwtweetsOfMe"", e);"	<line12>	"logger.warn(""Exception at getRetweetsOfMe"", e)"	"<line12> logger.warn(""Exception at getRetweetsOfMe"", e)"
task5	<line7>        log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line7>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line7> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line5>      log.trace(""Document {} is not a user workspace, it cannot be adapted as a FileSystemItem."",doc::getId);"	<line7>	"log.debug(""isFileSystemItem: {}{}"", doc.getTitle(), doc.getPathAsString())"	"<line7> log.debug(""isFileSystemItem: {}{}"", doc.getTitle(), doc.getPathAsString())"
task5	"<line31>        logger.debug(""Unknown event type: {} in state {}"", event.encodeType(EventTypes.class), state);"	<line31>	"logger.debug(""Received an unknown event {}"", event)"	"<line31> logger.debug(""Received an unknown event {}"", event)"
task5	"<line4>      LOG.error(""Cannot create folder: "" + pathToDir.toAbsolutePath(), e);"	<line4>	"logger.warn(""Unable to create directory "" + pathToDir.toString())"	"<line4> logger.warn(""Unable to create directory "" + pathToDir.toString())"
task5	"<line5>    LOG.debug(""opps = {}."", opps);"	<line5>	"LOG.debug(""{}"", opps)"	"<line5> LOG.debug(""{}"", opps)"
task5	"<line11>      logger.debug(""Created ServerTypeDesc for type ["" + typeName + ""]."" + getClientAddressAddition());"	<line5>	"logger.debug(""createServerTypeDescInstance: typeName={}"", typeName)"	"<line5> logger.debug(""createServerTypeDescInstance: typeName={}"", typeName)"
task5	"<line4>      LOG.trace(""not found: {}"", path, e);"	<line4>	"LOG.warn(""File not found"", e)"	"<line4> LOG.warn(""File not found"", e)"
task5	"<line5>    logger.info(""Note name changed: {} -> {}"", oldName, note.getName());"	<line5>	"logger.info(""Note name changed: {}"", note)"	"<line5> logger.info(""Note name changed: {}"", note)"
task5	"<line43>    LOGGER.debug(""Updated json serialiser to use: {}, and modules: {}"",jsonSerialiserClass,moduleFactories);"	<line34>	"LOGGER.info(""Registering JSONSerialiserModules: {}"", factoryClass)"	"<line34> LOGGER.info(""Registering JSONSerialiserModules: {}"", factoryClass)"
task5	"<line3>      logger.debug(""Step: ""+ info+ "" memory: free / total / max MB ""+ runtime.freeMemory() / (1000 * 1000)+ "" / ""+ runtime.totalMemory() / (1000 * 1000)+ "" / ""+ runtime.maxMemory() / (1000 * 1000));"	<line3>	"logger.debug(""Progress: "" + info + "" ("" + runtime.totalMemory() / 1024 + "" KB)"")"	"<line3> logger.debug(""Progress: "" + info + "" ("" + runtime.totalMemory() / 1024 + "" KB)"")"
task5	"<line21>        LOG.error(""Error JSON-ifying environment {}: {}"", environment.getId(), e.getMessage());"	<line21>	"LOG.error(""Error: list environments: {}"", e.getMessage())"	"<line21> LOG.error(""Error: list environments: {}"", e.getMessage())"
task5	"<line2>    LOG.trace(""Consumer {} drain request timed out"", this);"	<line4>	"log.info(""Stopping request timer"", cause)"	"<line4> log.info(""Stopping request timer"", cause)"
task5	"<line2>    LOGGER.info(""{} hits {}."", mir.getClass().getSimpleName(), this.getClass().getSimpleName());"	<line2>	"log.info(""No collision resolve for "" + mir)"	"<line2> log.info(""No collision resolve for "" + mir)"
task5	"<line14>        log.debug(""An exception occured when checking if the publish "" + ""action should be displayed"",portalException);"	<line14>	log.debug(portalException, portalException)	<line14> log.debug(portalException, portalException)
task5	"<line36>      log.info(""result: numLinesBefore=""+ numLinesOrig+ ""; numLinesAfter=""+ numLinesAfter+ ""; first=""+ grepFirst+ ""; last=""+ grepLast);"	<line9>	"LOG.info(""Testing modifyEtcHosts on "" + loc)"	"<line9> LOG.info(""Testing modifyEtcHosts on "" + loc)"
task5	"<line1>    log.debug("""");"	<line1>	"log.debug("""")"	"<line1> log.debug("""")"
task5	"<line8>      log.debug(""addForward"");"	<line8>	"log.debug(""addForward"")"	"<line8> log.debug(""addForward"")"
task5	"<line1>    log.info(""B headers "" + exchange.getIn().getHeaders());"	<line1>	"LOG.info(""Processing exchange: "" + exchange)"	"<line1> LOG.info(""Processing exchange: "" + exchange)"
task5	"<line3>      LOG.debug(""Getting all enterprise events occurring between {} and {} {}"",after == null ? ""unspecified date"" : DateFormat.getDateTimeInstance().format(after),before == null ? ""unspecified date"" : DateFormat.getDateTimeInstance().format(before),position == null ? """" : ("" starting at "" + position));"	<line9>	"LOG.debug(""Getting enterprise events"")"	"<line9> LOG.debug(""Getting enterprise events"")"
task5	"<line20>      logger.error(""failed to create class "" + getController().getEntityClass() + "": "" + e);"	<line20>	"logger.error(""Error creating entity"", e)"	"<line20> logger.error(""Error creating entity"", e)"
task5	"<line3>        log.error(""device is null"");"	<line3>	"logger.info(""Device not initialized"")"	"<line3> logger.info(""Device not initialized"")"
task5	"<line2>    log.error(""error - {} {}"", tokenToString(token), throwable);"	<line2>	"logger.error(""Connection to Hono failed: {}"", throwable.getMessage())"	"<line2> logger.error(""Connection to Hono failed: {}"", throwable.getMessage())"
task5	"<line14>      log.error(""Could not find type of narrow expression"");"	<line2>	"log.debug(""Casting expression to desired type: "" + node)"	"<line2> log.debug(""Casting expression to desired type: "" + node)"
task5	"<line16>    log.info(""[{}] Successfully unsubscribed {} on namespace bundle {}/{}"",clientAppId(),subscription,namespaceName,bundleRange);"	<line15>	"log.info(""[{}] Unsubscribe namespace {} from {}"",this.clientAppId(),namespaceName,subscription)"	"<line15> log.info(""[{}] Unsubscribe namespace {} from {}"",this.clientAppId(),namespaceName,subscription)"
task5	"<line9>    log.warn(String.format(""Lookup failed for %s in cache"", reference));"	<line7>	"log.debug(""CacheReference.lookup {} found value {} in {}"", reference, f, entry)"	"<line7> log.debug(""CacheReference.lookup {} found value {} in {}"", reference, f, entry)"
task5	<line1>    LOG.warn(DEFAULT_EXCEPTION_RESPONSE, e);	<line4>	"LOGGER.error(""Exception in REST service"", e)"	"<line4> LOGGER.error(""Exception in REST service"", e)"
task5	"<line8>    logger.debug(""Strategies : {}"", bufferSizes);"	<line6>	"logger.debug(""Encoded buffer size for strategy {} is {}"", strategy, encodedBufferSize)"	"<line6> logger.debug(""Encoded buffer size for strategy {} is {}"", strategy, encodedBufferSize)"
task5	"<line11>    LOG.debug(""adding command [name: {}, request-id: {}] to response for device [tenant-id: {},""+ "" device-id: {}]"",command.getName(),command.getRequestId(),command.getTenant(),command.getGatewayOrDeviceId());"	<line2>	"logger.debug(""Adding command [{}] to response"", command.getName())"	"<line2> logger.debug(""Adding command [{}] to response"", command.getName())"
task5	"<line1>    LOGGER.info(""Creating resources before the test class"");"	<line1>	"LOGGER.info(""Deploy Kafka and Zookeeper"")"	"<line1> LOGGER.info(""Deploy Kafka and Zookeeper"")"
task5	<line8>    LOGGER.error(message);	<line8>	LOG.error(message)	<line8> LOG.error(message)
task5	"<line6>      logger.warn(""Channel {} not found."", name);"	<line6>	"logger.debug(""Channel {} not found"", name)"	"<line6> logger.debug(""Channel {} not found"", name)"
task5	"<line1>    log.debug(""Altering '"", object, ""'"");"	<line1>	"log.debug(""postProcess: "" + object)"	"<line1> log.debug(""postProcess: "" + object)"
task5	"<line6>      LOGGER.warn(""Could not find action ''{}'' in collection: {}"", action, collectionName);"	<line6>	"LOGGER.error(""There is no collection with the name {}"", collectionName)"	"<line6> LOGGER.error(""There is no collection with the name {}"", collectionName)"
task5	"<line2>    logger.info(""[Update Cluster]{},{}"", clusterName, cluster);"	<line2>	"logger.info(""Update cluster: {}"", clusterName)"	"<line2> logger.info(""Update cluster: {}"", clusterName)"
task5	"<line8>      logger.error(""Error extracting dataObjects id"", t);"	<line8>	"logger.error(""Error extracting dataObjects id"", t)"	"<line8> logger.error(""Error extracting dataObjects id"", t)"
task5	"<line16>      log.warn(""Oracle leadership watcher has been interrupted unexpectedly"");"	<line16>	"LOG.error(""Interrupted while watching for changes in the cluster"", e)"	"<line16> LOG.error(""Interrupted while watching for changes in the cluster"", e)"
task5	"<line21>      LOG.warn(""Error deploying '""+ url+ ""' to ""+ targetName+ "" on ""+ toString()+ ""; rethrowing..."",e);"	<line21>	"LOG.warn(""Error deploying WAR file from URL ({}) to {} on {}"", url, targetName, this, e)"	"<line21> LOG.warn(""Error deploying WAR file from URL ({}) to {} on {}"", url, targetName, this, e)"
task5	"<line2>    logger.debug(""WorkManager set."");"	<line1>	"log.info(""Setting work manager to "" + workManager)"	"<line1> log.info(""Setting work manager to "" + workManager)"
task5	"<line2>    LOGGER.info(""StorageSystems returned to client : "" + storageSystems.toJsonString());"	<line2>	"LOGGER.info(""StorageSystems returned to client (count) : "" + storageSystems.getCount())"	"<line2> LOGGER.info(""StorageSystems returned to client (count) : "" + storageSystems.getCount())"
task5	<line16>      log.error(exception, exception);	<line16>	log.error(exception, exception)	<line16> log.error(exception, exception)
task5	"<line14>                log.error(""Failed to replicate entry: {}"", indexed, commitError);"	<line13>	"log.error(""Failed to commit entry {}"", indexed, commitError)"	"<line13> log.error(""Failed to commit entry {}"", indexed, commitError)"
task5	"<line7>      logger.debug(""Successfully initialized index provider '{0}' in repository '{1}'"",provider.getName(), repository.name());"	<line7>	"logger.debug(""IndexProvider initialized: "" + provider)"	"<line7> logger.debug(""IndexProvider initialized: "" + provider)"
task5	"<line22>      logger.error(""Error on COM_BINLOG_DUMP: file = "" + fileName + "", position = "" + filePosition);"	<line18>	"LOGGER.info(""Send dump request to MySQL for file: "" + fileName + "", position: "" + filePosition)"	"<line18> LOGGER.info(""Send dump request to MySQL for file: "" + fileName + "", position: "" + filePosition)"
task5	"<line2>    log.debug(""PARTICIPANT {}: Leaving room {}"", user.getName(), this.name);"	<line2>	"log.info(""{} leaving {}"", user.getName(), this.getName())"	"<line2> log.info(""{} leaving {}"", user.getName(), this.getName())"
task5	<line9>      log.error(exception, exception);	<line9>	log.error(exception, exception)	<line9> log.error(exception, exception)
task5	"<line4>      LOG.error(""Error creating a tar file"");"	<line4>	"log.error(""Error creating tar file"", e)"	"<line4> log.error(""Error creating tar file"", e)"
task5	"<line1>    LOGGER.debug(""XACML policies will be looked for in the following location(s): {}"",xacmlPolicyDirectories);"	<line9>	"logger.debug(""Starting XACML policy finder."")"	"<line9> logger.debug(""Starting XACML policy finder."")"
task5	"<line2>    LOG.info(""Running testRunAllParagraph_FirstFailed"");"	<line21>	"LOGGER.info(""Remove note1 "" + note1.getId())"	"<line21> LOGGER.info(""Remove note1 "" + note1.getId())"
task5	<line4>      log.debug(s);	<line7>	"LOGGER.info(""Adding message to audit log: {}"", s)"	"<line7> LOGGER.info(""Adding message to audit log: {}"", s)"
task5	"<line10>              LOG.trace(""Configuring client-auth on SSLEngine [{}] to [{}]."", engine, clientAuthValue);"	<line2>	"LOG.trace(""getSSLEngineConfigurers()"")"	"<line2> LOG.trace(""getSSLEngineConfigurers()"")"
task5	<line16>        log.warn(portalException, portalException);	<line16>	"log.warn(""Unable to update commerce channel for group "" + group.getGroupId(), portalException)"	"<line16> log.warn(""Unable to update commerce channel for group "" + group.getGroupId(), portalException)"
task5	"<line3>    log.trace(""Executing findByTenantId [{}]"", tenantId);"	<line3>	"log.debug(""findLwM2mObject()"")"	"<line3> log.debug(""findLwM2mObject()"")"
task5	"<line16>      log.trace(""processing directory : "" + entry.getName());"	<line16>	"log.info(""Skipping directory {}"", name)"	"<line16> log.info(""Skipping directory {}"", name)"
task5	"<line3>      log.info(""...Setting executeStatusLogLevelInfo: "" + executeStatusLogLevelInfo);"	<line3>	"log.info(""Execute status log level info: "" + executeStatusLogLevelInfo)"	"<line3> log.info(""Execute status log level info: "" + executeStatusLogLevelInfo)"
task5	<line9>      logger.error(NO_REQUEST_FIND_FOR_SEQUENCE_NUMBER + pduHeader.getSequenceNumber());	<line9>	"logger.error(""No request found for {}"", pduHeader)"	"<line9> logger.error(""No request found for {}"", pduHeader)"
task5	"<line7>      LOGGER.error("""", exc);"	<line7>	"LOG.error(""Error while executing service"", exc)"	"<line7> LOG.error(""Error while executing service"", exc)"
task5	"<line14>      log.debug(""getReferralsByFacility: clientId="" + clientId + "",# of results="" + results.size());"	<line14>	"log.debug(""getReferralsByFacility: # of results="" + results.size())"	"<line14> log.debug(""getReferralsByFacility: # of results="" + results.size())"
task5	<line23>      log.error(systemException, systemException);	<line23>	log.error(systemException, systemException)	<line23> log.error(systemException, systemException)
task5	"<line5>      logger.error(""Exception occured while counting series."", e);"	<line5>	"logger.error(""Failed to get series count"", e)"	"<line5> logger.error(""Failed to get series count"", e)"
task5	"<line19>    LOGGER.info(""did remote the repository source mirror [{}]"", request.code);"	<line19>	"LOGGER.info(""the repository source mirror has been removed: {}"", repositorySourceMirror.getCode())"	"<line19> LOGGER.info(""the repository source mirror has been removed: {}"", repositorySourceMirror.getCode())"
task5	"<line14>        log.info(""Put key: "" + i);"	<line17>	"log.info(""Start iteration..."")"	"<line17> log.info(""Start iteration..."")"
task5	"<line8>      logger.error(""Error deleting item"", t);"	<line8>	"logger.error(""Error deleting item"", t)"	"<line8> logger.error(""Error deleting item"", t)"
task5	"<line4>    LOG.trace(""Adding parentOfferings {} to offering {}"", parentOfferings, offering);"	<line4>	"LOG.trace(""Adding parent offerings {} to {}"", parentOfferings, offering)"	"<line4> LOG.trace(""Adding parent offerings {} to {}"", parentOfferings, offering)"
task5	<line3>    logger.fatal(alertMessage);	<line3>	logger.fatal(alertMessage)	<line3> logger.fatal(alertMessage)
task5	<line13>      LOG.error(e.getMessage(), e);	<line13>	"log.error(""Unable to execute request"", e)"	"<line13> log.error(""Unable to execute request"", e)"
task5	<line15>      LOGGER.error(e);	<line15>	LOGGER.error(e)	<line15> LOGGER.error(e)
task5	<line8>        LOG.warn(e.getMessage());	<line8>	"LOG.warn(""Unable to create resource resolver for template "" + template, e)"	"<line8> LOG.warn(""Unable to create resource resolver for template "" + template, e)"
task5	"<line2>      LOG.info(""{} Minor Compaction back to normal since bookie has enough space now."",Thread.currentThread().getName());"	<line2>	"LOG.info(""Resuming minor GC"")"	"<line2> LOG.info(""Resuming minor GC"")"
task5	"<line2>    log.debug(""Emulating close file channel"");"	<line2>	"logger.info(""Close channel"")"	"<line2> logger.info(""Close channel"")"
task5	"<line48>      logger.error(""StudyController - reOrderComprehensionTestQuestion - ERROR"", e);"	<line48>	"logger.error(""StudyController - reOrderComprehensionTestQuestion() - Error"", e)"	"<line48> logger.error(""StudyController - reOrderComprehensionTestQuestion() - Error"", e)"
task5	"<line3>    logger.info(""{} resource {} in cluster {}."", enabled ? ""Enable"" : ""Disable"", resourceName, clusterName);"	<line28>	"LOG.info(""Enable resource: "" + resourceName + "" on cluster: "" + clusterName + "" to: "" + enabled)"	"<line28> LOG.info(""Enable resource: "" + resourceName + "" on cluster: "" + clusterName + "" to: "" + enabled)"
task5	"<line9>    logger.warn(String.format(""management node[uuid:%s] becomes unavailable, reply %s to message[%s]. Message""+ "" metadata dump: %s"",mgmtNodeId, err, rmeta.messageName, JSONObjectUtil.toJsonString(rmeta)));"	<line4>	"logger.debug(String.format(""management node[uuid:%s] is unavailable"", mgmtNodeId))"	"<line4> logger.debug(String.format(""management node[uuid:%s] is unavailable"", mgmtNodeId))"
task5	<line5>        log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line5>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line5> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line7>        LOG.debug(""Adding {} {} to the set of runner-executed transforms"",PTransformNode.class.getSimpleName(),consumer.getId());"	<line5>	"LOG.debug(""Adding {} to unfused nodes of {}"", consumer, inputPCollection)"	"<line5> LOG.debug(""Adding {} to unfused nodes of {}"", consumer, inputPCollection)"
task5	"<line8>        LOGGER.warn(""Unable to load plugin: {} due to: {}"", plugin.getKey(), ex.getMessage());"	<line8>	"log.error(""Failed to instantiate plugin {}"", plugin.getKey(), ex)"	"<line8> log.error(""Failed to instantiate plugin {}"", plugin.getKey(), ex)"
task5	"<line31>      log.error(""Error in fetching status of system"", e);"	<line31>	"logger.error(""Error in fetching the status of system"", e)"	"<line31> logger.error(""Error in fetching the status of system"", e)"
task5	"<line5>    Log.debug(""Could not retrieve basic test db password, using default from unit tests"");"	<line5>	"log.error(""You must define the database password in the settings.xml file!"")"	"<line5> log.error(""You must define the database password in the settings.xml file!"")"
task5	"<line7>      logger.error(""Error while last modified date of "" + this, fex);"	<line7>	"logger.error("""", fex)"	"<line7> logger.error("""", fex)"
task5	"<line14>      LOG.debug(""Loading Alert Scheme : {}"", alertSchemeType);"	<line12>	"LOG.info(""Alert schemes to execute: {}"", alertSchemes)"	"<line12> LOG.info(""Alert schemes to execute: {}"", alertSchemes)"
task5	<line9>    logger.debug(result);	<line9>	logger.debug(result)	<line9> logger.debug(result)
task5	"<line5>    logger.debug(""-----getEditors--- "");"	<line5>	"log.debug(""Getting all editors."")"	"<line5> log.debug(""Getting all editors."")"
task5	"<line32>      this.logger.warn(""Failed to compute access level for [{}] on [{}]: {}"",userOrGroup,entity.getId(),ex.getMessage());"	<line32>	"this.logger.error(""Failed to check entity [{}] access level"", entity.getId(), ex)"	"<line32> this.logger.error(""Failed to check entity [{}] access level"", entity.getId(), ex)"
task5	"<line11>    Logger.trace(""< "" + sb.toString());"	<line11>	"logger.debug(""Read {} bytes: {}"", length, sb.toString())"	"<line11> logger.debug(""Read {} bytes: {}"", length, sb.toString())"
task5	"<line4>      LOG.error(""Error deploying '"" + url + ""' on "" + toString() + ""; rethrowing..."", e);"	<line4>	"log.error(e, ""Error deploying tarball resource '%s'"", targetName)"	"<line4> log.error(e, ""Error deploying tarball resource '%s'"", targetName)"
task5	"<line4>      logger.error(""Assume concurrent modification happened, perform remapping: {}"", mapExactMatches);"	<line4>	"logger.info(""Assume concurrent modification happened, perform remapping: {}"",mapExactMatches)"	"<line4> logger.info(""Assume concurrent modification happened, perform remapping: {}"",mapExactMatches)"
task5	"<line2>      LOG.error(""minEvictableIdleTimeMillis should be greater than 30000"");"	<line2>	"logger.error(""minEvictableIdleTimeMillis should be 30s or more, now it's ""+ minEvictableIdleTimeMillis)"	"<line2> logger.error(""minEvictableIdleTimeMillis should be 30s or more, now it's ""+ minEvictableIdleTimeMillis)"
task5	<line10>      log.error(exception, exception);	<line10>	log.error(exception, exception)	<line10> log.error(exception, exception)
task5	"<line33>    log.trace(name + "" has authorizations union "" + list.getAllAuths());"	<line33>	"log.info(""Listing effective authorizations for user {}"", name)"	"<line33> log.info(""Listing effective authorizations for user {}"", name)"
task5	"<line25>      LOG.error(""Error while submitting extension job: "", e);"	<line25>	"LOG.error(""Error when submitting and scheduling the extension job"", e)"	"<line25> LOG.error(""Error when submitting and scheduling the extension job"", e)"
task5	"<line2>    log.info(""Initialisation complete."");"	<line2>	"LOG.info(""Configuring AvroGenericRecordConverter"")"	"<line2> LOG.info(""Configuring AvroGenericRecordConverter"")"
task5	"<line9>      LOG.warn(""Wrong type of {} attribute. Expected {}, got {}"",PaxWebConstants.CONTEXT_PARAM_BUNDLE_CONTEXT,BundleContext.class.getName(),attribute.getClass().getName());"	<line9>	"LOG.warn(""Unexpected value for Pax Web context parameter {}"", PaxWebConstants.CONTEXT_PARAM_BUNDLE_CONTEXT, attribute)"	"<line9> LOG.warn(""Unexpected value for Pax Web context parameter {}"", PaxWebConstants.CONTEXT_PARAM_BUNDLE_CONTEXT, attribute)"
task5	"<line2>      log.error(""No documents in version {}:{}"", version.getProject().getSlug(), version.getSlug());"	<line2>	"LOG.warn(""Project iteration {} has no documents"", version)"	"<line2> LOG.warn(""Project iteration {} has no documents"", version)"
task5	"<line8>      LOGGER.debug(""No context with alias "" + alias + "" found, nothing to remove"");"	<line8>	"LOGGER.warn(""Trying to remove unknown context "" + alias)"	"<line8> LOGGER.warn(""Trying to remove unknown context "" + alias)"
task5	"<line38>      log.error(""Error while retrieving records for entity {}, row keys {}"", entityClass, rowIds);"	<line38>	"logger.error(""Error while finding data for entity class {}, Caused By : {}"", entityClass, e)"	"<line38> logger.error(""Error while finding data for entity class {}, Caused By : {}"", entityClass, e)"
task5	<line13>      log.info(msg);	<line13>	logger.info(msg)	<line13> logger.info(msg)
task5	"<line10>      logger.error(""PropertyNotSetException while deleting nominal label "" + e.getMessage());"	<line10>	"logger.error(""PropertyNotSetException while deleting nominal labels"", e)"	"<line10> logger.error(""PropertyNotSetException while deleting nominal labels"", e)"
task5	<line7>        log.warn(portalException, portalException);	<line7>	log.warn(portalException, portalException)	<line7> log.warn(portalException, portalException)
task5	"<line2>      log.warn(""Kafka TLS sidecar container has been removed and the environment variable {} is not used""+ "" anymore. You can remove it from the Strimzi Cluster Operator deployment."",STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE);"	<line2>	"LOGGER.warn(""Kafka sidecar image removed"")"	"<line2> LOGGER.warn(""Kafka sidecar image removed"")"
task5	"<line4>        logger.debug(""Outbound local IP.\""{}\"""", localAddress);"	<line14>	"LOGGER.warn(""Failed to resolve local IP address to "" + adr + "". Using first found IP."", e)"	"<line14> LOGGER.warn(""Failed to resolve local IP address to "" + adr + "". Using first found IP."", e)"
task5	"<line1>    logger.trace(""resetAuthentication() called."");"	<line1>	"logger.debug(""Resetting authentication"")"	"<line1> logger.debug(""Resetting authentication"")"
task5	"<line7>        logger.debug(""Failure trying to obtain (Terminal-Information) Software-Version AVP value"", ex);"	<line7>	"logger.debug(""Failure trying to obtain Software Version AVP value"", ex)"	"<line7> logger.debug(""Failure trying to obtain Software Version AVP value"", ex)"
task5	"<line11>            logger.debug(""findDeviceFirewallOpenPorts() :: adding new Open Port Entry: {}"",((FirewallOpenPortConfigIP4) netConfig).getPort());"	<line37>	"logger.error(""Error getting firewall open port configurations"", e)"	"<line37> logger.error(""Error getting firewall open port configurations"", e)"
task5	"<line17>    log.info(""Start put [key="" + key + ']');"	<line22>	"log.info(""Start put [key="" + key + ']')"	"<line22> log.info(""Start put [key="" + key + ']')"
task5	"<line9>    LOG.info(""Configuring stats with csv output to directory [{}]"", outputDir.getAbsolutePath());"	<line9>	"log.info(""Configuring CSV reporter. Writing to {}"", outputDir)"	"<line9> log.info(""Configuring CSV reporter. Writing to {}"", outputDir)"
task5	"<line3>    log.debug(""[{}] evict device profile from cache: {}"", profileId, oldProfile);"	<line4>	"log.info(""[{}] Updated device profile [{}]"", tenantId, newProfile)"	"<line4> log.info(""[{}] Updated device profile [{}]"", tenantId, newProfile)"
task5	<line19>      log.error(systemException, systemException);	<line19>	log.error(systemException, systemException)	<line19> log.error(systemException, systemException)
task5	<line2>    log.trace(text);	<line2>	"log.debug(""text node: "" + text)"	"<line2> log.debug(""text node: "" + text)"
task5	"<line3>      logger.warn(""Tried to report FP Complications of a non-existing EC, with submission: "" + submission);"	<line3>	"logger.warn(""Tried to report FP complications for a non-existing EC, with submission: "" + submission)"	"<line3> logger.warn(""Tried to report FP complications for a non-existing EC, with submission: "" + submission)"
task5	"<line2>    LOGGER.trace(""Visiting PropertyName expression"");"	<line2>	"LOG.error(""Property name not valid: "" + expression.toString())"	"<line2> LOG.error(""Property name not valid: "" + expression.toString())"
task5	"<line2>    LOG.trace(""Start the unmarshalling of the node: ""+ nodeToUnmarshal.toString()+ "" to clazz: ""+ destinationClazz.toString());"	<line9>	"LOGGER.error(""Error while unmarshaling node: "" + nodeToUnmarshal, e)"	"<line9> LOGGER.error(""Error while unmarshaling node: "" + nodeToUnmarshal, e)"
task5	"<line8>        logger.warn(String.format(""Failed to close file %s"", olf.f.getAbsolutePath()), e);"	<line8>	"LOG.warn(""Failed to close RAF for oplog file {}"", olf.f, e)"	"<line8> LOG.warn(""Failed to close RAF for oplog file {}"", olf.f, e)"
task5	"<line8>      log.error(""Error while saving the report .. {}"", e.getMessage());"	<line8>	"log.error(""Error while saving assessment report configuration {}"", assessmentReportJson, e)"	"<line8> log.error(""Error while saving assessment report configuration {}"", assessmentReportJson, e)"
task5	"<line2>      log.warn(""No .zip suffix[%s], putting files from [%s] into it anyway."", outputZipFile, directory);"	<line2>	"logger.warn(""The file '"" + outputZipFile.getName() + ""' is not a zip file."")"	"<line2> logger.warn(""The file '"" + outputZipFile.getName() + ""' is not a zip file."")"
task5	"<line4>      log.debug(""created subreports thread executor ""+ threadExecutor+ "" for ""+ fillContext.getMasterFiller().getJasperReport().getName());"	<line4>	"log.debug(""Subreport thread executor "" + threadExecutor)"	"<line4> log.debug(""Subreport thread executor "" + threadExecutor)"
task5	"<line3>          logger.warn(""No repo loaded warning."");"	<line3>	"log.warn(""No repo loaded warning."")"	"<line3> log.warn(""No repo loaded warning."")"
task5	"<line3>    logger.debug(""Updating user with id : "" + userId);"	<line9>	"log.info(""User info updated"")"	"<line9> log.info(""User info updated"")"
task5	"<line23>      logger.debug(""failed to reset"", cx);"	<line23>	log.error(cx.getMessage(), cx)	<line23> log.error(cx.getMessage(), cx)
task5	"<line8>    log.debug(""new SHARD datasource'{}' is ADDED in {} ms"",shardDataSourceCreateHelper.getShardName(),System.currentTimeMillis() - start);"	<line8>	"log.info(""connected to shard "" + shardId + "" in "" + (System.currentTimeMillis() - start) + "" ms"")"	"<line8> log.info(""connected to shard "" + shardId + "" in "" + (System.currentTimeMillis() - start) + "" ms"")"
task5	"<line9>    log.debug(""cacheKey:{} LessEqualsFilter: {} percentiles[{}] = {} multiplier: {}"",cacheKey,lessEqualFilter,minBound,percentiles[minBound],result);"	<line9>	"log.debug(""cacheKey:{} LessEqualFilter:{} percentiles[{}] = {} multiplier: {}"",cacheKey,lessEqualFilter,minBound,result)"	"<line9> log.debug(""cacheKey:{} LessEqualFilter:{} percentiles[{}] = {} multiplier: {}"",cacheKey,lessEqualFilter,minBound,result)"
task5	<line18>      log.debug(e.toString());	<line10>	"log.debug(""Connecting to endpoint: {}"", endpoint)"	"<line10> log.debug(""Connecting to endpoint: {}"", endpoint)"
task5	<line14>      logger.info(ex.getMessage());	<line14>	logger.info(ex.getMessage())	<line14> logger.info(ex.getMessage())
task5	"<line11>    logger.debug(""About to marshal task attachment with id '{}' {}"", attachmentId, attachment);"	<line2>	"logger.debug(""About to get attachment content for task "" + taskId + "" and attachment "" + attachmentId)"	"<line2> logger.debug(""About to get attachment content for task "" + taskId + "" and attachment "" + attachmentId)"
task5	"<line14>      log.debug(""Falling back to describe '{}' table by querying {}"", tableId, db);"	<line14>	"log.warn(""Unable to find auto incrementing column for table: {}"", tableId)"	"<line14> log.warn(""Unable to find auto incrementing column for table: {}"", tableId)"
task5	"<line5>      LOG.debug(""Using "" + impl.getName() + "" for "" + protocol.getName());"	<line9>	"LOG.info(""Loaded RpcEngine: "" + engine)"	"<line9> LOG.info(""Loaded RpcEngine: "" + engine)"
task5	"<line5>      logger.error(""Unable to access "" + properties_file, ex);"	<line5>	"log.error(""Failed to load properties file: "" + properties_file, ex)"	"<line5> log.error(""Failed to load properties file: "" + properties_file, ex)"
task5	"<line10>                logger.warn(""Link extractor ({}) returned invalid URI: {}"", name, e.getMessage());"	<line10>	"log.warn(""Malformed URI {}"", l, e)"	"<line10> log.warn(""Malformed URI {}"", l, e)"
task5	"<line2>    logger.debug(""Restoring vm ""+ vm.getUuid()+ ""from backup ""+ backup.getUuid()+ "" on the Dummy Backup Provider"");"	<line2>	"LOGGER.info(""Restore VM "" + vm.getId() + "" from backup "" + backup.getId())"	"<line2> LOGGER.info(""Restore VM "" + vm.getId() + "" from backup "" + backup.getId())"
task5	"<line2>      log.debug(""going ""+ MemberExpression.DIRECTION.DOWN+ "" by ""+ (expression.isWildcard() ? ""wildcard"" : ""key: ["" + expression.getObjectKey() + ""]"")+ "" on ""+ jrJsonNode.getDataNode());"	<line2>	"log.debug(""applying wildcard step to node: "" + jrJsonNode)"	"<line2> log.debug(""applying wildcard step to node: "" + jrJsonNode)"
task5	"<line2>      log.warn(""Detected failure in monitor accessing "" + getUrl() + "": "" + problem);"	<line2>	"log.debug(""onFailure: "" + problem)"	"<line2> log.debug(""onFailure: "" + problem)"
task5	"<line10>        log.debug(StringBundler.concat(""Unable to locate status for background task "",backgroundTaskId,"" to process "",message));"	<line10>	"log.debug(""Unable to find background task status for background task id "" + backgroundTaskId)"	"<line10> log.debug(""Unable to find background task status for background task id "" + backgroundTaskId)"
task5	"<line8>            logger.error(""Session not found : "" + sessionId);"	<line8>	"logger.error(""Your session expired: joinTournament "" + tournamentId)"	"<line8> logger.error(""Your session expired: joinTournament "" + tournamentId)"
task5	"<line5>      log.info(""using AWS for salt tests because named:SaltTests does not exist"");"	<line5>	"log.info(""No SaltTests location found; defaulting to us-east-1a"")"	"<line5> log.info(""No SaltTests location found; defaulting to us-east-1a"")"
task5	<line24>      logger.error(e.getMessage(), e);	<line24>	"log.error(""Failed to process file {}"", file, e)"	"<line24> log.error(""Failed to process file {}"", file, e)"
task5	"<line3>    LOGGER.debug(""Get all criteria={}"", criteria);"	<line3>	"LOGGER.debug(""get all tenants criteria={}"", criteria)"	"<line3> LOGGER.debug(""get all tenants criteria={}"", criteria)"
task5	"<line26>      LOGGER.error(""ActivityMetaDataDao - getFrequencyRunsDetailsForActiveTasks() :: ERROR"", e);"	<line26>	"LOGGER.error(""StudyMetaDataDao - getFrequencyRunsDetailsForActiveTasks() :: ERROR"", e)"	"<line26> LOGGER.error(""StudyMetaDataDao - getFrequencyRunsDetailsForActiveTasks() :: ERROR"", e)"
task5	"<line2>      LOG.debug(""truncating Cassandra table {}"", mapping.getCoreName());"	<line2>	"LOG.debug(""Truncate table: {}"", mapping.getTableName())"	"<line2> LOG.debug(""Truncate table: {}"", mapping.getTableName())"
task5	<line18>      LOG.error(msg, e);	<line18>	LOG.warn(msg, e)	<line18> LOG.warn(msg, e)
task5	"<line2>    LOGGER.debug(""ExtendedRandomLength: "" + msg.getExtendedRandomLength().getValue());"	<line2>	"LOGGER.debug(""ExtendedRandomLength: "" + msg.getExtendedRandomLength().getValue())"	"<line2> LOGGER.debug(""ExtendedRandomLength: "" + msg.getExtendedRandomLength().getValue())"
task5	"<line7>        logger.debug(""Pipelines [id={} , pipeline={} ]"", line[0], line[1]);"	<line13>	"logger.error(""Error in reading the pipelines csv file: "" + csvFilePipelines, e)"	"<line13> logger.error(""Error in reading the pipelines csv file: "" + csvFilePipelines, e)"
task5	"<line10>            LOG.error(""Unable to extract the underlying Sequence Iterator: {}. Falling back to""+ "" EMPTY_ITERATOR"",xpe.getMessage(),xpe);"	<line10>	"LOG.warn(""Failed to iterate over sequence: {}"", xpe.getMessage(), xpe)"	"<line10> LOG.warn(""Failed to iterate over sequence: {}"", xpe.getMessage(), xpe)"
task5	"<line2>      logger.trace(LogMarker.DLS_VERBOSE, ""[DLockGrantor.handleLockQuery] {}"", query);"	<line2>	"logger.trace(LogMarker.DLS_VERBOSE, ""handleLockQuery: {}"", query)"	"<line2> logger.trace(LogMarker.DLS_VERBOSE, ""handleLockQuery: {}"", query)"
task5	"<line2>    logger.info(""Get all modules from registry"");"	<line4>	"log.info(""Pipeline creation is not implemented yet"")"	"<line4> log.info(""Pipeline creation is not implemented yet"")"
task5	"<line3>      LOGGER.debug(""Listing topics"");"	<line6>	"log.error(""Failed to list topics"", e)"	"<line6> log.error(""Failed to list topics"", e)"
task5	"<line9>      LOGGER.error(""Failed to get revision {} of note {}"", revId, noteId, e);"	<line9>	"LOGGER.error(""Failed to get note {} revision {} in default notebook repository"", noteId, revId, e)"	"<line9> LOGGER.error(""Failed to get note {} revision {} in default notebook repository"", noteId, revId, e)"
task5	"<line2>    logger.debug(""RestartFreezePosition="" + seekTo);"	<line2>	"logger.debug(""Restarting video playback of "" + this)"	"<line2> logger.debug(""Restarting video playback of "" + this)"
task5	"<line3>      log.warn(""addGrid {} already exists"");"	<line3>	"log.warn(""grid already exists"")"	"<line3> log.warn(""grid already exists"")"
task5	"<line41>        logger.warn(""Cannot find a parser for the "" + attribute.getName().getNamespaceURI() + "" namespace"");"	<line41>	"logger.warn(""No SBML Level 2 vocabulary attribute found for attribute "" + attributeName)"	"<line41> logger.warn(""No SBML Level 2 vocabulary attribute found for attribute "" + attributeName)"
task5	"<line7>      logger.error(""Unable to determine if user "" + string + "" exists"", fex);"	<line7>	"logger.error(""Error in doesExist()"", fex)"	"<line7> logger.error(""Error in doesExist()"", fex)"
task5	<line18>      log.error(systemException, systemException);	<line18>	log.error(systemException, systemException)	<line18> log.error(systemException, systemException)
task5	"<line1>    log.debug(""Clearing resource definitions"");"	<line1>	"log.debug(""Clearing resource definitions"")"	"<line1> log.debug(""Clearing resource definitions"")"
task5	"<line4>      LOG.debug(""Removed Scout server session from cache [scoutSessionId={}, httpSessionId={}]."",scoutSessionId,httpSessionId);"	<line3>	"LOG.info(""ServerSessionEntry for session {} removed."", httpSessionId)"	"<line3> LOG.info(""ServerSessionEntry for session {} removed."", httpSessionId)"
task5	"<line2>    log.debug(""Migration1707ArtifactUuidFix  fix group:  resource id {}, group name {} "",resource.getUniqueId(),group.getName());"	<line2>	"logger.debug(""fixVfGroup: group: {}"", group.getGroupId())"	"<line2> logger.debug(""fixVfGroup: group: {}"", group.getGroupId())"
task5	"<line5>      logger.warn(String.format(""Class[%s] doesn't has EO."", VOClazz));"	<line5>	"logger.warn(""The entity '{}' does not have an EO counterpart."", VOClazz.getName())"	"<line5> logger.warn(""The entity '{}' does not have an EO counterpart."", VOClazz.getName())"
task5	"<line2>    LOG.info(""Catalog Server ("" + bindAddress + "") shutdown"");"	<line9>	"LOG.info(""Thrift monitor stopped"")"	"<line9> LOG.info(""Thrift monitor stopped"")"
task5	"<line23>        LOG.info(""Found new partition {} of table {}, generating splits for it"",partSpec,tablePath.getFullName());"	<line2>	"LOG.debug(""Reading hive partitions {}"", fetcher.getPartitions(fetcherContext))"	"<line2> LOG.debug(""Reading hive partitions {}"", fetcher.getPartitions(fetcherContext))"
task5	"<line1>    logger.debug(""Recommending to Peer {} that Protocol Version {} be used"",peerDescription,protocolVersion);"	<line6>	"LOG.debug(""Recommending protocol version {}"", buffer)"	"<line6> LOG.debug(""Recommending protocol version {}"", buffer)"
task5	"<line4>      log.warn(""MD5 calculation disabled"");"	<line4>	"LOG.warn(""No message digest provided, so not calculating any digest."")"	"<line4> LOG.warn(""No message digest provided, so not calculating any digest."")"
task5	"<line7>    LOGGER.info(""Experiment created successfully"");"	<line11>	"log.info(""Experiment created successfully"")"	"<line11> log.info(""Experiment created successfully"")"
task5	"<line17>      LOGGER.debug(""Created voltagelevel {}"", voltageLevel.getId());"	<line8>	"LOGGER.trace(""Create voltage level '{}'"", voltageLevelId)"	"<line8> LOGGER.trace(""Create voltage level '{}'"", voltageLevelId)"
task5	"<line7>        logger.warn(""Exception at getFavorites"", e);"	<line7>	"logger.warn(""Exception at getFavorites"", e)"	"<line7> logger.warn(""Exception at getFavorites"", e)"
task5	"<line3>      LOGGER.info(""dispose: "" + this.getId());"	<line3>	"LOGGER.info(""Disposing {}"", this.getId())"	"<line3> LOGGER.info(""Disposing {}"", this.getId())"
task5	"<line1>    logger.debug(""Get Acl"");"	<line1>	"logger.debug(""Get ACL"")"	"<line1> logger.debug(""Get ACL"")"
task5	"<line8>    LOGGER.info(""Finding devices which have no owner for organisation: {}."", organisationIdentification);"	<line8>	"LOGGER.info(""Find devices which have no owner for organisation: {}."", organisationIdentification)"	"<line8> LOGGER.info(""Find devices which have no owner for organisation: {}."", organisationIdentification)"
task5	"<line7>      logger.error(""Failed to process heartbeats"", e);"	<line7>	"LOG.error(""Failed to process heartbeats from nodes due to {}"", e.getMessage(), e)"	"<line7> LOG.error(""Failed to process heartbeats from nodes due to {}"", e.getMessage(), e)"
task5	<line25>      logger.warn(e.getMessage(), e);	<line25>	"log.debug(""Expected exception: "", e)"	"<line25> log.debug(""Expected exception: "", e)"
task5	<line38>        LOG.error(ERROR_TRANSLATING_POSTGRES_EXC_MSG, pSqlException);	<line38>	LOG.error(ERROR_TRANSLATING_EXCEPTION_MSG, pSqlException)	<line38> LOG.error(ERROR_TRANSLATING_EXCEPTION_MSG, pSqlException)
task5	"<line4>      LOGGER.debug(""Added object {} to the commit for updating"", obj.getOID());"	<line2>	"log.debug(""Update object {}"", obj.getOID())"	"<line2> log.debug(""Update object {}"", obj.getOID())"
task5	"<line1>    logger.debug(""getCloudsByCloudRequestDTOs started..."");"	<line3>	"logger.debug(""getCloudsByCloudRequestDTOs started..."")"	"<line3> logger.debug(""getCloudsByCloudRequestDTOs started..."")"
task5	"<line7>      log.error(""InvocationTargetException or InterruptedException during conversion"", e);"	<line7>	log.error(e.getMessage(), e)	<line7> log.error(e.getMessage(), e)
task5	"<line6>      logger.error(""Failed to instantiate asr driver (className = "" + clazz + "")"", e);"	<line5>	"LOG.info(""Registered ASR driver {}"", name)"	"<line5> LOG.info(""Registered ASR driver {}"", name)"
task5	"<line1>    LOG.error(""TestReadListener error"", t);"	<line1>	"logger.error(""Error: Vector Ingest failed."", t)"	"<line1> logger.error(""Error: Vector Ingest failed."", t)"
task5	"<line7>        logger.warn(""Exception at createSavedSearch"", e);"	<line7>	"logger.warn(""Exception at createSavedSearch"", e)"	"<line7> logger.warn(""Exception at createSavedSearch"", e)"
task5	"<line2>      log.error(""Unexpected end state: {}"", states.peek());"	<line2>	"log.warn(""Unclosed states detected, closing now"")"	"<line2> log.warn(""Unclosed states detected, closing now"")"
task5	"<line6>    LOG.info(""Result of CalcMath.calcSum() method is {}"", result);"	<line6>	"logger.info(""Groovy Math sum: "" + result)"	"<line6> logger.info(""Groovy Math sum: "" + result)"
task5	"<line11>      logger.error(""query logs from db error"", e);"	<line11>	"logger.error(""Get log by group id failed, group id = {}"", groupId, e)"	"<line11> logger.error(""Get log by group id failed, group id = {}"", groupId, e)"
task5	"<line19>    log.info(""Removing all confirmationConfiguration objects"");"	<line20>	"log.info(""Removed all confirmationConfiguration objects"")"	"<line20> log.info(""Removed all confirmationConfiguration objects"")"
task5	"<line17>      logger.info(""Resolved function from provided [routing-expression]  "" + routingExpression);"	<line17>	"logger.info(""Resolved function name {} from expression {}"", functionName, expression)"	"<line17> logger.info(""Resolved function name {} from expression {}"", functionName, expression)"
task5	"<line20>      logger.error(""StudyDAOImpl - getComprehensionTestQuestionById() - Error"", e);"	<line20>	"logger.error(""StudyQuestionnaireDAOImpl - getComprehensionTestQuestionById() - ERROR "", e)"	"<line20> logger.error(""StudyQuestionnaireDAOImpl - getComprehensionTestQuestionById() - ERROR "", e)"
task5	"<line2>    log.debug("""");"	<line2>	"log.debug("""")"	"<line2> log.debug("""")"
task5	<line6>        log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line6>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line6> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line3>    log.error(""Found unresolved type in the VDM AST"");"	<line3>	"log.error(""Unresolved type in "" + question.getUserDescription())"	"<line3> log.error(""Unresolved type in "" + question.getUserDescription())"
task5	"<line22>      logger.info(""local avatar not available"", t);"	<line22>	"logger.error(""Error extracting avatar for user "" + this.getUsername(), t)"	"<line22> logger.error(""Error extracting avatar for user "" + this.getUsername(), t)"
task5	"<line2>    log.info(""Validating failing in configuration with explicit total flink and managed memory size."");"	<line2>	"log.info(""Validating fail with explicit total flink and managed memory."")"	"<line2> log.info(""Validating fail with explicit total flink and managed memory."")"
task5	"<line7>        LOG.error(""Exception in WebDriverManager while getWebDriver "", e);"	<line7>	"LOG.error(""Exception in WebDriverManager while getWebDriver "", e)"	"<line7> LOG.error(""Exception in WebDriverManager while getWebDriver "", e)"
task5	"<line33>        log.error(""Interrupted while waiting for XML tag threads to terminate - no datatags were added!"");"	<line33>	"log.error(""Failed to retrieve the data tag configuration XML string for equipment #{}"",pEquipment.getId(),e)"	"<line33> log.error(""Failed to retrieve the data tag configuration XML string for equipment #{}"",pEquipment.getId(),e)"
task5	"<line11>      this.logger.info(""{} events were saved in the new store because they did not already exist"",eventsToSave.size());"	<line11>	"logger.info(""events saved"")"	"<line11> logger.info(""events saved"")"
task5	"<line6>      log.debug(""committing in TestTransactionUtil"");"	<line1>	"log.debug(""flushAndClear"")"	"<line1> log.debug(""flushAndClear"")"
task5	"<line19>      logger.debug(""Nothing to refresh"");"	<line8>	"logger.debug(""No connection available. Skipping refresh."")"	"<line8> logger.debug(""No connection available. Skipping refresh."")"
task5	"<line5>    LOG.info(""Hive source({}}) {} use time: {} ms, result: {}"",tablePath,operationName,System.currentTimeMillis() - startTimeMillis,result);"	<line5>	"LOG.info(""Finished {} after {} ms"", operationName, System.currentTimeMillis() - startTimeMillis)"	"<line5> LOG.info(""Finished {} after {} ms"", operationName, System.currentTimeMillis() - startTimeMillis)"
task5	<line24>      log.error(e);	<line24>	log.error(e)	<line24> log.error(e)
task5	"<line1>    LOGGER.info(""Searching cases in "" + folder.getPath());"	<line1>	"LOGGER.info(""Searching for cases in folder: "" + folder.getAbsolutePath())"	"<line1> LOGGER.info(""Searching for cases in folder: "" + folder.getAbsolutePath())"
task5	<line15>    log.info(sb.toString());	<line15>	log.info(sb.toString())	<line15> log.info(sb.toString())
task5	"<line27>    LOG.debug(""Successfully created default index set: {}"", savedConfig);"	<line27>	"LOG.info(""Default index set created"")"	"<line27> LOG.info(""Default index set created"")"
task5	"<line33>              Logger.info(String.format(""Bienvenue, Bienvenido, Willkommen, Hello, Namaskar, Welkom, Bonjour to""+ "" OpenPnP version %s."",Main.getVersion()));"	<line35>	"logger.error(""Exception while starting the PNP application"", e)"	"<line35> logger.error(""Exception while starting the PNP application"", e)"
task5	<line15>      LOGGER.warn(String.format(GENERIC_INSECURE_DEFAULTS_MSG, keystorePath), e);	<line15>	"log.debug(""Unable to fetch certificates from keystore due to: "" + e.getMessage())"	"<line15> log.debug(""Unable to fetch certificates from keystore due to: "" + e.getMessage())"
task5	"<line30>    LOG.info(""NCSARequestlogging is using directory {}"", lc.getLogNCSADirectory());"	<line30>	"LOG.info(""NCSA request log enabled: {}"", requestLog)"	"<line30> LOG.info(""NCSA request log enabled: {}"", requestLog)"
task5	"<line3>    logger.info(""Attempting to terminate all cloud resources (timeout set to ""+ duration+ "" ""+ unit+ "")"");"	<line20>	"logger.info(""All resources terminated"")"	"<line20> logger.info(""All resources terminated"")"
task5	"<line10>      logger.warn(""no entity manager found with code {}"", entityManagerCode);"	<line1>	"logger.debug(""extractEntityManager"")"	"<line1> logger.debug(""extractEntityManager"")"
task5	"<line1>    LOG.info(""Disconnecting sessions"");"	<line1>	"log.info(""Disconnecting {}"", this)"	"<line1> log.info(""Disconnecting {}"", this)"
task5	"<line5>        logger.warn(""Exception when de-serializing "" + clazz + "" with "" + jsonString, ex);"	<line5>	"LOG.error(""Exception when de-serializing "" + clazz + "" with "" + jsonString, ex)"	"<line5> LOG.error(""Exception when de-serializing "" + clazz + "" with "" + jsonString, ex)"
task5	"<line3>      logger.debug(""{} onNext:{}"", listener, value);"	<line3>	"logger.debug(""{}: next value: {}"", streamId, value)"	"<line3> logger.debug(""{}: next value: {}"", streamId, value)"
task5	"<line1>    LOG.trace(""Seeking offset for topic-partition [{}] with [{}] and committed offset [{}]"",newTp,firstPollOffsetStrategy,committedOffset);"	<line1>	"log.debug(""Seeking to committed offset {} for topic-partition {}"", committedOffset, newTp)"	"<line1> log.debug(""Seeking to committed offset {} for topic-partition {}"", committedOffset, newTp)"
task5	<line16>      log.error(portalException, portalException);	<line16>	log.error(portalException, portalException)	<line16> log.error(portalException, portalException)
task5	"<line42>              logger.warn(String.format(""update vms priority failed on host[%s],because %s"",inv.getUuid(), reply.getError()));"	<line42>	"logger.warn(String.format(""update vm priority failed, %s"", reply.getError()))"	"<line42> logger.warn(String.format(""update vm priority failed, %s"", reply.getError()))"
task5	"<line2>    logger.debug(""Removing all electron containers"");"	<line2>	"logger.debug(""Removing all electron containers: "", this.electronContainers)"	"<line2> logger.debug(""Removing all electron containers: "", this.electronContainers)"
task5	"<line12>    logger.info(""Initializer Jackrabbit Repository in: "" + home.getAbsolutePath());"	<line9>	"log.info(""Using temp directory: "" + home.getAbsolutePath())"	"<line9> log.info(""Using temp directory: "" + home.getAbsolutePath())"
task5	"<line2>    logger.debug(""Connecting to database {} at {}"",configuration.getDatabase().getDriverClass(),configuration.getDatabase().getUrl());"	<line2>	"log.info(""Getting database attribution source for {}"", configuration.getDatabase().getDriverClass())"	"<line2> log.info(""Getting database attribution source for {}"", configuration.getDatabase().getDriverClass())"
task5	"<line8>      logger.error(""event=cns_topic_delivery_policy_to_string"", e);"	<line8>	"logger.error(""Error toString"", e)"	"<line8> logger.error(""Error toString"", e)"
task5	"<line7>    logger.debug(""getting page list with request {}"", searchRequest);"	<line7>	"logger.debug(""user {} requesting page search"", user.getUsername())"	"<line7> logger.debug(""user {} requesting page search"", user.getUsername())"
task5	<line25>      LOGGER.error(e.getLocalizedMessage(), e);	<line25>	"LOG.error(""Could not initialize Azure Functions wizard"", e)"	"<line25> LOG.error(""Could not initialize Azure Functions wizard"", e)"
task5	"<line3>    log.info(""Testing Job lifecycle for {} of type {}"",jobInfo.getOperation(),jobInfo.getContentType());"	<line3>	"LOG.info(""Starting testJobLifecycle with {}"", jobInfo)"	"<line3> LOG.info(""Starting testJobLifecycle with {}"", jobInfo)"
task5	"<line56>      log.trace(""Created network policy {}"", networkPolicy);"	<line56>	"LOGGER.debug(""Generated NetworkPolicy {} for {}"", networkPolicy, name)"	"<line56> LOGGER.debug(""Generated NetworkPolicy {} for {}"", networkPolicy, name)"
task5	"<line5>      log.debug(""log4j-web not available, skipping MDC setup"");"	<line5>	"LOGGER.warn(""Unable to load ServletRequestThreadContext, you may see increasing number of open file""+ "" handle"",e)"	"<line5> LOGGER.warn(""Unable to load ServletRequestThreadContext, you may see increasing number of open file""+ "" handle"",e)"
task5	"<line4>    LOGGER.info(""id={}"", id);"	<line4>	"LOGGER.debug(""PUT /{id}"")"	"<line4> LOGGER.debug(""PUT /{id}"")"
task5	"<line8>        LOG.error(""JSON Error Exception"", ex);"	<line8>	"LOGGER.info(""Error during compare: "" + ex.getMessage())"	"<line8> LOGGER.info(""Error during compare: "" + ex.getMessage())"
task5	"<line11>      LOGGER.warn(""Failed to save HexviewerPlus settings file. Error:{}"", ex.toString());"	<line11>	"logger.error(""Error while saving object to file "" + path, ex)"	"<line11> logger.error(""Error while saving object to file "" + path, ex)"
task5	"<line2>    LOG.debug(""testClassLdapConnectionPool"");"	<line2>	"LOG.debug(""testClassLdapConnectionPool"")"	"<line2> LOG.debug(""testClassLdapConnectionPool"")"
task5	"<line15>    LOG.debug(""owner:"" + owner + "", group:"" + group);"	<line3>	"LOG.debug(""initialize: {}"", name)"	"<line3> LOG.debug(""initialize: {}"", name)"
task5	"<line14>        log.error(""Problems encountered when trying to construct local variable"");"	<line14>	"log.error(""Unexpected definition type: "" + def)"	"<line14> log.error(""Unexpected definition type: "" + def)"
task5	"<line6>      log.info(""Found previous state: "" + iterationPath);"	<line6>	"LOG.info(""Model already exists at "" + iterationPath)"	"<line6> LOG.info(""Model already exists at "" + iterationPath)"
task5	"<line22>              LOG.error(""Error during processing of: "" + vfile.getName(), e);"	<line22>	LOG.error(e)	<line22> LOG.error(e)
task5	"<line2>      logger.debug(""Evohome Gateway not online, scanning postponed"");"	<line2>	"logger.debug(""Discovery: Location {} status is {}"", location.getName(), location.getStatus())"	"<line2> logger.debug(""Discovery: Location {} status is {}"", location.getName(), location.getStatus())"
task5	"<line2>      LOG.info(""Stopping the StorageContainerManager"");"	<line2>	"LOG.info(""Stopping SCM"")"	"<line2> LOG.info(""Stopping SCM"")"
task5	<line5>        LOG.error(e);	<line5>	"log.error(""Failed to close random access file"", e)"	"<line5> log.error(""Failed to close random access file"", e)"
task5	"<line13>    LOG.debug(""From primitive type array we've created the list: "" + resultList);"	<line2>	"LOG.info(""Testing collection to primitive array conversion"")"	"<line2> LOG.info(""Testing collection to primitive array conversion"")"
task5	"<line12>      log.trace(""getPath({}): {}"", uri, p);"	<line12>	"log.trace(""getPath: "" + uri + "" -> "" + p)"	"<line12> log.trace(""getPath: "" + uri + "" -> "" + p)"
task5	"<line2>    logger.debug(""deactivating..."");"	<line2>	"logger.info(""Deactivating {}"", context.getProperties().get(KURA_SERVICE_PID))"	"<line2> logger.info(""Deactivating {}"", context.getProperties().get(KURA_SERVICE_PID))"
task5	<line9>      log.error(exception, exception);	<line9>	log.error(exception, exception)	<line9> log.error(exception, exception)
task5	"<line10>    log.info(""Response: {}"", response);"	<line10>	log.info(response)	<line10> log.info(response)
task5	"<line16>          ServletContextInitializerBeans.logger.debug(""Created ""+ type.getSimpleName()+ "" initializer for bean '""+ beanName+ ""'; order=""+ order+ "", resource=""+ getResourceDescription(beanName, beanFactory));"	<line16>	"ServletContextInitializerBeans.logger.debug(""Created ""+ type.getSimpleName()+ "" initializer for bean '""+ beanName+ ""'"	"<line16> ServletContextInitializerBeans.logger.debug(""Created ""+ type.getSimpleName()+ "" initializer for bean '""+ beanName+ ""'"
task5	"<line15>      LOG.error(""Exception {} detected."", ex.toString());"	<line15>	LOG.error(ex.getMessage(), ex)	<line15> LOG.error(ex.getMessage(), ex)
task5	"<line38>      LOGGER.warn(""Adapt DefaultDatabaseSet to ClusterDatabaseSet exception"", t);"	<line34>	"LOGGER.error(""tryAdapt exception"", t)"	"<line34> LOGGER.error(""tryAdapt exception"", t)"
task5	"<line11>              Log.error(""Error while retrieving org unit ""+ userJS.getMainOrgUnit()+ "" for user ""+ userJS.getId());"	<line11>	"Log.error(""Error while getting main org unit for user "" + id, caught)"	"<line11> Log.error(""Error while getting main org unit for user "" + id, caught)"
task5	"<line2>      LOG.error(""fail to set config. invalid config scope. Scope: {}."", scope);"	<line22>	"LOG.debug(""Updating config for {} with keyValueMap: {}"", scope, keyValueMap)"	"<line22> LOG.debug(""Updating config for {} with keyValueMap: {}"", scope, keyValueMap)"
task5	"<line12>          LOG.trace(""No delay for exchangeId: {}"", exchange.getExchangeId());"	<line12>	"LOG.trace(""Run not allowed, will skip process"")"	"<line12> LOG.trace(""Run not allowed, will skip process"")"
task5	"<line20>      LOG.warn(""exception while writing the last shutdown report"", e);"	<line20>	"LOG.debug(""Could not write last shutdown file"", e)"	"<line20> LOG.debug(""Could not write last shutdown file"", e)"
task5	"<line38>        LOGGER.warn(""Errored as expected"", ex);"	<line38>	"logger.warn(""Exception in thread "" + Thread.currentThread().getId(), ex)"	"<line38> logger.warn(""Exception in thread "" + Thread.currentThread().getId(), ex)"
task5	"<line4>        logger.trace(this + "" informing "" + listener + "" about node down = "" + nodeId);"	<line4>	"logger.trace(""ClusterTopologyListenerImpl::nodeDown {}"", listener)"	"<line4> logger.trace(""ClusterTopologyListenerImpl::nodeDown {}"", listener)"
task5	"<line1>    logger.debug(""Destroying SCTP Server"");"	<line1>	"log.info(""Destroying client"")"	"<line1> log.info(""Destroying client"")"
task5	"<line6>      logger.debug(""No method name provided, CrudRepository.saveAll will be used."");"	<line6>	"logger.warn(""No methodName set on SimpleCrudService"")"	"<line6> logger.warn(""No methodName set on SimpleCrudService"")"
task5	"<line12>      LOG.warn(""RocksDBStateBackend performance will be poor because of the current Flink memory""+ "" configuration! RocksDB will flush memtable constantly, causing high IO and CPU.""+ "" Typically the easiest fix is to increase task manager managed memory size. If""+ "" running locally, see the parameter taskmanager.memory.managed.size. Details:""+ "" arenaBlockSize {} > mutableLimit {} (writeBufferSize = {},""+ "" arenaBlockSizeConfigured = {}, defaultArenaBlockSize = {},""+ "" writeBufferManagerCapacity = {})"",arenaBlockSize,mutableLimit,writeBufferSize,arenaBlockSizeConfigured,defaultArenaBlockSize,writeBufferManagerCapacity);"	<line12>	"LOGGER.warn(""The configured arena block size is not valid for the current write buffer size. The""+ "" default arena block size is {} bytes, while the current write buffer size is {} bytes. The""+ "" mutable limit is {} bytes."",defaultArenaBlockSize,writeBufferSize,mutableLimit)"	"<line12> LOGGER.warn(""The configured arena block size is not valid for the current write buffer size. The""+ "" default arena block size is {} bytes, while the current write buffer size is {} bytes. The""+ "" mutable limit is {} bytes."",defaultArenaBlockSize,writeBufferSize,mutableLimit)"
task5	"<line2>    log.debug(""Event received"");"	<line2>	"logger.debug(""Event: {}"", event.getTopic())"	"<line2> logger.debug(""Event: {}"", event.getTopic())"
task5	"<line1>    log.info(""Information message text"");"	<line1>	"log.info(""Executing doSomething()"")"	"<line1> log.info(""Executing doSomething()"")"
task5	<line11>        log.debug(ioException, ioException);	<line11>	log.debug(ioException, ioException)	<line11> log.debug(ioException, ioException)
task5	"<line21>          logger.warn(""detected overlapped IP blocks: "" + prev + "", "" + curr);"	<line14>	"logger.debug(""merging "" + ipBlocks.size() + "" ip blocks"")"	"<line14> logger.debug(""merging "" + ipBlocks.size() + "" ip blocks"")"
task5	"<line3>      LOG.warn(""Not attempting to re-login since the last re-login was ""+ ""attempted less than {} seconds before."",(MIN_TIME_BEFORE_RELOGIN / 1000));"	<line3>	"LOG.info(""Not attempting to re-login since the last re-login was ""+ ""attempted less than {} seconds before."",MIN_TIME_BEFORE_RELOGIN / 1000)"	"<line3> LOG.info(""Not attempting to re-login since the last re-login was ""+ ""attempted less than {} seconds before."",MIN_TIME_BEFORE_RELOGIN / 1000)"
task5	"<line11>          logger.debug(""Found match for string in source file: {} in line: {}"", textUnitNameInSource, line);"	<line4>	"logger.debug(""getGitBlameWithUsagesFromLine"")"	"<line4> logger.debug(""getGitBlameWithUsagesFromLine"")"
task5	"<line6>        logger.error(""ERROR # disconnect meta connection for address:{}"",metaConnection.getConnector().getAddress(),e);"	<line6>	"LOG.error(""After dump, failed to disconnect from meta server"", e)"	"<line6> LOG.error(""After dump, failed to disconnect from meta server"", e)"
task5	"<line2>    logger.info(""System benchmark result = {}"", SystemUtil.bench());"	<line2>	"LOG.info(String.format(""Java version: %s"", System.getProperty(""java.version"")))"	"<line2> LOG.info(String.format(""Java version: %s"", System.getProperty(""java.version"")))"
task5	"<line5>        log.warn(""the DB have duplicated jobName({})"", jobName);"	<line5>	"log.info(""Remove duplicate job config: {}"", streamChangedJob.toString())"	"<line5> log.info(""Remove duplicate job config: {}"", streamChangedJob.toString())"
task5	"<line11>          LOGGER.info(""Undeploying library {}.{}"", dataverseName, libraryName);"	<line11>	"LOGGER.info(""Undeploying library {}.{}"", getLibraryName(), getLibraryVersion())"	"<line11> LOGGER.info(""Undeploying library {}.{}"", getLibraryName(), getLibraryVersion())"
task5	"<line2>      LOGGER.debug(""succeeded reconciliation {}"", name);"	<line2>	"LOGGER.debug(""Stopping reconciliation timer for {}"", name)"	"<line2> LOGGER.debug(""Stopping reconciliation timer for {}"", name)"
task5	"<line9>      log.debug(""Waiting for interrupt"");"	<line6>	"log.info(""Executing long running operation"")"	"<line6> log.info(""Executing long running operation"")"
task5	"<line4>      logger.error(""{}:replace users failed"", metaGroupMember.getName(), e);"	<line4>	"LOG.error(""Auth error when installing snapshot: {}"", e.getMessage(), e)"	"<line4> LOG.error(""Auth error when installing snapshot: {}"", e.getMessage(), e)"
task5	"<line2>    logger.info(name.getMethodName() + "" - callback - got unexpected exception"");"	<line3>	"logger.info(""Enumeration callback error: {}"", error.getMessage())"	"<line3> logger.info(""Enumeration callback error: {}"", error.getMessage())"
task5	<line13>      log.error(systemException, systemException);	<line13>	log.error(systemException, systemException)	<line13> log.error(systemException, systemException)
task5	"<line9>      logger.debug(""Platform: Android"");"	<line9>	"logger.info(""Android 0.x detected"")"	"<line9> logger.info(""Android 0.x detected"")"
task5	<line9>      log.error(exception, exception);	<line9>	log.error(exception, exception)	<line9> log.error(exception, exception)
task5	"<line17>      logger.warn(""Invalidating this batch! The results returned do not match the addresses given."");"	<line24>	"log.info(""Geocode result validation failed. Batch geocode result is not valid."")"	"<line24> log.info(""Geocode result validation failed. Batch geocode result is not valid."")"
task5	"<line8>          logger.debug(""Caching "" + type.name());"	<line14>	"logger.info(""Adding district map: {}"", map.toString())"	"<line14> logger.info(""Adding district map: {}"", map.toString())"
task5	"<line15>      log.error(""main threw"", e);"	<line15>	"log.error(""main threw"", e)"	"<line15> log.error(""main threw"", e)"
task5	"<line6>    logger.info(""Serializer = "" + serializerType + "", UseRawLocalFileSystem = "" + useRawLocalFileSystem);"	<line6>	"LOGGER.debug(""Using serializer type {}"", serializerType)"	"<line6> LOGGER.debug(""Using serializer type {}"", serializerType)"
task5	"<line7>      log.warn(""query["" + debugKey + ""]: match="" + match + "" miss="" + miss);"	<line7>	"LOG.debug(""hits: {}"	"<line7> LOG.debug(""hits: {}"
task5	<line28>        log.debug(exception, exception);	<line28>	log.debug(exception, exception)	<line28> log.debug(exception, exception)
task5	"<line6>      log.warn(""getSplits() was called more than once and the 'seed' is set, ""+ ""this can lead to no-repeatable behavior"");"	<line6>	"LOG.info(""Using seed : "" + seed)"	"<line6> LOG.info(""Using seed : "" + seed)"
task5	"<line13>      LOGGER.warn(""saveDataHostIndexToZk err:"", e);"	<line13>	"logger.error(""saveDataHostIndexToZk error"", e)"	"<line13> logger.error(""saveDataHostIndexToZk error"", e)"
task5	"<line5>      logger.debug(""storing response message {}"", message.toStringForDebug(false));"	<line5>	"logger.debug(""saving message {} to {}"", message, parentURI)"	"<line5> logger.debug(""saving message {} to {}"", message, parentURI)"
task5	"<line27>        log.info(""Could not read replication table, waiting and will retry"");"	<line27>	"log.info(""Waiting for permissions to propagate"")"	"<line27> log.info(""Waiting for permissions to propagate"")"
task5	"<line9>        LOG.warn(""Writing a request: {} to channel {} failed : cause = {}"",new Object[] {getBasicInfoFromRequest(request), channel, channelFuture.getCause().getMessage()});"	<line15>	"LOG.debug(""Successfully wrote request {} to channel {}"", request, channel)"	"<line15> LOG.debug(""Successfully wrote request {} to channel {}"", request, channel)"
task5	"<line5>      log.warn(""Credential reset notification failed"", e);"	<line5>	"log.warn(""Credential reset notification failed"", e)"	"<line5> log.warn(""Credential reset notification failed"", e)"
task5	<line9>      logger.error(NONE_RESOURCE_FOUND_MESSAGE);	<line3>	"logger.debug(""doDel {}"", reqMessage)"	"<line3> logger.debug(""doDel {}"", reqMessage)"
task5	"<line3>    LOGGER.debug(""Providing {} docs"", persistQueue.size());"	<line8>	"LOGGER.trace(""readCurrent: {}"", result)"	"<line8> LOGGER.trace(""readCurrent: {}"", result)"
task5	"<line5>    logger.info(""[Redis-Change] {}, master: {}"", redisMeta, redisMeta.isMaster());"	<line5>	"logger.debug(""[accept]{}"", redisMeta)"	"<line5> logger.debug(""[accept]{}"", redisMeta)"
task5	"<line7>      log.info(""Binding "" + filterParser);"	<line7>	"log.info(""Binding "" + filterParser)"	"<line7> log.info(""Binding "" + filterParser)"
task5	"<line4>    logger.trace(""wrote: {}, got: {} "", requestPacket, returnPacket);"	<line4>	"logger.info(""{}"", returnPacket.getReturnPayload())"	"<line4> logger.info(""{}"", returnPacket.getReturnPayload())"
task5	"<line4>      logger.debug(""OW connection state: set to failed as max retries exceeded."");"	<line2>	"logger.info(""Connection to OW server failed - closing handler (retry={})"", connectionErrorCounter)"	"<line2> logger.info(""Connection to OW server failed - closing handler (retry={})"", connectionErrorCounter)"
task5	"<line7>      log.error(""Error creating Drools base message validator."", ex);"	<line7>	"LOG.error(""Unable to set rules file: {}"", ex.getMessage(), ex)"	"<line7> LOG.error(""Unable to set rules file: {}"", ex.getMessage(), ex)"
task5	"<line9>    LOGGER.debug(""Loaded User: "" + result);"	<line4>	"logger.debug(""ApplicationUser: "" + user.toString())"	"<line4> logger.debug(""ApplicationUser: "" + user.toString())"
task5	"<line7>      LOG.error(""Update failed"", e);"	<line7>	"LOG.error(""Exception while updating entity"", e)"	"<line7> LOG.error(""Exception while updating entity"", e)"
task5	"<line37>      LOG.trace(""Cannot convert field {} to type {}. Content was: {}"",fieldName,Type.getTypeName(type),content);"	<line37>	"LOG.warn(""Cannot convert to a LongField: {}"", e.getMessage())"	"<line37> LOG.warn(""Cannot convert to a LongField: {}"", e.getMessage())"
task5	"<line1>    log.info(""Enter project ID {}"", projectId);"	<line1>	"log.info(""Enter project id {}"", projectId)"	"<line1> log.info(""Enter project id {}"", projectId)"
task5	<line8>        log.error(exception, exception);	<line8>	log.error(exception, exception)	<line8> log.error(exception, exception)
task5	"<line1>    logger.trace(""[{}] isDirectory() -> {}"", name, isDirectory);"	<line1>	"logger.trace(""[{}] isDirectory() -> {}"", name, isDirectory)"	"<line1> logger.trace(""[{}] isDirectory() -> {}"", name, isDirectory)"
task5	"<line2>    log.debug(""Retuning OAuth bearer error response: "" + header);"	<line2>	"LOG.debug(""Retuning bearer error: "" + header)"	"<line2> LOG.debug(""Retuning bearer error: "" + header)"
task5	<line10>        LOG.warn(message);	<line10>	LOG.warn(message)	<line10> LOG.warn(message)
task5	"<line4>    LOGGER.info(""ServerProfileCompliancePreview object returned to client : ""+ JsonPrettyPrinter.print(compliance));"	<line4>	"LOGGER.info(""ServerProfileCompliancePreview object returned to client : "" + compliance.toJsonString())"	"<line4> LOGGER.info(""ServerProfileCompliancePreview object returned to client : "" + compliance.toJsonString())"
task5	"<line22>      LOG.debug(""<<<< {}"", entry);"	<line2>	"LOG.info(""Waiting for feed to get the latest events"")"	"<line2> LOG.info(""Waiting for feed to get the latest events"")"
task5	<line6>      logger.warn(e.getMessage());	<line6>	"logger.error(""Exception: "", e)"	"<line6> logger.error(""Exception: "", e)"
task5	"<line12>                LOGGER.error(""**** Error!! Error running privileged action."", ex);"	<line12>	"log.error(""Exception in doAs"", ex)"	"<line12> log.error(""Exception in doAs"", ex)"
task5	"<line2>    logger.debug(""convertFromString: values={}, toClass={}"", values, toClass);"	<line3>	"log.warn(""The date value is null"")"	"<line3> log.warn(""The date value is null"")"
task5	"<line1>    logger.debug(""checkTokenGenerationRequest started..."");"	<line1>	"logger.debug(""checkTokenGenerationRequest started..."")"	"<line1> logger.debug(""checkTokenGenerationRequest started..."")"
task5	"<line15>      log.debug(""Expected error while shutting down Hibernate Search, caused by the deletion of an index"",e);"	<line15>	"logger.debug(""Expected error while shutting down Hibernate Search, caused by the addition of an index"",e)"	"<line15> logger.debug(""Expected error while shutting down Hibernate Search, caused by the addition of an index"",e)"
task5	"<line6>    logger.debug(String.format(""Created SR (mount point:%1$s)"", d.path));"	<line1>	"log.debug(""Create OCFS2 storage pool on host"")"	"<line1> log.debug(""Create OCFS2 storage pool on host"")"
task5	"<line6>      LOG.trace(""Added custom request header: {}: {}"", header.getValue(), header.getValue());"	<line6>	"LOG.debug(""Set request header "" + header.getKey() + "" to "" + header.getValue())"	"<line6> LOG.debug(""Set request header "" + header.getKey() + "" to "" + header.getValue())"
task5	"<line6>      log.info(""Starting JMS adaptor: ""+ adaptorID+ "" started on brokerURL=""+ brokerURL+ "", topic=""+ topic+ "", selector=""+ selector+ "", offset =""+ bytesReceived);"	<line2>	"log.debug(""Starting JMS Adaptor"")"	"<line2> log.debug(""Starting JMS Adaptor"")"
task5	"<line11>      logger.info(""The restart policy of JobManager pod will be overwritten to 'always' ""+ ""since it is controlled by the Kubernetes deployment."");"	<line11>	"LOG.info(""The restart policy of the pod is set to Never."")"	"<line11> LOG.info(""The restart policy of the pod is set to Never."")"
task5	<line18>    logger.info(actual.toJSONString());	<line18>	logger.info(actual.toJSONString())	<line18> logger.info(actual.toJSONString())
task5	<line8>      LOG.error(Freedomotic.getStackTraceInfo(e));	<line8>	"logger.error(""Error in modify command: "" + e.toString())"	"<line8> logger.error(""Error in modify command: "" + e.toString())"
task5	"<line1>    log.info(format(""Updating category %s to parent %s and name %s"", categoryUrl, parentUrl, name));"	<line1>	"logger.info(""Updating category "" + name + "" at "" + categoryUrl)"	"<line1> logger.info(""Updating category "" + name + "" at "" + categoryUrl)"
task5	"<line1>    logger.info(""Stopping thread {}..."", thread.getName());"	<line9>	"logger.error(""{} wait timeout, thread state: {}"", thread.getName(), thread.getState())"	"<line9> logger.error(""{} wait timeout, thread state: {}"", thread.getName(), thread.getState())"
task5	"<line13>        logger.trace(LogMarker.PERSIST_RECOVERY_VERBOSE, ""bad disk region id!"");"	<line13>	"logger.trace(LogMarker.PERSIST_RECOVERY_VERBOSE, ""bad disk region id!"")"	"<line13> logger.trace(LogMarker.PERSIST_RECOVERY_VERBOSE, ""bad disk region id!"")"
task5	"<line16>    LOGGER.debug(""Inserted FeatureOfInterest. Created id = {}."", generatedId);"	<line17>	"LOG.debug(""Generated ID for FeatureOfInterest: {}"", foi.getId())"	"<line17> LOG.debug(""Generated ID for FeatureOfInterest: {}"", foi.getId())"
task5	"<line2>    log.info(""Automatic with 250 with same prefix"");"	<line36>	"log.info(""Waiting on automatic split"")"	"<line36> log.info(""Waiting on automatic split"")"
task5	<line29>      LOGGER.debug(txt.toString());	<line29>	LOGGER.debug(txt.toString())	<line29> LOGGER.debug(txt.toString())
task5	"<line12>        log.error(""Error getting projects!"", e);"	<line12>	"log.error(""cannot get projects"", e)"	"<line12> log.error(""cannot get projects"", e)"
task5	"<line4>    SystemUtils.LOG.info(""aggregateTemporal "" + ctx.getIndex() + "" onmaxvar contribution="" + value);"	<line6>	"LOGGER.debug(""aggregateTemporal "" + ctx.getIndex())"	"<line6> LOGGER.debug(""aggregateTemporal "" + ctx.getIndex())"
task5	"<line2>    LOGGER.debug(""dequeueGetPQValuesResponse called with correlation uid {}"", correlationUid);"	<line2>	"LOGGER.debug(""dequeueGetPQValuesResponse called with correlation uid {}"", correlationUid)"	"<line2> LOGGER.debug(""dequeueGetPQValuesResponse called with correlation uid {}"", correlationUid)"
task5	"<line35>      logger.warn(""Could not perform search query"", e);"	<line35>	"logger.error(""Error while searching for events with series id {}"", seriesId, e)"	"<line35> logger.error(""Error while searching for events with series id {}"", seriesId, e)"
task5	"<line12>      LOGGER.info(""Generator discovery performed, found [{}]"", generatorMessages);"	<line12>	"LOGGER.info(""Enabled generators: {}"", generatorMessages)"	"<line12> LOGGER.info(""Enabled generators: {}"", generatorMessages)"
task5	"<line6>        log.warn(""got multiple titles for document "" + id + "", storing first title only"");"	<line6>	"log.warn(""Found more than one title element, using the first one: {}"", titleGroup)"	"<line6> log.warn(""Found more than one title element, using the first one: {}"", titleGroup)"
task5	"<line17>      LOGGER.error(""Unable to create SimpleFeatureType"", e);"	<line17>	"LOGGER.error(""Failed to create simple feature type"", e)"	"<line17> LOGGER.error(""Failed to create simple feature type"", e)"
task5	"<line25>      logger.warn(""Unable to get Processor of type {}; its default properties will be fingerprinted instead""+ "" of being ignored."",className);"	<line25>	"logger.warn(""Unable to find component for className: {}"", className)"	"<line25> logger.warn(""Unable to find component for className: {}"", className)"
task5	"<line8>    log.info(""{}"", parsed);"	<line6>	log.info(r.getEntity().toString())	<line6> log.info(r.getEntity().toString())
task5	"<line13>      this.logger.info(""Failed to initialize logging using {} or {}"", this.logConfig, defaultLogLocation, e);"	<line10>	"logger.info(""Using default logging configuration file: {}"", defaultLogLocation)"	"<line10> logger.info(""Using default logging configuration file: {}"", defaultLogLocation)"
task5	"<line19>        logger.error(""Unexpected lines reached while parsing health check response. Skipping line:- ""+ line);"	<line19>	"logger.debug(""Unable to parse line - "" + line)"	"<line19> logger.debug(""Unable to parse line - "" + line)"
task5	"<line1>    LOG.debug(""identifyDuplicateGroupNames"");"	<line4>	"LOG.debug(""Duplicate group name: {}"", group.getName())"	"<line4> LOG.debug(""Duplicate group name: {}"", group.getName())"
task5	"<line12>      this.logger.warn(""Failed to query patient documents with label [{}] and corresponding external ID [{}]:""+ "" {}"",label,id,ex.getMessage(),ex);"	<line12>	"this.logger.error(""Failed to query patients by label and eid: {}"", ex.getMessage(), ex)"	"<line12> this.logger.error(""Failed to query patients by label and eid: {}"", ex.getMessage(), ex)"
task5	"<line19>        LOG.warn(""Created subscription {} to topic {}.""+ "" Note this subscription WILL NOT be deleted when the pipeline terminates"",subscriptionPath,topic);"	<line19>	"LOG.info(""Created subscription {} to topic {} on project {}"",subscriptionPath,topicPath,projectPath)"	"<line19> LOG.info(""Created subscription {} to topic {} on project {}"",subscriptionPath,topicPath,projectPath)"
task5	"<line1>    logger.debug(""Starting connection monitor job for thing {} at IP {}"",thingID(),commandConnection.getIP());"	<line1>	"logger.debug(""Scheduling connection monitor job in {} seconds"",CONNECTION_MONITOR_START_DELAY)"	"<line1> logger.debug(""Scheduling connection monitor job in {} seconds"",CONNECTION_MONITOR_START_DELAY)"
task5	<line39>      logger.debug(sb.toString());	<line39>	logger.debug(sb.toString())	<line39> logger.debug(sb.toString())
task5	"<line5>        LOGGER.debug(""Restored universe: "" + Thread.currentThread());"	<line5>	"LOGGER.debug(""[{}] Unset universe {}"", this.getClass().getSimpleName(), universeList.getLast().getName())"	"<line5> LOGGER.debug(""[{}] Unset universe {}"", this.getClass().getSimpleName(), universeList.getLast().getName())"
task5	"<line22>        logger.warn(""Could not handle {} for {}"", device.getStatus(), device);"	<line22>	"logger.warn(""Could not handle {} for {}"", device.getStatus(), device.getName())"	"<line22> logger.warn(""Could not handle {} for {}"", device.getStatus(), device.getName())"
task5	"<line15>      LOG.warn(""Unexpected error when accessing file handle limit"", t);"	<line15>	"logger.warn(""Unable to determine the number of open file handles"", t)"	"<line15> logger.warn(""Unable to determine the number of open file handles"", t)"
task5	"<line7>      logger.debug(""Removed live pub channel from archived media package {}"", mp);"	<line9>	"logger.error(""Error while retracting live event {}, {}"", mp.getIdentifier(), e)"	"<line9> logger.error(""Error while retracting live event {}, {}"", mp.getIdentifier(), e)"
task5	"<line14>        LOGGER.warn(""Spatial filtering for lat/lon is not yet implemented!"");"	<line14>	"LOGGER.info(""Spatial Filtering Profile criteria could not be applied as the dataset does not support""+ "" spatial filtering!"")"	"<line14> LOGGER.info(""Spatial Filtering Profile criteria could not be applied as the dataset does not support""+ "" spatial filtering!"")"
task5	"<line3>    LOG.trace(""NM: Container started: "" + containerId);"	<line3>	"log.debug(""Container started: id="" + containerId)"	"<line3> log.debug(""Container started: id="" + containerId)"
task5	"<line2>    LOG.info(""Adding command {}"", command);"	<line2>	"logger.debug(""execute: {}"", command)"	"<line2> logger.debug(""execute: {}"", command)"
task5	"<line8>      log.error(""Failed to prepare JSON from ImportPersonConfig: '{}'"",oxTrustImportPersonConfiguration,ex);"	<line8>	"log.error(""Failed to prepare JSON from ImportPersonConfig: '{}'"", oxTrustImportPersonConfiguration, ex)"	"<line8> log.error(""Failed to prepare JSON from ImportPersonConfig: '{}'"", oxTrustImportPersonConfiguration, ex)"
task5	"<line1>    logger.debug(""Stopping Call Monitor thread..."");"	<line3>	"logger.debug(""Interrupting monitor thread "" + thread.getId())"	"<line3> logger.debug(""Interrupting monitor thread "" + thread.getId())"
task5	"<line5>        LOGGER.debug(""Waiting for flushing primary index {} to complete..."", selectedIndex);"	<line5>	"LOGGER.debug(""Selected index {} for flushing"", selectedIndex.getIndexId())"	"<line5> LOGGER.debug(""Selected index {} for flushing"", selectedIndex.getIndexId())"
task5	"<line11>    logger.debug(""Device notification query requested for device {}"", deviceId);"	<line11>	"logger.debug(""Device notification query requested for device {}"", deviceId)"	"<line11> logger.debug(""Device notification query requested for device {}"", deviceId)"
task5	"<line8>      LOG.info(null, ""Hooked into "" + plugins + ""!"");"	<line8>	"LOGGER.info(""Plugins hooked into debug console: "" + plugins)"	"<line8> LOGGER.info(""Plugins hooked into debug console: "" + plugins)"
task5	"<line1>    log.debug(""passivate connection: {}"", connection);"	<line1>	"log.debug(""passivate connection: {}"", connection)"	"<line1> log.debug(""passivate connection: {}"", connection)"
task5	"<line5>      LOG.warn(""Admin Dist request body was null"");"	<line5>	"logger.info(""Cannot check policy without distribution body."")"	"<line5> logger.info(""Cannot check policy without distribution body."")"
task5	"<line4>    LOG.info(""Created queue named: "" + name);"	<line4>	"LOG.info(""created temporary queue: {}"", name)"	"<line4> LOG.info(""created temporary queue: {}"", name)"
task5	"<line8>      logger.error(""Error unmarshalling activity stream info config. xml: {}"", xml, t);"	<line8>	"logger.error(""Error unmarshalling activity stream info config"", t)"	"<line8> logger.error(""Error unmarshalling activity stream info config"", t)"
task5	"<line9>        LOGGER.info(""Connection released"");"	<line2>	"LOG.debug(""Release connection to MarkLogic Database"")"	"<line2> LOG.debug(""Release connection to MarkLogic Database"")"
task5	"<line5>      LOG.error(""Message queue overflow, dropping message: "" + e.getMessage());"	<line5>	"LOGGER.error(""Message queue overflow, dropping message"")"	"<line5> LOGGER.error(""Message queue overflow, dropping message"")"
task5	"<line1>    LOG.error(""Unable to execute query : "" + exception.toString());"	<line1>	"LOG.error(""Unable to execute query : "" + exception.toString())"	"<line1> LOG.error(""Unable to execute query : "" + exception.toString())"
task5	"<line18>    LOG.info(""Create a new firehose for [%d] objects"", objects.size());"	<line7>	"log.info(""Connecting to file[%s]"", file)"	"<line7> log.info(""Connecting to file[%s]"", file)"
task5	"<line16>    LOGGER.info(""inside4 AddBusinessObjectDataStorageFiles"");"	<line16>	"LOGGER.debug(""Calling businessObjectDataStorageFilesCreateRequest"")"	"<line16> LOGGER.debug(""Calling businessObjectDataStorageFilesCreateRequest"")"
task5	"<line2>    LOGGER.debug(""Invalidate cache."");"	<line2>	"log.debug(""Clearing ACL class cache"")"	"<line2> log.debug(""Clearing ACL class cache"")"
task5	"<line33>          LOG.debug(""replaceBookie for bookie: {} in ensemble: {} ""+ ""is not adhering to placement policy and chose {}"",oldBookie,ensemble,newBookie);"	<line33>	"LOG.debug(""Ensemble {} does not adhere to placement policy {} with exclusion of bookies {}."",ensemble,bkc.getPlacementPolicy(),bookiesToExclude)"	"<line33> LOG.debug(""Ensemble {} does not adhere to placement policy {} with exclusion of bookies {}."",ensemble,bkc.getPlacementPolicy(),bookiesToExclude)"
task5	"<line4>        logger.info(""Missing test input file. mvn test -DcreateInputTestFiles=true ""+ ""or temporarilly: System.setProperty(\""createInputTestFiles\"", \""true\"");"");"	<line4>	"log.info(""Input file not found: {}"", inputFile)"	"<line4> log.info(""Input file not found: {}"", inputFile)"
task5	"<line12>              logger.warn(""No property widget for 'num tokens' found!"");"	<line16>	"logger.info(""Setting the default number of tokens to 2 because the token target is set to rows."")"	"<line16> logger.info(""Setting the default number of tokens to 2 because the token target is set to rows."")"
task5	"<line28>          LOG.error(""Error running system job"", e);"	<line28>	"LOG.error(""Failed to start cleanup job for index set <{}>"", id, e)"	"<line28> LOG.error(""Failed to start cleanup job for index set <{}>"", id, e)"
task5	"<line18>    logger.info(msg + "", "" + count + "" rows, "" + speed(t) + ""K row/sec"");"	<line18>	"logger.info(msg + "", "" + count + "" records, "" + speed(t) + ""K rec/sec"")"	"<line18> logger.info(msg + "", "" + count + "" records, "" + speed(t) + ""K rec/sec"")"
task5	"<line10>      LOG.warn(""Trying to scrape prometheus, while it is disabled, set""+ "" \""secor.monitoring.metrics.collector.micrometer.prometheus.enabled\"" to""+ "" \""true\"""");"	<line2>	"LOG.debug(""Handle scrape request: {}"", exchange.getRequestUrl())"	"<line2> LOG.debug(""Handle scrape request: {}"", exchange.getRequestUrl())"
task5	"<line6>    Freedomotic.logger.info(""Scene: "" + group.address + "" was renamed to "" + group.name);"	<line1>	"Freedomotic.logger.info(""Group renamed: "" + group.address)"	"<line1> Freedomotic.logger.info(""Group renamed: "" + group.address)"
task5	"<line4>    LOGGER.debug(""Got request on /experimentoverview(experimentType={}, matching={}"",experimentType,matchingString);"	<line4>	"logger.info(""Loading latest results for experiments of type "" + experimentType)"	"<line4> logger.info(""Loading latest results for experiments of type "" + experimentType)"
task5	<line11>      logger.warn(ex.getMessage());	<line11>	"logger.error(""Failed to remove iscsi target: "" + ex.getMessage())"	"<line11> logger.error(""Failed to remove iscsi target: "" + ex.getMessage())"
task5	<line24>      log.error(systemException, systemException);	<line24>	log.error(systemException, systemException)	<line24> log.error(systemException, systemException)
task5	"<line4>      log.debug(String.format(""Calculate checksum with header %s"", header));"	<line4>	"log.debug(String.format(""Compute checksum for file %s with offset %d"", cryptomator.getFileName(), offset))"	"<line4> log.debug(String.format(""Compute checksum for file %s with offset %d"", cryptomator.getFileName(), offset))"
task5	"<line3>      logger.info(""Not starting the API..."");"	<line14>	"LOG.info(""Starting API server"")"	"<line14> LOG.info(""Starting API server"")"
task5	"<line9>      log.debug(""expected exception: "" + e.getMessage());"	<line9>	"logger.debug(""Expected exception: "" + e)"	"<line9> logger.debug(""Expected exception: "" + e)"
task5	<line5>        log.debug(sqlException, sqlException);	<line5>	log.debug(sqlException, sqlException)	<line5> log.debug(sqlException, sqlException)
task5	"<line8>      log.info(""Rollover segment [""+ idx+ "" to ""+ res.getSegmentId()+ ""], recordType=""+ (rec == null ? null : rec.type()));"	<line8>	"log.info(""Closed write handle [idx="" + idx + "", res="" + res + ']')"	"<line8> log.info(""Closed write handle [idx="" + idx + "", res="" + res + ']')"
task5	"<line3>    LOG.info(""Test Dir = {}"", schedulerStoreDir);"	<line2>	"LOG.info(""Setting up test"")"	"<line2> LOG.info(""Setting up test"")"
task5	"<line15>      logger.error(""Failed to start application"", e);"	<line15>	"LOG.error(""Exception in HelloWorld server"", e)"	"<line15> LOG.error(""Exception in HelloWorld server"", e)"
task5	"<line2>    LOGGER.debug(""Forgetting transaction branch {}"", xid);"	<line4>	"logger.debug(""forget: "" + xid + "" - context not found"")"	"<line4> logger.debug(""forget: "" + xid + "" - context not found"")"
task5	"<line2>    logger.info(""x"");"	<line2>	"log.info(""isReadOnly()"")"	"<line2> log.info(""isReadOnly()"")"
task5	"<line8>      this.logger.debug(""No registered environment, keep default Groovy setup"", e);"	<line8>	"this.logger.error(""Could not set groovy root directory"", e)"	"<line8> this.logger.error(""Could not set groovy root directory"", e)"
task5	"<line34>    logger.debug(""Fetched group by result from {} of [{}, {}]: {}"",source,curStartTime,curEndTime,results);"	<line24>	"logger.error(""Query {} interrupted"", this, e)"	"<line24> logger.error(""Query {} interrupted"", this, e)"
task5	<line4>      LOGGER.error(String.format(Messages.Log.ERROR_WHILE_GETTING_TEMPLATES_S, response.getErrorMessage()));	<line4>	"log.error(String.format(""Error when getting template pool for client %s"", client.getId()))"	"<line4> log.error(String.format(""Error when getting template pool for client %s"", client.getId()))"
task5	"<line2>    log.debug(""Reloading..."");"	<line2>	"log.debug(""Refreshing FHIR Module"")"	"<line2> log.debug(""Refreshing FHIR Module"")"
task5	"<line19>      LOG.error(""init schedule task failed !"");"	<line10>	"LOG.debug(""Start to deal batch operation."")"	"<line10> LOG.debug(""Start to deal batch operation."")"
task5	<line19>      log.error(systemException, systemException);	<line19>	log.error(systemException, systemException)	<line19> log.error(systemException, systemException)
task5	<line9>      log.error(e.getMessage());	<line9>	log.error(e.getMessage())	<line9> log.error(e.getMessage())
task5	"<line15>          logger.warn(""Failed to close a socket."", t);"	<line15>	"LOG.debug(""Could not connect to {} - binding to local port {} first"",remoteAddress,localAddress,t)"	"<line15> LOG.debug(""Could not connect to {} - binding to local port {} first"",remoteAddress,localAddress,t)"
task5	<line19>        log.debug(exception, exception);	<line19>	log.debug(exception, exception)	<line19> log.debug(exception, exception)
task5	<line6>        log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line6>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line6> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line10>      logger.info(""VSM could not be deleted"");"	<line7>	"logger.info(""DeleteCiscoNexusVSMCmd: Deleting VSM"")"	"<line7> logger.info(""DeleteCiscoNexusVSMCmd: Deleting VSM"")"
task5	"<line14>      logger.warn("""", ex);"	<line14>	"logger.error(""Error"", ex)"	"<line14> logger.error(""Error"", ex)"
task5	"<line35>              LOGGER.debug(""Invalidating flow from caches named {}"", notification.getResourceIdentifier());"	<line2>	"LOGGER.info(""Initialising the Policy Manager Service"")"	"<line2> LOGGER.info(""Initialising the Policy Manager Service"")"
task5	"<line8>      logger.warn(""Cannot set internet address"", e);"	<line8>	"logger.error(""Could not create email address for user {}"", udr, e)"	"<line8> logger.error(""Could not create email address for user {}"", udr, e)"
task5	"<line6>      LOG.error(""sync db to tasks error"", e);"	<line6>	"LOG.error(""Failed to create tasks for data sources on DB load."", e)"	"<line6> LOG.error(""Failed to create tasks for data sources on DB load."", e)"
task5	"<line17>      LOG.error(""Failed to convert the Ipv6 subnetmask from integer to mask value "", e);"	<line17>	"LOG.debug(""Failed to parse IPv6 address mask"", e)"	"<line17> LOG.debug(""Failed to parse IPv6 address mask"", e)"
task5	"<line2>    logger.error(""Error occurred during Application Key Mappings discovery"", throwable);"	<line2>	"logger.error(""Error occurred during Application Key Mapping discovery"", throwable)"	"<line2> logger.error(""Error occurred during Application Key Mapping discovery"", throwable)"
task5	"<line22>      logger.error(""error updating user stats to cloud_usage db"", ex);"	<line22>	"logger.warn(""Exception: "", ex)"	"<line22> logger.warn(""Exception: "", ex)"
task5	"<line5>    logger.debug(""ajaxChangeDiagnosis"");"	<line5>	"logger.debug(""issueList_ajax - change diagnosis - index: "" + strIndex)"	"<line5> logger.debug(""issueList_ajax - change diagnosis - index: "" + strIndex)"
task5	"<line10>          log.error(""Unrecognized state for table with tableId={}: {}"", tableId, sState);"	<line10>	"log.warn(""Unknown table state {} from cache"", sState)"	"<line10> log.warn(""Unknown table state {} from cache"", sState)"
task5	"<line1>    logger.debug(""JDBC::createNewEntryInItemsTable"");"	<line1>	"logger.debug(""createNewEntryInItemsTable"")"	"<line1> logger.debug(""createNewEntryInItemsTable"")"
task5	"<line7>      LOGGER.warn(String.format(Locale.ROOT, ""Could not delete %s."", file));"	<line7>	"LOG.warn(""Could not delete "" + file.getAbsolutePath())"	"<line7> LOG.warn(""Could not delete "" + file.getAbsolutePath())"
task5	"<line19>      log.debug(StringBundler.concat(""Adding interest terms \"""",StringUtil.merge(interestTerms),""\"" to asset query for user ID "",userId));"	<line19>	"log.debug(""interestTerms "" + StringUtil.merge(interestTerms))"	"<line19> log.debug(""interestTerms "" + StringUtil.merge(interestTerms))"
task5	"<line5>      LOG.debug(""query = {} {}."", query, folderId);"	<line5>	"logger.debug(""Setting pageToken to {}"", request.getPageToken())"	"<line5> logger.debug(""Setting pageToken to {}"", request.getPageToken())"
task5	"<line8>        log.error(""error executing shutdown hook"", e);"	<line8>	"log.error(""An error occurred while running a shutdown hook."", e)"	"<line8> log.error(""An error occurred while running a shutdown hook."", e)"
task5	"<line6>      log.trace(""#{} {} <- {}"", impl.uniqueId(), key, prev + delta);"	<line6>	"log.trace(""#{} addToInt {} {}"", impl.uniqueId(), key, delta)"	"<line6> log.trace(""#{} addToInt {} {}"", impl.uniqueId(), key, delta)"
task5	"<line17>            LOGGER.info(""Received a SOAP fault on setSchedule"");"	<line6>	"LOGGER.info(""Querying setSchedule response"")"	"<line6> LOGGER.info(""Querying setSchedule response"")"
task5	"<line6>      log.error(""Unable to check is back order allowed"", portalException);"	<line6>	"log.error(""Unable to check back order allowed for commerce product instance "" + cpInstance.getCommerceProductId(),portalException)"	"<line6> log.error(""Unable to check back order allowed for commerce product instance "" + cpInstance.getCommerceProductId(),portalException)"
task5	"<line2>      log.debug(""Raising WakeupException in response to user wakeup"");"	<line2>	"log.info(""Triggering wakeup"")"	"<line2> log.info(""Triggering wakeup"")"
task5	"<line6>      log.error(""failed to redirect request to {}"", redirectTo, e);"	<line6>	"log.error(""Failed to redirect to login page"", e)"	"<line6> log.error(""Failed to redirect to login page"", e)"
task5	"<line6>      log.error(""Problem retrieving all the Vendor names"", e);"	<line6>	"log.error(""Problem fetching vendor list from backend"", e)"	"<line6> log.error(""Problem fetching vendor list from backend"", e)"
task5	"<line2>    LOG.info(""Slot with allocationId {} already exist, with resource profile {}, job id {} and index {}.""+ "" The required index is {}."",taskSlot.getAllocationId(),taskSlot.getResourceProfile(),taskSlot.getJobId(),taskSlot.getIndex(),index);"	<line2>	"LOG.debug(""Check for duplicated slot. taskSlot: {}, jobId: {}, resourceProfile: {}, index: {}"",taskSlot.getIndex(),jobId,resourceProfile,index)"	"<line2> LOG.debug(""Check for duplicated slot. taskSlot: {}, jobId: {}, resourceProfile: {}, index: {}"",taskSlot.getIndex(),jobId,resourceProfile,index)"
task5	"<line3>        logger.debug(""Request matched by universal pattern '/**'"");"	<line3>	"logger.debug(""match all url: "" + url.getPath())"	"<line3> logger.debug(""match all url: "" + url.getPath())"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line19>      log.warn(""Got an invalid SAML Single Logout response (XML is broken)"", e);"	<line22>	"log.debug(""Async Logout response was canceled"", e)"	"<line22> log.debug(""Async Logout response was canceled"", e)"
task5	"<line8>      logger.error(""Error loading groups"", t);"	<line8>	"logger.error(""Error loading groups"", t)"	"<line8> logger.error(""Error loading groups"", t)"
task5	"<line2>    logger.debug(""getInterDirectPingMeasurementFromQoSMonitor started..."");"	<line2>	"logger.debug(""getInterDirectPingMeasurementFromQoSMonitor started ..."")"	"<line2> logger.debug(""getInterDirectPingMeasurementFromQoSMonitor started ..."")"
task5	"<line13>      LOGGER.warn(""Found plugin {} for executable plugin type {} that is not itself executable."",uncastResult.getId(),uncastResult.getPluginType());"	<line18>	"LOGGER.debug(""Result is not valid data: {}"", castResult)"	"<line18> LOGGER.debug(""Result is not valid data: {}"", castResult)"
task5	"<line3>    LOG.info(""Bean: Other -> XOrder"");"	<line2>	"LOG.info(""Bean: XOrder -> Other"")"	"<line2> LOG.info(""Bean: XOrder -> Other"")"
task5	"<line2>    logger.debug(""About to send POST request to '{}' with payload '{}'"", uri, body);"	<line2>	"logger.debug(""About to make backward compatible HTTP POST request to '{}' with payload '{}'"",uri,body)"	"<line2> logger.debug(""About to make backward compatible HTTP POST request to '{}' with payload '{}'"",uri,body)"
task5	"<line6>      log.error(""pin definition null"");"	<line8>	"log.info(""pin.isAnalog() {}"", pin.isAnalog())"	"<line8> log.info(""pin.isAnalog() {}"", pin.isAnalog())"
task5	"<line3>    logger.debug(""Handling: "" + message);"	<line3>	"logger.info(""Processing request: "" + message)"	"<line3> logger.info(""Processing request: "" + message)"
task5	<line6>      logger.error(e.getMessage(), e);	<line6>	"logger.error(""Failed: testCalculator"", e)"	"<line6> logger.error(""Failed: testCalculator"", e)"
task5	"<line24>          logger.debug(String.format(""file MD5 changed, src[%s, md5:%s] dest[%s, md5, %s]"",sourceFilePath, srcMd5, destFilePath, destMd5));"	<line24>	"logger.info(""The md5sum of file {} is not the same as the md5sum of file {}"",sourceFilePath,destFilePath)"	"<line24> logger.info(""The md5sum of file {} is not the same as the md5sum of file {}"",sourceFilePath,destFilePath)"
task5	"<line5>    LOGGER.debug(""check exist accessContract={}"", accessContractDto);"	<line5>	"LOGGER.debug(""check exist security profile={}"", accessContractDto)"	"<line5> LOGGER.debug(""check exist security profile={}"", accessContractDto)"
task5	<line12>      log.error(e.getMessage());	<line12>	"LOG.error(""Failed to retrieve logs of container "" + containerId, e)"	"<line12> LOG.error(""Failed to retrieve logs of container "" + containerId, e)"
task5	<line3>    logger.trace(marker, msg);	<line3>	logger.trace(marker, msg)	<line3> logger.trace(marker, msg)
task5	"<line6>      LOGGER.error(""Failed to create "" + Conf.class.getPackage().getName() + "" for "" + loaderClass.getName(),e);"	<line3>	"log.debug(""Using loader class: "" + loaderClass.getName())"	"<line3> log.debug(""Using loader class: "" + loaderClass.getName())"
task5	"<line11>      LOGGER.debug(""ExperimentRun parentId updated successfully"");"	<line12>	"LOGGER.error(""Failed to set parent experiment run id of ExperimentRun {}"", experimentRunId, ex)"	"<line12> LOGGER.error(""Failed to set parent experiment run id of ExperimentRun {}"", experimentRunId, ex)"
task5	"<line1>    logger.info(""Checking the "" + this.action + "" request"");"	<line1>	"logger.info(""Verifying the request content for action: "" + this.action)"	"<line1> logger.info(""Verifying the request content for action: "" + this.action)"
task5	<line11>          log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line11>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line11> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line8>      LOG.error(""Error while serializing object for dnd"", e);"	<line8>	"log.error(""write error"", e)"	"<line8> log.error(""write error"", e)"
task5	<line27>      log.error(systemException, systemException);	<line27>	log.error(systemException, systemException)	<line27> log.error(systemException, systemException)
task5	"<line2>    log.debug(""Recovering upload, object-id: {}"", objectId);"	<line13>	"LOGGER.debug(""Error while checking upload data recoverability for object-id {}. Error: {}"",objectId,e.getMessage())"	"<line13> LOGGER.debug(""Error while checking upload data recoverability for object-id {}. Error: {}"",objectId,e.getMessage())"
task5	"<line29>              logger.error(""Failed to parse PgArray: "" + pgArray, e);"	<line29>	"LOGGER.error(""Cannot convert to a Java array"", column)"	"<line29> LOGGER.error(""Cannot convert to a Java array"", column)"
task5	"<line2>      LOG.debug(""Stopping tracking of resources for job {}."", jobId);"	<line2>	"log.debug(""Removing job scoped resource tracker for job {} because it is empty"", jobId)"	"<line2> log.debug(""Removing job scoped resource tracker for job {} because it is empty"", jobId)"
task5	"<line13>      LOG.warn(""output directory "" + convertedModelDir + "" already exists"");"	<line33>	"LOG.info(""Model converted to row-oriented format at "" + convertedModelPath)"	"<line33> LOG.info(""Model converted to row-oriented format at "" + convertedModelPath)"
task5	"<line3>      LOGGER.debug(""Schedule execute solution change with previous chBestSolution: {}"", chBestSolution);"	<line10>	"LOGGER.debug(""Scheduling solution change to be executed in {} ms."", delay)"	"<line10> LOGGER.debug(""Scheduling solution change to be executed in {} ms."", delay)"
task5	"<line3>      log.debug(""Shutting down scheduler thread pool"");"	<line3>	"log.debug(""Stopping scheduler"")"	"<line3> log.debug(""Stopping scheduler"")"
task5	"<line6>      LOG.debug(String.format(""acquire permits: %s, maxPremits: %s"", numOps, maxPermits));"	<line7>	"log.error(""Unable to acquire permits"", e)"	"<line7> log.error(""Unable to acquire permits"", e)"
task5	"<line7>    logger.info(""guestId=""+ updateInfo.getGuestId()+ "" connector=fitbit action=loadWeightDataForOneDay json=""+ json);"	<line2>	"logger.debug(""loading weight data for "" + formattedDate)"	"<line2> logger.debug(""loading weight data for "" + formattedDate)"
task5	<line16>      LOGGER.error(Constants.ERROR_UNIQUEHOST, e);	<line16>	"logger.error(""error in getUniqueApp"", e)"	"<line16> logger.error(""error in getUniqueApp"", e)"
task5	"<line18>      LOGGER.warn(""The variable '{}' appears more than once: {}."",duplicatedVariableId,duplicatedVariables);"	<line18>	"logger.info(""Duplicated variables: "" + duplicatedVariableId)"	"<line18> logger.info(""Duplicated variables: "" + duplicatedVariableId)"
task5	<line13>        log.debug(principalException, principalException);	<line13>	log.debug(principalException, principalException)	<line13> log.debug(principalException, principalException)
task5	"<line2>    log.debug(""Building Process for command: {}"", () -> String.join("" "", processBuilder.command()));"	<line5>	"log.debug(""Created process builder: {}"", processBuilder)"	"<line5> log.debug(""Created process builder: {}"", processBuilder)"
task5	<line14>      log.error(systemException, systemException);	<line14>	log.error(systemException, systemException)	<line14> log.error(systemException, systemException)
task5	"<line14>            LOGGER.warn(""Fixed MD5 of {} to {}"", path, md5);"	<line6>	"LOGGER.info(""Calculating md5sum for {}"", path)"	"<line6> LOGGER.info(""Calculating md5sum for {}"", path)"
task5	"<line28>    log.info(String.format(""Produced %s recommendations for MetroPoint placement."",rpProtectionRecommendaton.getResourceCount()));"	<line28>	"log.info(""created RP protection recommendation for MetroPoint"")"	"<line28> log.info(""created RP protection recommendation for MetroPoint"")"
task5	"<line3>      logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Writing File {}"", file);"	<line3>	"logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Writing file {}"", file)"	"<line3> logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Writing file {}"", file)"
task5	<line8>      log.warn(e.getMessage(), e);	<line8>	"log.warn(""Failed to release state for peid: {}"", peid, e)"	"<line8> log.warn(""Failed to release state for peid: {}"", peid, e)"
task5	"<line5>      Log.debug(""blocking TM request until outstanding request returns"");"	<line5>	"log.info(""Only one TM request at a time is allowed. The request {} will be submitted after the previous""+ "" request {}"",action,lastRequest)"	"<line5> log.info(""Only one TM request at a time is allowed. The request {} will be submitted after the previous""+ "" request {}"",action,lastRequest)"
task5	"<line3>    logger.debug(""Spotify auth callback servlet received GET request {}."", req.getRequestURI());"	<line3>	"logger.info(""Received do GET request."")"	"<line3> logger.info(""Received do GET request."")"
task5	"<line7>            log.error(t, ""Unexpected exception while cleaning up expired transactions"");"	<line7>	"log.error(""Unable to clean up expired transactions"", t)"	"<line7> log.error(""Unable to clean up expired transactions"", t)"
task5	"<line2>      log.debug(""A new run info set "" + runInfo);"	<line2>	"log.debug(""Setting run info to: "" + runInfo)"	"<line2> log.debug(""Setting run info to: "" + runInfo)"
task5	"<line39>        LOG.debug(""compiling stylesheet {}"", stylesheet);"	<line13>	"LOG.debug(""stylesheet is not a valid URI: {}"", stylesheet, e)"	"<line13> LOG.debug(""stylesheet is not a valid URI: {}"", stylesheet, e)"
task5	"<line4>      LOGGER.debug(""MANAGER["" + name + ""] SESSION["" + branchSession + ""] "" + LogOperation.BRANCH_REMOVE);"	<line4>	"LOGGER.debug(""removeBranchSession, globalSessionId={}, branchSession={}"", globalSession.getId(), branchSession)"	"<line4> LOGGER.debug(""removeBranchSession, globalSessionId={}, branchSession={}"", globalSession.getId(), branchSession)"
task5	"<line17>    LOGGER.info(""WFS filter GetFeature response:\n"" + prettyString(doc));"	<line17>	LOGGER.info(prettyString(doc))	<line17> LOGGER.info(prettyString(doc))
task5	"<line1>    log.debug("""");"	<line1>	"log.debug("""")"	"<line1> log.debug("""")"
task5	"<line16>    log.info(""finished processing for id "" + documentId + "" in "" + (processingTime / 1000) + "" secs"");"	<line3>	"log.info(""Processing time threshold exceeded for document {} ({} ms)"", documentId, processingTime)"	"<line3> log.info(""Processing time threshold exceeded for document {} ({} ms)"", documentId, processingTime)"
task5	"<line6>      log.warn(""Rollback failed"", e);"	<line6>	"LOG.warn(""rollback error:"", e)"	"<line6> LOG.warn(""rollback error:"", e)"
task5	<line25>      log.error(systemException, systemException);	<line25>	log.error(systemException, systemException)	<line25> log.error(systemException, systemException)
task5	"<line7>      LOG.error(""Missing input parameters"");"	<line7>	"LOG.warn(""No AAM document was found in the request!"")"	"<line7> LOG.warn(""No AAM document was found in the request!"")"
task5	"<line2>      log.warn(""Temporal column type of table ID %s set incorrectly to %s"", tableId, type);"	<line2>	"log.warn(""Column of type {} is not a valid temporal column for table {}."", type, tableId)"	"<line2> log.warn(""Column of type {} is not a valid temporal column for table {}."", type, tableId)"
task5	"<line1>    log.debug(""findAllTemplates()"");"	<line1>	"log.debug(""findAllTemplates()"")"	"<line1> log.debug(""findAllTemplates()"")"
task5	"<line13>      logger.error(""Failed to fetch container ids "", e);"	<line13>	"logger.error(""Failed to fetch case definitions for config: "" + configCode, e)"	"<line13> logger.error(""Failed to fetch case definitions for config: "" + configCode, e)"
task5	"<line6>    LOG.info(""start: scheduler started"");"	<line2>	"log.debug(""Starting the fiber"")"	"<line2> log.debug(""Starting the fiber"")"
task5	"<line2>    LOGGER.debug(() -> ""using prefetched list: "" + list);"	<line2>	"LOGGER.debug(""Building category from prefetched list. Returning ID: {}"", returnID)"	"<line2> LOGGER.debug(""Building category from prefetched list. Returning ID: {}"", returnID)"
task5	"<line7>    log.debug(""User "" + personDao.getLoggedPerson().getEmail() + "" retrieved list of people."");"	<line5>	"log.debug(""Adding "" + person + "" to list of people."")"	"<line5> log.debug(""Adding "" + person + "" to list of people."")"
task5	"<line5>      LOG.debug(""{}: Creating read view for subpartition {} of partition {}."",parent.getOwningTaskName(),getSubPartitionIndex(),parent.getPartitionId());"	<line4>	"LOG.debug(""Creating read view on {}"", this)"	"<line4> LOG.debug(""Creating read view on {}"", this)"
task5	"<line21>          logger.warn(""Accessing MemoryPool '{}' threw an Internal Error: {}"",mp.getName(),ie.getMessage());"	<line18>	"logger.warn(""Cannot get usage statistics of memory pool "" + mp, ie)"	"<line18> logger.warn(""Cannot get usage statistics of memory pool "" + mp, ie)"
task5	"<line8>        logger.info(""Event index does not support denial via ACL, ignoring {}"", entry);"	<line8>	"logger.warn(""Denying "" + entry.getRole() + "" the "" + entry.getAction() + "" permission."")"	"<line8> logger.warn(""Denying "" + entry.getRole() + "" the "" + entry.getAction() + "" permission."")"
task5	"<line9>        log.error(e, ""Task failed"");"	<line9>	"log.error(""executeOrMerge"", e)"	"<line9> log.error(""executeOrMerge"", e)"
task5	<line10>      logger.error(e.getLocalizedMessage(), e);	<line10>	logger.error(e)	<line10> logger.error(e)
task5	<line28>      log.error(systemException, systemException);	<line28>	log.error(systemException, systemException)	<line28> log.error(systemException, systemException)
task5	"<line2>    LOGGER.debug(""SerializedPublicKexLength: "" + msg.getPublicKeyLength().getValue());"	<line2>	"LOGGER.debug(""SerializedPublicKeyLength: "" + msg.getPublicKeyLength().getValue())"	"<line2> LOGGER.debug(""SerializedPublicKeyLength: "" + msg.getPublicKeyLength().getValue())"
task5	"<line7>    logger.debug("">> canceling service for guest(%s) billingItem(%s)"", id, guest.getBillingItemId());"	<line7>	"logger.info(""canceling service for guest(%s)"", id)"	"<line7> logger.info(""canceling service for guest(%s)"", id)"
task5	<line2>    logger.debug(msg, thrown);	<line2>	logger.debug(msg, thrown)	<line2> logger.debug(msg, thrown)
task5	"<line10>      log.trace(""Append record id = "" + id + "" recordType = "" + recordType);"	<line10>	"log.trace(""AppendAddEvent "" + id)"	"<line10> log.trace(""AppendAddEvent "" + id)"
task5	"<line3>    logger.warn(""component=metadata action=setTimeZone message=attempt to set timezone"");"	<line3>	"logger.warn(""Setting the timezone for a guest is not supported yet"")"	"<line3> logger.warn(""Setting the timezone for a guest is not supported yet"")"
task5	"<line40>    logger.info(""listening on port: ""+ strPort+ "" for trace data ""+ ""(Jaeger Protobuf format over gRPC)"");"	<line32>	"logger.info(""listening on port: "" + strPort + "" for Jaeger gRPC trace collector"")"	"<line32> logger.info(""listening on port: "" + strPort + "" for Jaeger gRPC trace collector"")"
task5	"<line26>      logger.info(""detach disks from volume-wrapper VM "" + vmName);"	<line17>	"logger.info(""Cloning VM "" + vmTemplate.getName() + "" to create volume "" + volume.toString())"	"<line17> logger.info(""Cloning VM "" + vmTemplate.getName() + "" to create volume "" + volume.toString())"
task5	"<line2>    logger.debug(""Removing all metadata for item {}"", name);"	<line2>	"log.debug(""Removing item metadata for: {}"", name)"	"<line2> log.debug(""Removing item metadata for: {}"", name)"
task5	"<line5>      log.debug(""Access denied"", e);"	<line5>	"log.debug(""Access denied"", e)"	"<line5> log.debug(""Access denied"", e)"
task5	<line2>    LOGGER.info(TestcontainersConfiguration.getInstance().toString());	<line2>	LOGGER.info(TestcontainersConfiguration.getInstance().toString())	<line2> LOGGER.info(TestcontainersConfiguration.getInstance().toString())
task5	"<line8>      logger.debug(""Scanner (scan now) failed on server instance {} due to {}"",container.getUrl(),response.getMsg());"	<line8>	"LOGGER.error(""Scanner failed to start on server instance {} due to {}"",container.getUrl(),response.getMsg())"	"<line8> LOGGER.error(""Scanner failed to start on server instance {} due to {}"",container.getUrl(),response.getMsg())"
task5	"<line11>      logger.warn(""createHandler({}) failed: ThingHandler not found for {}."",thingTypeUID,thing.getLabel());"	<line11>	"logger.trace(""Unsupported ThingType: {}"", thingTypeUID.getAsString())"	"<line11> logger.trace(""Unsupported ThingType: {}"", thingTypeUID.getAsString())"
task5	<line55>      log.error(systemException, systemException);	<line55>	log.error(systemException, systemException)	<line55> log.error(systemException, systemException)
task5	"<line12>          logger.error(""Cannot open transport for client {}"", node, e);"	<line12>	"LOG.error(""push sync client to cache error"", e)"	"<line12> LOG.error(""push sync client to cache error"", e)"
task5	"<line5>    log.info(""Generating tests"");"	<line28>	"log.info(""RdfUnit tests written to "" + output)"	"<line28> log.info(""RdfUnit tests written to "" + output)"
task5	"<line2>      logger.warn(new IllegalThreadStateException(""connectionordered channel handler `queue size: ""+ connectionExecutor.getQueue().size()+ "" exceed the warning limit number :""+ queuewarninglimit));"	<line2>	"log.warn(""The connection pool queue length is ""+ connectionExecutor.getQueue().size()+ "" which is above the warning limit of ""+ queuewarninglimit)"	"<line2> log.warn(""The connection pool queue length is ""+ connectionExecutor.getQueue().size()+ "" which is above the warning limit of ""+ queuewarninglimit)"
task5	"<line5>      log.error(""Exception while executing runnable "" + task, t);"	<line5>	log.error(t.getMessage(), t)	<line5> log.error(t.getMessage(), t)
task5	"<line9>      LOG.warn(""Could not read attribute {}."", attributeName, e);"	<line9>	"log.warn(""Could not retrieve attribute "" + attributeName + "" from MBean "" + objectName, e)"	"<line9> log.warn(""Could not retrieve attribute "" + attributeName + "" from MBean "" + objectName, e)"
task5	"<line12>        log.warn(""Duplicate MassTruncate RestException type: "" + alias);"	<line12>	"log.warn(""Duplicate alias for class "" + requestType)"	"<line12> log.warn(""Duplicate alias for class "" + requestType)"
task5	"<line4>      log.info(""adding {}"", type.getSimpleName());"	<line1>	"LOGGER.info(""Loading default tests"")"	"<line1> LOGGER.info(""Loading default tests"")"
task5	<line5>      logger.error(e.getMessage(), e);	<line5>	"logger.error(""Error in obtaining the authorization cache instance..."", e)"	"<line5> logger.error(""Error in obtaining the authorization cache instance..."", e)"
task5	"<line2>    logger.debug(""WeMoMakerHandler disposed."");"	<line6>	"logger.debug(""Disposing the RadioThermostat handler."")"	"<line6> logger.debug(""Disposing the RadioThermostat handler."")"
task5	"<line5>      log.trace(""Failed to reply due to error"", e);"	<line5>	"log.error(""Error while responding to client"", e)"	"<line5> log.error(""Error while responding to client"", e)"
task5	"<line5>    log.trace(""Loaded settings from {}."", systemId);"	<line5>	"log.info(""Loaded settings for system {}"", systemId)"	"<line5> log.info(""Loaded settings for system {}"", systemId)"
task5	"<line17>      logger.warn(""Requested torrent hash was: {}"", announceRequest.getHexInfoHash());"	<line24>	"logger.warn(""Bad peer IP address. Request URI is {}, IP address is {}"", uri, announceRequest.getIp())"	"<line24> logger.warn(""Bad peer IP address. Request URI is {}, IP address is {}"", uri, announceRequest.getIp())"
task5	"<line4>      logger.error(""VM status updator is interrupted."");"	<line30>	"logger.info(""settings: "" + settings)"	"<line30> logger.info(""settings: "" + settings)"
task5	<line6>        LOG.debug(qname.toString());	<line9>	"LOG.debug(""Element names: {}"", names)"	"<line9> LOG.debug(""Element names: {}"", names)"
task5	"<line30>          log.error(""Unable to install "" + file, invocationTargetException);"	<line30>	log.error(invocationTargetException, invocationTargetException)	<line30> log.error(invocationTargetException, invocationTargetException)
task5	"<line5>    LOGGER.info(""Login statut: {} / user: {} - {} / surrogate: {} / IP: {} / errorMessage: {}"",errorMessage != null ? StatusCode.KO : StatusCode.OK,user.getIdentifier(),user.getEmail(),surrogateIdentifier,ip,errorMessage);"	<line5>	"logger.info(""Emulate login event for user {}, surrogateIdentifier {}, ip {} with errorMessage {}"",user.getUserId(),surrogateIdentifier,ip,errorMessage)"	"<line5> logger.info(""Emulate login event for user {}, surrogateIdentifier {}, ip {} with errorMessage {}"",user.getUserId(),surrogateIdentifier,ip,errorMessage)"
task5	"<line13>            log.error(""Could not find profile ""+ profileRef.getName()+ "" of user ""+ getAuthService().getUsername());"	<line13>	"LOG.warn(""ProfileRef '{}' does not match a profile in the profile map!"", profileRef.getName())"	"<line13> LOG.warn(""ProfileRef '{}' does not match a profile in the profile map!"", profileRef.getName())"
task5	<line19>      log.error(systemException, systemException);	<line19>	log.error(systemException, systemException)	<line19> log.error(systemException, systemException)
task5	"<line2>    log.debug(""Claz: "" + claz.getName() + "" method: "" + method, e);"	<line2>	"LOG.error(""methodException format not implemented"")"	"<line2> LOG.error(""methodException format not implemented"")"
task5	<line1>    LOG.warn(FIXED_REASON, what, reason);	<line1>	log.info(FIXED_REASON, what, reason)	<line1> log.info(FIXED_REASON, what, reason)
task5	"<line40>      LOGGER.info(""Starting CC in "" + ccRoot.getAbsolutePath());"	<line40>	"LOGGER.info(""Started ClusterController at "" + cc.getURI())"	"<line40> LOGGER.info(""Started ClusterController at "" + cc.getURI())"
task5	"<line6>        LOGGER.error(""handle global session failed: {}"", globalSession.getXid(), th);"	<line6>	"LOGGER.error(""forEach global session error, xid {}"", globalSession.getXid(), th)"	"<line6> LOGGER.error(""forEach global session error, xid {}"", globalSession.getXid(), th)"
task5	"<line10>    LOG.trace(""path for key: {} is: {}"", key, path);"	<line9>	"LOG.trace(""path for key:{} is:{}"", key, path)"	"<line9> LOG.trace(""path for key:{} is:{}"", key, path)"
task5	"<line3>    LOG.debug(""get repair_schedule called with: id = {}"", repairScheduleId);"	<line3>	"LOG.debug(""get repair schedule for customer {}"", repairScheduleId)"	"<line3> LOG.debug(""get repair schedule for customer {}"", repairScheduleId)"
task5	"<line15>    logger.warn(""Unknown airport code: "" + code);"	<line15>	"logger.info(""Could not find airport for code "" + code)"	"<line15> logger.info(""Could not find airport for code "" + code)"
task5	"<line4>      logger.error(""meet error when doing start checking"", e);"	<line4>	"logger.error(""IoTDB config check failed"", e)"	"<line4> logger.error(""IoTDB config check failed"", e)"
task5	"<line3>      log.info(""setting up..."");"	<line3>	"log.info(""setup()"")"	"<line3> log.info(""setup()"")"
task5	"<line5>    LOGGER.debug(""overlaps:\n{}"", output);"	<line5>	LOGGER.info(output)	<line5> LOGGER.info(output)
task5	"<line1>    LOG.debug(""TPnodeEquipments"");"	<line1>	"LOGGER.debug("""")"	"<line1> LOGGER.debug("""")"
task5	"<line3>      LOGGER.trace(""Completing ConfigObservable for termination."");"	<line2>	"log.debug(""onCompleted config observable"")"	"<line2> log.debug(""onCompleted config observable"")"
task5	<line9>      log.error(e.getMessage(), e);	<line9>	"LOG.error(""Cannot parse integer value {} for property {}"", strValue, property, e)"	"<line9> LOG.error(""Cannot parse integer value {} for property {}"", strValue, property, e)"
task5	"<line45>      log.error(""Could not read input stream from request"", e);"	<line2>	"LOG.debug(""Converting servlet request to container request"")"	"<line2> LOG.debug(""Converting servlet request to container request"")"
task5	"<line11>              log.warn(""Parent edge from child {} to parent {} does not have a branch uuid. Skipping""+ "" this edge."",vertex.getProperty(""uuid""),branchUuid);"	<line11>	"log.warn(""Found edge without branchUuid: {}"", edge)"	"<line11> log.warn(""Found edge without branchUuid: {}"", edge)"
task5	"<line4>      logger.warn(""exception occurred during releasing thrift client"", e);"	<line4>	"LOG.error(""Failed to release broken client to pool"", e)"	"<line4> LOG.error(""Failed to release broken client to pool"", e)"
task5	"<line8>      LOG.debug(""Identifier [{}] deleted. It took [{}]ms."",new Object[] {identifier, (System.currentTimeMillis() - start)});"	<line15>	"LOG.debug(""Took {} ms to delete object {} in bucket {}"",System.currentTimeMillis() - start,key,bucket)"	"<line15> LOG.debug(""Took {} ms to delete object {} in bucket {}"",System.currentTimeMillis() - start,key,bucket)"
task5	"<line4>    LOGGER.info(""AMQP.BasicProperties: {}"", properties);"	<line4>	"LOG.info(""Received message [{}]"", new String(body))"	"<line4> LOG.info(""Received message [{}]"", new String(body))"
task5	"<line4>      LOG.error(""Error while waiting for extractor job to be finished"", e);"	<line4>	"LOGGER.error(""Error waiting for future"", e)"	"<line4> LOGGER.error(""Error waiting for future"", e)"
task5	"<line2>    logger.info(""python task params {}"", taskExecutionContext.getTaskParams());"	<line2>	"log.info(""init python task"")"	"<line2> log.info(""init python task"")"
task5	"<line2>    log.info(""Starting mysql server. Docker image: {}"", properties.dockerImage);"	<line2>	"log.info(""Starting MySQL server. Docker image: {}"", properties.dockerImage)"	"<line2> log.info(""Starting MySQL server. Docker image: {}"", properties.dockerImage)"
task5	"<line5>      logger.debug(""Stopped polling: {}"", stopped);"	<line5>	"logger.debug(""Stop polling scheduler: {}"", stopped)"	"<line5> logger.debug(""Stop polling scheduler: {}"", stopped)"
task5	"<line3>      logger.debug(""Detect meters from #{} objects"", telegram.getCosemObjects().size());"	<line3>	"logger.debug(""[{}] Received DSMR telegram: {}"", dsmrBridgeHandler.getThing().getUID(), telegram)"	"<line3> logger.debug(""[{}] Received DSMR telegram: {}"", dsmrBridgeHandler.getThing().getUID(), telegram)"
task5	"<line12>      LOG.error(""Error while initializing CoordinateOperations"", e);"	<line12>	LOG.error(e)	<line12> LOG.error(e)
task5	"<line6>      LOG.warn(""Could not create a SASL client with valid Kerberos credential"");"	<line6>	"LOG.info(""testHBaseSaslRpcClientCreation with principal/localhost@DOMAIN.COM failed. ""+ ""This is expected, ignoring the exception."")"	"<line6> LOG.info(""testHBaseSaslRpcClientCreation with principal/localhost@DOMAIN.COM failed. ""+ ""This is expected, ignoring the exception."")"
task5	"<line4>      LOG.warn(""{} couldn't be stopped gracefully"", getClass().getSimpleName());"	<line4>	"log.error(""Failed to stop grizzly2 container"", ex)"	"<line4> log.error(""Failed to stop grizzly2 container"", ex)"
task5	<line10>          log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line10>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line10> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line3>    LOG.debug(""Found config value {} for key {} "" + ""from YAML configuration."", result, option);"	<line3>	"LOG.info(""Found config value {} for key {}"", result, option)"	"<line3> LOG.info(""Found config value {} for key {}"", result, option)"
task5	"<line3>          logger.warn(""Git error on branch notification"");"	<line3>	"logger.warn(""Generic git error notification with branch {}"", branch)"	"<line3> logger.warn(""Generic git error notification with branch {}"", branch)"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line8>                    logger.debug(""Characteristic {} from {} has been read - value {}"",characteristicUUID,address,HexUtils.bytesToHex(data));"	<line8>	"logger.debug(""readCharacteristic({}, {}) completed"", serviceUUID, characteristicUUID)"	"<line8> logger.debug(""readCharacteristic({}, {}) completed"", serviceUUID, characteristicUUID)"
task5	<line20>      log.error(exception, exception);	<line20>	log.error(exception, exception)	<line20> log.error(exception, exception)
task5	<line5>      LOG.error(e.getMessage(), e);	<line5>	"log.error(""Unable to clear expired discovery entries"", e)"	"<line5> log.error(""Unable to clear expired discovery entries"", e)"
task5	"<line3>    LOG.info(""Removing all values for table {}, keys = {}."", table, keysToRemove);"	<line4>	"log.info(""Removing key: {} from table: {}"", key, table)"	"<line4> log.info(""Removing key: {} from table: {}"", key, table)"
task5	"<line12>      LOGGER.error(""Cannot create lock on "" + lockF, e);"	<line9>	"log.warn(""Failed to lock file: "" + lockF, oe)"	"<line9> log.warn(""Failed to lock file: "" + lockF, oe)"
task5	"<line7>      logger.debug(""The buffer for AMQP Large Mesasge was probably not complete, so an exception eventually""+ "" would be expected"",expected);"	<line7>	"LOG.debug(""Expected exception while parsing large message"", expected)"	"<line7> LOG.debug(""Expected exception while parsing large message"", expected)"
task5	"<line4>      LOG.debug(""Failed to clone the AstElement. Returning same reference; the client may fail. {} - {}"",e.getClass().getName(),e);"	<line4>	"LOG.debug(""Copy of element not made, reference is preserved: {}"", e)"	"<line4> LOG.debug(""Copy of element not made, reference is preserved: {}"", e)"
task5	"<line29>        logger.error(""Error"", e);"	<line28>	"log.error(""Error in getWarnings for demo: "" + demo, e)"	"<line28> log.error(""Error in getWarnings for demo: "" + demo, e)"
task5	"<line7>      LOGGER.debug(""Unable to get connectionn string"", ex);"	<line7>	"LOGGER.error(""Error while getting connection string from configuration."", ex)"	"<line7> LOGGER.error(""Error while getting connection string from configuration."", ex)"
task5	"<line2>    LOGGER.debug(""CCSProtocollType: "" + msg.getCcsProtocolType().getValue());"	<line2>	"LOGGER.debug(""CcsProtocolType: "" + msg.getCcsProtocolType().getValue())"	"<line2> LOGGER.debug(""CcsProtocolType: "" + msg.getCcsProtocolType().getValue())"
task5	"<line13>      LOG.error(""error during delete document: {}"", e.getLocalizedMessage(), e);"	<line13>	"LOG.error(""error during delete document: {}"", e.getLocalizedMessage(), e)"	"<line13> LOG.error(""error during delete document: {}"", e.getLocalizedMessage(), e)"
task5	"<line7>    log.trace(""Scheduling proactive sas token renewal for device {} in {} milliseconds"",this.amqpsSessionHandler.getDeviceId(),sasTokenRenewalPeriod);"	<line7>	"log.debug(""Scheduling sas token renewal in {} milliseconds"", sasTokenRenewalPeriod)"	"<line7> log.debug(""Scheduling sas token renewal in {} milliseconds"", sasTokenRenewalPeriod)"
task5	"<line4>        LOGGER.error(""Host Name should not be null."");"	<line2>	"LOGGER.debug(""Creating new Couchbase Client."")"	"<line2> LOGGER.debug(""Creating new Couchbase Client."")"
task5	"<line3>    LOGGER.debug(""getting service for filter {} from tracker"", filter);"	<line2>	"LOGGER.debug(""retrieving service for filter {}"", filter)"	"<line2> LOGGER.debug(""retrieving service for filter {}"", filter)"
task5	"<line22>                  logger.trace(LogMarker.DLS_VERBOSE, ""getLockTokensForRecovery is skipping {}"", token);"	<line22>	"logger.trace(LogMarker.DLS_VERBOSE, ""Token {} ignoring for recovery"", token)"	"<line22> logger.trace(LogMarker.DLS_VERBOSE, ""Token {} ignoring for recovery"", token)"
task5	"<line4>    LOG.trace(""Adding parentProcedure {} to procedure {}"", parentProcedure, procedure);"	<line4>	"LOG.trace(""Adding parent procedure {} -> {}"", procedure, parentProcedure)"	"<line4> LOG.trace(""Adding parent procedure {} -> {}"", procedure, parentProcedure)"
task5	"<line7>      LOG.error(""Failed to process ValidationResult as JSON"", e);"	<line7>	"logger.error(""Failed to write validation result to http output"", e)"	"<line7> logger.error(""Failed to write validation result to http output"", e)"
task5	"<line5>    log.error(""BUG! %s for %s leaked with %s %s.  Cleaning up so server can continue to function."",getClass().getName(), taskId, leakedValues, counterName);"	<line5>	"logger.warn(""Removed {} leaked values"", leakedValues)"	"<line5> logger.warn(""Removed {} leaked values"", leakedValues)"
task5	"<line5>    logger.warn(""no extension found for class:"" + clazz.getName());"	<line5>	"LOG.warn(""Could not find service for {}"", clazz.getName())"	"<line5> LOG.warn(""Could not find service for {}"", clazz.getName())"
task5	"<line2>      LOG.debug(""Getting info for task(id={})"", taskAssignmentId);"	<line2>	"LOG.debug(""Getting info for task assignment(id={})"", taskAssignmentId)"	"<line2> LOG.debug(""Getting info for task assignment(id={})"", taskAssignmentId)"
task5	<line9>              LOGGER.error(msg, t);	<line9>	LOGGER.error(msg, t)	<line9> LOGGER.error(msg, t)
task5	"<line4>    LOGGER.debug(""Get {}"", id);"	<line4>	"LOGGER.debug(""Get customer {}"", id)"	"<line4> LOGGER.debug(""Get customer {}"", id)"
task5	"<line10>    logger.debug(""deleting {}"", target);"	<line10>	"logger.debug(""Deleting user {}"", target)"	"<line10> logger.debug(""Deleting user {}"", target)"
task5	"<line7>      LOGGER.warn(""You have provided additional parameters that are not necessary for the information""+ "" parameter {}."",infoRequest.getInfoParameter());"	<line7>	"logger.debug(""The information parameter {} you requested does not have all parameters it needs."",infoRequest.getInfoParameter())"	"<line7> logger.debug(""The information parameter {} you requested does not have all parameters it needs."",infoRequest.getInfoParameter())"
task5	"<line15>        log.error(""Can not handle POP3 connection"", e);"	<line14>	"log.error(""Exception while handling POP3 connection"", e)"	"<line14> log.error(""Exception while handling POP3 connection"", e)"
task5	"<line2>    logger.warn(""Nuvo binding incorrectly configured. Please configure for Serial or IP over serial""+ "" connection"");"	<line2>	"logger.warn(""Nuvo SDK not connected"")"	"<line2> logger.warn(""Nuvo SDK not connected"")"
task5	"<line3>      log.warn(""Asterisk is not configured or denied in room #{}"", r.getId());"	<line11>	"logger.info(""Allocating local port "" + port + "" for SIP stack "" + name)"	"<line11> logger.info(""Allocating local port "" + port + "" for SIP stack "" + name)"
task5	"<line12>      Log.info(""Project extracted to '"" + outputFolder.getAbsolutePath() + ""'"");"	<line2>	"LOGGER.info(""Extracting files to: "" + outputFolder)"	"<line2> LOGGER.info(""Extracting files to: "" + outputFolder)"
task5	<line7>      LOGGER.info(prettyString(doc));	<line7>	"LOGGER.info(""WFS GetFeature response:\n"" + prettyString(doc))"	"<line7> LOGGER.info(""WFS GetFeature response:\n"" + prettyString(doc))"
task5	"<line4>      LOGGER.error(""Failed to terminate workers"", e);"	<line4>	log.error(e.getMessage(), e)	<line4> log.error(e.getMessage(), e)
task5	"<line1>    LOG.info(StringUtils.format("" type = %s, density = %06.5f, count = %5d, average byte size = %5d"",type, density, count, totalBytes / count));"	<line1>	"log.info(""Type: %s, count: %d, density: %f, total size: %d kb"", type, count, density, totalBytes / 1024)"	"<line1> log.info(""Type: %s, count: %d, density: %f, total size: %d kb"", type, count, density, totalBytes / 1024)"
task5	"<line8>      LOG.debug(""execute command: "" + hardLink.toString());"	<line9>	"LOG.debug(""Created user_data link due to "" + executionResult)"	"<line9> LOG.debug(""Created user_data link due to "" + executionResult)"
task5	"<line2>      log.debug(""Try relogin kerberos at first!"");"	<line9>	"LOG.error(""Could not retry kerberos login"", e)"	"<line9> LOG.error(""Could not retry kerberos login"", e)"
task5	"<line13>              log.debug(""Authentication failed"", e);"	<line13>	"log.debug(""Authentication failed"", e)"	"<line13> log.debug(""Authentication failed"", e)"
task5	"<line4>      log.warn(""Transport error"", exception);"	<line4>	"log.warn(""WebSocket transport error for user {} in room {}"", user.getUserId(), room.getId(), exception)"	"<line4> log.warn(""WebSocket transport error for user {} in room {}"", user.getUserId(), room.getId(), exception)"
task5	"<line17>      logger.warn("""", t);"	<line17>	"logger.warn("""", t)"	"<line17> logger.warn("""", t)"
task5	<line27>      log.error(systemException, systemException);	<line27>	log.error(systemException, systemException)	<line27> log.error(systemException, systemException)
task5	"<line21>        logger.warn(""eXist-db does not support the collation reorderCode: {}"", reorderCode);"	<line21>	"LOGGER.warn(""Unrecognized reorder code: \""{}\"""", reorderCode)"	"<line21> LOGGER.warn(""Unrecognized reorder code: \""{}\"""", reorderCode)"
task5	"<line6>        LOG.warn(""Ignoring attempt to create spout '{}' with override == false."", id);"	<line6>	"logger.warn(""Spout id already exists: {}"", id)"	"<line6> logger.warn(""Spout id already exists: {}"", id)"
task5	"<line34>        logger.error(""Could not update family {}: {}"", family.getId(), e.getMessage(), e);"	<line34>	"logger.error(""Could not update family {}: {}"", family.getId(), e.getMessage(), e)"	"<line34> logger.error(""Could not update family {}: {}"", family.getId(), e.getMessage(), e)"
task5	"<line2>    LOG.info(""onCachePeriodChanged with value {} has been triggered!"", period);"	<line2>	"LOG.info(""Cache period changed to {} seconds"", period)"	"<line2> LOG.info(""Cache period changed to {} seconds"", period)"
task5	"<line21>        logger.error(""Failed retrieving features: {}"", e.getMessage(), debugException(e));"	<line21>	"logger.warn(""Failed to uninstall features for package '{}'"", currentPackage, e)"	"<line21> logger.warn(""Failed to uninstall features for package '{}'"", currentPackage, e)"
task5	"<line4>        logger.info(""Cuboid "" + lastCuboidId + "" has "" + cuboidRowCount + "" rows"");"	<line15>	"logger.warn(""Buffer Overflow Exception: "", boe)"	"<line15> logger.warn(""Buffer Overflow Exception: "", boe)"
task5	"<line2>    log.warn(""Not implemented: DockerIaas.releaseAddress()"");"	<line2>	"log.warn(""Not implemented: releaseAddress()"")"	"<line2> log.warn(""Not implemented: releaseAddress()"")"
task5	"<line28>    LOGGER.info(""Checking if MirrorMaker has log level set properly"");"	<line28>	"LOGGER.info(""Checking if Mirror-maker has log level set properly"")"	"<line28> LOGGER.info(""Checking if Mirror-maker has log level set properly"")"
task5	"<line11>          LOG.debug(""Set attributes for {}, options: {}"", path.getPath(), options);"	<line8>	"LOG.debug(""setAttribute({}, {})"", path.getPath(), mergedOptions)"	"<line8> LOG.debug(""setAttribute({}, {})"", path.getPath(), mergedOptions)"
task5	"<line2>    logger.debug(""Adding ring set: "", ringSet);"	<line2>	"logger.debug(""Adding ring set: "" + ringSet.toString())"	"<line2> logger.debug(""Adding ring set: "" + ringSet.toString())"
task5	"<line28>      LOGGER.debug(""Problem determining size of resource; defaulting to {}."", size, e);"	<line28>	"LOG.debug(""Unable to determine size of {}"", path, e)"	"<line28> LOG.debug(""Unable to determine size of {}"", path, e)"
task5	"<line11>      LOG.error(""Exception when doing join on delegate "" + this, e);"	<line11>	"LOG.error(""Error when joining calls"", e)"	"<line11> LOG.error(""Error when joining calls"", e)"
task5	"<line13>        log.info(this, ""@key: "" + key + ""@value:"" + value);"	<line12>	"log.debug(""Set field "" + key + "" to value "" + value)"	"<line12> log.debug(""Set field "" + key + "" to value "" + value)"
task5	"<line2>      logger.error(""failed to execute multiSearch: {}"", multiSearchResponse);"	<line2>	logger.error(multiSearchResponse.errorMessage)	<line2> logger.error(multiSearchResponse.errorMessage)
task5	"<line10>        LOG.warn(""could not get table column view index for [{}]. Loaded value '{}'"",col.getClass().getName(),value,e);"	<line10>	"LOG.warn(""Could not parse the value of the preference key '{}' (value='{}')"", key, value, e)"	"<line10> LOG.warn(""Could not parse the value of the preference key '{}' (value='{}')"", key, value, e)"
task5	"<line9>            log.debug(""to be introspected: {}"", type);"	<line9>	"log.debug(""defensive copy of introspectable types: {}"", type)"	"<line9> log.debug(""defensive copy of introspectable types: {}"", type)"
task5	<line7>      log.debug(key);	<line7>	"LOGGER.debug(""Adding key "" + key)"	"<line7> LOGGER.debug(""Adding key "" + key)"
task5	"<line6>        LOG.debug(""Merging XML based CamelContext with Spring Boot configuration properties"");"	<line8>	"LOG.warn(""Error while configuring CamelContext with CamelConfigurationProperties"", e)"	"<line8> LOG.warn(""Error while configuring CamelContext with CamelConfigurationProperties"", e)"
task5	<line6>      logger.error(errMsg);	<line6>	logger.error(errMsg)	<line6> logger.error(errMsg)
task5	"<line8>      LOG.warn(""Progress from unknown child task: "" + taskId);"	<line8>	"LOG.warn(""Unknown child task: "" + taskId + "". Ignored."")"	"<line8> LOG.warn(""Unknown child task: "" + taskId + "". Ignored."")"
task5	"<line14>        logger.info(""Creating new table '{}' with command(s): {}"", spec.getName(), sqlCmds.toString());"	<line14>	logger.info(sqlCmds.toString())	<line14> logger.info(sqlCmds.toString())
task5	"<line2>    logger.debug(""Received API discovery response "" + response);"	<line2>	"logger.debug(""Received response: {}"", response)"	"<line2> logger.debug(""Received response: {}"", response)"
task5	"<line2>    logger.debug(""postProcessContext() for "" + deploymentUnit.getName());"	<line2>	"logger.info(""postProcessContext() for "" + deploymentUnit.getName())"	"<line2> logger.info(""postProcessContext() for "" + deploymentUnit.getName())"
task5	"<line3>    LOG.trace(""Sleeping {} ms before retry #{}..."", sleepTime, attempts);"	<line3>	"logger.info(""Sleeping for {} times {}, then do retry."", attempts, sleepTime)"	"<line3> logger.info(""Sleeping for {} times {}, then do retry."", attempts, sleepTime)"
task5	"<line6>      logger.warn(""Failed to create reflection factory [""+ factoryClass.getName()+ ""], falling back to standard reflection instead"");"	<line3>	"logger.info(""Using ""+ factoryClass.getName()+ "" as the reflection factory. If this is an unit test, you can override this""+ "" behavior by setting the system property 'com.gigaspaces.reflection.factory' to the""+ "" full class name of the factory you wish to use."")"	"<line3> logger.info(""Using ""+ factoryClass.getName()+ "" as the reflection factory. If this is an unit test, you can override this""+ "" behavior by setting the system property 'com.gigaspaces.reflection.factory' to the""+ "" full class name of the factory you wish to use."")"
task5	"<line7>        LOG.warn(""Cannot generate NodeStat, datanode {} not found."", dn.getUuid());"	<line7>	"LOG.error(""NodeNotFound when getting container files of {}"", dn.getUuid())"	"<line7> LOG.error(""NodeNotFound when getting container files of {}"", dn.getUuid())"
task5	"<line5>    logger.info(""Stopping EnOcean discovery scan"");"	<line3>	"logger.debug(""Bridge handler is not defined. Only valid for testing."")"	"<line3> logger.debug(""Bridge handler is not defined. Only valid for testing."")"
task5	"<line2>    LOG.info(""Running Verify with outputDir="" + outputDir + "", numReducers="" + numReducers);"	<line9>	"LOG.info(""Running VerifyJob.run() as user "" + USER.getUser())"	"<line9> LOG.info(""Running VerifyJob.run() as user "" + USER.getUser())"
task5	"<line49>      log.error(""Exception while comparing values of property '"" + prop + ""': "" + ex.getMessage());"	<line49>	"log.warn(""Error comparing {} and {} on property {}, ascending {}"", o1, o2, prop, asc, ex)"	"<line49> log.warn(""Error comparing {} and {} on property {}, ascending {}"", o1, o2, prop, asc, ex)"
task5	"<line4>      LOG.warn(""Cannot send ping message over web-socket session {}."", session, e);"	<line4>	"log.warn(""Error while sending ping message"", e)"	"<line4> log.warn(""Error while sending ping message"", e)"
task5	"<line3>      log.debug(""Calling ExampleActionSetService"");"	<line3>	"log.debug(""Calling example action set service "" + name + "" version: "" + version)"	"<line3> log.debug(""Calling example action set service "" + name + "" version: "" + version)"
task5	"<line7>      LOG.warn(""Unable to find user role in SAML, will not be included in message to policy engine"");"	<line7>	"LOG.warn(""Null or empty user role coded system name in the assertion."")"	"<line7> LOG.warn(""Null or empty user role coded system name in the assertion."")"
task5	"<line3>      ActiveMQRALogger.LOGGER.trace(""getClientID()"");"	<line3>	"ActiveMQRALogger.LOGGER.trace(""getClientID()"")"	"<line3> ActiveMQRALogger.LOGGER.trace(""getClientID()"")"
task5	"<line4>    LOGGER.info(""instances: {}"", instances);"	<line4>	"LOGGER.info(""instances: {}"", instances)"	"<line4> LOGGER.info(""instances: {}"", instances)"
task5	"<line13>        log.warn(""exception closing inputstream"", e);"	<line13>	"log.error(""Unable to close file stream for properties file: "" + propertiesFile, e)"	"<line13> log.error(""Unable to close file stream for properties file: "" + propertiesFile, e)"
task5	<line19>    LOGGER.info(sb.toString());	<line19>	LOG.info(sb.toString())	<line19> LOG.info(sb.toString())
task5	"<line28>        LOG.error(""Error getting container quota: {}"", e.getMessage());"	<line28>	"log.error(""Error while converting ContainerQuota to ContainerQuotaDto."")"	"<line28> log.error(""Error while converting ContainerQuota to ContainerQuotaDto."")"
task5	<line13>        log.debug(sb.toString());	<line13>	log.debug(sb.toString())	<line13> log.debug(sb.toString())
task5	"<line7>      log.error(""Error in thread "" + Thread.currentThread().getId(), ex);"	<line7>	"log.error(""Error"", ex)"	"<line7> log.error(""Error"", ex)"
task5	"<line12>        LOGGER.error(String.format(""Unable to compare Kubernetes version for cluster version : %s with %s"",version.getName(), KubernetesClusterService.MIN_KUBERNETES_VERSION_HA_SUPPORT),e);"	<line12>	"LOG.error(""Failed to compare Kubernetes version for HA support."")"	"<line12> LOG.error(""Failed to compare Kubernetes version for HA support."")"
task5	"<line9>            LOGGER.warn(""On notify lost lock"", e);"	<line9>	"log.error(""An error occurred while notifying a LockListener that the lock was lost."", e)"	"<line9> log.error(""An error occurred while notifying a LockListener that the lock was lost."", e)"
task5	"<line11>        log.trace(""Sending additional invalidation for requestors if necessary."");"	<line11>	"log.trace(""[handleDataWriteCommand] flushing cache on key: "" + key)"	"<line11> log.trace(""[handleDataWriteCommand] flushing cache on key: "" + key)"
task5	"<line6>    LOG.info(""Successfully processed password reset request for user {}"", resetPassword.getUser());"	<line5>	"LOG.debug(""Reset password for user {}"", resetPassword.getUser())"	"<line5> LOG.debug(""Reset password for user {}"", resetPassword.getUser())"
task5	"<line2>    log.info(""Entering: isVisible"");"	<line6>	"logger.error(""Error occured while checking visibility of object: "" + locator, t)"	"<line6> logger.error(""Error occured while checking visibility of object: "" + locator, t)"
task5	<line10>      log.error(portalException, portalException);	<line10>	log.error(portalException, portalException)	<line10> log.error(portalException, portalException)
task5	"<line7>      log.debug(this, ""Send SMS END: phone="" + phoneNum + "",code="" + code + "",desc="" + desc);"	<line7>	"log.debug(this, ""completed result: "" + results)"	"<line7> log.debug(this, ""completed result: "" + results)"
task5	"<line10>        logger.info(""found non-instrumented http url connection output stream, please""+ "" report to the Glowroot project: {}"",returnValue.getClass().getName());"	<line10>	"logger.info(""found non-instrumented http url connection output stream, please""+ "" report to the Glowroot project: {}"",returnValue.getClass().getName())"	"<line10> logger.info(""found non-instrumented http url connection output stream, please""+ "" report to the Glowroot project: {}"",returnValue.getClass().getName())"
task5	"<line2>      log.debug(""Entering finally block in test case"");"	<line14>	"log.debug(""Test case failed on final action execution"", contextException)"	"<line14> log.debug(""Test case failed on final action execution"", contextException)"
task5	"<line3>      LOG.info(""reading "" + dockerConf);"	<line3>	"log.info(""Reading docker configuration file: "" + dockerConf)"	"<line3> log.info(""Reading docker configuration file: "" + dockerConf)"
task5	"<line34>          LOGGER.error(""Exception while trying to get attachment version !"", e);"	<line34>	"LOGGER.error(""Failed to create attachment URL for document [{}], revision [{}]: {}"",context.getDoc(),context.get(""rev""),e.getMessage())"	"<line34> LOGGER.error(""Failed to create attachment URL for document [{}], revision [{}]: {}"",context.getDoc(),context.get(""rev""),e.getMessage())"
task5	"<line28>              LOG.error(""Caught exception while checking all ledgers"", e);"	<line28>	"LOG.error(""Exception when checking ledgers"", e)"	"<line28> LOG.error(""Exception when checking ledgers"", e)"
task5	"<line6>        logger.debug(""Set header {}={}"", name, value);"	<line6>	"logger.debug(""Set header {}={}"", name, value)"	"<line6> logger.debug(""Set header {}={}"", name, value)"
task5	"<line4>    log.debug(""objectClassTypes={}"", Arrays.toString(objectClassTypes));"	<line17>	"log.debug(""Failed to find attribute '{}' metadata"", attribute.getOrigin())"	"<line17> log.debug(""Failed to find attribute '{}' metadata"", attribute.getOrigin())"
task5	"<line2>    log.info(""Executing: {}"", testInfo.getDisplayName());"	<line2>	"LOGGER.info(""Running test {}"", testInfo.getDisplayName())"	"<line2> LOGGER.info(""Running test {}"", testInfo.getDisplayName())"
task5	"<line4>        LOG.trace(""Expected active node {} but it wasn't there"", event.getPath());"	<line4>	"LOG.trace(""Expected active node {} but it wasn't there"", event.getPath())"	"<line4> LOG.trace(""Expected active node {} but it wasn't there"", event.getPath())"
task5	"<line8>        logger.error(""Error processing "" + tableName, ex);"	<line8>	"LOG.error(""Error processing "" + tableName, ex)"	"<line8> LOG.error(""Error processing "" + tableName, ex)"
task5	"<line6>      LOG.debug(""Session not of the expected type [session={}, expectedType={}]"", session, type);"	<line6>	"LOG.warn(""Current session is not of type "" + type)"	"<line6> LOG.warn(""Current session is not of type "" + type)"
task5	<line58>      logger.debug(advice);	<line58>	"logger.debug(""InitialImageAdvice is {}"", advice)"	"<line58> logger.debug(""InitialImageAdvice is {}"", advice)"
task5	"<line6>        LOG.warn(""Ignoring child {} of location {}({}), as cannot be found"",new Object[] {childId, memento.getType(), memento.getId()});"	<line6>	"LOG.warn(""Ignoring child location '{}' of location '{}' because cannot be found"", childId, memento)"	"<line6> LOG.warn(""Ignoring child location '{}' of location '{}' because cannot be found"", childId, memento)"
task5	"<line9>          LOG.warn(""No preferred Writer {} for format: {} - use {}"",param.className,param.formatName,writer.getClass().getName());"	<line9>	"LOGGER.warn(""Writer for format: "" + param.formatName + "" not of expected type: "" + param.className)"	"<line9> LOGGER.warn(""Writer for format: "" + param.formatName + "" not of expected type: "" + param.className)"
task5	"<line4>    LOGGER.info(""Initializing domainDistributionAutomationInboundKafkaRequestsMessageListenerContainer""+ "" bean."");"	<line4>	"LOGGER.info(""Initializing domainDistributionAutomationInboundKafkaRequestsMessageListenerContainer bean."")"	"<line4> LOGGER.info(""Initializing domainDistributionAutomationInboundKafkaRequestsMessageListenerContainer bean."")"
task5	"<line2>    LOG.trace(""TX:{} has failed a acknowledge."", getTransactionId());"	<line2>	"LOG.trace(""TX:{} has failed. Will restart on next message."", getTransactionId())"	"<line2> LOG.trace(""TX:{} has failed. Will restart on next message."", getTransactionId())"
task5	"<line40>              log.warn(""KaleoTaskFormInstancePersistenceImpl.fetchByKaleoTaskFormId(long, boolean) with""+ "" parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."");"	<line40>	"log.warn(""KaleoTaskFormInstancePersistenceImpl.fetchByKaleoTaskFormId(long, boolean) with""+ "" parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."")"	"<line40> log.warn(""KaleoTaskFormInstancePersistenceImpl.fetchByKaleoTaskFormId(long, boolean) with""+ "" parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."")"
task5	"<line2>      LOG.info(""Not authorized to access resource id <{}>. User <{}> is missing permissions {} on""+ "" instance <{}>"",instanceId,getSubject().getPrincipal(),Arrays.toString(permissions),instanceId);"	<line2>	"logger.info(""Not authorized to access resource id <"" + instanceId + "">"")"	"<line2> logger.info(""Not authorized to access resource id <"" + instanceId + "">"")"
task5	"<line16>            LOG.error(""Invalid execution status '"" + execution.getStatus() + '\'', e);"	<line16>	"LOG.debug(""Invalid task execution status: {}"", execution.getStatus())"	"<line16> LOG.debug(""Invalid task execution status: {}"", execution.getStatus())"
task5	"<line19>          logger.debug(""Failed to parse {}"", pager.requestedTimeRange, e);"	<line19>	"logger.debug(""Failed to parse requested time range."", e)"	"<line19> logger.debug(""Failed to parse requested time range."", e)"
task5	<line5>      Log.error(ex);	<line5>	Log.error(ex)	<line5> Log.error(ex)
task5	<line8>      log.error(exception, exception);	<line8>	log.error(exception, exception)	<line8> log.error(exception, exception)
task5	<line15>      LOGGER.error(e.getMessage(), e);	<line15>	"logger.error(""Fail to get resource: "", e)"	"<line15> logger.error(""Fail to get resource: "", e)"
task5	"<line5>    log.debug(""Operator event for {} - {}"", executionAttemptID, operatorId);"	<line16>	"LOG.debug(""Exception while sending operator event to task {}"", executionAttemptID, t)"	"<line16> LOG.debug(""Exception while sending operator event to task {}"", executionAttemptID, t)"
task5	"<line3>      LOGGER.info(""Found "" + type + "" file: "" + path.toAbsolutePath());"	<line3>	"log.info(""Config source is file: {}"", path)"	"<line3> log.info(""Config source is file: {}"", path)"
task5	"<line7>        logger.error(""Hibernate exception on deleting ModelFamily using ID=""+ modelFamilyID+ he.getStackTrace());"	<line7>	"log.error(""Hibernate exception on deleting model family with ID "" + modelFamilyID, he)"	"<line7> log.error(""Hibernate exception on deleting model family with ID "" + modelFamilyID, he)"
task5	"<line5>    log.info(m1, ""markers - INFO"");"	<line5>	"log.debug(""Hello world"")"	"<line5> log.debug(""Hello world"")"
task5	"<line9>    logger.info(""Created master and branch1 branches in "" + helper.getGithubRepository().getFullName());"	<line14>	"LOGGER.info(""Pipeline created"")"	"<line14> LOGGER.info(""Pipeline created"")"
task5	<line39>    LOGGER.debug(LOG_TIME_TO_QUERY, System.currentTimeMillis() - start);	<line47>	"LOGGER.debug(""Time to query {} observations: {} ms"", result.size(), System.currentTimeMillis() - start)"	"<line47> LOGGER.debug(""Time to query {} observations: {} ms"", result.size(), System.currentTimeMillis() - start)"
task5	<line9>      LOG.error(Freedomotic.getStackTraceInfo(e));	<line9>	"LOG.error(""Error during delete all"", e)"	"<line9> LOG.error(""Error during delete all"", e)"
task5	"<line7>    LOG.warn(""Invalid commit level provided, using the default commit level."");"	<line7>	"LOGGER.warn(""Commit Level not set to a valid value. Using COMMIT_ALL"")"	"<line7> LOGGER.warn(""Commit Level not set to a valid value. Using COMMIT_ALL"")"
task5	"<line12>      LOG.error(""Exception do pre-connect job"", e);"	<line12>	"LOG.error(""Exception in registering custom code runner: "" + e)"	"<line12> LOG.error(""Exception in registering custom code runner: "" + e)"
task5	"<line5>    log.info(Color.GREEN + ""Shape_7 : invalid column shape_dist_traveled"" + Color.NORMAL);"	<line5>	"log.info(Color.GREEN + ""Shape_7 : invalid column shape_dist_traveled"" + Color.NORMAL)"	"<line5> log.info(Color.GREEN + ""Shape_7 : invalid column shape_dist_traveled"" + Color.NORMAL)"
task5	<line4>      log.error(exception, exception);	<line4>	log.error(exception, exception)	<line4> log.error(exception, exception)
task5	"<line6>      log.error(""setEndTime must be called after setStartTime"", new Throwable(INVALID_CALL_SEQUENCE_MSG));"	<line6>	"log.warn(""startTime not set for trace item"")"	"<line6> log.warn(""startTime not set for trace item"")"
task5	"<line5>      LOG.debug(""Parsing json array : {}"", value);"	<line5>	"LOG.debug(""Parsing array: {}"", value)"	"<line5> LOG.debug(""Parsing array: {}"", value)"
task5	"<line7>    logger.error(""{}: INVALID message type with tx: {} from {}"",new Object[] {serverConnection.getName(),Integer.valueOf(clientMessage.getTransactionId()),serverConnection.getSocketString()});"	<line7>	"logger.debug(""Invalid message type: {}"", clientMessage.getMessageType())"	"<line7> logger.debug(""Invalid message type: {}"", clientMessage.getMessageType())"
task5	"<line2>      logger.debug(""Closing handles for LedgerRange: {}"", range);"	<line2>	"logger.debug(""Closing handles"")"	"<line2> logger.debug(""Closing handles"")"
task5	"<line14>        logger.warn(""Invalid property value: {}={}"", propertyName, typedValue);"	<line14>	"logger.debug(""Property {} is not a number and will be ignored"", propertyName)"	"<line14> logger.debug(""Property {} is not a number and will be ignored"", propertyName)"
task5	"<line8>    log.info(""getProjectOverview took "" + watch.taken());"	<line8>	"log.info(""Took "" + watch.taken() + "" ms. to scan for overview."")"	"<line8> log.info(""Took "" + watch.taken() + "" ms. to scan for overview."")"
task5	"<line27>            log.error(e, ""Internal Server Error: Could not covert message body to a Buffer"");"	<line27>	"log.error(""Error decoding message body."", e)"	"<line27> log.error(""Error decoding message body."", e)"
task5	"<line24>    log.info(""Resolved {} to {}"", name, uris);"	<line24>	"log.info(String.format(""Found %d %s endpoints for %s"", uris.size(), protocol, name))"	"<line24> log.info(String.format(""Found %d %s endpoints for %s"", uris.size(), protocol, name))"
task5	"<line31>            LOG.warn(""Persistence tasks took too long to terminate, when stopping persistence, although""+ "" pending changes were persisted (ignoring): ""+ scheduledTask);"	<line31>	"log.warn(""Listener task did not end within expected time of "" + scheduledTask.getDisplayName())"	"<line31> log.warn(""Listener task did not end within expected time of "" + scheduledTask.getDisplayName())"
task5	"<line6>      LOGGER.info(""Failed parsing charset"", e);"	<line6>	"LOGGER.warn(""Error while extracting charset from {}"", descriptor, e)"	"<line6> LOGGER.warn(""Error while extracting charset from {}"", descriptor, e)"
task5	"<line13>    log.info(""getContact {}"", contact.toString());"	<line13>	"logger.debug(""Getting contact for "" + r.getUser())"	"<line13> logger.debug(""Getting contact for "" + r.getUser())"
task5	"<line15>        log.error(EcompLoggerErrorCode.DATA_ERROR,null,""GetToscaElement"",result.right().value().name() + ""for component with id {}"",componentId);"	<line15>	"log.debug(""Failed to fetch component with id {}. Error: {}"", componentId, result.right().value())"	"<line15> log.debug(""Failed to fetch component with id {}. Error: {}"", componentId, result.right().value())"
task5	"<line4>      log.error(""Local alert buffer full!  Clearing!  Dropping "" + alert.getId() + "" record"");"	<line4>	"log.error(""Could not persist alert: _alerts is full"")"	"<line4> log.error(""Could not persist alert: _alerts is full"")"
task5	"<line13>    LOG.error(""Unknown message category: "" + category);"	<line13>	"LOG.error(""Unknown message category"")"	"<line13> LOG.error(""Unknown message category"")"
task5	"<line2>    log.info(""Server: {} - onPing ping={}"", server, ping);"	<line2>	"logger.info(""onPing: {}"", ping)"	"<line2> logger.info(""onPing: {}"", ping)"
task5	"<line2>      LOGGER.info(""Loading libs..."");"	<lineinjector>	"log.debug(""Created injector from {} configuration"", configuration.getPrefix())"	"<lineinjector> log.debug(""Created injector from {} configuration"", configuration.getPrefix())"
task5	"<line28>        LOG.warn(String.format(""Error while closing the input stream of process %s: %s"", process, e.getMessage()));"	<line28>	"LOG.error(""Failed to close process input stream: "" + e, e)"	"<line28> LOG.error(""Failed to close process input stream: "" + e, e)"
task5	"<line28>      LOG.info(""> {}"", new String(buffer));"	<line2>	"LOG.info(""testAppend"")"	"<line2> LOG.info(""testAppend"")"
task5	"<line3>    ActiveMQRestLogger.LOGGER.debug(""Handling POST request for \"""" + uriInfo.getPath() + ""\"""");"	<line34>	"log.error(""Failed to create queue."", e)"	"<line34> log.error(""Failed to create queue."", e)"
task5	<line2>    logger.warn(string, o);	<line2>	logger.warn(string, o)	<line2> logger.warn(string, o)
task5	"<line2>    LOG.warn(""Failed Context Inferrence"");"	<line4>	"LOG.info(""ContextInferenceFailedException"", exception)"	"<line4> LOG.info(""ContextInferenceFailedException"", exception)"
task5	"<line11>    logger.trace(""Using configuration {}"", deviceConfig);"	<line2>	"logger.info(""Initializing DSMR handler."")"	"<line2> logger.info(""Initializing DSMR handler."")"
task5	"<line8>      logger.error(""Error while converting tuple {} {}"", tuple, e);"	<line8>	"log.error(""JsonProcessingException in convert method"", e)"	"<line8> log.error(""JsonProcessingException in convert method"", e)"
task5	"<line2>      LOG.error(""currentElement == null"");"	<line2>	"LOG.warn(""appendAttrToBeIndexedLater: currentElement is null!"")"	"<line2> LOG.warn(""appendAttrToBeIndexedLater: currentElement is null!"")"
task5	"<line6>      LOG.warn(""Failed to marshal the events: "" + e, e);"	<line6>	log.error(e.getMessage(), e)	<line6> log.error(e.getMessage(), e)
task5	"<line13>          logger.warn(""Unknown extension mapping type specified in fedora.fcfg"");"	<line13>	"log.error(""Bad value for mapping type: "" + mappingType)"	"<line13> log.error(""Bad value for mapping type: "" + mappingType)"
task5	"<line39>          LOGGER.error(() -> ""Unsupported LogType: "" + reusableLog.getLogType());"	<line39>	"LOG.warn(""Unknown log type: {}"", reusableLog.getLogType())"	"<line39> LOG.warn(""Unknown log type: {}"", reusableLog.getLogType())"
task5	"<line18>      LOGGER.error(""Error writing HTTP result"", ex);"	<line18>	"logger.error(""Error writing response"", ex)"	"<line18> logger.error(""Error writing response"", ex)"
task5	"<line11>        LOG.error(""Timer thread caught, ignored an exception"", e);"	<line11>	"log.error(""Exception from callback"", e)"	"<line11> log.error(""Exception from callback"", e)"
task5	<line57>      LOGGER.error(e.getMessage(), e);	<line57>	"logger.error(""Error while searching client versions"", e)"	"<line57> logger.error(""Error while searching client versions"", e)"
task5	"<line11>      log.error(""Error writing Metadata Value"", e);"	<line10>	"log.error(""Connection exception persisting metadata"", e)"	"<line10> log.error(""Connection exception persisting metadata"", e)"
task5	"<line23>      log.error(""Problem with GET request"", e);"	<line17>	"LOGGER.error(""Could not process GetMap request"", se)"	"<line17> LOGGER.error(""Could not process GetMap request"", se)"
task5	"<line5>    LOG.info(""---------------1 addSchemaVersion {} {}"", schemaMetadata, schemaVersion);"	<line5>	"LOG.info(""--------------- addSchemaVersion {}"", schemaVersion)"	"<line5> LOG.info(""--------------- addSchemaVersion {}"", schemaVersion)"
task5	"<line3>      LOG.info(""Attempting to declare TX:[{}]"", txId);"	<line2>	"log.debug(""Successfully wrote request {} to coordinator"", request)"	"<line2> log.debug(""Successfully wrote request {} to coordinator"", request)"
task5	"<line5>      logger.debug(""CSRF token from login html: {}"", csrfTokenString);"	<line5>	"logger.debug(""Found CSRF token: {}"", csrfTokenString)"	"<line5> logger.debug(""Found CSRF token: {}"", csrfTokenString)"
task5	"<line1>    log.warn(""WebSocket server is unreachable. Possible VPN/Network issues, will retry in: ""+ reconnectDelay+ "" milliseconds."");"	<line1>	"log.warn(""Connection to {} unreachable. Retrying."", webSocketServerUrl)"	"<line1> log.warn(""Connection to {} unreachable. Retrying."", webSocketServerUrl)"
task5	"<line13>      logger.debug(""Could not resolve a reasonable super-query alias for SelectItem: {}"", toSql());"	<line13>	"log.warn(""No alias specified for the super query!"")"	"<line13> log.warn(""No alias specified for the super query!"")"
task5	"<line4>      log.warn(""CryptoTransfer has no throttle buckets, fee multiplier will remain at one!"");"	<line4>	"log.debug(""No active throttles for CryptoTransfer"")"	"<line4> log.debug(""No active throttles for CryptoTransfer"")"
task5	"<line2>      LOGGER.debug(""No LdapContextFactory specified - creating a default instance."");"	<line8>	"LOGGER.debug(""Setting the LdapContextFactory to the default one."")"	"<line8> LOGGER.debug(""Setting the LdapContextFactory to the default one."")"
task5	"<line18>    LOGGER.info(""Found {} testcases."", testcases.size());"	<line12>	"LOGGER.debug(""Creating testcase {}"", testcase.getName())"	"<line12> LOGGER.debug(""Creating testcase {}"", testcase.getName())"
task5	"<line4>    logger.debug(""onAuthenticationSuccess() started"");"	<line5>	"logger.debug(""Authentication success for user {}"", userId)"	"<line5> logger.debug(""Authentication success for user {}"", userId)"
task5	<line3>      LOG.info(chat.getParticipant());	<line10>	LOG.error(ex.getMessage(), ex)	<line10> LOG.error(ex.getMessage(), ex)
task5	<line14>      logger.info(ex.getMessage());	<line14>	logger.info(ex.getMessage())	<line14> logger.info(ex.getMessage())
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	<line35>      LOG.error(msg, e);	<line35>	log.error(msg, e)	<line35> log.error(msg, e)
task5	"<line2>    logger.info(""registering servlet"");"	<line2>	"LOGGER.debug(""HttpService instance found"")"	"<line2> LOGGER.debug(""HttpService instance found"")"
task5	"<line4>      log.warn(""Capacity hit adding client back to queue. Closing extra"");"	<line4>	"LOG.debug(""Adding client to pool gently: {}"", client, ise)"	"<line4> LOG.debug(""Adding client to pool gently: {}"", client, ise)"
task5	<line49>            LOGGER.debug(e.getMessage());	<line40>	"LOGGER.warn(""Could not parse "" + s, e)"	"<line40> LOGGER.warn(""Could not parse "" + s, e)"
task5	"<line5>    log.debug(""TAC-participate-commit ::: {}"", hmilyParticipantList);"	<line13>	"log.error("" hmilyParticipant execute confirm exception:{}"", participant.toString(), throwable)"	"<line13> log.error("" hmilyParticipant execute confirm exception:{}"", participant.toString(), throwable)"
task5	"<line5>      log.debug(""Task not found matching "" + matcher + ""; contender names were "" + taskNames);"	<line5>	"log.debug(""Failed to find task matching "" + matcher + "" in "" + tasks + "" with names "" + taskNames)"	"<line5> log.debug(""Failed to find task matching "" + matcher + "" in "" + tasks + "" with names "" + taskNames)"
task5	"<line10>        log.error(""Unable to get IDP alias for:"" + delegate, e);"	<line10>	"log.error(""Unable to get SP entity name for:"" + delegate, e)"	"<line10> log.error(""Unable to get SP entity name for:"" + delegate, e)"
task5	"<line1>    logger.warn(""Unexpected exception in the selector loop."", t);"	<line1>	"log.error(""Loop exception"", t)"	"<line1> log.error(""Loop exception"", t)"
task5	"<line12>    LOG.debug(""[deleteResource] (record = [{}]). deletedId: {}"", new Object[] {record, fileId});"	<line13>	"log.info(""Google Drive file deleted with id: "" + fileId)"	"<line13> log.info(""Google Drive file deleted with id: "" + fileId)"
task5	"<line7>    logger.debug(""Query for alert having id {} resulted in : {}"", id, result);"	<line7>	"logger.debug(""Alert found for ID {} : {}"", id, result)"	"<line7> logger.debug(""Alert found for ID {} : {}"", id, result)"
task5	"<line2>    logger.info(""The URI "" + uri + "" is recognized as "" + uriType);"	<line14>	"logger.error(""Failed to load kylin config from uri:"" + uri, e)"	"<line14> logger.error(""Failed to load kylin config from uri:"" + uri, e)"
task5	"<line29>      LOG.trace(""Index was not found after recomputing the reducer map"");"	<line29>	"LOG.error(""Cannot find the reducer for the split ""+ index+ "" of table ""+ tableName+ "". It might be because the split point ""+ ""is too small for the table. Try to increase the split point."")"	"<line29> LOG.error(""Cannot find the reducer for the split ""+ index+ "" of table ""+ tableName+ "". It might be because the split point ""+ ""is too small for the table. Try to increase the split point."")"
task5	"<line9>      log.warn(""Duplicate property values for ["" + propertyKey + ""]."");"	<line9>	"LOG.warn(""Duplicate property key in profile: {}"", propertyKey)"	"<line9> LOG.warn(""Duplicate property key in profile: {}"", propertyKey)"
task5	"<line6>      logger.error(""Error on searching pages"", t);"	<line6>	"logger.error(""Error on searching pages"", t)"	"<line6> logger.error(""Error on searching pages"", t)"
task5	"<line3>      logger.error(""Null content"");"	<line3>	"logger.error(""Null dataObject to check authorization"")"	"<line3> logger.error(""Null dataObject to check authorization"")"
task5	"<line3>      LOGGER.debug(""ApplicationName of filterFactory had been updated to {}"", applicationName);"	<line1>	"logger.debug(""Application name set to: {}"", applicationName)"	"<line1> logger.debug(""Application name set to: {}"", applicationName)"
task5	<line23>      log.error(systemException, systemException);	<line23>	log.error(systemException, systemException)	<line23> log.error(systemException, systemException)
task5	"<line13>        log.info(MessageFormat.format(""Found multiple implementations for {0}. Returning first implementation"",executionRequestLabelKey.toString()));"	<line13>	"LOGGER.info(MessageFormat.format(""Found multiple implementations for {0}. Returning first implementation"",executionRequestLabelKey.toString()))"	"<line13> LOGGER.info(MessageFormat.format(""Found multiple implementations for {0}. Returning first implementation"",executionRequestLabelKey.toString()))"
task5	"<line18>            log.error(""matching returned error. (Should never happen): {}"", match.getMessage());"	<line18>	"log.debug(""Type of match result is not boolean: {}"", match)"	"<line18> log.debug(""Type of match result is not boolean: {}"", match)"
task5	"<line1>    logger.debug(""createNetModeTransaction"");"	<line1>	"logger.trace(""createNetModeTransaction"")"	"<line1> logger.trace(""createNetModeTransaction"")"
task5	"<line9>    logger.debug(""Import file: {}"", dropFile.getName());"	<line9>	"logger.debug(""Importing file: {}"", dropFile.getName())"	"<line9> logger.debug(""Importing file: {}"", dropFile.getName())"
task5	"<line2>    LOG.info(""Aborting repair on segment with id {} on coordinator {}"",segment.getId(),segment.getCoordinatorHost());"	<line7>	"LOG.info(""Aborting segment {}"", segment.getId())"	"<line7> LOG.info(""Aborting segment {}"", segment.getId())"
task5	<line11>      LOGGER.error(t.getMessage(), t);	<line11>	"logger.error(""Error during findClasses()"", t)"	"<line11> logger.error(""Error during findClasses()"", t)"
task5	<line8>      log.error(exception, exception);	<line8>	log.error(exception, exception)	<line8> log.error(exception, exception)
task5	"<line6>    LOG.debug(""value: {} timestamp: {}"", value, context.timestamp().getMillis());"	<line12>	"LOG.info(""Latch count down for {}"", context.element().getKey())"	"<line12> LOG.info(""Latch count down for {}"", context.element().getKey())"
task5	"<line11>      log.error(""Test failed"", e);"	<line11>	"log.error(""Test failed"", e)"	"<line11> log.error(""Test failed"", e)"
task5	"<line8>        log.debug(""Found {} entitlements for consumer: {}"", foundEntitlements.size(), consumer.getUuid());"	<line11>	"log.debug(""filtered entitlements: {}"", filteredEntitlements.size())"	"<line11> log.debug(""filtered entitlements: {}"", filteredEntitlements.size())"
task5	"<line25>        log.info(""Property type unknown: "" + actionMap.get(""type""));"	<line25>	"LOG.warn(""Unknown action type: "" + actionMap.get(""type""))"	"<line25> LOG.warn(""Unknown action type: "" + actionMap.get(""type""))"
task5	"<line6>      Logger.logger.info(Logger.MISC_LOG + id + "": "" + message);"	<line6>	"Logger.logger.info(Logger.MISC_LOG + id + "": "" + message)"	"<line6> Logger.logger.info(Logger.MISC_LOG + id + "": "" + message)"
task5	"<line21>          log.warn(""Found non-definitional spec parameter: "" + p + "" adding to "" + spec);"	<line21>	"LOG.warn(""Parameter ""+ p.getConfigKey().getName()+ "" of ""+ spec+ "" is not inheritable and will be overwritten"")"	"<line21> LOG.warn(""Parameter ""+ p.getConfigKey().getName()+ "" of ""+ spec+ "" is not inheritable and will be overwritten"")"
task5	"<line1>    logger.info(""rsfNetManager, shutdownGracefully."");"	<line1>	"logger.debug(""Shutting down all protocol connectors"")"	"<line1> logger.debug(""Shutting down all protocol connectors"")"
task5	"<line2>    log.trace(""draggedImage_movedTo"");"	<line2>	"log.debug(""draggedImage_movedTo:"" + point)"	"<line2> log.debug(""draggedImage_movedTo:"" + point)"
task5	"<line4>      logger.trace(""scheduled {} for refresh"", this.thing.getUID());"	<line3>	"logger.debug(""Refreshing bridge '{}'"", getThing().getUID().getId())"	"<line3> logger.debug(""Refreshing bridge '{}'"", getThing().getUID().getId())"
task5	"<line1>    logger.info(""Scheduling report aggregator job..."");"	<line7>	"LOGGER.debug(""Timed scheduler started"")"	"<line7> LOGGER.debug(""Timed scheduler started"")"
task5	"<line4>      log.trace(""Not found portalUser with username ""+ principal.getUserName()+ "". Redirecting to registration form"");"	<line4>	"log.trace(""Handle redirect to registration form for "" + principal.toString())"	"<line4> log.trace(""Handle redirect to registration form for "" + principal.toString())"
task5	"<line10>      log.error(""Error while Flushing Lucene Indexes, Caused by: "", e);"	<line3>	"log.info(""Committing Lucene Index"")"	"<line3> log.info(""Committing Lucene Index"")"
task5	"<line2>    logger.info(""{}"", this);"	<line3>	"logger.debug(""Injected properties: {}"", visitor.getResults())"	"<line3> logger.debug(""Injected properties: {}"", visitor.getResults())"
task5	"<line5>        LOGGER.warn(""Unable to create XACML PDP."", e);"	<line5>	"LOGGER.error(""Error while creating XACML PDP."", e)"	"<line5> LOGGER.error(""Error while creating XACML PDP."", e)"
task5	<line2>    log.warn(msg);	<line2>	logger.warn(msg)	<line2> logger.warn(msg)
task5	"<line2>    logger.warn(""Error on '{}' delivery: {}"", variant.getType().getTypeName(), reason);"	<line2>	"LOGGER.error(""Error while pushing message to {}"", variant.name(), new IOException(reason))"	"<line2> LOGGER.error(""Error while pushing message to {}"", variant.name(), new IOException(reason))"
task5	"<line9>      log.info(""Trying {}"", method);"	<line9>	"log.info(""Testing image resize method: "" + method)"	"<line9> log.info(""Testing image resize method: "" + method)"
task5	"<line6>    log.debug(""getAggregated() = {}"", result);"	<line6>	"log.debug(""{} : result = {}"", this, result)"	"<line6> log.debug(""{} : result = {}"", this, result)"
task5	"<line1>    logger.info(""Downloading gene Ensembl data (gtf, pep, cdna, motifs) ..."");"	<line1>	"logger.info(""Downloading gene information ..."")"	"<line1> logger.info(""Downloading gene information ..."")"
task5	"<line2>    LOG.debug(""Shutting down journal!"");"	<line11>	"log.info(""Stopping the log flushing service."")"	"<line11> log.info(""Stopping the log flushing service."")"
task5	<line3>    logger.info(LOG_MESSAGE);	<line3>	"logger.info(""Hello world"")"	"<line3> logger.info(""Hello world"")"
task5	"<line7>              log.info(""zookeeper client register success: {}"", v);"	<line2>	"log.debug(""handleStateChanged: {}"", keeperState)"	"<line2> log.debug(""handleStateChanged: {}"", keeperState)"
task5	<line20>    logger.info(strb.toString());	<line20>	logger.info(strb.toString())	<line20> logger.info(strb.toString())
task5	"<line4>      log.debug(String.format(""Run with feature %s"", feature));"	<line4>	"log.debug(String.format(""Run with feature %s"", feature))"	"<line4> log.debug(String.format(""Run with feature %s"", feature))"
task5	"<line4>      LOG.info(""Domain group not found. Nothing to do."");"	<line4>	"logger.info(""No domain group found for ring group {}"", ringGroup.getRingGroupName())"	"<line4> logger.info(""No domain group found for ring group {}"", ringGroup.getRingGroupName())"
task5	"<line9>      log.error(""Error getting department"", e);"	<line9>	"log.error(""Unable to get department for user "" + user.getUserId(), e)"	"<line9> log.error(""Unable to get department for user "" + user.getUserId(), e)"
task5	"<line13>          this.logger.error(""Failed to parse extension [{}]"", localExtension.getId(), e);"	<line13>	"logger.error(""Failed to parse extension [{}]"", localExtension.getExtensionKey(), e)"	"<line13> logger.error(""Failed to parse extension [{}]"", localExtension.getExtensionKey(), e)"
task5	"<line6>      LOGGER.debug(""Proxy handler "" + this + "": connect.strategy="" + connectStrategy + ""."");"	<line6>	"LOGGER.debug(""[setConnectStrategy]{}"", connectStrategy)"	"<line6> LOGGER.debug(""[setConnectStrategy]{}"", connectStrategy)"
task5	<line12>        log.debug(sb.toString());	<line12>	log.debug(sb.toString())	<line12> log.debug(sb.toString())
task5	"<line4>      logger.debug(String.format(""Attempting to realign read %s at %d more than %d bases to %d."",read.getReadName(), read.getAlignmentStart(), MAX_POS_MOVE_ALLOWED, newStart));"	<line4>	"logger.warn(""Realigned read has moved too far from original position; skipping update"")"	"<line4> logger.warn(""Realigned read has moved too far from original position; skipping update"")"
task5	"<line5>    logger.info(""Writing to COS '"" + bucketName + "":"" + objectName + ""', bytes: "" + raw.length);"	<line1>	"logger.info(""Writing to COS: ["" + bucketName + ""]/"" + objectName)"	"<line1> logger.info(""Writing to COS: ["" + bucketName + ""]/"" + objectName)"
task5	"<line3>    logger.debug(""Putting {} on cache. size: {}"", key, size());"	<line2>	"if (log.isDebugEnabled()) log.debug(""put("" + key + "", "" + value + "")"")"	"<line2> if (log.isDebugEnabled()) log.debug(""put("" + key + "", "" + value + "")"")"
task5	<line7>      log.error(msg);	<line7>	log.error(msg)	<line7> log.error(msg)
task5	"<line5>    LOGGER.debug(""Update partially provider id={} with partialDto={}"", id, provider);"	<line5>	"LOGGER.debug(""Patch provider {} with {}"", id, provider)"	"<line5> LOGGER.debug(""Patch provider {} with {}"", id, provider)"
task5	"<line6>      LOGGER.debug(""UUID matched previously registered subscription."", e);"	<line3>	"logger.debug(""Creating subscription {}"", uuid)"	"<line3> logger.debug(""Creating subscription {}"", uuid)"
task5	<line6>      logger.error(String.format(NEGATIV_WEIGHT, w));	<line6>	"logger.warn(""collectNaive: negative or zero weight "" + w)"	"<line6> logger.warn(""collectNaive: negative or zero weight "" + w)"
task5	<line21>      log.error(e.getMessage(), e);	<line21>	"logger.warn(""Exception:"", e)"	"<line21> logger.warn(""Exception:"", e)"
task5	"<line1>    log.info(""Query API Key"");"	<line1>	"log.info(""Query API Key"")"	"<line1> log.info(""Query API Key"")"
task5	<line22>      LOGGER.warn(error.toString());	<line22>	LOGGER.error(error.toString())	<line22> LOGGER.error(error.toString())
task5	"<line2>    LOGGER.trace(MessageFormat.format(""Deleting Connection {0}."", metadataKey.toString()));"	<line2>	"LOGGER.trace(MessageFormat.format(""Deleting ConnectionParameter {0}."", metadataKey.toString()))"	"<line2> LOGGER.trace(MessageFormat.format(""Deleting ConnectionParameter {0}."", metadataKey.toString()))"
task5	"<line2>    logger.info(""Starting the Source Connector"");"	<line8>	"log.debug(""Started CosmosDBSourceConnector"")"	"<line8> log.debug(""Started CosmosDBSourceConnector"")"
task5	"<line6>      LOGGER.debug(""Experiment Count : {}"", count);"	<line6>	"LOGGER.debug(""Experiment count: {}"", count)"	"<line6> LOGGER.debug(""Experiment count: {}"", count)"
task5	"<line7>      logger.error(""Error loading actionlogger records"", t);"	<line7>	"logger.error(""Error loading actionlogger records"", t)"	"<line7> logger.error(""Error loading actionlogger records"", t)"
task5	"<line2>    LOG.debug(""Starting..."");"	<line2>	"LOG.info(""setUp in ITCombinationTestCase"")"	"<line2> LOG.info(""setUp in ITCombinationTestCase"")"
task5	"<line9>    logger.debug(""deleting {}"", pageCode);"	<line9>	"logger.debug(""Deleting page {}"", pageCode)"	"<line9> logger.debug(""Deleting page {}"", pageCode)"
task5	"<line6>      log.error(""Thrift error"", e);"	<line6>	"log.error(""Unable to render edit view for id "" + id, e)"	"<line6> log.error(""Unable to render edit view for id "" + id, e)"
task5	"<line2>    logger.debug(""Initializing MQTT skeleton (ownGbid={}) ..."", ownGbid);"	<line2>	"logger.info(""Initializing MqttMessageBus. Own gbid: {}"", ownGbid)"	"<line2> logger.info(""Initializing MqttMessageBus. Own gbid: {}"", ownGbid)"
task5	"<line16>      log.error(""Error while agent {} "", action, e);"	<line16>	"log.error(""Error while performing agent action"", e)"	"<line16> log.error(""Error while performing agent action"", e)"
task5	"<line14>                logger.warn(""Failed to write {} to response."", id, e);"	<line14>	"log.error(""Failed to write ndjson response"", e)"	"<line14> log.error(""Failed to write ndjson response"", e)"
task5	"<line2>    log.warn(""[{}] Affected data:\n{}"", this.sqlTableName, this.dataToString(data));"	<line2>	"logger.debug(""Ignoring record: {}"", data)"	"<line2> logger.debug(""Ignoring record: {}"", data)"
task5	"<line17>          LOGGER.warn(""Could not find a streaming server provider."");"	<line17>	"LOGGER.error(""Cannot register streaming server because the ServerProvider is not modifiable."")"	"<line17> LOGGER.error(""Cannot register streaming server because the ServerProvider is not modifiable."")"
task5	"<line20>      LOGGER.warn(""Unable to parse aquisition date"", e);"	<line20>	"LOGGER.warn(""Unable to parse acquisition date field"", e)"	"<line20> LOGGER.warn(""Unable to parse acquisition date field"", e)"
task5	<line1>    log.debug(printStatus());	<line1>	"log.debug(""Scheduling status log"")"	"<line1> log.debug(""Scheduling status log"")"
task5	"<line7>      log.error(""main threw"", e);"	<line7>	"log.error(""main threw"", e)"	"<line7> log.error(""main threw"", e)"
task5	<line9>          logger.debug(exception, ex);	<line9>	logger.debug(exception)	<line9> logger.debug(exception)
task5	"<line23>      logger.debug(""Entity {} created"", entity.getProperty(""name""));"	<line2>	"logger.debug(""testNonGeolocationEntities"")"	"<line2> logger.debug(""testNonGeolocationEntities"")"
task5	"<line8>      LOG.error(""Error while substituting variables"", e);"	<line8>	log.error(e.getMessage(), e)	<line8> log.error(e.getMessage(), e)
task5	<line6>      log.error(exception, exception);	<line6>	log.error(exception, exception)	<line6> log.error(exception, exception)
task5	"<line22>          log.debug(""Outbound Websocket frame is throttled. "" + ctx.channel().toString());"	<line22>	"log.debug(""Blocked websocket frame written to channel - "", msg)"	"<line22> log.debug(""Blocked websocket frame written to channel - "", msg)"
task5	"<line17>            log.trace(""sendHeartBeat({}) received reply size={} for request={}"",session,reply.available(),heartbeatRequest);"	<line17>	"log.trace(""sendHeartBeat({}) request={} reply={}"", session, heartbeatRequest, reply)"	"<line17> log.trace(""sendHeartBeat({}) request={} reply={}"", session, heartbeatRequest, reply)"
task5	<line2>    logger.debug(Messages.GETTING_PARAMETERS_OF_SERVICE_BINDING_0, guid);	<line2>	logger.debug(Messages.GETTING_SERVICE_BINDING_PARAMETERS_0, guid)	<line2> logger.debug(Messages.GETTING_SERVICE_BINDING_PARAMETERS_0, guid)
task5	"<line7>      LOG.debug(""Removing file [{0}] with length [{1}]."", name, length);"	<line2>	"LOG.debug(""deleteFile({})"", name)"	"<line2> LOG.debug(""deleteFile({})"", name)"
task5	<line29>              log.debug(illegalArgumentException, illegalArgumentException);	<line29>	log.debug(illegalArgumentException, illegalArgumentException)	<line29> log.debug(illegalArgumentException, illegalArgumentException)
task5	<line7>      log.error(exception, exception);	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	"<line3>      LOG.debug(""The configured batch timeout '{}' for sensor type '{}' is <=0 or > the maximum allowable""+ "" batch timeout '{}'. Setting the batch timeout to the maximum allowable."",batchTimeoutSecs,sensorType,maxBatchTimeout);"	<line3>	"log.warn(""{} batch timeout value of {} seconds is invalid, using the maximum allowed value of {} ""+ ""seconds"",sensorType,batchTimeoutSecs,maxBatchTimeout)"	"<line3> log.warn(""{} batch timeout value of {} seconds is invalid, using the maximum allowed value of {} ""+ ""seconds"",sensorType,batchTimeoutSecs,maxBatchTimeout)"
task5	"<line12>      LOGGER.warn(""Could not generate Signature! Using empty one instead!"", E);"	<line12>	"LOGGER.warn(""Could not generate signature for DHEServerKeyExchangeMessage"")"	"<line12> LOGGER.warn(""Could not generate signature for DHEServerKeyExchangeMessage"")"
task5	"<line25>      log.error(""Exception was thrown during entry processing."", e);"	<line25>	"if (log.isDebugEnabled()) log.debug(""Entry processor failed: "" + e.getMessage(), e)"	"<line25> if (log.isDebugEnabled()) log.debug(""Entry processor failed: "" + e.getMessage(), e)"
task5	<line12>      log.error(ex.getMessage(), ex);	<line12>	log.error(ex.getMessage(), ex)	<line12> log.error(ex.getMessage(), ex)
task5	"<line1>    LOG.trace(""buildRepairRunFromRow {} / {}"", id, repairRunResult);"	<line1>	"LOG.trace(""Converting repair run result to object"")"	"<line1> LOG.trace(""Converting repair run result to object"")"
task5	<line10>        log.debug(exception, exception);	<line10>	log.debug(exception, exception)	<line10> log.debug(exception, exception)
task5	"<line16>    LOGGER.info(""Modify the business object definition in the search index associated with the business""+ "" object definition tag being deleted. tagTypeCode=\""{}\"", tagCode=\""{}\"",""+ "" businessObjectDefinitionId=\""{}\"", searchIndexUpdateType=\""{}\"""",businessObjectDefinitionTagEntity.getTag().getTagType().getCode(),businessObjectDefinitionTagEntity.getTag().getTagCode(),businessObjectDefinitionEntity.getId(),SEARCH_INDEX_UPDATE_TYPE_UPDATE);"	<line12>	"LOGGER.info(""Modify the business object definition in the search index associated with the business""+ "" object definition tag being deleted. tagKey=\""{}\"",""+ "" businessObjectDefinitionId=\""{}\"",""+ "" searchIndexUpdateType=\""{}\"""",businessObjectDefinitionTagKey.toString(),businessObjectDefinitionTagEntity.getBusinessObjectDefinitionId(),SEARCH_INDEX_UPDATE_TYPE_UPDATE)"	"<line12> LOGGER.info(""Modify the business object definition in the search index associated with the business""+ "" object definition tag being deleted. tagKey=\""{}\"",""+ "" businessObjectDefinitionId=\""{}\"",""+ "" searchIndexUpdateType=\""{}\"""",businessObjectDefinitionTagKey.toString(),businessObjectDefinitionTagEntity.getBusinessObjectDefinitionId(),SEARCH_INDEX_UPDATE_TYPE_UPDATE)"
task5	"<line46>      logger.info(""orphan = "" + _orphaned);"	<line46>	"logger.info(""Orphaned replicas: "" + _orphaned)"	"<line46> logger.info(""Orphaned replicas: "" + _orphaned)"
task5	"<line5>      LOG.warn(""Can't commit a completed message."");"	<line4>	"LOG.trace(""Committing message {}"", messageToCommit)"	"<line4> LOG.trace(""Committing message {}"", messageToCommit)"
task5	"<line15>        logger.error(""[refresh]"", e);"	<line15>	"LOG.error(""Error loading migration event"", e)"	"<line15> LOG.error(""Error loading migration event"", e)"
task5	"<line5>      LOG.error(""Error while creating process log"", e);"	<line4>	log.error(e)	<line4> log.error(e)
task5	"<line2>    LOGGER.debug(""GET called on : {}"", arg0);"	<line6>	"logger.warn(""ServiceMap is empty!"")"	"<line6> logger.warn(""ServiceMap is empty!"")"
task5	"<line1>    log.debug(""findAllDataFileColumns() - dataFileId: {}"", dataFileId);"	<line1>	"log.debug(""findAllDataFileColumns() - dataFileId: {}"", dataFileId)"	"<line1> log.debug(""findAllDataFileColumns() - dataFileId: {}"", dataFileId)"
task5	"<line10>        log.warn(""update: remove failed for key: {0}"", toSpool.getKey());"	<line14>	"log.debug(""update: removed last element: "" + toSpool)"	"<line14> log.debug(""update: removed last element: "" + toSpool)"
task5	<line8>          log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line8>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line8> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	<line23>    logger.info(statusString);	<line23>	LOGGER.info(statusString)	<line23> LOGGER.info(statusString)
task5	"<line10>        log.info(""Failed to de-registering driver {}"", driver);"	<line10>	"this.logger.error(""Could not de-register JDBC driver {}"", driver.getClass().getName(), e)"	"<line10> this.logger.error(""Could not de-register JDBC driver {}"", driver.getClass().getName(), e)"
task5	"<line12>    logger.warn(""Unable to parse the long integer system property '{}':{} - using the default value: {}"",key,value,def);"	<line10>	"LOG.warn(key + "" with invalid value: "" + value, e)"	"<line10> LOG.warn(key + "" with invalid value: "" + value, e)"
task5	"<line3>    LOG.debug(""Calling OpenstackSwiftContainerResource.getAllShouldSucceed()"");"	<line3>	"LOG.debug(""Calling OpenstackKeystoneContainerResource.getAllShouldSucceed()"")"	"<line3> LOG.debug(""Calling OpenstackKeystoneContainerResource.getAllShouldSucceed()"")"
task5	"<line8>          LOG.warn(""[converLeadRecord] Couldn't find mapping for column {}."", f.name());"	<line8>	"LOG.debug(""No column mapping found for {}"", f.name())"	"<line8> LOG.debug(""No column mapping found for {}"", f.name())"
task5	"<line10>      logger.error(""Action=CreateQueue status=error exception="", e);"	<line10>	"logger.error(""event=create_queue error_code=failed"", e)"	"<line10> logger.error(""event=create_queue error_code=failed"", e)"
task5	"<line10>      logger.debug(""insert HostApplicationMap, host:{}, app:{},SType:{},parentApp:{},parentAppSType{}"",host,bindApplicationName,bindServiceType,parentApplicationName,parentServiceType);"	<line10>	"logger.debug(""insert() started. host: {}, bindApplicationName: {}, bindServiceType: {}, parentApplicationName:""+ "" {}, parentServiceType: {}"",host,bindApplicationName,bindServiceType,parentApplicationName,parentServiceType)"	"<line10> logger.debug(""insert() started. host: {}, bindApplicationName: {}, bindServiceType: {}, parentApplicationName:""+ "" {}, parentServiceType: {}"",host,bindApplicationName,bindServiceType,parentApplicationName,parentServiceType)"
task5	"<line4>        logger.trace(""Iterator not complete and there are results object is null, advancing"");"	<line4>	"logger.trace(""QueryResponseImpl.hasNext()"")"	"<line4> logger.trace(""QueryResponseImpl.hasNext()"")"
task5	"<line4>    LOGGER.info(""Server Profile Template object returned to client: {}"", template.toJsonString());"	<line4>	"LOGGER.info(""Server Profile Template object returned to client: {}"", template.toJsonString())"	"<line4> LOGGER.info(""Server Profile Template object returned to client: {}"", template.toJsonString())"
task5	"<line2>    log.info(""Generating POJO"", out.file().getName());"	<line4>	"log.info(""generated {}"", out.toString())"	"<line4> log.info(""generated {}"", out.toString())"
task5	"<line22>      log.error(""{}"", e);"	<line22>	"log.error("""", e)"	"<line22> log.error("""", e)"
task5	"<line12>    LOGGER.info(""got values {}"", values.toString());"	<line2>	"log.debug(""{} : {}"", this, values)"	"<line2> log.debug(""{} : {}"", this, values)"
task5	"<line8>      logger.info(""more accurate (""+ dfPercent.format(currentHighestAccuracy)+ "") class expression found after ""+ durationStr+ "": ""+ descriptionToString(bestEvaluatedDescriptions.getBest().getDescription()));"	<line8>	"logger.info(""Current highest accuracy: ""+ currentHighestAccuracy+ "" % (""+ bestEvaluatedDescriptions.getBestAccuracy()+ "" %), after ""+ expressionTests+ "" expression tests, ""+ ""in ""+ durationStr+ "" (""+ getDurationAsString(durationInMillis)+ "" ms)"")"	"<line8> logger.info(""Current highest accuracy: ""+ currentHighestAccuracy+ "" % (""+ bestEvaluatedDescriptions.getBestAccuracy()+ "" %), after ""+ expressionTests+ "" expression tests, ""+ ""in ""+ durationStr+ "" (""+ getDurationAsString(durationInMillis)+ "" ms)"")"
task5	"<line3>    LOG.debug(""[{}] SSE exception"", this);"	<line2>	"log.error(""Event chunked output exception"", exception)"	"<line2> log.error(""Event chunked output exception"", exception)"
task5	<line7>      LOG.error(e.getLocalizedMessage(), e);	<line7>	"LOG.error(""Could not create KeyInfo element"", e)"	"<line7> LOG.error(""Could not create KeyInfo element"", e)"
task5	"<line5>      log.error(""onStatus threw"", e);"	<line5>	"log.error(""Failed to fire event {}"", event, e)"	"<line5> log.error(""Failed to fire event {}"", event, e)"
task5	"<line8>    LOG.error(""schedule is not supported on Server.Please run your operation on Prism "");"	<line8>	"LOG.error(""schedule is not supported on Server.Please run your operation on Prism "")"	"<line8> LOG.error(""schedule is not supported on Server.Please run your operation on Prism "")"
task5	<line15>                  LOGGER.info(CALLED);	<line3>	"LOGGER.info(""Called"")"	"<line3> LOGGER.info(""Called"")"
task5	"<line2>    LOGGER.debug(""Browser window size was maximized!"");"	<line1>	"logger.debug(""Window maximized"")"	"<line1> logger.debug(""Window maximized"")"
task5	"<line4>      logger.debug(""Received an exception sending pdx type to pool {}, {}"",pool,serverConnectivityException.getMessage(),serverConnectivityException);"	<line4>	"logger.error(""ServerConnectivityException adding pdx type to pool"", serverConnectivityException)"	"<line4> logger.error(""ServerConnectivityException adding pdx type to pool"", serverConnectivityException)"
task5	"<line6>    logger.trace(""{}"", arg);"	<line6>	"logger.trace(""{}"", arg)"	"<line6> logger.trace(""{}"", arg)"
task5	"<line20>      log.error(""Unable to get asset entries"", exception);"	<line20>	log.error(exception, exception)	<line20> log.error(exception, exception)
task5	"<line7>    log.info(""TestOpenL: Elapsed time = {}."", System.currentTimeMillis() - t);"	<line4>	"LOG.info(""OpenL expression test took "" + (System.currentTimeMillis() - t) + "" ms"")"	"<line4> LOG.info(""OpenL expression test took "" + (System.currentTimeMillis() - t) + "" ms"")"
task5	"<line13>            logger.error(""Unable to open GPIO resource {}"", pin.getName(), e);"	<line13>	"logger.error(""Failed to open GPIO pin {}"", resourceName, e)"	"<line13> logger.error(""Failed to open GPIO pin {}"", resourceName, e)"
task5	"<line35>      log.debug(""Logged in as '"" + user + ""'"");"	<line35>	"logger.debug(""Login successful for user {}"", user)"	"<line35> logger.debug(""Login successful for user {}"", user)"
task5	"<line16>      LOG.error(""Error updating domain: {}"", domainException.getLocalizedMessage(), domainException);"	<line8>	"LOG.error(""Cannot update domain."", domainException)"	"<line8> LOG.error(""Cannot update domain."", domainException)"
task5	"<line15>        logger.debug(""Exception creating connection: "" + e);"	<line1>	"logger.info(""Opening serial port: {}"", port)"	"<line1> logger.info(""Opening serial port: {}"", port)"
task5	"<line12>      LOGGER.warn(""Cannot save output of time measuring: "" + ex.getMessage());"	<line12>	"log.warn(""Cannot save output of time measuring: "" + ex.getMessage())"	"<line12> log.warn(""Cannot save output of time measuring: "" + ex.getMessage())"
task5	"<line2>    log.info(""Finding document by id."");"	<line3>	"log.debug(""findDocumentByDocumentId: "" + documentId + "" - "" + document)"	"<line3> log.debug(""findDocumentByDocumentId: "" + documentId + "" - "" + document)"
task5	"<line15>        LOG.debug(""request finalize {}"", prevPartNotFinalized);"	<line21>	"LOG.debug(""File {} finalized"", fileName)"	"<line21> LOG.debug(""File {} finalized"", fileName)"
task5	"<line2>    LOGGER.trace(event.getPhaseId().toString() + "" - Before Phase"");"	<line3>	"LOG.debug(""Before phase: RESTORE_VIEW"")"	"<line3> LOG.debug(""Before phase: RESTORE_VIEW"")"
task5	"<line10>        log.debug(""Impossible to undelete document ""+ docRef+ "" as it does not support transition ""+ LifeCycleConstants.UNDELETE_TRANSITION);"	<line10>	"log.debug(""Stopping to restore deleted document "" + doc.getTitle() + "" because it is not possible"")"	"<line10> log.debug(""Stopping to restore deleted document "" + doc.getTitle() + "" because it is not possible"")"
task5	"<line13>      logger.error(""Failed to retrieve job process status for process "" + processId, ex);"	<line13>	"logger.error(""Failed to retrieve job process status for processId="" + processId, ex)"	"<line13> logger.error(""Failed to retrieve job process status for processId="" + processId, ex)"
task5	"<line8>        LOG.debug(""Request received error: {}"", result.getMessage());"	<line2>	"LOG.debug(""Provider failed: {}"", result)"	"<line2> LOG.debug(""Provider failed: {}"", result)"
task5	"<line16>    LOG.info(""Full Outer Join ("" + plan.getPID() + "") chooses [Hash Join]"");"	<line16>	"LOG.info(""Full Outer Join: Selected ""+ plan.getPID()+ "" as join executor, left executor ""+ selectedLeft.getPID()+ "", right executor ""+ selectedRight.getPID())"	"<line16> LOG.info(""Full Outer Join: Selected ""+ plan.getPID()+ "" as join executor, left executor ""+ selectedLeft.getPID()+ "", right executor ""+ selectedRight.getPID())"
task5	<line7>      LookupResource.LOG.error(message);	<line7>	BasicResource.LOG.debug(message)	<line7> BasicResource.LOG.debug(message)
task5	"<line10>        log.debug(""No applicable policy at "" + absPath);"	<line10>	log.debug(e.getMessage())	<line10> log.debug(e.getMessage())
task5	<line14>      log.error(exception, exception);	<line14>	log.error(exception, exception)	<line14> log.error(exception, exception)
task5	"<line18>    LOG.info(""Found at ""+ instantTime+ "" from CleanerPlan. #partitions_updated=""+ records.size()+ "", #files_deleted=""+ fileDeleteCount[0]);"	<line18>	"LOG.info(""Converted "" + fileDeleteCount[0] + "" file deletes into records"")"	"<line18> LOG.info(""Converted "" + fileDeleteCount[0] + "" file deletes into records"")"
task5	"<line12>        LOG.warn(""Cannot find managed bundle for added bundle "" + id + ""; ignoring"");"	<line12>	"log.warn(""Cannot find managed bundle "" + id + "" to persist it"	"<line12> log.warn(""Cannot find managed bundle "" + id + "" to persist it"
task5	"<line2>    logger.info(""Connection to Minecraft server stopped"");"	<line2>	"logger.debug(""Closing subscriber for {}"", this)"	"<line2> logger.debug(""Closing subscriber for {}"", this)"
task5	"<line2>      log.debug(""JBoss 6 VFS API is not available in this environment."");"	<line2>	"log.debug(""Setting VFS cache invalidator to true"")"	"<line2> log.debug(""Setting VFS cache invalidator to true"")"
task5	"<line6>        LOGGER.debug(""Routes: \n{}"", ModelHelper.dumpModelAsXml(camelContext, routes));"	<line6>	LOGGER.debug(camelContext.getRoutesAsXml())	<line6> LOGGER.debug(camelContext.getRoutesAsXml())
task5	<line33>      log.error(e);	<line33>	"log.error(""Unable to scan cardinalities"", e)"	"<line33> log.error(""Unable to scan cardinalities"", e)"
task5	"<line1>    log.debug(""Initializing Metadata Validation Timer"");"	<line3>	"log.debug(""Initializing timer with delay {} and interval {}"", delay, interval)"	"<line3> log.debug(""Initializing timer with delay {} and interval {}"", delay, interval)"
task5	"<line5>      logger.debug(""GetStorageStatsCommand on pool "" + cmd.getStorageId() + "" failed"", e);"	<line5>	"logger.debug(""Failed to get storage stats on host "" + _ip, e)"	"<line5> logger.debug(""Failed to get storage stats on host "" + _ip, e)"
task5	"<line3>      logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Writing Short {}"", value);"	<line3>	"logger.trace(LogMarker.SERIALIZER_VERBOSE, ""WriteShort {}"", value)"	"<line3> logger.trace(LogMarker.SERIALIZER_VERBOSE, ""WriteShort {}"", value)"
task5	"<line3>    logger.info(""Stopping processor [{}]"", name);"	<line3>	"log.info(""Stopping inbound event connector: {}"", this.getClass().getSimpleName())"	"<line3> log.info(""Stopping inbound event connector: {}"", this.getClass().getSimpleName())"
task5	"<line2>    LOGGER.debug(""KeyShareLength: "" + entry.getPublicKeyLength().getValue());"	<line2>	"LOGGER.debug(""PublicKeyLength: "" + entry.getPublicKeyLength().getValue())"	"<line2> LOGGER.debug(""PublicKeyLength: "" + entry.getPublicKeyLength().getValue())"
task5	"<line40>    logger.info(""Started redis cluster with mapped ports: {}"", translationMappings);"	<line40>	"logger.info(""Starting up redis cluster"")"	"<line40> logger.info(""Starting up redis cluster"")"
task5	"<line10>    logger.trace(String.format(""getting nodes: %s"", Joiner.on(',').join(toGet)));"	<line10>	"log.debug(String.format(""getting nodes: %s"", Joiner.on(',').join(toGet)))"	"<line10> log.debug(String.format(""getting nodes: %s"", Joiner.on(',').join(toGet)))"
task5	<line11>      log.error(exception, exception);	<line11>	log.error(exception, exception)	<line11> log.error(exception, exception)
task5	"<line12>      log.error(""Unable to add folder menu item"", exception);"	<line12>	log.error(exception, exception)	<line12> log.error(exception, exception)
task5	"<line2>    logger.error(""OAuth exception: "" + ex.getMessage());"	<line2>	"logger.error(""OAuth problem: "" + ex.getMessage(), ex)"	"<line2> logger.error(""OAuth problem: "" + ex.getMessage(), ex)"
task5	<line18>              log.error(e.getMessage(), e);	<line18>	"LOG.error(""Failed to instantiate component {}"", componentClass.getName(), e)"	"<line18> LOG.error(""Failed to instantiate component {}"", componentClass.getName(), e)"
task5	"<line2>    log.trace(""[{}] Processing edge {} event update "", tenantId, edgeId);"	<line10>	"log.trace(""PUSHING msg: {} to:{}"", msg, tpi)"	"<line10> log.trace(""PUSHING msg: {} to:{}"", msg, tpi)"
task5	"<line3>    logger.debug(""sendScreenshotMissingMessage to: {}"", username);"	<line3>	"logger.debug(""Send screenshot missing message for revision {} to {}"", messageId, username)"	"<line3> logger.debug(""Send screenshot missing message for revision {} to {}"", messageId, username)"
task5	"<line7>      LOGGER.trace(format(""Generate iterator for select : %s"",statementWrapper.getBoundStatement().preparedStatement().getQueryString()));"	<line7>	"LOGGER.trace(""StatementWrapper: {}"", statementWrapper)"	"<line7> LOGGER.trace(""StatementWrapper: {}"", statementWrapper)"
task5	"<line11>            log.debug(""Tick"");"	<line2>	"LOG.info(""testScheduler"")"	"<line2> LOG.info(""testScheduler"")"
task5	"<line4>        LOG.info(""Creating configuration store directory: {}"", storePath);"	<line6>	"LOG.info(""Config store initialized: {}"", storePath)"	"<line6> LOG.info(""Config store initialized: {}"", storePath)"
task5	<line7>      log.error(new IllegalStateException(_getDependentStringErrorMessage(WindowId.class)));	<line7>	"LOG.warn(""Unable to get portlet request from dependent string - windowId"")"	"<line7> LOG.warn(""Unable to get portlet request from dependent string - windowId"")"
task5	"<line2>    logger.info(""Scheduler msg timeout ""+ _originalMessage.getMsgId()+ "" timout with ""+ _timeout+ "" Ms"");"	<line2>	"log.error(""Task timeout"")"	"<line2> log.error(""Task timeout"")"
task5	"<line1>    LOGGER.info(""Create Provider {}"", sourceEvent.toString());"	<line1>	"LOGGER.info(""Create Provider {}"", sourceEvent.toString())"	"<line1> LOGGER.info(""Create Provider {}"", sourceEvent.toString())"
task5	"<line48>      logger.error(""Either check for network connection or table isn't in enabled state, Caused by:"", ioe);"	<line27>	"LOG.info(""column family {} does not exist in table {}"",tableInfo.getTableName(),databaseName)"	"<line27> LOG.info(""column family {} does not exist in table {}"",tableInfo.getTableName(),databaseName)"
task5	"<line11>      LOG.error(""Fail to set resource status, resource: "" + idealState.getResourceName(), e);"	<line11>	"LOG.error(""Failed to update resource state for {} due to {}"", resourceName, e.getMessage())"	"<line11> LOG.error(""Failed to update resource state for {} due to {}"", resourceName, e.getMessage())"
task5	"<line28>        log.warn(""Unexpected receipt response {} "", response);"	<line28>	"log.warn(""getReceiptByTransactionId(): precheck code '{}', receipt status '{}'"",preCheck,code)"	"<line28> log.warn(""getReceiptByTransactionId(): precheck code '{}', receipt status '{}'"",preCheck,code)"
task5	"<line4>        logger.debug(""key matches usagesKeyPattern, add the value as usage"");"	<line5>	"log.warn(""Adding usage {} to {}"", value, currentKeyName)"	"<line5> log.warn(""Adding usage {} to {}"", value, currentKeyName)"
task5	"<line24>        LOG.warn(""Task {} is missing port but is being passed to LB  ({})"", task.getTaskId(), task);"	<line24>	"LOG.warn(""Failed to find load balancer port for task {}"", task)"	"<line24> LOG.warn(""Failed to find load balancer port for task {}"", task)"
task5	"<line2>    logger.info(""### Create Cache Server. ###"");"	<line2>	"logger.info(""Starting CQDUnitTest"")"	"<line2> logger.info(""Starting CQDUnitTest"")"
task5	"<line34>        log.info(""Starting: "" + msg);"	<line39>	"log.error(""Failed on: "" + msg)"	"<line39> log.error(""Failed on: "" + msg)"
task5	"<line13>          logger.info(""Overwriting existing file {} because import file is newer."", entry.getName());"	<line17>	"LOG.info(""Overwriting "" + newFile.getAbsolutePath())"	"<line17> LOG.info(""Overwriting "" + newFile.getAbsolutePath())"
task5	"<line12>      LOG.trace(""Backpressure happens: in flight {} limit {}"",appendEntryLimiter.getInflight(),appendEntryLimiter.getLimit());"	<line12>	"LOG.error(""Unable to acquire entry limit, deferring append"")"	"<line12> LOG.error(""Unable to acquire entry limit, deferring append"")"
task5	"<line7>        LOGGER.debug(""New mail - sender: {}, recipients: {}, name: {}, remoteHost: {}, remoteAddr: {},""+ "" state: {}, lastUpdated: {}, errorMessage: {}"",newMail.getMaybeSender(),newMail.getRecipients(),newMail.getName(),newMail.getRemoteHost(),newMail.getRemoteAddr(),newMail.getState(),newMail.getLastUpdated(),newMail.getErrorMessage());"	<line7>	"LOGGER.info(""Processing bounce for mail: {}"", newMail.getName())"	"<line7> LOGGER.info(""Processing bounce for mail: {}"", newMail.getName())"
task5	"<line29>    logger.info(""Runtime took {} milliseconds to search"", endTime - startTime);"	<line29>	"logger.debug(""Search for \""location within 1000 of 48.38626, 9.94175\"" took {} ms"",endTime - startTime)"	"<line29> logger.debug(""Search for \""location within 1000 of 48.38626, 9.94175\"" took {} ms"",endTime - startTime)"
task5	"<line5>      log.info(""Score at iteration {} is {}"", iteration, score);"	<line5>	"log.info(""Iteration ""+ iteration+ "" done. Score: ""+ score+ "" Loss: ""+ model.getLoss()+ "" Epoch: ""+ epoch)"	"<line5> log.info(""Iteration ""+ iteration+ "" done. Score: ""+ score+ "" Loss: ""+ model.getLoss()+ "" Epoch: ""+ epoch)"
task5	"<line11>      logger.info(""Changed last login column to allow NULL values. Please verify the registration feature ""+ ""if you are hooking into a forum."");"	<line10>	logger.debug(sql)	<line10> logger.debug(sql)
task5	<line4>      log.error(formattingTuple.getMessage(), formattingTuple.getThrowable());	<line4>	log.error(formattingTuple.getMessage(), formattingTuple.getThrowable())	<line4> log.error(formattingTuple.getMessage(), formattingTuple.getThrowable())
task5	"<line4>      log.warn(""Task '"" + taskId + ""' not found"");"	<line4>	"log.warn(""Task '"" + taskId + ""' not found"")"	"<line4> log.warn(""Task '"" + taskId + ""' not found"")"
task5	<line16>      log.error(ex.toString());	<line16>	"log.error(""Error while reading CF parameter file: "" + ex.getMessage())"	"<line16> log.error(""Error while reading CF parameter file: "" + ex.getMessage())"
task5	<line9>        log.debug(exception, exception);	<line9>	log.debug(exception, exception)	<line9> log.debug(exception, exception)
task5	"<line2>    LOG.info(""Starting Recon Task Controller."");"	<line2>	"LOGGER.info(""Starting the executor service."")"	"<line2> LOGGER.info(""Starting the executor service."")"
task5	<line12>      log.error(e.getMessage(), e);	<line12>	"log.error(""Error initialising country/state province centres"", e)"	"<line12> log.error(""Error initialising country/state province centres"", e)"
task5	<line33>      log.error(exception, exception);	<line33>	log.error(exception, exception)	<line33> log.error(exception, exception)
task5	"<line2>    logger.trace(""Getting sample metadata for "" + sampleId);"	<line2>	"logger.debug(""Getting metadata for sample "" + sampleId)"	"<line2> logger.debug(""Getting metadata for sample "" + sampleId)"
task5	"<line4>        logger.debug(""processing QueueSynchronizationMessage region {} does not exist."", regionName);"	<line4>	"logger.debug(""Unable to find region "" + regionName)"	"<line4> logger.debug(""Unable to find region "" + regionName)"
task5	"<line4>      LOG.warn(""Graph transaction commit failed: {}; attempting to rollback graph transaction."", ex);"	<line5>	"LOGGER.error(""Graph commit failed"", ex)"	"<line5> LOGGER.error(""Graph commit failed"", ex)"
task5	"<line32>              log.error(""Error occurred"", exc);"	<line32>	"log.error(""write() failed"", exc)"	"<line32> log.error(""write() failed"", exc)"
task5	"<line9>      LOG.warn(""Failed to verify local attachment file"", e);"	<line9>	"log.error(""Error fetching attachment from db."", e)"	"<line9> log.error(""Error fetching attachment from db."", e)"
task5	"<line3>    logger.debug(""Updating config group: "" + confGroup);"	<line11>	"logger.error(""Error updating config group"", e)"	"<line11> logger.error(""Error updating config group"", e)"
task5	"<line6>      this.logger.warn(""land workAt None mode, so land cannot be started."");"	<line8>	"logger.info(""land work at: {}"", workMode)"	"<line8> logger.info(""land work at: {}"", workMode)"
task5	"<line3>    this.logger.info(""Rx: onServiceStartedEvent: event="" + event + "", serviceID="" + serviceID);"	<line3>	"logger.info(""onServiceStartedEvent: {}"", serviceID.getServiceName())"	"<line3> logger.info(""onServiceStartedEvent: {}"", serviceID.getServiceName())"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line4>      LOGGER.error(""Model tracking failed for core: {}"", coreName, t);"	<line4>	"logger.warn(""Error ensuring first model sync"", t)"	"<line4> logger.warn(""Error ensuring first model sync"", t)"
task5	"<line14>      logger.error(""Error extracting the allowed types of attribute elements"", t);"	<line14>	"logger.error(""Error extracting the allowed types of attribute elements"", t)"	"<line14> logger.error(""Error extracting the allowed types of attribute elements"", t)"
task5	"<line13>    logger.debug(""Deleting a named, parametrized Query with ID ({})."", queryId);"	<line13>	"logger.debug(""DELETE /named-queries/parameterized/{queryId}"")"	"<line13> logger.debug(""DELETE /named-queries/parameterized/{queryId}"")"
task5	"<line22>    logger.debug(""Select filtered application map elapsed. {}ms"", watch.getTotalTimeMillis());"	<line22>	"logger.info(""selectApplicationMapWithScatterData took "" + watch.taken())"	"<line22> logger.info(""selectApplicationMapWithScatterData took "" + watch.taken())"
task5	<line17>        log.debug(exception, exception);	<line17>	log.debug(exception, exception)	<line17> log.debug(exception, exception)
task5	<line13>        log.debug(exception, exception);	<line13>	log.debug(exception, exception)	<line13> log.debug(exception, exception)
task5	"<line3>      LOG.error(""Already registered: "" + listener);"	<line3>	"LOG.error(""Listener ""+ listener+ "" already registered as document listener for ""+ this+ "". Registered listeners are ""+ getListeners())"	"<line3> LOG.error(""Listener ""+ listener+ "" already registered as document listener for ""+ this+ "". Registered listeners are ""+ getListeners())"
task5	"<line53>      logger.debug(""Unable to initialize local storage pool: "" + e);"	<line53>	"logger.warn(""Failed to create local storage pool on startup"", e)"	"<line53> logger.warn(""Failed to create local storage pool on startup"", e)"
task5	<line18>      log.error(systemException, systemException);	<line18>	log.error(systemException, systemException)	<line18> log.error(systemException, systemException)
task5	"<line6>        LOG.debug(""State get for {} {} {} {}"",pTransformId,userStateId,Arrays.toString(keyedStateBackend.getCurrentKey().array()),window);"	<line6>	"LOG.debug(""Reading user state for key {} from {}"", key, namespace)"	"<line6> LOG.debug(""Reading user state for key {} from {}"", key, namespace)"
task5	<line3>      logger.debug(LogUtil.getMsg(msg), obj);	<line3>	logger.debug(LogUtil.getMsg(msg), obj)	<line3> logger.debug(LogUtil.getMsg(msg), obj)
task5	"<line2>    logger.debug(""Rollback Conn Transaction"");"	<line2>	"logger.debug(""Rollback"")"	"<line2> logger.debug(""Rollback"")"
task5	"<line39>        log.warn(""alias fail, missing "" + LessStrings.join(p, "" / ""));"	<line39>	"log.debug(String.format(""Failed to locate node: %s"", name))"	"<line39> log.debug(String.format(""Failed to locate node: %s"", name))"
task5	"<line6>      log.debug(""Set start loop point of Buffer {} to {}"", this.getSystemName(), startLoopPoint);"	<line6>	"log.debug(""Set start loop point of Buffer {} to {}"", this.getSystemName(), startLoopPoint)"	"<line6> log.debug(""Set start loop point of Buffer {} to {}"", this.getSystemName(), startLoopPoint)"
task5	"<line10>    log.debug(""Find documents: collection: %s, filter: %s, projection: %s"",tableHandle.getSchemaTableName(), query.toJson(), output.toJson());"	<line8>	"log.debug(""Executing query for table %s with projection %s"",tableHandle.getSchemaTableName(), output)"	"<line8> log.debug(""Executing query for table %s with projection %s"",tableHandle.getSchemaTableName(), output)"
task5	"<line15>        logger.warn(""Could not handle {} for {}"", ((TellstickDevice) device).getStatus(), device);"	<line15>	"LOG.warn(""Could not handle {} for {}"", (((TellstickDevice) device).getStatus())), device)"	"<line15> LOG.warn(""Could not handle {} for {}"", (((TellstickDevice) device).getStatus())), device)"
task5	"<line6>          LOGGER.warn(""Can't load driver file \""""+ d+ ""\""""+ (ioe.getMessage() != null ? "", reason: "" + ioe.getMessage() : "".""));"	<line6>	"log.info(""Unable to load database driver from file {}"", d)"	"<line6> log.info(""Unable to load database driver from file {}"", d)"
task5	"<line2>    LOG.info(""Load output dir: "" + outputDir);"	<line2>	"LOG.info(""Loading data to target table with numMapTasks="" + conf.getInt(NUM_MAP_TASKS_KEY, NUM_MAP_TASKS_DEFAULT))"	"<line2> LOG.info(""Loading data to target table with numMapTasks="" + conf.getInt(NUM_MAP_TASKS_KEY, NUM_MAP_TASKS_DEFAULT))"
task5	<line20>      log.error(systemException, systemException);	<line20>	log.error(systemException, systemException)	<line20> log.error(systemException, systemException)
task5	<line18>          LOG.error(e.getMessage(), e);	<line18>	"LOG.error(""Error exporting data for record summary "" + s.getId(), e)"	"<line18> LOG.error(""Error exporting data for record summary "" + s.getId(), e)"
task5	<line13>        log.debug(sb.toString());	<line13>	log.debug(sb.toString())	<line13> log.debug(sb.toString())
task5	"<line4>    logger.info(""Disabling scheduling via the management service."");"	<line4>	"log.info(""Disabling scheduling"")"	"<line4> log.info(""Disabling scheduling"")"
task5	"<line1>    LOGGER.debug(""Get {}"", id);"	<line1>	"LOGGER.debug(""Get group by id: {}"", id)"	"<line1> LOGGER.debug(""Get group by id: {}"", id)"
task5	"<line8>      log.trace(""message [ID: {}, address: {}] accepted by peer"", messageId, messageAddress);"	<line7>	"log.trace(""message sent: {}"", message)"	"<line7> log.trace(""message sent: {}"", message)"
task5	"<line4>      LOG.debug(""Sleeping, i = {}"", i);"	<line5>	"LOG.info(""Waiting for {}"", FILE_PATH)"	"<line5> LOG.info(""Waiting for {}"", FILE_PATH)"
task5	"<line2>    logger.info(""Found existing servers matching the name: "" + managementMachinePrefix);"	<line15>	"log.info(""Existing management servers are: "" + serverDescriptions)"	"<line15> log.info(""Existing management servers are: "" + serverDescriptions)"
task5	"<line2>    logger.debug(""XATerminator set."");"	<line1>	"LOG.debug(""Setting XATerminator to {}"", terminator)"	"<line1> LOG.debug(""Setting XATerminator to {}"", terminator)"
task5	"<line7>        logger.error(""An error occurred whilst redoing the last set of undone changes."", e);"	<line7>	"logger.error(""An error occurred whilst attempting to redo the last set of changes."", e)"	"<line7> logger.error(""An error occurred whilst attempting to redo the last set of changes."", e)"
task5	"<line5>      log.debug(""val="" + val + "" is not a valid number.  Fudge factor will be 0 seconds"");"	<line5>	"log.warn(""Could not parse agent.dsl.fudge property, using default value of 0"")"	"<line5> log.warn(""Could not parse agent.dsl.fudge property, using default value of 0"")"
task5	<line6>      log.error(exception, exception);	<line6>	log.error(exception, exception)	<line6> log.error(exception, exception)
task5	"<line7>      LOG.error(""Unable to set task as running in recovery db: SQLState: {} Error: {}"",e.getSQLState(),e.getMessage());"	<line7>	"LOGGER.error(""Could not update task state in database"", e)"	"<line7> LOGGER.error(""Could not update task state in database"", e)"
task5	"<line12>                logger.debug(""{}"", this);"	<line39>	"logger.info(""testSequence end"")"	"<line39> logger.info(""testSequence end"")"
task5	"<line3>      logger.error(""Null content"");"	<line3>	"logger.error(""Null content"")"	"<line3> logger.error(""Null content"")"
task5	"<line10>    LOG.debug(""model: {}"", changedModel);"	<line10>	"LOG.debug(""model: {}"", changedModel)"	"<line10> LOG.debug(""model: {}"", changedModel)"
task5	"<line2>    LOG.error(""Failed to stop Container "" + containerId);"	<line2>	"log.error(""Failed to stop Container "" + containerId, t)"	"<line2> log.error(""Failed to stop Container "" + containerId, t)"
task5	"<line5>      LOG.error(""Error in getChildren()"", e);"	<line5>	"log.error(""Error while getting children of GefaehrdungsBaumElement"", e)"	"<line5> log.error(""Error while getting children of GefaehrdungsBaumElement"", e)"
task5	"<line9>        log.info(""dropping latest partition from fact storage table: {}. Spec: {}"",storageTableName,partition.getSpec());"	<line9>	"log.info(""Skipping the latest partition. It will be loaded separately."")"	"<line9> log.info(""Skipping the latest partition. It will be loaded separately."")"
task5	"<line11>      LOG.error(""jar file with reports not found"", ex);"	<line11>	"LOG.error(""Failed to find template directory"", ex)"	"<line11> LOG.error(""Failed to find template directory"", ex)"
task5	"<line2>      logger.debug(""Canceling old scheduled job"");"	<line5>	"log.debug(""Scheduling job to update processor time"")"	"<line5> log.debug(""Scheduling job to update processor time"")"
task5	<line12>      LOG.error(I18n.err(I18n.ERR_132, key, value, name), ioe);	<line12>	LOG.error(ioe.getMessage(), ioe)	<line12> LOG.error(ioe.getMessage(), ioe)
task5	"<line2>    LOGGER.info(""Opening session"");"	<line2>	"LOGGER.debug(""Run Cypher query: {}"", cypherQuery)"	"<line2> LOGGER.debug(""Run Cypher query: {}"", cypherQuery)"
task5	"<line28>          logger.error(""Failed to close JMS connection: "", e);"	<line28>	"LOG.error(""Failed to close JMS connection"", e)"	"<line28> LOG.error(""Failed to close JMS connection"", e)"
task5	"<line5>      logger.debug(""Set header {}={}"", name, value);"	<line5>	"logger.debug(""Set header {}={}"", name, value)"	"<line5> logger.debug(""Set header {}={}"", name, value)"
task5	"<line16>    LOG.info(""DATA: "" + dataAsJson);"	<line16>	"LOG.info(""dataAsJson = {}"", dataAsJson)"	"<line16> LOG.info(""dataAsJson = {}"", dataAsJson)"
task5	"<line2>      LOG.debug(""Initializing autoflush handler on channel {}"", ctx.channel());"	<line2>	"LOG.debug(""Initializing the writer idle timeout handler"")"	"<line2> LOG.debug(""Initializing the writer idle timeout handler"")"
task5	"<line33>      logger.error(""getMessageById error"", e);"	<line33>	"logger.error(""getMessageById error"", e)"	"<line33> logger.error(""getMessageById error"", e)"
task5	"<line19>          LOGGER.debug(""optionalMap: {}"", optionalMap);"	<line17>	"LOGGER.info(""Waiting for node state to change"")"	"<line17> LOGGER.info(""Waiting for node state to change"")"
task5	"<line4>      log.debug(String.format(""Run with feature %s"", feature));"	<line4>	"log.debug(String.format(""Run with feature %s"", feature))"	"<line4> log.debug(String.format(""Run with feature %s"", feature))"
task5	"<line16>    LOG.info(""Successfully fetched consent status entity for bic={}, consentId={}"",getXS2AStandard().getAspsp().getBic(),consentId);"	<line16>	"LOG.info(""Successfully fetched consent status for bic={}, consentId={}"",getXS2AStandard().getAspsp().getBic(),consentId)"	"<line16> LOG.info(""Successfully fetched consent status for bic={}, consentId={}"",getXS2AStandard().getAspsp().getBic(),consentId)"
task5	"<line5>    logger.debug(""CatchAllFilter [""+ displayPath+ ""] received provided allowed context paths from NiFi properties: ""+ getAllowedContextPaths());"	<line5>	"logger.debug(""displayPath: "" + displayPath)"	"<line5> logger.debug(""displayPath: "" + displayPath)"
task5	"<line33>    log.info(""trips="" + totalTrips + "" withoutStopTimes="" + tripsWithoutStopTimes);"	<line37>	"log.info(""getTripsByBlockInSortedOrder: trips without stopTimes = "" + tripsWithoutStopTimes)"	"<line37> log.info(""getTripsByBlockInSortedOrder: trips without stopTimes = "" + tripsWithoutStopTimes)"
task5	"<line3>      log.info(""Iteration: "" + i);"	<line13>	"log.info(""Test iteration: "" + i)"	"<line13> log.info(""Test iteration: "" + i)"
task5	"<line7>    LOG.info(""Activating Netconf channel for {} with {}"", getRemoteAddress(), listener);"	<line2>	"LOG.debug(""Activating session on channel {}"", ch)"	"<line2> LOG.debug(""Activating session on channel {}"", ch)"
task5	"<line7>      LOG.info(ScriptEngineManager.class.getName() + "" initialized in "" + (end - start) + "" ms"");"	<line7>	"LOG.info(""Loaded script engine manager in "" + (end - start) + "" ms"")"	"<line7> LOG.info(""Loaded script engine manager in "" + (end - start) + "" ms"")"
task5	<line4>    LOGGER.info(messageBuilder.append(cleanAndEncode(message)).toString(), paramSuppliers);	<line4>	log.info(messageBuilder.append(cleanAndEncode(message)).toString(), paramSuppliers)	<line4> log.info(messageBuilder.append(cleanAndEncode(message)).toString(), paramSuppliers)
task5	"<line6>        LOGGER.error(""Unable to parse custom height value: "" + e.getMessage());"	<line6>	"LOGGER.error(""Failed to parse custom height."", e)"	"<line6> LOGGER.error(""Failed to parse custom height."", e)"
task5	"<line4>      LOGGER.warn(""Failed to close Kie Server Controller Client due to: "" + ex.getMessage(), ex);"	<line4>	"logger.warn(""Could not close client"", ex)"	"<line4> logger.warn(""Could not close client"", ex)"
task5	<line26>      log.error(systemException, systemException);	<line26>	log.error(systemException, systemException)	<line26> log.error(systemException, systemException)
task5	"<line6>        log.info(""BrokerName {}, topicName {}, queueId {} is pause, Discard the message {}"",messageQueue.getBrokerName(),messageQueue.getTopic(),message.getQueueId(),msgId);"	<line6>	"log.info(""Removing msgId: {} from pause queue of topic: {}"", msgId, topic)"	"<line6> log.info(""Removing msgId: {} from pause queue of topic: {}"", msgId, topic)"
task5	"<line2>    LOGGER.info(""RiakHttpClient.start {}"", config);"	<line2>	"LOG.info(""Starting riak client"")"	"<line2> LOG.info(""Starting riak client"")"
task5	"<line9>    log.debug(""cacheKey:{} LessThanFilter:{} percentiles[{}] = {} multiplier: {}"",cacheKey,lessThanFilter,minBound,percentiles[minBound],result);"	<line9>	"log.debug(""cacheKey:{} LessThanFilter:{} percentiles[{}] = {} multiplier: {}"",cacheKey,lessThanFilter,minBound,result)"	"<line9> log.debug(""cacheKey:{} LessThanFilter:{} percentiles[{}] = {} multiplier: {}"",cacheKey,lessThanFilter,minBound,result)"
task5	"<line6>      log.error(e, ""Error reloading configuration"");"	<line6>	"log.error(e, ""unable to fetch session match specs from database"")"	"<line6> log.error(e, ""unable to fetch session match specs from database"")"
task5	<line7>        LOGGER.error(e, e);	<line7>	logger.error(e.getMessage(), e)	<line7> logger.error(e.getMessage(), e)
task5	<line37>      log.error(exception, exception);	<line37>	log.error(exception, exception)	<line37> log.error(exception, exception)
task5	"<line1>    logger.info(""stopping bus ..."");"	<line1>	"logger.info(""Stopping {}"", this)"	"<line1> logger.info(""Stopping {}"", this)"
task5	"<line7>      log.debug(""Use default invitation type = "" + InvitationType.REGISTRATION.toString());"	<line7>	"LOGGER.warn(""Invitation type is null. Defaulting to registration."")"	"<line7> LOGGER.warn(""Invitation type is null. Defaulting to registration."")"
task5	"<line2>    JpqlQuery.LOG.debug(""Parsed query successfully {0}"",JpqlQuery.LOG.lazyBoxed(this.qlString, new Object[] {tree.toStringTree()}));"	<line2>	"log.debug(""Parsed: "" + tree)"	"<line2> log.debug(""Parsed: "" + tree)"
task5	"<line5>          log.debug(""Closing file handle "" + this);"	<line5>	"log.debug(""close("" + this.path + "")"")"	"<line5> log.debug(""close("" + this.path + "")"")"
task5	"<line4>      logger.error(""Get file list exception"", e);"	<line4>	"log.error(""Get file list exception"", e)"	"<line4> log.error(""Get file list exception"", e)"
task5	"<line24>      log.error(String.format(""Unable to get the output parameters for data provider "" + ""instance with id '%d'"",dataProviderInstanceId),exception);"	<line24>	log.error(exception, exception)	<line24> log.error(exception, exception)
task5	"<line26>      logger.error(""Error when trying to encrypt using asymmetric key. Please check the following:\n""+ ""\t- Does the application use an IAM role?\n""+ ""\t- Does the application's role have the permission to use the CMK the value was""+ "" encrypted with?\n""+ ""More information on that topic:""+ "" https://confluence.in.here.com/display/CMECMCPDOWS/Encryption+of+secrets"",e);"	<line26>	"logger.error(""Encryption error : "" + e.getMessage())"	"<line26> logger.error(""Encryption error : "" + e.getMessage())"
task5	"<line10>    LOG.info(""Running with ""+ numberOfClients+ "" clients - sending ""+ numberOfBatches+ "" batches of ""+ batchSize+ "" messages"");"	<line30>	"LOG.info(""Next client destination: "" + outDestination)"	"<line30> LOG.info(""Next client destination: "" + outDestination)"
task5	<line4>      log.debug(ex.getMessage());	<line4>	"logger.warn(""Error while executing SQL script: "" + sql, ex)"	"<line4> logger.warn(""Error while executing SQL script: "" + sql, ex)"
task5	"<line16>      logger.debug(""done..."");"	<line20>	"log.debug(""Exception: "", e)"	"<line20> log.debug(""Exception: "", e)"
task5	"<line21>      LOG.error(""Failed to read report with id {}"", reportId, e);"	<line25>	"LOG.error(String.format(""Failed to read report with id %s"", reportId), e)"	"<line25> LOG.error(String.format(""Failed to read report with id %s"", reportId), e)"
task5	"<line16>        logger.debug(""Could not reevaluate key for hash index"");"	<line16>	"logger.debug(""Could not reevaluate key for hash index"", e)"	"<line16> logger.debug(""Could not reevaluate key for hash index"", e)"
task5	"<line8>      log.debug(""Ignoring expected exception during 1-phase prepare"", e);"	<line8>	"log.info(""Expected exception: "" + e)"	"<line8> log.info(""Expected exception: "" + e)"
task5	"<line9>    log.info(LogManager.getHeader(context, ""load_bitstream_formats"", ""number_loaded="" + typeNodes.getLength()));"	<line3>	"logger.info(""Loading bitstream formats from "" + filename)"	"<line3> logger.info(""Loading bitstream formats from "" + filename)"
task5	"<line2>      log.trace(""menuKeyEquivalentTarget_forEvent:"" + menu);"	<line2>	"log.trace(""menuKeyEquivalentTarget_forEvent:"" + menu)"	"<line2> log.trace(""menuKeyEquivalentTarget_forEvent:"" + menu)"
task5	<line10>        log.info(records);	<line10>	"log.info(""Verbose logging for contract records RPC: {}"", response)"	"<line10> log.info(""Verbose logging for contract records RPC: {}"", response)"
task5	<line25>    log.info(json);	<line25>	log.info(json)	<line25> log.info(json)
task5	"<line6>        logger.debug(""bound {}->{}"", boundSize, i);"	<line8>	"LOG.info(""Maximum size of a var32 integer is: {}"", boundSize)"	"<line8> LOG.info(""Maximum size of a var32 integer is: {}"", boundSize)"
task5	"<line10>              LOGGER.error(""Failed to delete SSO auth lines from auth index table"", e);"	<line10>	"LOG.error(""Exception adding jobs: "" + e, e)"	"<line10> LOG.error(""Exception adding jobs: "" + e, e)"
task5	"<line12>                    logger.warn(""Exception at getUserLists"", e);"	<line12>	"logger.warn(""Exception at getUserLists"", e)"	"<line12> logger.warn(""Exception at getUserLists"", e)"
task5	"<line7>    LOG.info(""ZeppelinHub REST API saving note {} "", note.getId());"	<line7>	"LOG.info(""ZeppelinHub REST API saving note {} "", jsonNote)"	"<line7> LOG.info(""ZeppelinHub REST API saving note {} "", jsonNote)"
task5	"<line6>      logger.info(""Failed to initialize LOG4J with xml file."");"	<line6>	"LOG.error(""Error while configuring LOG4J from "" + Log4jURL, e)"	"<line6> LOG.error(""Error while configuring LOG4J from "" + Log4jURL, e)"
task5	<line7>      log.error(exception, exception);	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	"<line32>          LOG.warn(""Unable to convert response headers to MantaHttpHeaders"", e);"	<line32>	"LOGGER.warn(""Unable to extract response headers"", re)"	"<line32> LOGGER.warn(""Unable to extract response headers"", re)"
task5	"<line4>    LOG.trace(""Removing procedure {} from offering {}"", procedure, offering);"	<line4>	"LOG.trace(""Removing procedure {} from offering {}"", procedure, offering)"	"<line4> LOG.trace(""Removing procedure {} from offering {}"", procedure, offering)"
task5	"<line5>    log.info(Color.GREEN + ""Transfer_4_1 : missing column min_transfer_time"" + Color.NORMAL);"	<line5>	"log.info(Color.GREEN + ""Transfer_4_1 : missing column min_transfer_time"" + Color.NORMAL)"	"<line5> log.info(Color.GREEN + ""Transfer_4_1 : missing column min_transfer_time"" + Color.NORMAL)"
task5	"<line36>        logger.info(""Waiting for partitioning tasks to complete: "" + taskCount.get());"	<line39>	"logger.info(""Tenant partition creation did not complete"")"	"<line39> logger.info(""Tenant partition creation did not complete"")"
task5	"<line20>      log.warn(""The matrix contains singular elements. Check S matrix at row "" + INFO.getInt(0));"	<line20>	"log.warn(""Parameter #"" + INFO.getInt(0) + "" to gesvd() was not valid"")"	"<line20> log.warn(""Parameter #"" + INFO.getInt(0) + "" to gesvd() was not valid"")"
task5	"<line2>    logger.debug(""Initializing RME handler."");"	<line14>	"log.info(""Initializing thing with configuration: {}"", getConfig())"	"<line14> log.info(""Initializing thing with configuration: {}"", getConfig())"
task5	<line8>    LOG.info(deserializeRpc.toString());	<line8>	LOG.info(deserializeRpc.toString())	<line8> LOG.info(deserializeRpc.toString())
task5	"<line1>    logger.debug(""Closing connection to the heat pump"");"	<line1>	"logger.debug(""Closing connection to Facebook"")"	"<line1> logger.debug(""Closing connection to Facebook"")"
task5	"<line39>      LOG.warn(""Can't get the current value for {}, from {}-{}"", me.getId(), startTime, endTime, e);"	<line39>	"LOG.warn(""Failed to load the current value for the metric slice {}"", currentSlice, e)"	"<line39> LOG.warn(""Failed to load the current value for the metric slice {}"", currentSlice, e)"
task5	"<line23>      log.error(""unexpected key/value types: ""+ k.getClass().getCanonicalName()+ "" and ""+ v.getClass().getCanonicalName());"	<line13>	"log.warn(""Unparseable report: "" + e)"	"<line13> log.warn(""Unparseable report: "" + e)"
task5	"<line11>      LOG.warn(""there isn't a logged user for:"" + loginName, e);"	<line11>	"LOG.info(""There is no user found with login name {}."", loginName)"	"<line11> LOG.info(""There is no user found with login name {}."", loginName)"
task5	"<line26>      LOG.error(""Exception while processing tuple"", e);"	<line24>	"LOG.warn(""Exception in parsing pcap alerts"", e)"	"<line24> LOG.warn(""Exception in parsing pcap alerts"", e)"
task5	"<line5>        logger.warn(LogMessage.format(""Failed to bind Hikari metrics: %s"", ex.getMessage()));"	<line5>	"log.warn(""Micrometer MetricsTrackerFactory creation failed."", ex)"	"<line5> log.warn(""Micrometer MetricsTrackerFactory creation failed."", ex)"
task5	"<line22>        this.logger.debug(""Found function for POST: "" + path);"	<line22>	"this.logger.debug(""Handler function: {}"", function)"	"<line22> this.logger.debug(""Handler function: {}"", function)"
task5	"<line4>      LOG.warn(""Connection close fails when migrates state from {} to CLOSED"", getZkState());"	<line4>	"LOG.error(""Failed to close client for session: 0x{}"", Long.toHexString(getSessionId()), e)"	"<line4> LOG.error(""Failed to close client for session: 0x{}"", Long.toHexString(getSessionId()), e)"
task5	"<line8>        log.warn(""Could not fetch partitions for topic/stream [%s]"", getIoConfig().getStream());"	<line19>	"log.info(""Seeked to latest on partitions {}"", partitions)"	"<line19> log.info(""Seeked to latest on partitions {}"", partitions)"
task5	"<line13>        LOGGER.warn(""Exporting the csar failed with an exception"", e);"	<line2>	"log.info(""Exporting Winery to CSAR at {}"", targetPath)"	"<line2> log.info(""Exporting Winery to CSAR at {}"", targetPath)"
task5	"<line1>    log.info(""Stopping forcefully (status: [%s])"", status);"	<line1>	"log.info(""Stop forcefully requested"")"	"<line1> log.info(""Stop forcefully requested"")"
task5	"<line2>    log.info(""------  testBlackListMultiValueIncluded  ------"");"	<line2>	"log.info(""------  testBlackListMultiValueIncluded  ------"")"	"<line2> log.info(""------  testBlackListMultiValueIncluded  ------"")"
task5	<line2>      LOG.warn(INVALID_REASON, what.get(), reason.get());	<line2>	LOG.warn(INVALID_REASON, what.get(), reason.get())	<line2> LOG.warn(INVALID_REASON, what.get(), reason.get())
task5	"<line25>        logger.debug(""Copying ""+ script.getPath()+ "" to ""+ s_ovsAgentPath+ "" on ""+ _ip+ "" with permission 0644"");"	<line25>	"logger.debug(String.format(""Copying script %s to ovm host %s"", script.getPath(), _ip))"	"<line25> logger.debug(String.format(""Copying script %s to ovm host %s"", script.getPath(), _ip))"
task5	"<line4>    logger.info(""Preparing to create tracker file for {} at {}"", fileToRoll, dest);"	<line15>	"LOG.debug(""Rolled current file to: {}"", dest)"	"<line15> LOG.debug(""Rolled current file to: {}"", dest)"
task5	"<line7>      log.warn(""Failed to terminate monitor executor service."");"	<line7>	"log.warn(""Pool did not terminate"")"	"<line7> log.warn(""Pool did not terminate"")"
task5	"<line34>      LOG.info(""Result: "" + counter + "" = "" + record);"	<line2>	"LOG.info(""Testing header and trailer"")"	"<line2> LOG.info(""Testing header and trailer"")"
task5	"<line3>      LOG.debug(""["" + id_ + ""] moveTo("" + x + "", "" + y + "")"");"	<line3>	"LOG.debug(""["" + id_ + ""] moveTo("" + x + "", "" + y + "")"")"	"<line3> LOG.debug(""["" + id_ + ""] moveTo("" + x + "", "" + y + "")"")"
task5	"<line16>      log.debug(""Total bytes read {}"", totalCount);"	<line16>	"LOG.info(""Received {} bytes"", totalCount)"	"<line16> LOG.info(""Received {} bytes"", totalCount)"
task5	"<line10>      logger.warn(""Could not find selection '{}' in mapping {} of device {}"",value,device.getMapping(),device);"	<line10>	"logger.warn(""No mapping found for value '{}'"", value)"	"<line10> logger.warn(""No mapping found for value '{}'"", value)"
task5	"<line5>    logger.info(""Initialized ripme v"" + UpdateUtils.getThisJarVersion());"	<line5>	"logger.info(""RipMe version "" + VERSION)"	"<line5> logger.info(""RipMe version "" + VERSION)"
task5	"<line2>    logger.error(""Message arrived to a PublishMQTT processor { topic:'""+ topic+ ""; payload:""+ Arrays.toString(message.getPayload())+ ""}"");"	<line2>	"logger.info(""Message arrived in client for topic: {}"", topic)"	"<line2> logger.info(""Message arrived in client for topic: {}"", topic)"
task5	"<line1>    LOGGER.debug(""Execute MCRAccessBaseImpl checkPermission for permission {}"", permission);"	<line1>	"LOG.debug(""No metadata connection"")"	"<line1> LOG.debug(""No metadata connection"")"
task5	"<line3>    LOGGER.debug(Messager.ELEMENT_ATTRIBUTE_FOUND.getMessage(""Location"", point.toString(), getName()));"	<line3>	"LOGGER.debug(Messager.ELEMENT_ATTRIBUTE_FOUND.getMessage(""Location"", point.toString(), getName()))"	"<line3> LOGGER.debug(Messager.ELEMENT_ATTRIBUTE_FOUND.getMessage(""Location"", point.toString(), getName()))"
task5	"<line8>    logger.info(""called API method: GET /dime/rest/"" + said + ""/resource/"" + personID + ""/"" + resourceID);"	<line7>	"logger.info(""called API method: GET /dime/rest/"" + said + ""/resource/"" + personID + ""/"" + resourceID)"	"<line7> logger.info(""called API method: GET /dime/rest/"" + said + ""/resource/"" + personID + ""/"" + resourceID)"
task5	"<line6>    logger.debug(""{} discovered, serialnumber: {}"", deviceTypeName, serialNumber);"	<line6>	"logger.debug(""Discovered a {} with serial number '{}'"", deviceTypeName, serialNumber)"	"<line6> logger.debug(""Discovered a {} with serial number '{}'"", deviceTypeName, serialNumber)"
task5	"<line2>      LOGGER.info(String.format(""Loading '%s' from the classpath."", defaultConfigFile));"	<line15>	"LOGGER.info(String.format(""Using default configuration file at %s"", configurationUrl))"	"<line15> LOGGER.info(String.format(""Using default configuration file at %s"", configurationUrl))"
task5	"<line16>        LOG.error(""Error accessing document"", e);"	<line16>	log.error(e.getMessage(), e)	<line16> log.error(e.getMessage(), e)
task5	"<line44>      LOG.error(""Not enough bookies are available to replaceBookie : {} in ensemble : {} with""+ "" excludeBookies {}."",bookieToReplace,currentEnsemble,excludeBookies);"	<line48>	"LOG.info(""Setting bookie {} in the ensemble to {}"", bookieToReplace, candidateAddr)"	"<line48> LOG.info(""Setting bookie {} in the ensemble to {}"", bookieToReplace, candidateAddr)"
task5	<line14>        log.debug(exception, exception);	<line14>	log.debug(exception, exception)	<line14> log.debug(exception, exception)
task5	"<line10>      logger.info(""Command line argument --""+ KEY_STORE_TYPE_ARG+ ""=""+ keyStoreType+ "" only applies to keystore, recommended truststore type of ""+ KeystoreType.JKS.toString()+ "" unaffected."");"	<line10>	"LOG.info(""Generating PKCS12 keystore; keySize: "" + keySize + "" bits"")"	"<line10> LOG.info(""Generating PKCS12 keystore; keySize: "" + keySize + "" bits"")"
task5	<line2>    logger.debug(Messages.BINDING_SERVICE_INSTANCE_0_TO_APPLICATION_1, serviceInstanceName, applicationName);	<line2>	logger.debug(Messages.BINDING_APPLICATION_0_TO_SERVICE_INSTANCE_1,applicationName,serviceInstanceName)	<line2> logger.debug(Messages.BINDING_APPLICATION_0_TO_SERVICE_INSTANCE_1,applicationName,serviceInstanceName)
task5	"<line4>      LOGGER.error(""Exception while waiting for registry mutex. Returning null."", e);"	<line4>	"LOGGER.error(""Annotator could not be registered"", e)"	"<line4> LOGGER.error(""Annotator could not be registered"", e)"
task5	<line20>      LOGGER.info(sb.toString());	<line20>	log.info(sb.toString())	<line20> log.info(sb.toString())
task5	"<line2>    log.info(""stopping orbcad ftp download client"");"	<line4>	"log.info(""FTP service stopped"")"	"<line4> log.info(""FTP service stopped"")"
task5	"<line16>    log.error(msg + "" "" + path);"	<line16>	log.debug(msg)	<line16> log.debug(msg)
task5	"<line6>      LOGGER.debug(""Got ExperimentRun Tags"");"	<line8>	"LOGGER.error(""ExperimentRun tags fetch failed for ExperimentRun id: "" + experimentRunId)"	"<line8> LOGGER.error(""ExperimentRun tags fetch failed for ExperimentRun id: "" + experimentRunId)"
task5	"<line2>    LOG.info(""Closing the SlotManager."");"	<line2>	"LOG.info(""Closing the slot manager."")"	"<line2> LOG.info(""Closing the slot manager."")"
task5	"<line20>      LOGGER.error(""Unable to retrieve OAuth provider's metadata."", e);"	<line20>	"LOG.error(""Could not obtain valid token"", e)"	"<line20> LOG.error(""Could not obtain valid token"", e)"
task5	"<line17>    log.debug(""Will allow CORS for the following origins: "" + originsJoiner.toString());"	<line17>	"LOG.debug(""Enabling CORS for {} with allowed origins: {}"",getEndpointPath(),allowedOrigins)"	"<line17> LOG.debug(""Enabling CORS for {} with allowed origins: {}"",getEndpointPath(),allowedOrigins)"
task5	"<line5>      log.debug(""doClose({})[id={}] SSH_FXP_CLOSE (handle={}[{}])"", session, id, handle, h);"	<line5>	"log.debug(""doClose({})[id={}] SSH_FXP_CLOSE (handle={})"", session, id, handle)"	"<line5> log.debug(""doClose({})[id={}] SSH_FXP_CLOSE (handle={})"", session, id, handle)"
task5	"<line5>      logger.debug(""Received message on topic {} that could not be decoded. Wrapping it into an""+ "" KuraPayload."",topic);"	<line5>	"logger.warn(""Error creating kura payload from proto buf"")"	"<line5> logger.warn(""Error creating kura payload from proto buf"")"
task5	"<line2>    LOGGER.info(""[TaskScheduler] Exception on action "" + action);"	<line2>	"LOGGER.debug(""[ReadyScheduler] Exception on action "" + action.getId())"	"<line2> LOGGER.debug(""[ReadyScheduler] Exception on action "" + action.getId())"
task5	"<line2>    logger.info(""DummyStateModel.onBecomeOfflineFromSlave()"");"	<line2>	"logger.info(""DummyStateModel.onBecomeOfflineFromSlave()"")"	"<line2> logger.info(""DummyStateModel.onBecomeOfflineFromSlave()"")"
task5	"<line2>    LOG.debug(""mark at {}"", position());"	<line2>	"logger.trace(""mark({})"", readlimit)"	"<line2> logger.trace(""mark({})"", readlimit)"
task5	"<line37>    LOGGER.debug("" # of intervals for M"" + i + "": "" + ms.size());"	<line38>	"LOG.debug(""Step 3: {}"", Arrays.toString(m))"	"<line38> LOG.debug(""Step 3: {}"", Arrays.toString(m))"
task5	<line11>      logger.error(msg, e);	<line11>	log.error(msg, e)	<line11> log.error(msg, e)
task5	"<line13>    logger.debug(""addMedicalData success : resultId="" + resultId);"	<line13>	"logger.info(""addMedicalData - resultId: "" + resultId)"	"<line13> logger.info(""addMedicalData - resultId: "" + resultId)"
task5	"<line2>    LOG.debug(""Current Backup Count = "" + failoverTransport.getCurrentBackups());"	<line2>	"LOG.info(""Current backups = "" + failoverTransport.getCurrentBackups())"	"<line2> LOG.info(""Current backups = "" + failoverTransport.getCurrentBackups())"
task5	<line12>          LOG.warn(ex);	<line12>	logger.error(ex)	<line12> logger.error(ex)
task5	"<line14>    LOGGER.info(""conversation {} runner: {} done"", conversationState.getConversationId(), runner);"	<line14>	"log.debug(""done with runner "" + runner)"	"<line14> log.debug(""done with runner "" + runner)"
task5	"<line17>        LOGGER.error(""Exception when starting embedded mongo"", e);"	<line17>	"LOGGER.error(""Unable to start embedded Mongodb"", e)"	"<line17> LOGGER.error(""Unable to start embedded Mongodb"", e)"
task5	"<line2>      log.debug(""JBoss 6 VFS API is not available in this environment."");"	<line2>	"logger.debug(""Setting VFS cache invalidation flag to true"")"	"<line2> logger.debug(""Setting VFS cache invalidation flag to true"")"
task5	"<line3>      logger.trace(""AIO on error issued. Error(code: "" + errno + "" msg: "" + message + "")"");"	<line3>	"logger.debug(""Error from Neo4j: {}"", message)"	"<line3> logger.debug(""Error from Neo4j: {}"", message)"
task5	"<line8>        logger.warn(""Exception consumer {} in handle {} threw an exception"", onException, this, ex);"	<line8>	"LOG.warn(""Exception while notifying onException"", ex)"	"<line8> LOG.warn(""Exception while notifying onException"", ex)"
task5	"<line1>    log.warn(String.format(""Validation result query failed, code: '%s', message: '%s'"",error.getErrorCode(), error.getMessage()));"	<line1>	log.debug(error.getMessage())	<line1> log.debug(error.getMessage())
task5	"<line5>    logger.warn(""page is not an instance of "" + IManageablePage.class);"	<line5>	"log.error(""Cannot convert to IManageablePage: "" + page.getClass().getName())"	"<line5> log.error(""Cannot convert to IManageablePage: "" + page.getClass().getName())"
task5	"<line12>        LOG.error(""Failed to delete token crc file."", e);"	<line12>	"LOG.info(""Unable to delete checksum file "" + checksumStr + "":"" + e.getMessage())"	"<line12> LOG.info(""Unable to delete checksum file "" + checksumStr + "":"" + e.getMessage())"
task5	"<line3>      LOG.info(""Running in Debug mode"");"	<line10>	"LOG.info(""Logging level is set to {}"", logLevel)"	"<line10> LOG.info(""Logging level is set to {}"", logLevel)"
task5	"<line7>                log.info(""Refreshing system access control from %s"", config.getConfigFile());"	<line7>	"log.info(""Refreshing file based access control data from {}"", config.getSource().getPath())"	"<line7> log.info(""Refreshing file based access control data from {}"", config.getSource().getPath())"
task5	"<line23>      log.warn(""Unexpected exception while map clean-up"", e);"	<line24>	"log.error(""Error while reloading websocket for room "" + roomId, e)"	"<line24> log.error(""Error while reloading websocket for room "" + roomId, e)"
task5	"<line4>    LOGGER.info(""Initializing wsDistributionAutomationInboundDomainResponsesMessageListenerContainer""+ "" bean."");"	<line4>	"LOGGER.info(""Initializing wsDistributionAutomationInboundDomainResponsesMessageListenerContainer bean."")"	"<line4> LOGGER.info(""Initializing wsDistributionAutomationInboundDomainResponsesMessageListenerContainer bean."")"
task5	"<line2>    LOGGER.debug(""ENTERING: PropertyIsEqualTo filter"");"	<line6>	"LOGGER.debug(""PropertyIsEqualTo filter: {}"", filter.toString())"	"<line6> LOGGER.debug(""PropertyIsEqualTo filter: {}"", filter.toString())"
task5	"<line9>      logger.error(""Error deleting work gui - typeCode {} - stepCode {}"", typeCode, stepCode, t);"	<line9>	"logger.error(""Error deleting work gui - typeCode {} - stepCode {}"", typeCode, stepCode, t)"	"<line9> logger.error(""Error deleting work gui - typeCode {} - stepCode {}"", typeCode, stepCode, t)"
task5	"<line2>    LOGGER.debug(""get Ingest Entities for id={} "", id);"	<line2>	"LOGGER.debug(""Get all paginated {}"", id)"	"<line2> LOGGER.debug(""Get all paginated {}"", id)"
task5	<line26>      LOG.error(e);	<line26>	"LOG.error(""Error occurred while retrieving data from disk cache."", e)"	"<line26> LOG.error(""Error occurred while retrieving data from disk cache."", e)"
task5	"<line3>    log.trace(""Calling onSubscribe of subscriber"");"	<line2>	"logger.debug(""Subscribe to execution result: {}"", s)"	"<line2> logger.debug(""Subscribe to execution result: {}"", s)"
task5	<line3>      logger.info(msg);	<line3>	logger.info(msg)	<line3> logger.info(msg)
task5	"<line2>    LOG.info(""finished node: "" + node + "" depth: "" + depth);"	<line2>	"LOG.debug(""node finished: "" + node + "" depth: "" + depth)"	"<line2> LOG.debug(""node finished: "" + node + "" depth: "" + depth)"
task5	"<line2>    logger.debug(String.format(""Skipped '%s' because idempotent and exists in the machine."", id));"	<line2>	"log.debug(""{} exists"", this)"	"<line2> log.debug(""{} exists"", this)"
task5	"<line3>    LOG.trace(""Using NoOp Implementation for Adapter CORE X12 Doc Submission Service"");"	<line3>	"LOG.trace(""Using {} Implementation for Adapter CORE X12 Doc Submission Service"", getServiceName())"	"<line3> LOG.trace(""Using {} Implementation for Adapter CORE X12 Doc Submission Service"", getServiceName())"
task5	"<line7>      LOGGER.debug("""", ex);"	<line4>	"LOGGER.debug(""Parsing suppression file: "" + file.getAbsolutePath())"	"<line4> LOGGER.debug(""Parsing suppression file: "" + file.getAbsolutePath())"
task5	"<line27>        log.info(""Protofile "" + protofile + "" registered."");"	<line2>	"LOG.info(""Registering protofiles in JMX"")"	"<line2> LOG.info(""Registering protofiles in JMX"")"
task5	<line6>      log.info(col);	<line6>	"log.info(""Columns: "" + col)"	"<line6> log.info(""Columns: "" + col)"
task5	"<line22>            LOG.info(""Error in pingAsyncAsync() {}"", t.getMessage());"	<line2>	PingPongImpl.this.streamRequests.add(streamRequests)	<line2> PingPongImpl.this.streamRequests.add(streamRequests)
task5	"<line4>    log.info(""DP is:\n"" + plan.toString());"	<line1>	"log.info(""Example plan YAML match:"")"	"<line1> log.info(""Example plan YAML match:"")"
task5	"<line14>      logger.debug(""exception while formatting :: {}"", e.getMessage(), e);"	<line14>	"logger.error(""Error occured while parsing JSON response"", e)"	"<line14> logger.error(""Error occured while parsing JSON response"", e)"
task5	"<line28>        log.debug(""Loading experimentOptParamDef to the command object for editing."");"	<line8>	"log.debug(""Preparing data for form"")"	"<line8> log.debug(""Preparing data for form"")"
task5	"<line20>        log.info(""Deleting background task "" + backgroundTask.toString());"	<line20>	"log.info(""Deleting background task "" + backgroundTaskId)"	"<line20> log.info(""Deleting background task "" + backgroundTaskId)"
task5	"<line10>      logger.error(""InternalServerErrorException in rollbackVfModule"", e);"	<line10>	"logger.error(""InternalServerErrorException in rollbackVfModule"", e)"	"<line10> logger.error(""InternalServerErrorException in rollbackVfModule"", e)"
task5	"<line1>    log.debug(""getConcept() == {}"", getConcept());"	<line1>	"log.debug(""Setting value as string: "" + s)"	"<line1> log.debug(""Setting value as string: "" + s)"
task5	"<line5>      logger.error(""Failed to initialize data grid: {}"", e);"	<line5>	"logger.error(""Error while initializing JvstmDataGrid"", e)"	"<line5> logger.error(""Error while initializing JvstmDataGrid"", e)"
task5	"<line8>    LOG.info(""Spilling to file location ""+ writeOnlyFile.getAbsolutePath()+ "" in host (""+ InetAddress.getLocalHost().getHostAddress()+ "") with hostname (""+ InetAddress.getLocalHost().getHostName()+ "")"");"	<line10>	"logger.info(""Initialized {}"", writeOnlyFile)"	"<line10> logger.info(""Initialized {}"", writeOnlyFile)"
task5	"<line24>        LOGGER.debug(""monitoring from ""+ req.getRemoteAddr()+ "", request=""+ req.getRequestURI()+ (req.getQueryString() != null ? '?' + req.getQueryString() : """")+ "", application=""+ application+ "" in ""+ (System.currentTimeMillis() - start)+ ""ms"");"	<line24>	"LOGGER.debug(""Request time: {}"", System.currentTimeMillis() - start)"	"<line24> LOGGER.debug(""Request time: {}"", System.currentTimeMillis() - start)"
task5	"<line40>    log.debug(""createGroup start"");"	<line27>	"log.debug(""Failed to fetch latest group type"")"	"<line27> log.debug(""Failed to fetch latest group type"")"
task5	"<line2>      logger.error(""Cannot invoke signing without signature token. Add 'withSignatureToken()' method call or""+ "" call 'buildDataToSign() instead.'"");"	<line2>	"logger.error(""The signature token was null"")"	"<line2> logger.error(""The signature token was null"")"
task5	"<line5>      LOG.error(""Could not run completion of exchange {}"", exchange, e);"	<line5>	"LOG.error(""Unable to run command: {}"", successCommand, e)"	"<line5> LOG.error(""Unable to run command: {}"", successCommand, e)"
task5	"<line6>        log.debug(""Unable to retrieve generic type of field: "" + f, e);"	<line6>	"log.warn(""Exception while getting generic type"", e)"	"<line6> log.warn(""Exception while getting generic type"", e)"
task5	"<line13>        log.debug(field.getProperty() + "": "" + msg);"	<line13>	log.debug(msg)	<line13> log.debug(msg)
task5	"<line16>            logger.debug(""Add table cache for database {}"", database);"	<line28>	"LOG.debug(""listTables: {}"", ret)"	"<line28> LOG.debug(""listTables: {}"", ret)"
task5	<line41>      LOG.warn(ex);	<line41>	LOG.warn(ex)	<line41> LOG.warn(ex)
task5	"<line3>      log.debug(""[DSU] skip "" + xpp.getName());"	<line3>	"log.debug(""Skipping sub-tree"")"	"<line3> log.debug(""Skipping sub-tree"")"
task5	"<line9>      logger.trace(""Unable to parse sensor definition: {}"", json, e);"	<line9>	"logger.info(""JsonSyntaxException: {}"", e.getMessage())"	"<line9> logger.info(""JsonSyntaxException: {}"", e.getMessage())"
task5	"<line4>      logger.error(""An error was produced during ""+ VFSPipelineExecutorRegistry.class.getName()+ "" directories initialization."",e);"	<line4>	"log.error(""Unable to initialize the pipeline executor registry root"", e)"	"<line4> log.error(""Unable to initialize the pipeline executor registry root"", e)"
task5	"<line4>      log.error(""Error while saving filter."", e);"	<line4>	"log.error(""Error while saving filter"", e)"	"<line4> log.error(""Error while saving filter"", e)"
task5	<line8>      log.error(exception, exception);	<line8>	log.error(exception, exception)	<line8> log.error(exception, exception)
task5	"<line2>    log.info(""Testing log resource"");"	<line4>	LOG.info(s)	<line4> LOG.info(s)
task5	"<line9>        LOGGER.debug(""File {} was removed from mining"", fileName);"	<line8>	"LOGGER.debug(""Deleting log file {}"", fileName)"	"<line8> LOGGER.debug(""Deleting log file {}"", fileName)"
task5	"<line26>      logger.error(""Error detected during user authentication"", e);"	<line26>	"logger.error(""Error detected during user authentication"", e)"	"<line26> logger.error(""Error detected during user authentication"", e)"
task5	"<line15>      log.error(""Error generating CND of "" + def, e);"	<line17>	log.info(out.toString())	<line17> log.info(out.toString())
task5	"<line6>      LOGGER.error(""Error doing {} init"", SiegfriedPlugin.class.getName(), e);"	<line6>	"LOGGER.error(""Error while cloning SiegfriedPlugin"", e)"	"<line6> LOGGER.error(""Error while cloning SiegfriedPlugin"", e)"
task5	"<line17>      LOG.debug(""Error occurred: "", e);"	<line14>	LOG.error(e.getMessage(), e)	<line14> LOG.error(e.getMessage(), e)
task5	<line2>      log.fatal(MessageFormat.format(message.toString(), args), t);	<line2>	log.fatal(MessageFormat.format(message.toString(), args), t)	<line2> log.fatal(MessageFormat.format(message.toString(), args), t)
task5	"<line27>          log.error(""Invalid state request: {}"", mAppearance);"	<line27>	"log.warn(""Unexpected appearance: {}"", mAppearance)"	"<line27> log.warn(""Unexpected appearance: {}"", mAppearance)"
task5	"<line3>    LOG.info(""call for oneway ping"");"	<line2>	"logger.info(""Ping!"")"	"<line2> logger.info(""Ping!"")"
task5	"<line14>    LOG.debug(""{} publishing value {} (original sensor value {}) for mapped sensor {}, of entity {}"",new Object[] {this, newVal.get(), sensorVal, mappedSensor, entity});"	<line14>	"log.debug(""Mapping {} from {} to {}"", sensor, entity, newVal.get())"	"<line14> log.debug(""Mapping {} from {} to {}"", sensor, entity, newVal.get())"
task5	"<line48>      log.debug(""Another Health query {} "", healthQuery);"	<line26>	"log.debug(""healthQuery {} "", healthQuery)"	"<line26> log.debug(""healthQuery {} "", healthQuery)"
task5	"<line2>    log.error(""Recording import failure"", error);"	<line1>	"log.error(""Error while importing data"", error)"	"<line1> log.error(""Error while importing data"", error)"
task5	"<line3>      log.debug(""Executing applications synchronization task"");"	<line3>	"log.debug(""Complete applications event sent successfully"")"	"<line3> log.debug(""Complete applications event sent successfully"")"
task5	"<line2>    Log.debug(""Test"");"	<line2>	"Log.debug(""Test"")"	"<line2> Log.debug(""Test"")"
task5	"<line5>    log.debug(""exists (then evict): "" + exists);"	<line5>	"logger.info(""clientExistsThenEvict: demographicNo="" + demographicNo + "", exists? "" + exists)"	"<line5> logger.info(""clientExistsThenEvict: demographicNo="" + demographicNo + "", exists? "" + exists)"
task5	<line7>      log.error(exception, exception);	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	"<line9>        log.error(""Failed to marshal deployment error, err="" + th, e);"	<line9>	"log.error(""Error while marshaling deployment error."", e)"	"<line9> log.error(""Error while marshaling deployment error."", e)"
task5	"<line4>      logger.warn(""No MD4 digest provider found !"");"	<line41>	LOG.debug(msgType3)	<line41> LOG.debug(msgType3)
task5	"<line3>      log.debug(""Member attribute changed: [""+ memberAttributeEvent.getKey()+ ""] ""+ memberAttributeEvent.getValue());"	<line3>	log.debug(memberAttributeEvent.toString())	<line3> log.debug(memberAttributeEvent.toString())
task5	"<line6>      logger.debug(""could not get '{}' value from scim resource as an array"", ResponseCodeConstants.SCHEMAS);"	<line6>	"logger.debug(""retrieving the 'schemas' field from the given json resource"")"	"<line6> logger.debug(""retrieving the 'schemas' field from the given json resource"")"
task5	"<line10>    logger.info(""Trying to set inconsistent user '"" + u + ""' domain to '"" + d + ""'."");"	<line2>	"logger.debug(""updateDomain : uuid : "" + uuid + "" domain : "" + domain)"	"<line2> logger.debug(""updateDomain : uuid : "" + uuid + "" domain : "" + domain)"
task5	"<line7>    LOG.info(""Finished deleting all ledgers so waiting for the GC thread to clean up the entryLogs"");"	<line7>	"LOG.info(""Finished deleting all ledgers so waiting for the GC thread to clean up the entryLogs"")"	"<line7> LOG.info(""Finished deleting all ledgers so waiting for the GC thread to clean up the entryLogs"")"
task5	"<line2>    LOG.info(""Instantiating {}"", this.getClass().getSimpleName());"	<line2>	"LOG.info(""Instantiating {}"", this.getClass().getSimpleName())"	"<line2> LOG.info(""Instantiating {}"", this.getClass().getSimpleName())"
task5	"<line14>          LOG.debug(""Rejected on attempt to queue message dispatch"", rje);"	<line14>	"LOG.error(""Dispatch of pending message was rejected"", rje)"	"<line14> LOG.error(""Dispatch of pending message was rejected"", rje)"
task5	"<line7>        LOGGER.debug(""TaskService.updateTask() for TaskId={} INSERTED an Attachment={}."",newTaskImpl.getId(),attachmentImpl);"	<line7>	"LOGGER.debug(""inserted attachment on task update, id = "" + attachmentImpl.getId())"	"<line7> LOGGER.debug(""inserted attachment on task update, id = "" + attachmentImpl.getId())"
task5	"<line3>          logger.warn(""Generic error warning."");"	<line3>	"log.error(""Error notification"")"	"<line3> log.error(""Error notification"")"
task5	"<line26>      LOG.debug(""Using SPN: {}"", spn);"	<line26>	"LOG.debug(""ServicePrincipalName is {}"", spn)"	"<line26> LOG.debug(""ServicePrincipalName is {}"", spn)"
task5	"<line27>          log.info(""Scenario '""+ tc.getScenario()+ ""' skipped due to constraints ""+ Arrays.toString(constraint.value()));"	<line27>	LOG.warn(constraint.toString())	<line27> LOG.warn(constraint.toString())
task5	<line19>      log.error(systemException, systemException);	<line19>	log.error(systemException, systemException)	<line19> log.error(systemException, systemException)
task5	"<line5>      log.warn(""admin has already joined the language [{}]"", localeId);"	<line1>	"log.info(""Adding language: {}"", localeId)"	"<line1> log.info(""Adding language: {}"", localeId)"
task5	"<line17>    logger.debug(""Update VF Module command attempted but not supported"");"	<line17>	"logger.warn(""UpdateVfModule:  Unsupported command"")"	"<line17> logger.warn(""UpdateVfModule:  Unsupported command"")"
task5	"<line18>        LOGGER.debug(""ignoring axis, can not be built: {} {}{}"",nameStep.getAxis(),prefix.isEmpty() ? """" : prefix + "":"",name);"	<line18>	"LOGGER.debug(""Unsupported axis: {}"", nameStep.getAxis())"	"<line18> LOGGER.debug(""Unsupported axis: {}"", nameStep.getAxis())"
task5	"<line9>    logger.trace(""Current inFlight = {}, {} connections needed, {} connections available, trashing {}"",currentLoad,needed,actual,toTrash);"	<line10>	"logger.trace(""[{}] Trashing {} connections"", logPrefix, toTrash)"	"<line10> logger.trace(""[{}] Trashing {} connections"", logPrefix, toTrash)"
task5	"<line15>          logger.error(""{} can not be deleted."", file, e);"	<line15>	"LOG.error(""Failed to delete file {}"", file.getAbsoluteFile(), e)"	"<line15> LOG.error(""Failed to delete file {}"", file.getAbsoluteFile(), e)"
task5	"<line15>      logger.error(""StudyDAOImpl - getComprehensionTestQuestionList() - Error"", e);"	<line15>	"logger.error(""StudyDAOImpl - getComprehensionTestQuestionList() - ERROR "", e)"	"<line15> logger.error(""StudyDAOImpl - getComprehensionTestQuestionList() - ERROR "", e)"
task5	"<line2>    LOG.info(""Connector config keys: {}"", String.join("", "", configProps.keySet()));"	<line2>	"log.info(""Starting ScaleToZeroPodDiscovery controller"")"	"<line2> log.info(""Starting ScaleToZeroPodDiscovery controller"")"
task5	"<line1>    logger.warn(""org.apache.kylin.storage.hbase.util.StorageCleanupJob is deprecated, use""+ "" org.apache.kylin.tool.StorageCleanupJob instead"");"	<line1>	"logger.info(""Executing StorageCleanupJob with args "" + Arrays.toString(args))"	"<line1> logger.info(""Executing StorageCleanupJob with args "" + Arrays.toString(args))"
task5	"<line1>    LOGGER.debug(""Storing message {} into outgoing after {} retries"", mail.getName(), retries);"	<line8>	"LOGGER.info(""Mail will be re-attempted delivery in {} for mail: {}"", delay, mail)"	"<line8> LOGGER.info(""Mail will be re-attempted delivery in {} for mail: {}"", delay, mail)"
task5	"<line1>    log.debug("""");"	<line1>	"log.debug("""")"	"<line1> log.debug("""")"
task5	"<line6>        LOGGER.error(""Destroying datasource"", e);"	<line6>	"LOG.error(""Failed to destroy source data source: {}"", sourceConfig.getName(), e)"	"<line6> LOG.error(""Failed to destroy source data source: {}"", sourceConfig.getName(), e)"
task5	"<line32>      logger.error(""error saving account to cloud_usage db"", ex);"	<line32>	"logger.error(""Exception: "", ex)"	"<line32> logger.error(""Exception: "", ex)"
task5	"<line23>        LOG.debug(""Dropping {} because no topic is specified."", jsonMessage);"	<line23>	"log.warn(""Missing topic for sensorType: {}"", sensorType)"	"<line23> log.warn(""Missing topic for sensorType: {}"", sensorType)"
task5	"<line6>    LOGGER.info(""Incoming SendNotificationRequest for organisation: {} device: {}."",organisationIdentification,request.getNotification().getDeviceIdentification());"	<line6>	"LOGGER.info(""Incoming SendNotificationRequest for organisation: {} device: {}."",organisationIdentification,request.getNotification().getDeviceIdentification())"	"<line6> LOGGER.info(""Incoming SendNotificationRequest for organisation: {} device: {}."",organisationIdentification,request.getNotification().getDeviceIdentification())"
task5	"<line5>      logger.debug(""Handling command [{}]"", command.getCommandName());"	<line5>	"logger.debug(""Handle command [{}] with callback"", command.getCommandName())"	"<line5> logger.debug(""Handle command [{}] with callback"", command.getCommandName())"
task5	"<line4>      LOG.debug(""Ignoring a duplicate slot request with allocation id {}."",slotRequest.getAllocationId());"	<line3>	"LOG.debug(""Registering slot request {}"", slotRequest.getAllocationId())"	"<line3> LOG.debug(""Registering slot request {}"", slotRequest.getAllocationId())"
task5	"<line5>    logger.debug(""-----deleteGroup--- , Group Name: {}"", groupName);"	<line5>	"logger.info(""Deleting group {}"", groupName)"	"<line5> logger.info(""Deleting group {}"", groupName)"
task5	"<line5>      logger.info(""Invalid payload {}"", value, e);"	<line5>	"LOG.error(""JsonProcessingException when consuming value: "" + value, e)"	"<line5> LOG.error(""JsonProcessingException when consuming value: "" + value, e)"
task5	<line8>      LOGGER.error(e.getMessage(), e);	<line8>	"log.error(""Invalid configuration property \""maintenance\""=\"""" + mode + ""\"""")"	"<line8> log.error(""Invalid configuration property \""maintenance\""=\"""" + mode + ""\"""")"
task5	"<line9>        logger.warn(""KeyValue source {} of {} returned invalid value {}"",_keySource.getUuid(),getUuid(),item);"	<line9>	"logger.warn(""No key-value pair returned from key-value source: "" + _keySource)"	"<line9> logger.warn(""No key-value pair returned from key-value source: "" + _keySource)"
task5	<line27>            log.warn(errorMessage);	<line20>	"log.warn(String.format(""Error performing %s on %s: %d, %s"", method, path, response.code(), responseString))"	"<line20> log.warn(String.format(""Error performing %s on %s: %d, %s"", method, path, response.code(), responseString))"
task5	"<line9>        log.debug(""handled image error with type "" + onErrorType, e);"	<line9>	"log.debug(""handled image error with type "" + imageType, e)"	"<line9> log.debug(""handled image error with type "" + imageType, e)"
task5	"<line22>    logger.debug(""wrote state snapshot"");"	<line1>	"logger.trace(""LookupService.takeSnapshot()"")"	"<line1> logger.trace(""LookupService.takeSnapshot()"")"
task5	"<line11>    LOG.debug(""Added mutation to the batch; size={}"", batchHelper.getBatchSize());"	<line1>	"LOG.debug(""Save tuple {}"", tuple)"	"<line1> LOG.debug(""Save tuple {}"", tuple)"
task5	"<line5>      log.warn(""Nested (i)frame depth exceeded limit: "" + MAX_FRAME_DEPTH);"	<line5>	"LOG.warn(""Reached maximum frame depth: "" + ploc.frameIndexList.size())"	"<line5> LOG.warn(""Reached maximum frame depth: "" + ploc.frameIndexList.size())"
task5	<line4>    log.debug(message);	<line3>	log.info(message, throwable)	<line3> log.info(message, throwable)
task5	"<line15>      LOG.error(""Failed to write token to cache File. "" + e.toString());"	<line15>	"LOG.info(""Error writing token to cache file: "" + e)"	"<line15> LOG.info(""Error writing token to cache file: "" + e)"
task5	"<line16>          log.trace(""{} spent {} outside home"", person, timeSpent);"	<line16>	"log.warn(""{} spent more than a day in a vehicle or facility. This should not happen!"",person.getPersonId())"	"<line16> log.warn(""{} spent more than a day in a vehicle or facility. This should not happen!"",person.getPersonId())"
task5	"<line46>      LOGGER.warn(""preparedInsertVarbinaryApi() only applies to TeradataJdbcDriver"");"	<line46>	"LOGGER.warn(""preparedInsertVarbinaryApi() only applies to TeradataJdbcDriver"")"	"<line46> LOGGER.warn(""preparedInsertVarbinaryApi() only applies to TeradataJdbcDriver"")"
task5	<line27>      log.error(systemException, systemException);	<line27>	log.error(systemException, systemException)	<line27> log.error(systemException, systemException)
task5	<line12>        log.debug(noSuchNodeException, noSuchNodeException);	<line12>	log.debug(noSuchNodeException, noSuchNodeException)	<line12> log.debug(noSuchNodeException, noSuchNodeException)
task5	"<line3>      logger.debug(""Aborted {}"", this);"	<line3>	"logger.debug(""abort()"")"	"<line3> logger.debug(""abort()"")"
task5	<line6>      logger.debug(HANDLER_IS_NULL);	<line6>	logger.debug(HANDLER_IS_NULL)	<line6> logger.debug(HANDLER_IS_NULL)
task5	<line17>                log.debug(e.getMessage(), e);	<line17>	log.error(e.getMessage(), e)	<line17> log.error(e.getMessage(), e)
task5	<line18>      log.error(systemException, systemException);	<line18>	log.error(systemException, systemException)	<line18> log.error(systemException, systemException)
task5	"<line5>    log.info(Color.GREEN + ""Calendar_3_8 : empty column sunday"" + Color.NORMAL);"	<line5>	"log.info(Color.GREEN + ""Calendar_3_8 : empty column sunday"" + Color.NORMAL)"	"<line5> log.info(Color.GREEN + ""Calendar_3_8 : empty column sunday"" + Color.NORMAL)"
task5	"<line2>      logger.error(""Failed to execute query."");"	<line2>	"logger.debug(""Executing empty query"")"	"<line2> logger.debug(""Executing empty query"")"
task5	"<line1>    logger.info(""called"");"	<line1>	"log.info(""MethodWithClassDbAnnotated"")"	"<line1> log.info(""MethodWithClassDbAnnotated"")"
task5	<line18>      logger.debug(sql.toString());	<line18>	logger.debug(sql.toString())	<line18> logger.debug(sql.toString())
task5	"<line11>      logger.info(""Expected error"", e);"	<line11>	logger.error(e.getMessage())	<line11> logger.error(e.getMessage())
task5	"<line23>    LOG.info(""Adding shutdown hook with kill in {} secs"", workerShutdownSleepSecs);"	<line24>	"LOG.info(""Starting worker {}"", worker.getId())"	"<line24> LOG.info(""Starting worker {}"", worker.getId())"
task5	"<line3>    logger.debug(""Phase {}"", this);"	<line2>	"logger.debug(""Running logon phase..."")"	"<line2> logger.debug(""Running logon phase..."")"
task5	"<line2>      log.debug(String.format(""Cache %s for file %s"", id, file));"	<line2>	"log.debug(String.format(""Cache %s for file %s"", id, file))"	"<line2> log.debug(String.format(""Cache %s for file %s"", id, file))"
task5	"<line8>            logger.debug(getString(""Tracing.4"",introspectedColumn.getActualColumnName(),entry.getKey().toString()));"	<line8>	"logger.debug(""Applying column override for column ""+ introspectedColumn.getActualColumnName()+ "" in table ""+ entry.getKey())"	"<line8> logger.debug(""Applying column override for column ""+ introspectedColumn.getActualColumnName()+ "" in table ""+ entry.getKey())"
task5	"<line3>    LOG.trace(""getCipher({}) -> {}"", transformation, safeClassname(result));"	<line3>	"logger.trace(""getCipher({}) returns {}"", transformation, result)"	"<line3> logger.trace(""getCipher({}) returns {}"", transformation, result)"
task5	<line15>        log.debug(searchException, searchException);	<line15>	log.debug(searchException, searchException)	<line15> log.debug(searchException, searchException)
task5	"<line12>              log.error(""Could not determine whether a field is indexed"", ex);"	<line18>	"log.warn(""field "" + identifier.image + "" is not indexed"")"	"<line18> log.warn(""field "" + identifier.image + "" is not indexed"")"
task5	"<line2>    LOG.trace(""Clearing composite phenomenon for observable property {}"", observableProperty);"	<line2>	"LOG.trace(""Clearing composite phenomenons for observableProperty: "" + observableProperty)"	"<line2> LOG.trace(""Clearing composite phenomenons for observableProperty: "" + observableProperty)"
task5	<line7>      log.error(exception, exception);	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	"<line5>          log.debug(""Removed Principal "" + principal.getName());"	<line5>	"log.debug(""Removed principal: "" + principal.getName())"	"<line5> log.debug(""Removed principal: "" + principal.getName())"
task5	"<line7>        LOG.info(""Starting service {}"", svc.getClass().getName());"	<line7>	"log.info(""Starting service: "" + svc.getClass().getSimpleName())"	"<line7> log.info(""Starting service: "" + svc.getClass().getSimpleName())"
task5	"<line1>    logger.debug(""xid = ["" + xid + ""] state = ["" + state + ""]"");"	<line1>	"logger.debug(""onXAEvent: "" + xid + "" - "" + state)"	"<line1> logger.debug(""onXAEvent: "" + xid + "" - "" + state)"
task5	"<line2>    LOG.trace(""Webhook {} for {} failed after {}"",webhook.getUri(),update,JavaUtils.duration(start),t);"	<line2>	"logger.error(""Failed to update webhook"", t)"	"<line2> logger.error(""Failed to update webhook"", t)"
task5	"<line2>    LOG.trace(""Shutdown Droplet {} : [{}] "", dropletId, action);"	<line2>	"LOG.trace(""Shutdown Droplet : [{}] "", action)"	"<line2> LOG.trace(""Shutdown Droplet : [{}] "", action)"
task5	"<line49>    ResourcesResourceTest.LOG.debug(""try to retrieve configurations of resource '{}'"", updatedComplexResource.getUuid());"	<line1>	"LOG.debug(""prepareGetResourceConfigurations"")"	"<line1> LOG.debug(""prepareGetResourceConfigurations"")"
task5	"<line4>      logger.error(""Failed to get buffered input stream for {}. "", filePath, e);"	<line4>	"LOG.error(""Failed to open file {} for reading"", filePath, e)"	"<line4> LOG.error(""Failed to open file {} for reading"", filePath, e)"
task5	"<line1>    log.debug(""reset"");"	<line1>	"log.info(""Resetting client for session: 0x{}"", Long.toHexString(getSessionId()))"	"<line1> log.info(""Resetting client for session: 0x{}"", Long.toHexString(getSessionId()))"
task5	"<line2>    LOGGER.debug(""Iam client factory: {}"", iamClientProperties);"	<line2>	"LOGGER.debug(""Creating IAM external REST client factory."")"	"<line2> LOGGER.debug(""Creating IAM external REST client factory."")"
task5	"<line8>    log.info(""Running group management api test cases using jmeter scripts"");"	<line9>	"log.info(""GroupManagementAPITestCase - Test Completed"")"	"<line9> log.info(""GroupManagementAPITestCase - Test Completed"")"
task5	"<line12>    LOG.info(""Execute computer job: {}"", String.join(SPACE, command));"	<line2>	"LOG.debug(""Execute computer job: {}"", job)"	"<line2> LOG.debug(""Execute computer job: {}"", job)"
task5	"<line15>              LOG.trace(""Ignore forwarding '{}' because the leadership runner is no longer the valid""+ "" leader for {}."",forwardDescription,expectedLeaderId);"	<line15>	"log.debug(""Ignoring response from invalid leader: {}"", forwardDescription)"	"<line15> log.debug(""Ignoring response from invalid leader: {}"", forwardDescription)"
task5	<line16>          log.error(sawException.getMessage(), sawException);	<line1>	"log.debug(""expandTerms: concurrent execution of ""+ todo.size()+ "" terms in ""+ this+ """	"<line1> log.debug(""expandTerms: concurrent execution of ""+ todo.size()+ "" terms in ""+ this+ """
task5	"<line5>    logger.debug(""Closing down entity objects...done"");"	<line2>	"log.debug(""Closing EMF"")"	"<line2> log.debug(""Closing EMF"")"
task5	"<line72>      logger.error(""Unexpected error during processing {}"", e.getMessage(), e);"	<line72>	"logger.error(""Unexpected error during processing {}"", e.getMessage(), e)"	"<line72> logger.error(""Unexpected error during processing {}"", e.getMessage(), e)"
task5	"<line5>      log.error(""Unable to obtain in progress knowledge base comments count ""+ ""for  group ""+ _kbSuggestionListDisplayContext.getGroupId(),portalException);"	<line5>	log.error(portalException, portalException)	<line5> log.error(portalException, portalException)
task5	"<line5>    logger.warn(MessageFormat.format(""Could not find any {0} for the given id \""{1}\""."",UnitDefinition.class.getSimpleName(), id));"	<line3>	"log.debug(""Removed unit definition "" + id)"	"<line3> log.debug(""Removed unit definition "" + id)"
task5	<line1>    log.info(TIPS);	<line1>	"LOG.info(""Preparing data..."")"	"<line1> LOG.info(""Preparing data..."")"
task5	"<line4>      LOG.warn(""Unable to close "" + file, e);"	<line4>	"logger.error(""Failed to close write file handle"", e)"	"<line4> logger.error(""Failed to close write file handle"", e)"
task5	<line9>          log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line9>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line9> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line2>    LOGGER.info(""OnMessage called '"" + message + ""'"");"	<line2>	"LOGGER.info(""OnMessage called '"" + message + ""'"")"	"<line2> LOGGER.info(""OnMessage called '"" + message + ""'"")"
task5	"<line4>    LOG.debug(""Indent options returned by ""+ provider.getClass().getName()+ "" for ""+ file.getName()+ "": indent size=""+ options.INDENT_SIZE+ "", use tabs=""+ options.USE_TAB_CHARACTER+ "", tab size=""+ options.TAB_SIZE);"	<line4>	"LOG.info(""indent options for "" + file.getLanguage() + "" are: "" + options)"	"<line4> LOG.info(""indent options for "" + file.getLanguage() + "" are: "" + options)"
task5	<line13>        log.debug(sb.toString());	<line13>	log.debug(sb.toString())	<line13> log.debug(sb.toString())
task5	<line7>      log.error(exception, exception);	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	"<line10>              log.info(""Exporting address list."");"	<line28>	"log.info(""Address book export started"")"	"<line28> log.info(""Address book export started"")"
task5	<line31>      log.error(e.getMessage(), e);	<line24>	"log.error(""Could not convert entry link to URI"", e1)"	"<line24> log.error(""Could not convert entry link to URI"", e1)"
task5	"<line2>    logger.debug(""Getting Serial: "", super.getSerial());"	<line2>	"logger.debug(""Getting serial: "", super.getSerial())"	"<line2> logger.debug(""Getting serial: "", super.getSerial())"
task5	"<line5>    log.debug(""readFromBigQuery(tableId=%s, projectedColumns=%s, actualParallelism=%s, filter=[%s])"",tableId, projectedColumns, actualParallelism, filter);"	<line14>	"log.debug(""Created ReadSession for tableId=%s, projectedColumns=%s, filter=%s, parallelism=%s"",tableId, projectedColumns, filter, actualParallelism)"	"<line14> log.debug(""Created ReadSession for tableId=%s, projectedColumns=%s, filter=%s, parallelism=%s"",tableId, projectedColumns, filter, actualParallelism)"
task5	"<line19>          LOGGER.warn(""Unable to close "" + file, e);"	<line19>	"LOG.warn(""Unable to close "" + file, e)"	"<line19> LOG.warn(""Unable to close "" + file, e)"
task5	<line4>      log.error(bundleException, bundleException);	<line4>	log.error(bundleException, bundleException)	<line4> log.error(bundleException, bundleException)
task5	"<line2>    LOGGER.debug(""Serializing EncryptedExtensionsMessage"");"	<line2>	"LOGGER.debug(""Serializing SupplementalDataMessage"")"	"<line2> LOGGER.debug(""Serializing SupplementalDataMessage"")"
task5	"<line3>      log.info(""Moving current data directory away to {"" + dataSourceFolder().getAbsolutePath() + ""}"");"	<line2>	"log.info(""Moving data folder to backup location {"" + dataTargetFolder().getAbsolutePath() + ""}."")"	"<line2> log.info(""Moving data folder to backup location {"" + dataTargetFolder().getAbsolutePath() + ""}."")"
task5	<line10>      LOG.warn(ex);	<line10>	log.error(ex)	<line10> log.error(ex)
task5	"<line2>    log.debug(""{} Setting timeout to {} ms"", this, timeoutMs);"	<line2>	"logger.info(""timeout set to {} ms"", timeoutMs)"	"<line2> logger.info(""timeout set to {} ms"", timeoutMs)"
task5	"<line11>      Log.warn(this, ""Rows = "" + rows + "" but only "" + indexed + "" indexes"");"	<line11>	"logger.warn(""Indexed solution set does not match rows in result set: {} indexed, {} rows"",indexed,rows)"	"<line11> logger.warn(""Indexed solution set does not match rows in result set: {} indexed, {} rows"",indexed,rows)"
task5	"<line14>      logger.debug(""Could not load appliance"", e);"	<line13>	"logger.debug(""Failed to get appliance."", e)"	"<line13> logger.debug(""Failed to get appliance."", e)"
task5	"<line19>        logger.debug(""Query targeted local bucket not found. {}"", bme.getMessage(), bme);"	<line19>	"logger.debug(""The Region on which query is executed may have been destroyed. "" + rde.getMessage(), rde)"	"<line19> logger.debug(""The Region on which query is executed may have been destroyed. "" + rde.getMessage(), rde)"
task5	"<line5>      logger.info(marker,""{} {} {} of [{}] at [{}], unix [{}]"",operation.toString().toLowerCase(Locale.ENGLISH),entityName,marker.getName().toLowerCase(),entity.getUuid(),now,now.getEpochSecond());"	<line5>	"logger.info(""{} {} {} @ {}"",marker,entityName,operation.name().toLowerCase(),now)"	"<line5> logger.info(""{} {} {} @ {}"",marker,entityName,operation.name().toLowerCase(),now)"
task5	"<line6>      LOGGER.error(""Giving up on retrying watcher"", cause);"	<line5>	"log.warn(""Failed to create watcher. Retry={}"", currentRetries, cause)"	"<line5> log.warn(""Failed to create watcher. Retry={}"", currentRetries, cause)"
task5	<line9>      LOG.error(e.getMessage());	<line9>	"logger.error(""Error in UserDelegateEntityService remove method"", e)"	"<line9> logger.error(""Error in UserDelegateEntityService remove method"", e)"
task5	"<line9>    log.trace(""Updated in db session activity timestamp for "" + id);"	<line7>	"log.debug(""Update activity for session {}"", id)"	"<line7> log.debug(""Update activity for session {}"", id)"
task5	"<line6>      logger.error(""error creating (or modifying) counter"", t);"	<line6>	"logger.error(""error creating (or modifying) counter"", t)"	"<line6> logger.error(""error creating (or modifying) counter"", t)"
task5	"<line17>      LOG.debug(""createSession userId: {}, sessionId: {}, resultCode: {}"",user.getUserId(),rbacCreateSessionResponse.getSessionId(),rbacCreateSessionResponse.getLdapResult().getResultCode());"	<line17>	"LOG.info(""createSession userId [{}] success: {}"", user.getUserId(), rbacCreateSessionResponse)"	"<line17> LOG.info(""createSession userId [{}] success: {}"", user.getUserId(), rbacCreateSessionResponse)"
task5	"<line7>      LOGGER.error(""unexpected exception caught from service center task. "", e);"	<line7>	"LOGGER.error(""Exception in ServiceCenterTask thread"", e)"	"<line7> LOGGER.error(""Exception in ServiceCenterTask thread"", e)"
task5	"<line2>    log.warn(""Can't append '{}' to comment. SessionInfoService is not supported in {}"", st, jaggerPlace);"	<line2>	logger.info(st)	<line2> logger.info(st)
task5	"<line34>      LOGGER.error(""Malformatted sparse row in line "" + line + "" (closing bracket not found)."");"	<line34>	"LOG.warn(""Line {} of sparse data did not end with '}'"", line)"	"<line34> LOG.warn(""Line {} of sparse data did not end with '}'"", line)"
task5	"<line13>          log.info(""Cluster message received to Refresh the cache, but uanble to as it is still being""+ "" populated."");"	<line13>	"log.debug(""Ignoring REFRESHED message sent by {}. Refresh is not supported by this provider"",from)"	"<line13> log.debug(""Ignoring REFRESHED message sent by {}. Refresh is not supported by this provider"",from)"
task5	"<line6>      logger.error(""Error while adding a role"", t);"	<line6>	"logger.error(""Error while adding a role"", t)"	"<line6> logger.error(""Error while adding a role"", t)"
task5	"<line5>    logger.info(""Found multiple message senders: {}."", names.stream().collect(Collectors.joining("", "")));"	<line5>	"logger.info(""Available Message Senders: {}"", names)"	"<line5> logger.info(""Available Message Senders: {}"", names)"
task5	"<line12>      LOGGER.error(""Failed to insert pattern. Maybe too long with a length of "" + axiomString.length() + ""?"",e);"	<line12>	"logger.error(""SQL Exception while trying to add pattern "" + axiomString, e)"	"<line12> logger.error(""SQL Exception while trying to add pattern "" + axiomString, e)"
task5	<line10>    log.error(msg);	<line10>	LOG.info(msg)	<line10> LOG.info(msg)
task5	"<line2>      logger.debug(""Invalidate: Entry already invalid: '{}'"", event.getKey());"	<line2>	"logger.debug(""Entry {} already invalidated by another cache for {}"", re.getKey(), owner)"	"<line2> logger.debug(""Entry {} already invalidated by another cache for {}"", re.getKey(), owner)"
task5	"<line6>      logger.warn(""redirectAfterValidation parameter may not be true when useSession parameter is false.""+ "" Resetting it to false in order to prevent infinite redirects."");"	<line10>	"LOG.debug(""{} ready for service"", getName())"	"<line10> LOG.debug(""{} ready for service"", getName())"
task5	"<line1>    log.info(""Installing "" + getEntity() + "" using couchbase-server-{} {}"",getCommunityOrEnterprise(),getVersion());"	<line39>	"LOG.info(""Installing Couchbase Server from {}"", urls)"	"<line39> LOG.info(""Installing Couchbase Server from {}"", urls)"
task5	"<line1>    log.info(""name:{},location:{}"", name, location);"	<line1>	"log.info(""adding swagger resource: "" + name + "" -> "" + location)"	"<line1> log.info(""adding swagger resource: "" + name + "" -> "" + location)"
task5	"<line3>      LOG.debug(""Extra value is null, throw away it."");"	<line3>	"log.warn(""Value should not be null for extra with key: "" + key)"	"<line3> log.warn(""Value should not be null for extra with key: "" + key)"
task5	"<line5>    log.info(Color.GREEN + ""Calendar_2_6 : missing column friday"" + Color.NORMAL);"	<line5>	"log.info(Color.GREEN + ""Calendar_2_6 : missing column friday"" + Color.NORMAL)"	"<line5> log.info(Color.GREEN + ""Calendar_2_6 : missing column friday"" + Color.NORMAL)"
task5	"<line5>      logger.debug(""Failed to parse peer info for SSL engine initialization"", e);"	<line5>	"LOGGER.debug(""Error while parsing peer info"", e)"	"<line5> LOGGER.debug(""Error while parsing peer info"", e)"
task5	"<line9>        logger.debug(""Query line: "" + line);"	<line14>	"logger.debug(""Filtered query: {}"", stringBuilder.toString())"	"<line14> logger.debug(""Filtered query: {}"", stringBuilder.toString())"
task5	"<line2>    log.info(""------  testNumericAndRange  ------"");"	<line2>	"log.info(""------  testNumericAndRange  ------"")"	"<line2> log.info(""------  testNumericAndRange  ------"")"
task5	"<line15>      LOGGER.warn(""At upper bound on partition.  Increase the bounds or condense the data."");"	<line15>	"LOGGER.debug(""Reached the upper bound per partition. No more items can be added to this partition."")"	"<line15> LOGGER.debug(""Reached the upper bound per partition. No more items can be added to this partition."")"
task5	"<line4>      LOG.info(""Deleted {} repository {}."", repoEntry.getType(), reponame);"	<line3>	"log.info(""Deleting repo entry {}"", repoEntry.getId())"	"<line3> log.info(""Deleting repo entry {}"", repoEntry.getId())"
task5	"<line7>    logger.info(PRINT_BORDER + ""shuffleStations: "" + oldStation + "" -> "" + currentStation + PRINT_BORDER);"	<line6>	"logger.info(PRINT_BORDER+ ""Now playing: ""+ currentStation.getName()+ "" - ""+ currentStation.getUrl()+ PRINT_BORDER)"	"<line6> logger.info(PRINT_BORDER+ ""Now playing: ""+ currentStation.getName()+ "" - ""+ currentStation.getUrl()+ PRINT_BORDER)"
task5	"<line21>    logger.debug(""Mocking the console input for drop id: {}"", dropId);"	<line2>	"log.debug(""test method: dropImport"")"	"<line2> log.debug(""test method: dropImport"")"
task5	"<line2>      logger.debug(""getConnectionAsync("" + intent + "")"");"	<line2>	"logger.debug(""Getting connection for intent: "" + intent)"	"<line2> logger.debug(""Getting connection for intent: "" + intent)"
task5	<line1>    logger.debug(msg, thr);	<line1>	logger.debug(msg, thr)	<line1> logger.debug(msg, thr)
task5	"<line11>      LOG.info(""Retrieved count of {}"", numberOfRecords);"	<line16>	"LOG.error(""Unable to retrieve count of DiGIR dataset [{}]"", dataset.getKey(), e)"	"<line16> LOG.error(""Unable to retrieve count of DiGIR dataset [{}]"", dataset.getKey(), e)"
task5	"<line38>      LOGGER.error(""Could not scan for "" + getProbeName(), E);"	<line38>	"LOGGER.error(""Could not scan for "" + getProbeName(), E)"	"<line38> LOGGER.error(""Could not scan for "" + getProbeName(), E)"
task5	<line4>      log.error(e.getMessage(), e);	<line4>	"log.error(""Caught exception."", e)"	"<line4> log.error(""Caught exception."", e)"
task5	"<line2>    log.info(""Killing job {}. {}"", jobId, out);"	<line2>	"LOGGER.info(""out = "" + out)"	"<line2> LOGGER.info(""out = "" + out)"
task5	"<line6>    logger.info(name + "": "" + total + "" from "" + results.size() + "" worker threads"");"	<line6>	"logger.info(""Total: "" + total)"	"<line6> logger.info(""Total: "" + total)"
task5	"<line9>        LOGGER.warn(""Address resover key:{}'s value:{} is not positive, please check!"", key, val);"	<line9>	"LOG.warn(""Ignoring invalid configuration property \""{}\"" with value \""{}\"""", key, val)"	"<line9> LOG.warn(""Ignoring invalid configuration property \""{}\"" with value \""{}\"""", key, val)"
task5	<line71>      log.error(systemException, systemException);	<line71>	log.error(systemException, systemException)	<line71> log.error(systemException, systemException)
task5	"<line2>    LOGGER.info(""Logical switches returned to client: {}"", logicalSwitches.toJsonString());"	<line2>	"LOGGER.info(""LogicalSwitches returned to client (count) : "" + logicalSwitches.getCount())"	"<line2> LOGGER.info(""LogicalSwitches returned to client (count) : "" + logicalSwitches.getCount())"
task5	<line14>      log.error(exception, exception);	<line14>	"log.error(""Unable to make callback to URL: "" + callbackURL, exception)"	"<line14> log.error(""Unable to make callback to URL: "" + callbackURL, exception)"
task5	"<line3>      log.debug(""HostObjectComponent activated"");"	<line3>	"log.debug(""Activated {}"", this.properties.get(ConfigurationService.KURA_SERVICE_PID))"	"<line3> log.debug(""Activated {}"", this.properties.get(ConfigurationService.KURA_SERVICE_PID))"
task5	"<line15>    log.info(""removed="" + removedStopTimeCount + "" total="" + totalStopTimeCount);"	<line15>	"log.info(""Removed "" + removedStopTimeCount + "" of "" + totalStopTimeCount + "" stopTimes"")"	"<line15> log.info(""Removed "" + removedStopTimeCount + "" of "" + totalStopTimeCount + "" stopTimes"")"
task5	"<line4>      LOG.debug(""Removing "" + old + "" when adding "" + policy + "" to "" + AbstractEntity.this);"	<line6>	"log.debug(""Adding policy "" + policy + "" to "" + AbstractEntity.this)"	"<line6> log.debug(""Adding policy "" + policy + "" to "" + AbstractEntity.this)"
task5	"<line9>      logger.warn("""", fex);"	<line9>	"logger.warn(""Unable to create document fragment."", fex)"	"<line9> logger.warn(""Unable to create document fragment."", fex)"
task5	"<line11>      LOG.debug(""retrieving document("" + documentId + "","" + user.getPrincipalName() + "")"");"	<line11>	"LOG.debug(""loadWorkflowDocument('"" + documentId + ""', "" + user + "")"")"	"<line11> LOG.debug(""loadWorkflowDocument('"" + documentId + ""', "" + user + "")"")"
task5	"<line6>      LOG.debug(readNext.getKey().get() + "" / "" + readNext.getValue().toString());"	<line8>	"LOG.info(""Total number of pairs: "" + numOfPairs)"	"<line8> LOG.info(""Total number of pairs: "" + numOfPairs)"
task5	<line14>        log.debug(sb.toString());	<line14>	log.debug(sb.toString())	<line14> log.debug(sb.toString())
task5	"<line3>    logger.info(""{}"", grpcTransportConfig);"	<line3>	"logger.info(""gRPC transport configuration: {}"", grpcTransportConfig)"	"<line3> logger.info(""gRPC transport configuration: {}"", grpcTransportConfig)"
task5	"<line5>      LOGGER.info(""Number of metrics registry: {}"", metricsRegistries.size());"	<line3>	"log.info(""Adding metrics registry registration listener: "" + listener.getClass().getName())"	"<line3> log.info(""Adding metrics registry registration listener: "" + listener.getClass().getName())"
task5	"<line6>    logger.info(name + "": "" + total + "" from "" + operationCounterList.size() + "" worker threads"");"	<line6>	"logger.info(""Total: "" + total)"	"<line6> logger.info(""Total: "" + total)"
task5	"<line1>    logger.info(String.format(""Extracting '%s' to '%s'"", zipFile.getAbsolutePath(), destination.getAbsolutePath()));"	<line27>	"logger.error(""Unable to unzip "" + zipFile.getAbsolutePath(), e)"	"<line27> logger.error(""Unable to unzip "" + zipFile.getAbsolutePath(), e)"
task5	"<line12>      logger.warn(""error deserializing event message"", e);"	<line12>	logger.error(e.getMessage(), e)	<line12> logger.error(e.getMessage(), e)
task5	"<line9>          log.info(""[{}] dispatcher reached to max unack msg limit on blocked-broker {}"",dispatcher.getName(),dispatcher.getTotalUnackedMessages());"	<line10>	"LOG.info(""Blocking dispatcher on unacked messages threshold exceeded. Dispatcher will not process any""+ "" more messages until the threshold is decreased below the""+ "" current level."")"	"<line10> LOG.info(""Blocking dispatcher on unacked messages threshold exceeded. Dispatcher will not process any""+ "" more messages until the threshold is decreased below the""+ "" current level."")"
task5	"<line2>    logger.trace(""createOutputStream: {}"", arg0);"	<line2>	"logger.debug(""createOutputStream("" + arg0 + "")"")"	"<line2> logger.debug(""createOutputStream("" + arg0 + "")"")"
task5	"<line3>      LOGGER.debug(""[{}] Cancelled SuspicionTimeoutTask for {}"", localMember, memberId);"	<line4>	"log.debug(""Cancelled suspicion timeout task for member {}"", memberId)"	"<line4> log.debug(""Cancelled suspicion timeout task for member {}"", memberId)"
task5	"<line12>        logger.warn(""Error deleting settings temp file: "" + file, e);"	<line12>	"log.error(""Could not delete file "" + file.getAbsolutePath(), e)"	"<line12> log.error(""Could not delete file "" + file.getAbsolutePath(), e)"
task5	"<line24>      LOGGER.error(""Cannot index representation: {}"", representation, e);"	<line24>	"LOGGER.error(""Error indexing representation {}"", representation.getId(), e)"	"<line24> LOGGER.error(""Error indexing representation {}"", representation.getId(), e)"
task5	"<line5>      logger.warn(""Could not convert a Nuxeo integer value to its string equivalent: "" + cce.getMessage());"	<line5>	"log.error(""Unexpected class cast exception while converting value to long"")"	"<line5> log.error(""Unexpected class cast exception while converting value to long"")"
task5	"<line17>                log.error(""Waiting is interrupted."", e);"	<line17>	"log.error(""Error while waiting for block: "" + e, e)"	"<line17> log.error(""Error while waiting for block: "" + e, e)"
task5	"<line5>    LOGGER.warn(""Unexpected exception."", cause);"	<line5>	"log.error(""exceptionCaught()"", cause)"	"<line5> log.error(""exceptionCaught()"", cause)"
task5	"<line2>      LOGGER.debug(""Deleting ALL temporary files from `{}`"", tempDirectory.toString());"	<line2>	"LOGGER.info(""Deleting temporary directory "" + tempDirectory)"	"<line2> LOGGER.info(""Deleting temporary directory "" + tempDirectory)"
task5	<line2>    log.trace(msg);	<line2>	LOGGER.info(msg)	<line2> LOGGER.info(msg)
task5	"<line8>        log.warn(""Unable to load presets"", e);"	<line8>	"logger.error(""error reading default package selection file"", e)"	"<line8> logger.error(""error reading default package selection file"", e)"
task5	"<line4>      this.logger.warn(""Could not delete temp directory"");"	<line4>	"LOGGER.warn(""Failed to delete world directory {}"", this.worldDir)"	"<line4> LOGGER.warn(""Failed to delete world directory {}"", this.worldDir)"
task5	"<line3>        LOGGER.info(""Global transaction is disabled."");"	<line3>	"LOGGER.info(""The use of global transaction is disabled."")"	"<line3> LOGGER.info(""The use of global transaction is disabled."")"
task5	"<line34>      logger.error(""update process definition json workergroup error"", e);"	<line34>	"logger.error(""update process definition json worker group error."", e)"	"<line34> logger.error(""update process definition json worker group error."", e)"
task5	"<line24>                    log.error(""Unexpected error: "" + e, e);"	<line24>	"log.error(""Unexpected error"", e)"	"<line24> log.error(""Unexpected error"", e)"
task5	"<line5>      log.debug(""After encoding"" + ((Command) msg).toString());"	<line5>	"log.debug(""wrapped message: {} writeFuture: {}"", msg, writeFuture)"	"<line5> log.debug(""wrapped message: {} writeFuture: {}"", msg, writeFuture)"
task5	"<line14>        log.debug(""ClientService request failed "" + server + "", retrying ... "", tte);"	<line14>	"log.debug(""Transport exception to server {}, retrying..."", server, tte)"	"<line14> log.debug(""Transport exception to server {}, retrying..."", server, tte)"
task5	"<line12>      LOG.error(""Cannot remove CustomizedStateConfig from cluster: {}, Exception: {}"", clusterId, ex);"	<line12>	"LOG.error(""Exception in removeCustomizedStateConfig"", ex)"	"<line12> LOG.error(""Exception in removeCustomizedStateConfig"", ex)"
task5	"<line4>      logger.warn(""{}: Only PresetID >6 is allowed"", handler.getDeviceName());"	<line4>	"logger.info(""Invalid command value {} for addCurrentContentItemToPresetContainer()"", command.intValue())"	"<line4> logger.info(""Invalid command value {} for addCurrentContentItemToPresetContainer()"", command.intValue())"
task5	"<line3>    log.info(""creating CDI container for bean bundle {} with extension bundles {}"", bundle, extensions);"	<line3>	"log.info(""Creating a new CDS extension container for bundle "" + bundle.getSymbolicName())"	"<line3> log.info(""Creating a new CDS extension container for bundle "" + bundle.getSymbolicName())"
task5	"<line8>      LOGGER.warn(""Bad PolyLineRecord Detected and Discarded."");"	<line8>	"LOGGER.warn(""Bad polyline or polygon record: "" + shapeRec)"	"<line8> LOGGER.warn(""Bad polyline or polygon record: "" + shapeRec)"
task5	"<line22>        LOG.info(""Request external resource {} with config key {}."",resourceQuantity.getAmount(),configKey);"	<line22>	"LOG.debug(""Adding external resource: {}: {}"", configKey, resourceQuantity)"	"<line22> LOG.debug(""Adding external resource: {}: {}"", configKey, resourceQuantity)"
task5	"<line1>    LOG.info(""{}: Restoring WebContainer for bundle {}/{}"", this, symbolicName, version);"	<line3>	"LOG.debug(""WebContainer or HTTP context is null; skipping cleanup of context"")"	"<line3> LOG.debug(""WebContainer or HTTP context is null; skipping cleanup of context"")"
task5	"<line7>    LOGGER.info(""Container destroyed"");"	<line5>	"LOGGER.debug(""Closing CDI container"")"	"<line5> LOGGER.debug(""Closing CDI container"")"
task5	"<line8>      log.warn("""", ex);"	<line8>	"log.error(""Error while processing path {}"", Arrays.toString(path), ex)"	"<line8> log.error(""Error while processing path {}"", Arrays.toString(path), ex)"
task5	"<line32>        log.warn(""Unable to get guest or current user ID"", principalException);"	<line32>	log.warn(principalException, principalException)	<line32> log.warn(principalException, principalException)
task5	"<line4>      this.logger.warn(""Could not find the Dashboard renderer for layout \"""" + layout + ""\"""");"	<line4>	"this.logger.error(""Failed to find dashboard renderer for layout {}"", layout, e)"	"<line4> this.logger.error(""Failed to find dashboard renderer for layout {}"", layout, e)"
task5	"<line6>      logger.info(""Unknown OWL entity type for: "" + entity);"	<line2>	"logger.warn(""Adding null entity to entity label map"")"	"<line2> logger.warn(""Adding null entity to entity label map"")"
task5	"<line2>    LOG.debug(""Lifecycle changed to {}"", lifecycle);"	<line2>	"LOGGER.debug(""Paused state changed to {}"", paused)"	"<line2> LOGGER.debug(""Paused state changed to {}"", paused)"
task5	"<line8>        logger.info(""Could not initiate event tracker from GII provider {}"", provider);"	<line8>	"logger.debug(""Failed to get event state from provider: {}"", provider)"	"<line8> logger.debug(""Failed to get event state from provider: {}"", provider)"
task5	"<line3>      LOG.debug(""["" + id_ + ""] fillText('"" + text + ""', "" + x + "", "" + y + "")"");"	<line3>	"LOG.debug(""["" + id_ + ""] fillText()"")"	"<line3> LOG.debug(""["" + id_ + ""] fillText()"")"
task5	"<line4>      log.warn(""Variables cannot be used in the 'plugin.path' property, since the property is ""+ ""used by plugin scanning before the config providers that replace the ""+ ""variables are initialized. The raw value '{}' was used for plugin scanning, as ""+ ""opposed to the transformed value '{}', and this may cause unexpected results."",rawPluginPath,transformedPluginPath);"	<line4>	"log.warn(""The configuration key {} is deprecated. Please update your configuration to use the key{}""+ "" instead. The plugin path configured in the raw form ({}) will be ignored."",PLUGIN_PATH_CONFIG,PLUGIN_PATH_CONFIG,rawPluginPath)"	"<line4> log.warn(""The configuration key {} is deprecated. Please update your configuration to use the key{}""+ "" instead. The plugin path configured in the raw form ({}) will be ignored."",PLUGIN_PATH_CONFIG,PLUGIN_PATH_CONFIG,rawPluginPath)"
task5	"<line38>      Log.error(""Failed to read help descriptionModel"", e);"	<line38>	"LOGGER.warn(""Failed to match sub-elements"", e)"	"<line38> LOGGER.warn(""Failed to match sub-elements"", e)"
task5	"<line7>      LOGGER.error(""Error while closing session"", e);"	<line7>	"LOGGER.debug(""Error while closing JMS connection, producer or session."", e)"	"<line7> LOGGER.debug(""Error while closing JMS connection, producer or session."", e)"
task5	"<line1>    LOG.debug(""Failed to capture snapshot %d for component %s"", componentId.getSnapshotId(), componentId);"	<line1>	"LOG.info(""Failed to capture component {}"", componentId)"	"<line1> LOG.info(""Failed to capture component {}"", componentId)"
task5	"<line8>      LOG.trace(""writing index file to cache failed"", e);"	<line8>	"LOG.error(""Error writing properties file for index {}"", indexUrl, e)"	"<line8> LOG.error(""Error writing properties file for index {}"", indexUrl, e)"
task5	"<line22>            LOGGER.debug("" Continuing for "" + latData.getLatitudeBand() + index);"	<line22>	"LOGGER.debug(""Skipping zone: "" + zoneNumber + latData.getLatitudeBand())"	"<line22> LOGGER.debug(""Skipping zone: "" + zoneNumber + latData.getLatitudeBand())"
task5	"<line7>      LOG.debug(""Could not parse from natural date: "" + string, e);"	<line7>	"LOG.error(""Unable to parse date"", e)"	"<line7> LOG.error(""Unable to parse date"", e)"
task5	"<line11>        log.warn(""Group with id '""+ id+ ""' not found in UserGroupCache. groupIds string was: ""+ userIds);"	<line11>	"log.warn(""User with id '""+ id+ ""' not found in cache. userIds string was: ""+ userIds)"	"<line11> log.warn(""User with id '""+ id+ ""' not found in cache. userIds string was: ""+ userIds)"
task5	"<line2>    log.debug(""{} receiver link with link correlation id {} was successfully opened"",getLinkInstanceType(),this.linkCorrelationId);"	<line2>	"log.debug(""onLinkRemoteOpen: {}"", event.getSource())"	"<line2> log.debug(""onLinkRemoteOpen: {}"", event.getSource())"
task5	"<line10>                  LOGGER.error(""subnetworkId for node ""+ nodeId+ "" (""+ createPoint(graph, nodeId)+ "") already set (""+ sn+ ""). ""+ ""Cannot change to ""+ subnetworkId);"	<line10>	"logger.warn(""Node {} is part of another subnetwork: {}"", nodeId, sn)"	"<line10> logger.warn(""Node {} is part of another subnetwork: {}"", nodeId, sn)"
task5	"<line2>    LOG.debug(""ZK Call - getData [{0}] [{1}] [{2}]"", path, watch, stat);"	<line2>	"LOG.debug(""ZK Call - getData [{0}] [{1}]"", path, watch)"	"<line2> LOG.debug(""ZK Call - getData [{0}] [{1}]"", path, watch)"
task5	"<line2>      LOGGER.info(""Stopping low level grizzly container"");"	<line3>	"log.debug(""Stopped {}"", this)"	"<line3> log.debug(""Stopped {}"", this)"
task5	"<line19>      logger.error(""StudyController - resetStudy - ERROR"", e);"	<line19>	"logger.error(""StudyController - resetStudy - ERROR"", e)"	"<line19> logger.error(""StudyController - resetStudy - ERROR"", e)"
task5	"<line2>    LOGGER.info(""Reading properties from: "" + fileName + "". Will try classpath, then file system."");"	<line2>	"LOG.info(""Reading properties from file {}"", fileName)"	"<line2> LOG.info(""Reading properties from file {}"", fileName)"
task5	"<line15>      LOGGER.error(""Error creating risk incidence in storage"", e);"	<line15>	"LOGGER.error(""Error while creating risk incidence"", e)"	"<line15> LOGGER.error(""Error while creating risk incidence"", e)"
task5	"<line12>      LOG.error(""run predictTest failed "", x);"	<line12>	"LOG.error(""run predictTest failed "", x)"	"<line12> LOG.error(""run predictTest failed "", x)"
task5	"<line4>      LOGGER.error(""Error reloading user page"", e);"	<line4>	"log.error(""Error while reloading page"", e)"	"<line4> log.error(""Error while reloading page"", e)"
task5	<line5>      logger.warn(msg);	<line5>	logger.warn(msg)	<line5> logger.warn(msg)
task5	<line36>        log.debug(exception, exception);	<line36>	log.debug(exception, exception)	<line36> log.debug(exception, exception)
task5	"<line2>    log.info(""Will send a request to ["" + requestUrl + ""]"");"	<line2>	"log.info(""Requesting {}"", requestUrl)"	"<line2> log.info(""Requesting {}"", requestUrl)"
task5	"<line13>        LOG.warn(""Error restarting webapp"", e);"	<line13>	"LOG.warn(""Error restarting webapp"", e)"	"<line13> LOG.warn(""Error restarting webapp"", e)"
task5	"<line6>    LOG.debug(""{}: Create {} {} via actor {}"", id, store, path, masterActor);"	<line6>	"LOG.debug(""{}: Create {} {} - {}"", id, store, path, data)"	"<line6> LOG.debug(""{}: Create {} {} - {}"", id, store, path, data)"
task5	"<line26>      logger.error(""Exception:"", e);"	<line26>	"logger.error(""Error occured while generating JSON!"", e)"	"<line26> logger.error(""Error occured while generating JSON!"", e)"
task5	"<line2>    LOG.debug(""Attempting to sync all data to filesystem"");"	<line2>	"logger.debug(""calling hsync()"")"	"<line2> logger.debug(""calling hsync()"")"
task5	"<line3>    LOG.debug(""processing tuple"");"	<line3>	"LOG.debug(""Received tuple {}"", tuple)"	"<line3> LOG.debug(""Received tuple {}"", tuple)"
task5	<line9>          log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line9>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line9> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line5>      logger.error(""error happens when merge fragments:"" + fragmentsToMerge, e);"	<line5>	"logger.error(""Cannot merge fragments"", e)"	"<line5> logger.error(""Cannot merge fragments"", e)"
task5	"<line4>      log.error("""", e);"	<line4>	"log.error(""Error getting value of field "" + property, e)"	"<line4> log.error(""Error getting value of field "" + property, e)"
task5	"<line21>    logger.debug(""Mocking the console input"");"	<line2>	"log.debug(""Import fetched test"")"	"<line2> log.debug(""Import fetched test"")"
task5	"<line5>      LOGGER.info(""Executing resource NetworkUsageCommand "" + cmd);"	<line5>	"LOGGER.info(""execute: "" + cmd.getClass())"	"<line5> LOGGER.info(""execute: "" + cmd.getClass())"
task5	"<line10>    LOGGER.debug(""enqueueGetConfigurationRequest called with organisation {} and device {}"",organisationIdentification,deviceIdentification);"	<line10>	"LOGGER.debug(""enqueueGetConfigurationRequest called with organisation {} and device {}"",organisationIdentification,deviceIdentification)"	"<line10> LOGGER.debug(""enqueueGetConfigurationRequest called with organisation {} and device {}"",organisationIdentification,deviceIdentification)"
task5	<line51>      log.error(systemException, systemException);	<line51>	log.error(systemException, systemException)	<line51> log.error(systemException, systemException)
task5	"<line1>    log.debug(""Aio Server started, waiting for accept."");"	<line1>	"LOG.info(""Starting listener {}."", this)"	"<line1> LOG.info(""Starting listener {}."", this)"
task5	"<line42>    logger.trace(""Getting all shared analysis output file info for project id="" + projectId);"	<line42>	"logger.trace(""Getting all automated analysis output file info shared with project"")"	"<line42> logger.trace(""Getting all automated analysis output file info shared with project"")"
task5	"<line3>    LOGGER.info(""Extra unmanaged storage volume attachments returned to client: {}"",JsonPrettyPrinter.print(extraStorageVolumes));"	<line3>	"LOGGER.info(""ExtraStorageVolumes returned to client : "" + extraStorageVolumes.toJsonString())"	"<line3> LOGGER.info(""ExtraStorageVolumes returned to client : "" + extraStorageVolumes.toJsonString())"
task5	"<line41>      log.error(""Error reading file input stream"", e);"	<line39>	"logger.error(""Error editing resource"", e)"	"<line39> logger.error(""Error editing resource"", e)"
task5	"<line5>      logger.debug(""ACL of "" + mutableAcl.getObjectIdentity() + "" updated successfully."");"	<line2>	"LOGGER.debug(""updateAcl()"")"	"<line2> LOGGER.debug(""updateAcl()"")"
task5	"<line11>        logger.debug(""sync snapshot "" + snapshotId + "" from cache to object store..."");"	<line11>	"logger.debug(""snapshot "" + snapshotId + "" is not on region store: "" + store.getName())"	"<line11> logger.debug(""snapshot "" + snapshotId + "" is not on region store: "" + store.getName())"
task5	"<line4>    LOGGER.debug(""Create {}"", contextDto);"	<line4>	"LOGGER.debug(""Create {}"", contextDto)"	"<line4> LOGGER.debug(""Create {}"", contextDto)"
task5	"<line25>                LOG.info(""Count of incomplete tasks now ""+ taskCountAfterAtOld+ "", ""+ unendedTasks+ "" unended""+ (extraAllowedMax > 0 ? "" ("" + extraAllowedMax + "" allowed)"" : """")+ ""; tasks remembered are: ""+ tasks);"	<line24>	"log.info(""Unended tasks: "" + unendedTasks)"	"<line24> log.info(""Unended tasks: "" + unendedTasks)"
task5	"<line1>    LOG.debug(""{}: Committing finalized checkpoint {}"", this, checkpointMark);"	<line1>	"log.debug(""Committing checkpoint mark {}"", checkpointMark)"	"<line1> log.debug(""Committing checkpoint mark {}"", checkpointMark)"
task5	"<line3>      log.debug(""receive the jvm metrics from service instance, name: {}, instance: {}"",request.getService(),request.getServiceInstance());"	<line3>	"log.debug(""Collect JVMMetricCollection: {}"", request)"	"<line3> log.debug(""Collect JVMMetricCollection: {}"", request)"
task5	"<line3>      logger.info(""Register task : {} for redriver with time : {}"", taskId, redriveDelay);"	<line3>	"logger.info(""Register task : {} with smId : {} redrive delay : {}"", taskId, stateMachineId, redriveDelay)"	"<line3> logger.info(""Register task : {} with smId : {} redrive delay : {}"", taskId, stateMachineId, redriveDelay)"
task5	"<line24>        log.info(""Assigning schema version {""+ latestSchemaVersion.getId()+ "" / ""+ latestSchemaVersion.getProperty(""uuid"")+ ""} to release"");"	<line2>	"log.info(""Applying the mesh migration to the database."")"	"<line2> log.info(""Applying the mesh migration to the database."")"
task5	"<line2>    logger.error(""TextUnitSearcher couldn't recover for \""call\"": {}\n{}"",textUnitSearcherError.getMessage(),textUnitSearcherError.nativeCriteria.getQueryInfo().toString());"	<line2>	"logger.error(""Error while searching text units"", textUnitSearcherError)"	"<line2> logger.error(""Error while searching text units"", textUnitSearcherError)"
task5	"<line7>      LOG.error(""While provisioning members of group {}"", model.getObject().getKey(), e);"	<line7>	"LOG.error(""While deprovisioning members for group {}"", model.getObject().getKey(), e)"	"<line7> LOG.error(""While deprovisioning members for group {}"", model.getObject().getKey(), e)"
task5	"<line5>      log.info(""*** Starting workspace mode: "" + wsm);"	<line5>	"log.info(""Starting: "" + wsm)"	"<line5> log.info(""Starting: "" + wsm)"
task5	<line28>      log.error(e.getMessage(), e);	<line28>	"log.error(""get version list error"", e)"	"<line28> log.error(""get version list error"", e)"
task5	<line4>      LOGGER.error(PRIVATE_KEY_MUST_BE_CONFIGURED_FOR_DECRYPTION);	<line2>	"LOGGER.debug(""Getting cipher for decryption"")"	"<line2> LOGGER.debug(""Getting cipher for decryption"")"
task5	"<line1>    log.info(""SessionContext got started. Init Object: "" + payload.toString());"	<line1>	"log.info(""SessionContext: "" + SessionContext.getCurrentSessionContext())"	"<line1> log.info(""SessionContext: "" + SessionContext.getCurrentSessionContext())"
task5	<line5>      log.error(exception, exception);	<line5>	log.error(exception, exception)	<line5> log.error(exception, exception)
task5	"<line34>    LOGGER.info(""Checking produced and consumed messages to pod:{}"", defaultKafkaClientsPodName);"	<line9>	"LOGGER.info(""Send and receive messages with anonymous authentication"")"	"<line9> LOGGER.info(""Send and receive messages with anonymous authentication"")"
task5	"<line2>      log.warn(""{}.attachSpeechRecognizer(null)"", getName());"	<line2>	"log.warn(""recognizer is null"")"	"<line2> log.warn(""recognizer is null"")"
task5	"<line19>    logger.debug(""[refreshCurrentMasterHealthStatus] cluster {}, shard {} remove not exist targetDcId {}"",clusterId,shardId,toDeleteTargetDcIds);"	<line22>	"logger.info(""[refreshCurrentMasterHealthStatus][{}] {}"", clusterId, shardId)"	"<line22> logger.info(""[refreshCurrentMasterHealthStatus][{}] {}"", clusterId, shardId)"
task5	"<line9>        log.warn(""ORC file %s was written by a newer Hive version %s. This file may not be readable by""+ "" this version of Hive (%s.%s)."",orcDataSource,Joiner.on('.').join(version),CURRENT_MAJOR_VERSION,CURRENT_MINOR_VERSION);"	<line9>	"LOG.info(""ORC version {} is not supported. The current version is {}.{}"",orcDataSource.getOrcVersion(),CURRENT_MAJOR_VERSION,CURRENT_MINOR_VERSION)"	"<line9> LOG.info(""ORC version {} is not supported. The current version is {}.{}"",orcDataSource.getOrcVersion(),CURRENT_MAJOR_VERSION,CURRENT_MINOR_VERSION)"
task5	"<line26>      LOGGER.error(""Error while checking for database"", e);"	<line26>	"LOG.error(""Error while checking for database existence"", e)"	"<line26> LOG.error(""Error while checking for database existence"", e)"
task5	"<line13>    log.info(""App started:"");"	<line13>	"log.info(""App started:"")"	"<line13> log.info(""App started:"")"
task5	"<line7>    LOGGER.error(""handling error: {} for message type: {}"", e.getMessage(), messageType, e);"	<line7>	"LOGGER.info(""handling error: {} for message type: {}"", e.getMessage(), messageType)"	"<line7> LOGGER.info(""handling error: {} for message type: {}"", e.getMessage(), messageType)"
task5	"<line4>        LOG.warn(""Ignoring XMLHttpRequest.setRequestHeader for "" + name + "": it is a restricted header"");"	<line4>	"LOG.warn(""Ignoring request header ["" + name + ""]"")"	"<line4> LOG.warn(""Ignoring request header ["" + name + ""]"")"
task5	<line9>      LOGGER.debug(parseException.getMessage(), parseException);	<line9>	LOG.error(parseException.getMessage())	<line9> LOG.error(parseException.getMessage())
task5	"<line5>      log.warn(""Error reading measurement list from storage = '""+ e+ ""' ,""+ "" trying to convert the list records size"");"	<line5>	"log.error(""Unexpected error while reading measurement records from the database."", e)"	"<line5> log.error(""Unexpected error while reading measurement records from the database."", e)"
task5	"<line7>        logger.warn(""Exception at showUserListMembership"", e);"	<line7>	"logger.warn(""Exception at showUserListMembership"", e)"	"<line7> logger.warn(""Exception at showUserListMembership"", e)"
task5	"<line12>      log.info(""The hive operation handle: {}"", op);"	<line22>	"log.info(""Result set is : "" + result)"	"<line22> log.info(""Result set is : "" + result)"
task5	"<line6>      LOG.warn(""Failed to set activity stream type with type:"" + name);"	<line6>	"log.error(""Unknown type: "" + name)"	"<line6> log.error(""Unknown type: "" + name)"
task5	"<line9>      logger.error(""return message error {} - {}"", message.getSubject(), message.getMessageId());"	<line9>	"log.error(""Failed to write error response: {}"", e.getMessage(), e)"	"<line9> log.error(""Failed to write error response: {}"", e.getMessage(), e)"
task5	"<line7>      logger.info(""init: "" + this.toString());"	<line7>	"log.info(""Distributed worker threads started"")"	"<line7> log.info(""Distributed worker threads started"")"
task5	"<line2>    logger.info(""Totally handled "" + mapCounter + "" records!"");"	<line3>	"LOG.debug(""Adding done."")"	"<line3> LOG.debug(""Adding done."")"
task5	"<line27>      LOG.trace(""Node {} has changes"", target);"	<line27>	"log.debug(""copied node state {} to {}"", source, target)"	"<line27> log.debug(""copied node state {} to {}"", source, target)"
task5	"<line4>      LOGGER.error(""file "" + file + "" doesn't exists"");"	<line4>	"log.error(""Mapping file not found: "" + file)"	"<line4> log.error(""Mapping file not found: "" + file)"
task5	"<line3>    logger.debug(""Starting CHARGEBACK for payment {} ({} {})"",paymentStateContext.getPaymentId(),paymentStateContext.getAmount(),paymentStateContext.getCurrency());"	<line3>	"LOG.debug(""Payment {} for amount {} with currency {} has been processed"",paymentStateContext.getPaymentId(),paymentStateContext.getAmount(),paymentStateContext.getCurrency())"	"<line3> LOG.debug(""Payment {} for amount {} with currency {} has been processed"",paymentStateContext.getPaymentId(),paymentStateContext.getAmount(),paymentStateContext.getCurrency())"
task5	"<line14>      log.error(String.format(""Unable to deserialize JSON localized property \""%s\"" "" + ""from request"",propertyName),jsonException);"	<line14>	"log.error(""Unable to parse JSON object"", jsonException)"	"<line14> log.error(""Unable to parse JSON object"", jsonException)"
task5	"<line4>    LOGGER.info(""requestReadAlarmRegister for organisationIdentification: {} for deviceIdentification: {}"",deviceMessageMetadata.getOrganisationIdentification(),deviceMessageMetadata.getDeviceIdentification());"	<line4>	"LOGGER.info(""requestReadAlarmRegister for organisationIdentification: {} for deviceIdentification: {}"",deviceMessageMetadata.getOrganisationIdentification(),deviceMessageMetadata.getDeviceIdentification())"	"<line4> LOGGER.info(""requestReadAlarmRegister for organisationIdentification: {} for deviceIdentification: {}"",deviceMessageMetadata.getOrganisationIdentification(),deviceMessageMetadata.getDeviceIdentification())"
task5	"<line2>    logger.debug(""Getting monomers as hashtable"");"	<line2>	"logger.debug(""Getting monomers: "", super.getMonomers())"	"<line2> logger.debug(""Getting monomers: "", super.getMonomers())"
task5	"<line39>      LOG.info(""Forwarded the prediction model of ""+ numForwarded+ "" rows. [lastLosses=""+ cvState.getCumulativeLoss()+ "", #trainingExamples=""+ count+ ""]"");"	<line38>	"LOG.info(""Forwarded "" + numForwarded + "" ratings"")"	"<line38> LOG.info(""Forwarded "" + numForwarded + "" ratings"")"
task5	<line2>    LOGGER.error(throwable.getMessage(), throwable);	<line2>	LOGGER.error(throwable.getMessage(), throwable)	<line2> LOGGER.error(throwable.getMessage(), throwable)
task5	"<line8>      log.warn(""The service is already shut down."");"	<line8>	"log.warn(""Trying to shutdown a non started limiter service!"")"	"<line8> log.warn(""Trying to shutdown a non started limiter service!"")"
task5	"<line40>      logger.error(""error occurred while trying to run jvm tool:\n{}\n{}"",Joiner.on(' ').join(command),errorStreamReader.getOutput().trim());"	<line7>	"logger.debug(""Running external attach command: {}"", command)"	"<line7> logger.debug(""Running external attach command: {}"", command)"
task5	"<line2>    logger.info(""Handling error: "" + e.getClass().getSimpleName() + "", "" + e.getMessage());"	<line5>	logger.info(e.getMessage(), e)	<line5> logger.info(e.getMessage(), e)
task5	"<line3>    logger.error(""Unable to get config {} / {}"", replyContext, error);"	<line3>	"logger.info(""getCurrentConfigFailed error:{}"", error)"	"<line3> logger.info(""getCurrentConfigFailed error:{}"", error)"
task5	<line7>      LOG.error(I18n.err(I18n.ERR_78, ldif, dn));	<line7>	"LOG.error(""Failed to create new entry"", e)"	"<line7> LOG.error(""Failed to create new entry"", e)"
task5	"<line20>      LOGGER.debug(""Created shunt {}"", newShunt.getId());"	<line20>	"LOGGER.trace(""Created shunt compensator '{}'"", newShunt.getId())"	"<line20> LOGGER.trace(""Created shunt compensator '{}'"", newShunt.getId())"
task5	"<line2>    log.debug(""Sending CommfaultTag tag {} (#{})"", tagName, tagID);"	<line2>	"log.info(""Commfault tag value is {}"", value)"	"<line2> log.info(""Commfault tag value is {}"", value)"
task5	"<line28>          logger.warn(""Unknown error type in proto serialization, setting unknown "" + errorType);"	<line28>	"logger.error(""Error Type "" + errorType + "" is not supported"")"	"<line28> logger.error(""Error Type "" + errorType + "" is not supported"")"
task5	"<line11>      log.error(String.format(""%s: failed sending discovery request"", local_addr), ex);"	<line11>	"log.error(Util.getMessage(""FailedSendingMulticastDiscoveryRequest""), ex)"	"<line11> log.error(Util.getMessage(""FailedSendingMulticastDiscoveryRequest""), ex)"
task5	"<line2>    logger.debug(""Getting Name: "", super.getName());"	<line2>	"logger.debug(""Getting Name: "", super.getName())"	"<line2> logger.debug(""Getting Name: "", super.getName())"
task5	"<line3>      logger.info(result.getRows().get(i).getValues().get(0)+ "" ""+ result.getRows().get(i).getValues().get(1));"	<line3>	"logger.debug(String.format(""Result: %s"", result.getRows().get(i).getValues().toString()))"	"<line3> logger.debug(String.format(""Result: %s"", result.getRows().get(i).getValues().toString()))"
task5	"<line13>      LOGGER.debug("""", e);"	<line13>	"logger.error("""", e)"	"<line13> logger.error("""", e)"
task5	"<line13>      logger.info(""Saved FQL Query : {}"", fqlStore.getQuery());"	<line14>	"LOG.error(""Couldn't save FQL query: "" + fqlStore.getQuery(), e)"	"<line14> LOG.error(""Couldn't save FQL query: "" + fqlStore.getQuery(), e)"
task5	<line9>      log.error(exception, exception);	<line9>	log.error(exception, exception)	<line9> log.error(exception, exception)
task5	"<line3>    LOGGER.info(""the UA by id {} "", id);"	<line3>	"LOGGER.debug(""Get unit {}"", id)"	"<line3> LOGGER.debug(""Get unit {}"", id)"
task5	"<line6>        log.warn(""Exception got when closing the tm socket:"", e);"	<line6>	"logger.error(""Could not close socket for TM "", e)"	"<line6> logger.error(""Could not close socket for TM "", e)"
task5	"<line9>      logger.debug(""NULL payload on topic: {}"", topic);"	<line9>	"log.debug(""Received message for topic: {} with no payload"", topic)"	"<line9> log.debug(""Received message for topic: {} with no payload"", topic)"
task5	"<line13>      logger.error(""Error removing consumed Token"", t);"	<line13>	"logger.error(""Error removing consumed Token"", t)"	"<line13> logger.error(""Error removing consumed Token"", t)"
task5	"<line3>      log.info(""Using non-artifact based module id: "" + moduleId);"	<line1>	"log.debug(""Initializing the module packager"")"	"<line1> log.debug(""Initializing the module packager"")"
task5	<line7>        log.debug(portalException, portalException);	<line7>	log.debug(portalException, portalException)	<line7> log.debug(portalException, portalException)
task5	<line6>      log.error(exception, exception);	<line6>	log.error(exception, exception)	<line6> log.error(exception, exception)
task5	"<line2>    LOG.debug(""Opening input stream at {}"", profileUrl);"	<line2>	"logger.debug(""Retrieving profile for scanning at {}"", profileUrl)"	"<line2> logger.debug(""Retrieving profile for scanning at {}"", profileUrl)"
task5	"<line2>    LOG.info(""Connect [{}]"", session);"	<line2>	"LOG.debug(""onConnect {}"", session)"	"<line2> LOG.debug(""onConnect {}"", session)"
task5	"<line6>      logger.warn(""No report history found (normal on first run), existing values will not be reset"");"	<line4>	"logger.debug(""Reading previous report from file: "" + reportHistoryFile)"	"<line4> logger.debug(""Reading previous report from file: "" + reportHistoryFile)"
task5	"<line14>      LOGGER.trace(""Unable to open a connection to the test database."", ex);"	<line14>	"LOG.info(""Database unavailable"", ex)"	"<line14> LOG.info(""Database unavailable"", ex)"
task5	"<line8>      logger.debug(""Looking for matching API with basepath: {} and version: {}"", basePath, version);"	<line8>	"logger.debug(""Looking for matching API with basepath: {} and version: {}"", basePath, version)"	"<line8> logger.debug(""Looking for matching API with basepath: {} and version: {}"", basePath, version)"
task5	<line95>      log.error(exception, exception);	<line95>	log.error(exception, exception)	<line95> log.error(exception, exception)
task5	"<line22>      logger.debug(""PLAY_STATUS - no match on message: {}"", message);"	<line22>	"logger.debug(""No match on message: {}"", message)"	"<line22> logger.debug(""No match on message: {}"", message)"
task5	"<line10>      logger.warn(""Unable to retrieve client hostname"", e);"	<line10>	"logger.warn(""Unable to get the hostname"", e)"	"<line10> logger.warn(""Unable to get the hostname"", e)"
task5	"<line7>      log.error(""Error in updating the webhook.. "", e);"	<line7>	"log.error(""Error while updating webhook configuration {}"", e.getMessage())"	"<line7> log.error(""Error while updating webhook configuration {}"", e.getMessage())"
task5	"<line21>                logger.debug(""Routing Map Null for collection: {}, PartitionKeyRangeId: {}, forceRefresh:{}"",collectionResourceId,partitionKeyRangeId,forceRefresh);"	<line21>	"logger.debug(""tryGetPartitionKeyRangeByIdAsync: collectionResourceId {} , partitionKeyRangeId {} ,""+ "" properties {} , return null"",collectionResourceId,partitionKeyRangeId,properties)"	"<line21> logger.debug(""tryGetPartitionKeyRangeByIdAsync: collectionResourceId {} , partitionKeyRangeId {} ,""+ "" properties {} , return null"",collectionResourceId,partitionKeyRangeId,properties)"
task5	<line5>        log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line5>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line5> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line6>        logger.debug(""Got null bucket region for bucketId={}{}{} for PartitionedRegion = {}"",this.partitionedRegion.getPRId(),PartitionedRegion.BUCKET_ID_SEPARATOR,bucketId,this.partitionedRegion);"	<line6>	"logger.debug(""Bucket id {} not found on VM {}"", new Object[] {bucketId, this.partitionedRegion.getMyId()})"	"<line6> logger.debug(""Bucket id {} not found on VM {}"", new Object[] {bucketId, this.partitionedRegion.getMyId()})"
task5	"<line14>      LOGGER.error(L.m(""Fehler beim Versuch, Bereich zu updaten: \""%1\"""", sectionNameComplete), x);"	<line14>	"LOGGER.trace("""", x)"	"<line14> LOGGER.trace("""", x)"
task5	"<line2>    logger.debug(""Processing the license solution"");"	<line1>	"logger.debug(""Processing license solutions..."")"	"<line1> logger.debug(""Processing license solutions..."")"
task5	"<line3>      LOGGER.info(MessageFormat.format(""No dead letter jobs found for process with id {0}"", processInstanceId));"	<line5>	"logger.debug(""Found {} dead letter jobs for process instance id {} that will be executed"",deadLetterJobsIds.size(),processInstanceId)"	"<line5> logger.debug(""Found {} dead letter jobs for process instance id {} that will be executed"",deadLetterJobsIds.size(),processInstanceId)"
task5	"<line12>      logger.error(""Application run failed"", failure);"	<line10>	"logger.warn(""Exception was not reported by any handler in the SpringBootExceptionReporter chain. ""+ ""This exception will be handled by the default error handling mechanism."",ex)"	"<line10> logger.warn(""Exception was not reported by any handler in the SpringBootExceptionReporter chain. ""+ ""This exception will be handled by the default error handling mechanism."",ex)"
task5	<line9>                LOG.error(exception.getMessage(), exception);	<line9>	"log.error(""Method {} not found on eventData!"", method.getName())"	"<line9> log.error(""Method {} not found on eventData!"", method.getName())"
task5	"<line19>          logger.debug(""Set asyncContext {}"", asyncContext);"	<line19>	"logger.debug(""Set asyncContext {}"", asyncContext)"	"<line19> logger.debug(""Set asyncContext {}"", asyncContext)"
task5	"<line19>      LOG.error(""could not start tomcat."", e);"	<line19>	"LOG.error(""Unable to start tomcat"", e)"	"<line19> LOG.error(""Unable to start tomcat"", e)"
task5	"<line1>    LOGGER.info(""Sending request message to OSGP."");"	<line1>	"LOGGER.info(""Sending request message to OSGP."")"	"<line1> LOGGER.info(""Sending request message to OSGP."")"
task5	"<line14>      log.warn(""Could not describe instance "" + instanceId, e);"	<line14>	"log.warn(""Failed to get AMI id from EC2 API"", e)"	"<line14> log.warn(""Failed to get AMI id from EC2 API"", e)"
task5	"<line17>              log.warn(""Warn limit reached for ""+ type+ "" beans. Currently there ""+ ""are ""+ size+ "" ""+ type+ "" EJB stubs cached in '""+ name+ ""' ""+ ""beanstalk."");"	<line17>	"logger.warn(""The number of ""+ type+ "" sessions (""+ size+ "") is greater than the warn limit (""+ warnLimit+ "")."")"	"<line17> logger.warn(""The number of ""+ type+ "" sessions (""+ size+ "") is greater than the warn limit (""+ warnLimit+ "")."")"
task5	"<line4>      log.debug(""onScript"");"	<line4>	"log.debug(""onScript"")"	"<line4> log.debug(""onScript"")"
task5	<line5>        log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line5>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line5> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line2>    log.info(""register XA resource"");"	<line2>	"LOG.debug(""register()"")"	"<line2> LOG.debug(""register()"")"
task5	<line3>      log.warn(throwable);	<line3>	log.warn(throwable)	<line3> log.warn(throwable)
task5	"<line6>      log.warn(""Cannot read idName, defaulting to 'id'"", e);"	<line6>	"log.error(""Cannot determine identifier property name for layer: "" + featureModel.getEntityMetadata().getLayerName())"	"<line6> log.error(""Cannot determine identifier property name for layer: "" + featureModel.getEntityMetadata().getLayerName())"
task5	"<line3>    LOG.debug(""Decoded SAML: \n{}\n"", base64DecodedResponse);"	<line3>	"logger.debug(""Decoded Response: "" + base64DecodedResponse)"	"<line3> logger.debug(""Decoded Response: "" + base64DecodedResponse)"
task5	"<line2>    LOGGER.debug(""config inited, \""{}\"" set to {}, effective key is \""{}\""."",joinedPriorityKeys,finalValue,effectiveKey);"	<line2>	"log.debug(""initValue() effectiveKey={}"", effectiveKey)"	"<line2> log.debug(""initValue() effectiveKey={}"", effectiveKey)"
task5	<line14>        log.debug(sb.toString());	<line14>	log.debug(sb.toString())	<line14> log.debug(sb.toString())
task5	"<line5>    LOGGER.info(""InstanceResponsePlanNode.run took: "" + (end - start));"	<line5>	"logger.debug(""time taken by plan node: "" + _planNode.toString() + "" "" + (end - start))"	"<line5> logger.debug(""time taken by plan node: "" + _planNode.toString() + "" "" + (end - start))"
task5	"<line2>    logger.debug(""Getting connected rings for ring: "", ring);"	<line2>	"logger.debug(""Getting connected rings for ring {}"", ring)"	"<line2> logger.debug(""Getting connected rings for ring {}"", ring)"
task5	<line6>        log.error(ex.toString(), ex);	<line6>	log.error(ex.toString(), ex)	<line6> log.error(ex.toString(), ex)
task5	"<line9>    logger.debug(""Main Response -> {}"", result);"	<line7>	"logger.debug(""getUserProfileAttributeTypes"")"	"<line7> logger.debug(""getUserProfileAttributeTypes"")"
task5	"<line2>    LOG.info(""KRADConfigurer:getPrimarySpringFiles: getRunMode => "" + getRunMode());"	<line7>	"LOG.debug(""returning primary spring files: "" + springFileLocations)"	"<line7> LOG.debug(""returning primary spring files: "" + springFileLocations)"
task5	<line4>      LOG.debug(msg);	<line4>	LOG.debug(msg)	<line4> LOG.debug(msg)
task5	"<line5>      logger.warn(""Client {} is a slow receiver."", new Object[] {proxy.getProxyID()});"	<line5>	"logger.info(""[denyListSlowReceiver] denying client connection {} for being a slow receiver"",proxy.getProxyID())"	"<line5> logger.info(""[denyListSlowReceiver] denying client connection {} for being a slow receiver"",proxy.getProxyID())"
task5	<line7>      log.error(TIPS);	<line7>	"log.error(""[PowerJob-Server] init datax-web admin failed."", t)"	"<line7> log.error(""[PowerJob-Server] init datax-web admin failed."", t)"
task5	"<line4>      LOG.info(""BodyTrackController.setFacetMetadata(): Attempting to set metadata for facet [""+ facetId+ ""] for connector [""+ connectorName+ ""] and object type [""+ objectTypeName+ ""]"");"	<line4>	"LOG.info(""Executing operation setMetadata on facet ["" + facetId + ""]"")"	"<line4> LOG.info(""Executing operation setMetadata on facet ["" + facetId + ""]"")"
task5	"<line3>    log.info(""Level changed to "" + level.getName());"	<line2>	"logger.debug(""Level set to {}"", level)"	"<line2> logger.debug(""Level set to {}"", level)"
task5	"<line2>      logger.warn(""Setting limit to {} but in current olap context, the limit is already {}, won't apply"",l,limit);"	<line2>	"logger.warn(""The limit is set to ""+ l+ "" requests. Please note that this setting can be overridden in the""+ "" configuration file."")"	"<line2> logger.warn(""The limit is set to ""+ l+ "" requests. Please note that this setting can be overridden in the""+ "" configuration file."")"
task5	<line4>    logger.info(elem);	<line2>	"LOGGER.info(""Getting next page: "" + doc.select(""li.next > a"").first().attr(""href""))"	"<line2> LOGGER.info(""Getting next page: "" + doc.select(""li.next > a"").first().attr(""href""))"
task5	"<line24>        logger.warn(""Initialize DB failed."", e);"	<line24>	"LOGGER.error(""Failed to initialize MariaDB database instance."", e)"	"<line24> LOGGER.error(""Failed to initialize MariaDB database instance."", e)"
task5	"<line7>        log.warn(""Session  "" + sessionHandle.getPublicId() + "" is invalid."");"	<line7>	"log.error(""Error while restoring session"", le)"	"<line7> log.error(""Error while restoring session"", le)"
task5	"<line4>      log.debug(String.format(""Run with feature %s"", feature));"	<line4>	"log.debug(String.format(""Run with feature %s"", feature))"	"<line4> log.debug(String.format(""Run with feature %s"", feature))"
task5	"<line9>            log.debug(String.format(""Artifact repository password encrypted: [application-id] %s ""+ ""[tenant-id] %d [repo-url] %s"",applicationSignUp.getApplicationId(),applicationSignUp.getTenantId(),artifactRepository.getRepoUrl()));"	<line9>	"log.debug(""Encrypted repository password for application: ""+ applicationSignUp.getApplicationName()+ "" with key: ""+ applicationKey)"	"<line9> log.debug(""Encrypted repository password for application: ""+ applicationSignUp.getApplicationName()+ "" with key: ""+ applicationKey)"
task5	"<line15>              LOG.error(""Unexpected exception occur when register owned bundle {}. Shutdown broker now""+ "" !!!"",ownedBundle.getNamespaceBundle(),ex);"	<line15>	"log.error(""Failed to handle unload request for namespace {}"", ownedBundle.getNamespaceBundle(), ex)"	"<line15> log.error(""Failed to handle unload request for namespace {}"", ownedBundle.getNamespaceBundle(), ex)"
task5	"<line4>    LOGGER.info(""registered Spring DM injection SPI for PAX Wicket."");"	<line4>	"LOGGER.info(""Spring DM Proxy Target Locator enabled"")"	"<line4> LOGGER.info(""Spring DM Proxy Target Locator enabled"")"
task5	"<line18>      LOG.warn(""Unable to extract assertion from context."", e);"	<line18>	"LOG.error(""Error extracting assertion from context"", e)"	"<line18> LOG.error(""Error extracting assertion from context"", e)"
task5	"<line1>    log.error(""getAllModuleTypesFallback()"");"	<line2>	"log.info(""getAllModuleTypesFallback failed"")"	"<line2> log.info(""getAllModuleTypesFallback failed"")"
task5	"<line7>      log.warn(""Failed to complete JMX registration for "" + objectName, e);"	<line7>	"LOG.warn(""register mbean error"", e)"	"<line7> LOG.warn(""register mbean error"", e)"
task5	"<line9>        LOG.warn(""Failed to find artist bio for "" + artistName, e);"	<line9>	"LOG.warn(""Failed to find artist info for "" + artistName, e)"	"<line9> LOG.warn(""Failed to find artist info for "" + artistName, e)"
task5	"<line10>    LOG.info(""slop={}"", this.slop);"	<line10>	"LOG.info(""slop = "" + slop)"	"<line10> LOG.info(""slop = "" + slop)"
task5	"<line30>        log.error(""Can not find Authenticator with Name [%s]"", authenticationResult.getAuthenticatedBy());"	<line30>	"log.warn(""Authenticator for %s not found"", authenticationResult.getAuthenticatedBy())"	"<line30> log.warn(""Authenticator for %s not found"", authenticationResult.getAuthenticatedBy())"
task5	"<line5>    logger.error(""request failed with HttpMessageNotReadableException"", e);"	<line5>	"logger.error(""request body is required"", e)"	"<line5> logger.error(""request body is required"", e)"
task5	"<line43>      logger.error(""DashBoardAndProfileController:  updateProfileDetails()' = "", e);"	<line43>	"logger.error(""DashBoardAndProfileController - updateProfileDetails() - ERROR"", e)"	"<line43> logger.error(""DashBoardAndProfileController - updateProfileDetails() - ERROR"", e)"
task5	<line3>    logger.warn(logMessage);	<line3>	"logger.info(""Hello world"")"	"<line3> logger.info(""Hello world"")"
task5	"<line25>              logger.debug(""Failed Request: {}\n=>{}"", req, failure.getMessage());"	<line25>	"logger.debug(""Failed to add all: index={}, id={}, message={}"", index, id, failure.getMessage())"	"<line25> logger.debug(""Failed to add all: index={}, id={}, message={}"", index, id, failure.getMessage())"
task5	"<line6>      Log.error(e, ""Couldn't open command server port: "" + port);"	<line6>	"log.error(""Error listening to port "" + port, e)"	"<line6> log.error(""Error listening to port "" + port, e)"
task5	"<line13>    LOG.warn(""Unsupported push node type {}"", node);"	<line7>	"LOG.debug(""Timeout for node {}"", node)"	"<line7> LOG.debug(""Timeout for node {}"", node)"
task5	"<line9>      log.warn(""Logical constraints evaluation is not supported by the current execution type: ""+ this.getExecutionType());"	<line2>	"log.debug(""Starting evaluation of test case group {}"", testCase.getId())"	"<line2> log.debug(""Starting evaluation of test case group {}"", testCase.getId())"
task5	"<line15>      logger.error(""Error loading BpmWidgetInfo list"", t);"	<line15>	"logger.error(""Error loading BpmWidgetInfo list"", t)"	"<line15> logger.error(""Error loading BpmWidgetInfo list"", t)"
task5	"<line29>      logger.warn(""Error deleting manged acl with id '{}': {}"", aclId, e);"	<line29>	"logger.error(""Error during deleting the ACL"", e)"	"<line29> logger.error(""Error during deleting the ACL"", e)"
task5	"<line6>    LOGGER.info(""InstanceDataManager is started! "" + getServerInfo());"	<line2>	"log.info(""Starting the Table Data Manager Service"")"	"<line2> log.info(""Starting the Table Data Manager Service"")"
task5	"<line18>    log.info(""Got no further schedule, can stop now"");"	<line18>	"log.error(""Error in getCurrentRate: no chunk found for time "" + this.rollingTime)"	"<line18> log.error(""Error in getCurrentRate: no chunk found for time "" + this.rollingTime)"
task5	"<line8>    LOGGER.trace(""Send Mercury request, seq: {}, uri: {}, method: {}"",seq,request.header.getUri(),request.header.getMethod());"	<line20>	"LOGGER.trace(""Sending {} packet."", cmd)"	"<line20> LOGGER.trace(""Sending {} packet."", cmd)"
task5	"<line2>      log.debug(""removing item for key: "" + key);"	<line2>	"log.debug(""Remove group attr cache element for key:"" + key)"	"<line2> log.debug(""Remove group attr cache element for key:"" + key)"
task5	"<line4>    logger.info(""Create or replace function "" + objectName);"	<line14>	"logger.info(""Creating function: "" + objectName)"	"<line14> logger.info(""Creating function: "" + objectName)"
task5	"<line19>          LOGGER.debug(""Writing binlog position to {}.positions: {}, last heartbeat read: {}"",c.getCatalog(),newPosition,heartbeat);"	<line29>	"logger.debug(""SQL: {}"", sql)"	"<line29> logger.debug(""SQL: {}"", sql)"
task5	<line25>      log.error(systemException, systemException);	<line25>	log.error(systemException, systemException)	<line25> log.error(systemException, systemException)
task5	"<line23>    Freedomotic.logger.info(""Sending 'GET /"" + page + "" HTTP 1.1' to relay board"");"	<line23>	"logger.debug(""Sending "" + message)"	"<line23> logger.debug(""Sending "" + message)"
task5	"<line2>    logger.debug(""getCloudsWithGatewayAndPublicRelays started..."");"	<line2>	"logger.debug(""getCloudsWithExclusiveGatewayAndPublicRelays started..."")"	"<line2> logger.debug(""getCloudsWithExclusiveGatewayAndPublicRelays started..."")"
task5	"<line6>      log.error(""JargonException in read is converted to IOException for method contract"", e);"	<line6>	"log.error(""jargon exception, rethrowing as IOException"", e)"	"<line6> log.error(""jargon exception, rethrowing as IOException"", e)"
task5	"<line1>    log.warn(""Using old-style extension point""+ "" org.nuxeo.ecm.core.repository.RepositoryService""+ "" for repository \""""+ cdesc.name+ ""\"", use org.nuxeo.ecm.core.storage.sql.RepositoryService instead"");"	<line2>	"log.info(""Adding repository contribution: "" + descriptor.getName())"	"<line2> log.info(""Adding repository contribution: "" + descriptor.getName())"
task5	"<line13>      LOGGER.error(""IccId is probably not supported in this session provider"", e);"	<line10>	"LOGGER.info(""Session provider did not return an IP address for device: {} with iccId: {}. Trying to""+ "" poll for the device IP address..."",dlmsDevice.getDeviceIdentification(),dlmsDevice.getIccId())"	"<line10> LOGGER.info(""Session provider did not return an IP address for device: {} with iccId: {}. Trying to""+ "" poll for the device IP address..."",dlmsDevice.getDeviceIdentification(),dlmsDevice.getIccId())"
task5	"<line20>          logger.error(""Failure to store the field values to file"" + oldBatch.getUpdates(), ex);"	<line20>	"log.error(""Unable to flush activity field store"", ex)"	"<line20> log.error(""Unable to flush activity field store"", ex)"
task5	"<line6>      LOG.debug(""Set parameter "" + name + "" = "" + value);"	<line6>	"LOG.debug(""[setParameter] "" + name + ""="" + value)"	"<line6> LOG.debug(""[setParameter] "" + name + ""="" + value)"
task5	"<line5>      log.warn(""Cannot get project descriptor for project '{}'. Physical project name will be used.""+ "" Cause: {}"",project.getName(),e.getMessage(),e);"	<line5>	log.error(e.getMessage(), e)	<line5> log.error(e.getMessage(), e)
task5	"<line5>      logger.info(this, ""AppHubInit CHECK APP done :uavapp_"" + appName + "" EXIST"");"	<line5>	"log.info(messages.getMessage(""error.init.alreadyExists"", appName))"	"<line5> log.info(messages.getMessage(""error.init.alreadyExists"", appName))"
task5	"<line6>      LOG.trace(""New Histogram:\n"" + tmp_userIdHistogram);"	<line7>	"log.error(""ERROR: failed to find a random buyer id!"")"	"<line7> log.error(""ERROR: failed to find a random buyer id!"")"
task5	"<line9>    logger.debug(""Unexpected StandaloneElement in {}:{}: {} [{}]"", line, col, elementName, attributes);"	<line9>	"logger.debug(""Error parsing options for {}: Unexpected StandaloneElement in {}{}: {} [{}]"",channelName,line,col,elementName,attributes)"	"<line9> logger.debug(""Error parsing options for {}: Unexpected StandaloneElement in {}{}: {} [{}]"",channelName,line,col,elementName,attributes)"
task5	"<line2>    logger.debug(""allocateConnection(connRequestInfo)..."");"	<line6>	"logger.debug(""Called allocateConnection() on a connectionManager ""+ ""created outside the Application Server."")"	"<line6> logger.debug(""Called allocateConnection() on a connectionManager ""+ ""created outside the Application Server."")"
task5	"<line25>      log.debug(""{} ms spent for fetching {} validators"",System.currentTimeMillis() - temp,validatorNames.size());"	<line40>	"log.debug(""Time to get metric names: "" + (System.currentTimeMillis() - temp))"	"<line40> log.debug(""Time to get metric names: "" + (System.currentTimeMillis() - temp))"
task5	"<line3>    LOG.trace(""Using NoOp Implementation for Entity Doc Submission Deferred Response Service"");"	<line3>	"LOG.debug(""Entering NoOp Implementation for Adapter Component Doc Submission Service"")"	"<line3> LOG.debug(""Entering NoOp Implementation for Adapter Component Doc Submission Service"")"
task5	"<line2>    log.debug(""Successfully send ENTITY_CREATED EVENT to rule engine [{}]"", device);"	<line2>	"log.trace(""[{}] Request sent: {}"", requestId, metadata)"	"<line2> log.trace(""[{}] Request sent: {}"", requestId, metadata)"
task5	"<line6>      log.warn(""resource not found: "" + resourceId);"	<line3>	"log.debug(""getExternalUrlForResources: "" + resourceId)"	"<line3> log.debug(""getExternalUrlForResources: "" + resourceId)"
task5	<line15>        log.debug(sb.toString());	<line15>	log.debug(sb.toString())	<line15> log.debug(sb.toString())
task5	"<line7>      log.error(""Problem rendering RequestStatus"", e);"	<line7>	"log.error(""Unable to render RequestStatus"", e)"	"<line7> log.error(""Unable to render RequestStatus"", e)"
task5	"<line12>      LOG.debug(""Requesting subpartition {} of {}."", subpartitionIndex, partition);"	<line12>	"LOG.debug(""Creating subpartition view for partition {}'s subpartition {}"", partitionId, subpartitionIndex)"	"<line12> LOG.debug(""Creating subpartition view for partition {}'s subpartition {}"", partitionId, subpartitionIndex)"
task5	<line7>        log.error(reason);	<line7>	LOG.error(reason)	<line7> LOG.error(reason)
task5	"<line12>      LOG.debug(""Found endpoint properties {}"", names.retainAll(ENDPOINT_CONFIG_FIELDS));"	<line12>	"LOG.debug(""Facebook endpoint configuration: {}"", properties)"	"<line12> LOG.debug(""Facebook endpoint configuration: {}"", properties)"
task5	"<line10>      log.info(""*Not found the file in the copy src directory: "" + baseDir.getPath());"	<line10>	"log.info(""*The directory '"" + baseDir + ""' has no element with the extension '"" + ext + ""'!"")"	"<line10> log.info(""*The directory '"" + baseDir + ""' has no element with the extension '"" + ext + ""'!"")"
task5	"<line6>    LOG.debug(""Graph [{}] get user: {}"", graph, id);"	<line6>	"LOG.debug(""Graph [{}] get user: {}"", graph, id)"	"<line6> LOG.debug(""Graph [{}] get user: {}"", graph, id)"
task5	"<line7>        log.trace(cf + "" "" + endCf);"	<line7>	"log.trace(""isBeyondRange() lastSeenKey="" + lastSeenKey + "" endKey="" + endKey)"	"<line7> log.trace(""isBeyondRange() lastSeenKey="" + lastSeenKey + "" endKey="" + endKey)"
task5	"<line1>    logger.info(""executing test case testRelevanceHashMapInt2StringArrayWay"");"	<line1>	"logger.info(""executing test case testRelevanceHashMapInt2StringArrayWay"")"	"<line1> logger.info(""executing test case testRelevanceHashMapInt2StringArrayWay"")"
task5	"<line3>    log.trace(""Executing findByTenantId [{}]"", tenantId);"	<line3>	"log.debug(""findLwM2mObjectPage() - tenantId: {}, sortProperty: {}, sortOrder: {}, pageLink: {}"",tenantId,sortProperty,sortOrder,pageLink)"	"<line3> log.debug(""findLwM2mObjectPage() - tenantId: {}, sortProperty: {}, sortOrder: {}, pageLink: {}"",tenantId,sortProperty,sortOrder,pageLink)"
task5	"<line28>        log.error(""Failed at expression "" + expected.getKey() + "" at event #"" + assertionNumber, t);"	<line28>	"log.error(""Error while evaluating expression"", t)"	"<line28> log.error(""Error while evaluating expression"", t)"
task5	"<line10>        log.error(""GC_GRACE_SECONDS should be numeric type, Caused by: ."", nfe);"	<line10>	"log.error(""READY_AFTER_MIGRATION property that is not an integer: {}"", gcGraceSeconds)"	"<line10> log.error(""READY_AFTER_MIGRATION property that is not an integer: {}"", gcGraceSeconds)"
task5	"<line3>    LOGGER.debug(""Configuring SAML LogoutRequest for POST."");"	<line8>	"LOG.debug(""Created logout request form: {}"", submitFormUpdated)"	"<line8> LOG.debug(""Created logout request form: {}"", submitFormUpdated)"
task5	"<line11>              log.warn(""Hive table already exists: {}.{}"", table.getDbName(), table.getTableName());"	<line1>	"LOG.debug(""Creating table: {}"", table)"	"<line1> LOG.debug(""Creating table: {}"", table)"
task5	"<line10>    logger.debug(""event=delete_message receipt_handle="" + receiptHandle);"	<line10>	"logger.debug(""event=delete_message receipt_handle="" + receiptHandle)"	"<line10> logger.debug(""event=delete_message receipt_handle="" + receiptHandle)"
task5	"<line4>      logger.debug(""Length is {}"", new Object[] {dataLength});"	<line12>	"LOGGER.debug(""Received invalid LENGTH byte: {}"", b)"	"<line12> LOGGER.debug(""Received invalid LENGTH byte: {}"", b)"
task5	"<line9>      log.debug(""No userCache bean in context"", exc);"	<line9>	"log.warn(""No user cache found in servlet context"", exc)"	"<line9> log.warn(""No user cache found in servlet context"", exc)"
task5	<line8>      logger.error(e.getMessage(), e);	<line8>	"logger.error(""stop canal failed."", e)"	"<line8> logger.error(""stop canal failed."", e)"
task5	"<line5>      LOG.error(""Trying to delete an already removed node"", e);"	<line5>	"LOG.error(""Trying to remove a node which doesn't exist: "" + element)"	"<line5> LOG.error(""Trying to remove a node which doesn't exist: "" + element)"
task5	"<line8>        this.logger.error(""Failed to execute job"", e);"	<line8>	"this.logger.error(""Failed to run indexing job"", e)"	"<line8> this.logger.error(""Failed to run indexing job"", e)"
task5	"<line2>      logger.debug(""Checking the hex key value that was loaded determined the key is empty."");"	<line4>	"logger.debug(""checkHexKey: input key: {}"", input)"	"<line4> logger.debug(""checkHexKey: input key: {}"", input)"
task5	"<line4>          log.info(""Rebalance happened "" + partition.topic() + "":"" + partition.partition());"	<line4>	"log.info(""topic {} - partition {} assigned."", partition.topic(), partition.partition())"	"<line4> log.info(""topic {} - partition {} assigned."", partition.topic(), partition.partition())"
task5	"<line11>      LOG.warn(""Failed to get bean properties on ({})"", clazz, e);"	<line11>	"LOG.error(""Failed to introspect "" + clazz, e)"	"<line11> LOG.error(""Failed to introspect "" + clazz, e)"
task5	<line9>        log.warn(exception, exception);	<line9>	log.warn(exception, exception)	<line9> log.warn(exception, exception)
task5	"<line2>    logger.debug(""Closing embedded node"");"	<line2>	"logger.info(""Destroying {}"", embeddedNode.getId())"	"<line2> logger.info(""Destroying {}"", embeddedNode.getId())"
task5	"<line2>    LOG.error(""Job Running"", jobRunningException);"	<line2>	"LOG.error(""JobRunningException"", jobRunningException)"	"<line2> LOG.error(""JobRunningException"", jobRunningException)"
task5	"<line6>        logger.info(""Excluding {} because it is not a valid Java "" + ""project"", project);"	<line6>	"logger.info(""The '"" + JavaPlugin.JAR_TASK_NAME + ""' task must be of type Jar."")"	"<line6> logger.info(""The '"" + JavaPlugin.JAR_TASK_NAME + ""' task must be of type Jar."")"
task5	"<line2>    LOGGER.info(""Changing to {} namespace"", futureNamespace);"	<line3>	"log.debug(""Set namespace "" + previousNamespace + "" to "" + namespace)"	"<line3> log.debug(""Set namespace "" + previousNamespace + "" to "" + namespace)"
task5	"<line21>      logger.debug(""op=look method={} cost={}"",joinPoint.getSignature().getName(),System.currentTimeMillis() - start);"	<line22>	"logger.info(""aroundMQAdminMethod cost {} ms"", System.currentTimeMillis() - start)"	"<line22> logger.info(""aroundMQAdminMethod cost {} ms"", System.currentTimeMillis() - start)"
task5	"<line7>        LOGGER.info(""Calling commitTask for alias: "" + alias);"	<line2>	"LOG.info(""Committing task for job: ""+ jobContext.getJobName()+ "" task: ""+ taskContext.getTaskId()+ "" alias: ""+ alias)"	"<line2> LOG.info(""Committing task for job: ""+ jobContext.getJobName()+ "" task: ""+ taskContext.getTaskId()+ "" alias: ""+ alias)"
task5	<line16>      logger.debug(e.getMessage(), e);	<line16>	logger.error(e.getMessage(), e)	<line16> logger.error(e.getMessage(), e)
task5	"<line1>    LOG.debug(""FRS service registered for: {}"", nodeId.getValue());"	<line1>	"LOG.info(""Device connected: {}"", nodeId)"	"<line1> LOG.info(""Device connected: {}"", nodeId)"
task5	"<line5>      log.error(""Parsing "" + test + "" for property '"" + property + ""'"", ex);"	<line1>	"log.info(""Testing "" + test + "" against "" + property)"	"<line1> log.info(""Testing "" + test + "" against "" + property)"
task5	<line1>    logger.error(e.getCause().getMessage());	<line1>	"logger.error(""Unhandled exception occurred in I/O thread or handler"", e.getCause())"	"<line1> logger.error(""Unhandled exception occurred in I/O thread or handler"", e.getCause())"
task5	"<line5>      Log.info(""[gwt-history] document list filter has changed"");"	<line5>	"Log.debug(""Updating document list filter to match history state"")"	"<line5> Log.debug(""Updating document list filter to match history state"")"
task5	"<line7>          LOGGER.error(""Error while opening POM file"", e);"	<line7>	"LOGGER.debug(""Error while reading pom.xml"", e)"	"<line7> LOGGER.debug(""Error while reading pom.xml"", e)"
task5	"<line28>      LOG.error(""Could not set AccessControlEntries in the ACL"", e);"	<line28>	"log.debug(""Could not set the ACL's entries field: {}"", e.getMessage())"	"<line28> log.debug(""Could not set the ACL's entries field: {}"", e.getMessage())"
task5	"<line4>        logger.trace(""Closing connection"");"	<line4>	"ActiveMQRALogger.LOGGER.trace(""closeConnection("" + connection + "")"")"	"<line4> ActiveMQRALogger.LOGGER.trace(""closeConnection("" + connection + "")"")"
task5	<line22>      log.error(systemException, systemException);	<line22>	log.error(systemException, systemException)	<line22> log.error(systemException, systemException)
task5	"<line1>    LOG.info(""Getting max data time for "" + dataset);"	<line31>	"LOG.error(""Failed to get max data time for dataset '{}'"", dataset, e)"	"<line31> LOG.error(""Failed to get max data time for dataset '{}'"", dataset, e)"
task5	"<line8>    LOG.trace(""Entering AdapterMpiProxyJavaImpl.findCandidates"");"	<line8>	"LOG.debug(""Using Java Implementation for Patient Discovery MPI Service"")"	"<line8> LOG.debug(""Using Java Implementation for Patient Discovery MPI Service"")"
task5	<line5>        log.warn(exception, exception);	<line5>	log.warn(exception, exception)	<line5> log.warn(exception, exception)
task5	<line37>      log.error(systemException, systemException);	<line37>	log.error(systemException, systemException)	<line37> log.error(systemException, systemException)
task5	"<line2>    log.trace(MessageFormat.format(""resolving {0} for Template"", input));"	<line2>	"log.debug(""Resolving template argument "" + input)"	"<line2> log.debug(""Resolving template argument "" + input)"
task5	"<line2>    LOG.info(""path: {}"", path);"	<line2>	"log.info(""Path: {}"", path)"	"<line2> log.info(""Path: {}"", path)"
task5	<line20>      log.error(systemException, systemException);	<line20>	log.error(systemException, systemException)	<line20> log.error(systemException, systemException)
task5	"<line48>        LOG.debug(""failed to clean empty index directory"", e);"	<line48>	"log.warn(""Got exception while trying to clean up index files for deletion"", e)"	"<line48> log.warn(""Got exception while trying to clean up index files for deletion"", e)"
task5	"<line7>      logger.error(""Error transferring file: "" + pair.getRemoteStatus().getURL(), e);"	<line7>	"logger.error(""Error mirroring sequence file pair: "" + pair.getRemoteStatus().getURL(), e)"	"<line7> logger.error(""Error mirroring sequence file pair: "" + pair.getRemoteStatus().getURL(), e)"
task5	"<line6>      LOG.info(""Kafka Adapter disconnected for topic(s): ""+ optionHolder.validateAndGetStaticValue(ADAPTOR_SUBSCRIBER_TOPIC));"	<line2>	"log.debug(""Disconnecting Kafka Source {}"", this.getSourceName())"	"<line2> log.debug(""Disconnecting Kafka Source {}"", this.getSourceName())"
task5	"<line9>        logger.warn(""deleteData failed"", e);"	<line9>	"logger.warn(""deleteData failed"", e)"	"<line9> logger.warn(""deleteData failed"", e)"
task5	"<line6>      logger.error(""unexpected error"", e);"	<line5>	"logger.error(""Error getting facilities to display"", e)"	"<line5> logger.error(""Error getting facilities to display"", e)"
task5	"<line3>    LOG.trace(""enter RFC2965Spec.validate(String, int, String, "" + ""boolean, Cookie)"");"	<line16>	"LOG.debug(""CookieProcessor: RCF2109 cookie processor will handle the validation"")"	"<line16> LOG.debug(""CookieProcessor: RCF2109 cookie processor will handle the validation"")"
task5	"<line9>          log.info(""Created new discovery listener for cacheName {0} and request {1}"",ilca.getCacheName(), key1);"	<line9>	"log.debug(""Creating new discovery listener for {0}"", key)"	"<line9> log.debug(""Creating new discovery listener for {0}"", key)"
task5	<line2>      logger.warn(e);	<line2>	logger.warn(e)	<line2> logger.warn(e)
task5	"<line25>      LOG.error(String.format(""error writing locator batch of size %s, granularity %s"",writeContexts.size(), writeContexts.get(0).getGranularity()),ex);"	<line24>	"LOG.error(""Exception writing metrics"", ex)"	"<line24> LOG.error(""Exception writing metrics"", ex)"
task5	<line9>        logger.error(e.toString(), e);	<line9>	"logger.warn(""Error deleting write file "" + writeFile, e)"	"<line9> logger.warn(""Error deleting write file "" + writeFile, e)"
task5	"<line6>      LOGGER.error(""Error occurred while persisting auth resources."", e);"	<line6>	"log.error(""Failed to persist default auth resources"", e)"	"<line6> log.error(""Failed to persist default auth resources"", e)"
task5	"<line17>        log.info(""Adding persisted queries {}"", persistedQueries.size());"	<line17>	"log.info(""Found {} queries for the user {} with driver {} and query name {}"",persistedQueries.size(),userName,driver,queryName)"	"<line17> log.info(""Found {} queries for the user {} with driver {} and query name {}"",persistedQueries.size(),userName,driver,queryName)"
task5	"<line10>        logger.info(""Retracting {} from youtube"", mediaPackage);"	<line2>	"logger.info(""Retracting mediapackage {} using a remote youtube publication service"",mediaPackage)"	"<line2> logger.info(""Retracting mediapackage {} using a remote youtube publication service"",mediaPackage)"
task5	<line6>    logger.debug(SEND_MESSAGE, () -> getBytesAsString(message));	<line6>	"logger.debug(""sendMessage({})"", message)"	"<line6> logger.debug(""sendMessage({})"", message)"
task5	"<line3>    logger.debug(serviceparameter + "": "" + isTrue);"	<line3>	"logger.debug(String.format(""isServiceSettingTrue for %s - %s"", serviceparameter, isTrue))"	"<line3> logger.debug(String.format(""isServiceSettingTrue for %s - %s"", serviceparameter, isTrue))"
task5	"<line2>      log.trace(""WARNING!!! Overriding verification of the XPath. Your tests may pass even though they""+ "" shouldn't"");"	<line2>	"logger.debug(""Ignoring XPath exception. XML document doesn't match the XPath expression"",expr.getException())"	"<line2> logger.debug(""Ignoring XPath exception. XML document doesn't match the XPath expression"",expr.getException())"
task5	"<line7>      log.debug(""Getting dialect for session: "" + dialect);"	<line7>	"log.debug(""Determined dialect to be "" + dialect)"	"<line7> log.debug(""Determined dialect to be "" + dialect)"
task5	"<line3>      LOGGER.trace(""Unbinding SourceAttributeRestriction instance with id {}"", sourceId);"	<line2>	"logger.debug(""Unbinding source attribute restriction: {}"", sourceAttributeRestriction.toString())"	"<line2> logger.debug(""Unbinding source attribute restriction: {}"", sourceAttributeRestriction.toString())"
task5	"<line2>    log.warn(""unsupported"");"	<line2>	"logger.warn(""punsubscribeAll is not implemented"")"	"<line2> logger.warn(""punsubscribeAll is not implemented"")"
task5	"<line2>      log.warn(""Only Java classloaders should be secondary"");"	<line2>	"log.warn(""Adding non-Java target to Java brooklyn class loader: "" + target)"	"<line2> log.warn(""Adding non-Java target to Java brooklyn class loader: "" + target)"
task5	"<line3>    this.logger.debug(""Setting {} collaborators to entity record [{}] via REST"",collaborators.getCollaborators().size(),entityId);"	<line3>	"logger.debug(""Adding collaborator to entity with id {}, entity type {}"", entityId, entityType)"	"<line3> logger.debug(""Adding collaborator to entity with id {}, entity type {}"", entityId, entityType)"
task5	"<line3>    logger.info(""TestEmailController#sendNCBIUploadExceptionEmail called."");"	<line3>	"logger.info(""No NCBI submission email sent for submission ID ${submissionId}: ${rootCause}"")"	"<line3> logger.info(""No NCBI submission email sent for submission ID ${submissionId}: ${rootCause}"")"
task5	"<line7>        LOG.info(""Please setup input path for vector and matrix and output path for result."");"	<line7>	"LOG.info(""Please provide paths to the matrix, vector, and output files"")"	"<line7> LOG.info(""Please provide paths to the matrix, vector, and output files"")"
task5	"<line7>      logger.warn("""", fex);"	<line7>	"logger.warn("""", fex)"	"<line7> logger.warn("""", fex)"
task5	"<line10>            logger.info(""Message: "" + message);"	<line10>	"LOG.info(""Received message: "" + message)"	"<line10> LOG.info(""Received message: "" + message)"
task5	"<line2>      LOG.debug(MessageFormat.format(""Launching application: {0}{1}"", tool.getClass().getName(), Arrays.toString(args)));"	<line2>	"LOG.debug(""Launching {} with {}"", tool, Arrays.toString(args))"	"<line2> LOG.debug(""Launching {} with {}"", tool, Arrays.toString(args))"
task5	"<line3>    LOG.debug(""SimpleAuthenticator called with {}"", credentials);"	<line7>	"log.info(""Denying access to {}"", byId.getEmail())"	"<line7> log.info(""Denying access to {}"", byId.getEmail())"
task5	"<line7>      LOGGER.debug(""Unable to parse Message-Id: {}"", headers[0]);"	<line8>	"LOGGER.warn(""Message-Id header not found in message or its value not parseable. Generating a random""+ "" message id."")"	"<line8> LOGGER.warn(""Message-Id header not found in message or its value not parseable. Generating a random""+ "" message id."")"
task5	"<line17>              log.warn(StringBundler.concat(""Unable to find key "", key, "" in theme "", _themeId),missingResourceException);"	<line17>	"log.warn(""Unable to find resource bundle value for key "" + value, missingResourceException)"	"<line17> log.warn(""Unable to find resource bundle value for key "" + value, missingResourceException)"
task5	<line1>    logger.info(s);	<line1>	"logger.info(""ActiveMqExample: "" + s)"	"<line1> logger.info(""ActiveMqExample: "" + s)"
task5	"<line7>      log.info(""Failed to read the dispatch file: "" + dispatchFile);"	<line7>	"log.debug(""Unable to read the first line of the file "" + dispatchFile.getAbsolutePath(),continued)"	"<line7> log.debug(""Unable to read the first line of the file "" + dispatchFile.getAbsolutePath(),continued)"
task5	"<line10>      logger.warn(""Failed to handle AgentStatBatch={}"", tAgentStatBatch, e);"	<line10>	"logger.error(""not create flink event"", e)"	"<line10> logger.error(""not create flink event"", e)"
task5	"<line5>      LOG.error(""Failed to rollback transacted session [session={}]"", m_transactedSession, e);"	<line5>	"LOG.error(""Rollback Error"", e)"	"<line5> LOG.error(""Rollback Error"", e)"
task5	"<line3>      LOGGER.error(""Pattern used for bucketName used in deletedMessageVault is invalid and end date cannot""+ "" be parsed {}"",bucketName);"	<line3>	"log.warn(""Unable to calculate end date for bucket: {}"", bucketName)"	"<line3> log.warn(""Unable to calculate end date for bucket: {}"", bucketName)"
task5	"<line38>      LOGGER.error(""Exception while interpreting cypher query"", e);"	<line38>	"LOGGER.error(""Error while running query"", e)"	"<line38> LOGGER.error(""Error while running query"", e)"
task5	<line10>      log.error(e.getMessage(), e);	<line10>	"log.error(""An error occurred while validating a form"", e)"	"<line10> log.error(""An error occurred while validating a form"", e)"
task5	"<line5>      LOGGER.error(() -> ""Error closing channel at: "" + remoteAddress, e);"	<line5>	"log.error(""Error closing RabbitMQ Channel; continuing"", e)"	"<line5> log.error(""Error closing RabbitMQ Channel; continuing"", e)"
task5	"<line1>    log.debug(""waitSensorActive[] starts"");"	<line1>	"logger.debug(""waitSensorActive({})"", Arrays.toString(mSensors))"	"<line1> logger.debug(""waitSensorActive({})"", Arrays.toString(mSensors))"
task5	<line11>      LOG.error(SETTING_NOT_FOUND_TEMPLATE,databaseConceptDefinition.getKey(),HibernateDatasourceConstants.HIBERNATE_DIRECTORY,concept,databaseConceptDefinition.getKey(),concept);	<line12>	"log.debug(""Database concept: "" + concept)"	"<line12> log.debug(""Database concept: "" + concept)"
task5	"<line15>    log.debug(""Creating view {} in {} with statement {}"", name, this.name, statementStr);"	<line15>	"log.info(""Running statement {}"", statementStr)"	"<line15> log.info(""Running statement {}"", statementStr)"
task5	"<line5>      LOG.info(""Couldn't check existence of key {} {} {}"",keyName,e.getStatusCode(),e.getDetails().toPrettyString(),e);"	<line3>	"LOG.info(""Service account key {} exists"", keyName)"	"<line3> LOG.info(""Service account key {} exists"", keyName)"
task5	"<line8>      logger.debug(""{} --> cldr size: {}, po size: {}, copy size: {}"", bcp47tag, cldrSize, poSize, copySize);"	<line3>	"log.info(""Testing copy form size for: {}"", bcp47tag)"	"<line3> log.info(""Testing copy form size for: {}"", bcp47tag)"
task5	"<line27>              log.warn(""Settings problem encountered at "" + problem.getLocation(),problem.getException());"	<line27>	"log.debug(""Settings problem encountered at "" + problem.getLocation())"	"<line27> log.debug(""Settings problem encountered at "" + problem.getLocation())"
task5	"<line2>    LOG.trace(""Creating LRUWeakCache with maximumCacheSize: {}"", maximumCacheSize);"	<line2>	"LOG.trace(""Creating LRUCache with maximumCacheSize: {}"", maximumCacheSize)"	"<line2> LOG.trace(""Creating LRUCache with maximumCacheSize: {}"", maximumCacheSize)"
task5	<line6>      logger.debug(HANDLER_IS_NULL);	<line6>	logger.debug(HANDLER_IS_NULL)	<line6> logger.debug(HANDLER_IS_NULL)
task5	"<line24>    LOG.info(""timestampDiffs="" + timestampDiffs + ""; timestamps="" + timestamps);"	<line42>	"LOG.info(""iteration {}, expectedDelay {}, actualDelay {}, min {}, max {}"",iteration,expectedDelay,actualDelay,min,max)"	"<line42> LOG.info(""iteration {}, expectedDelay {}, actualDelay {}, min {}, max {}"",iteration,expectedDelay,actualDelay,min,max)"
task5	"<line5>    LOG.debug(""Retrieving information about all "" + report + "" reports for account "" + accountId);"	<line2>	"LOG.debug(""Getting list of reports"")"	"<line2> LOG.debug(""Getting list of reports"")"
task5	"<line14>        LOG.warn(""{} field is ignored, couldn't find relevant field in the persistent mapping"", field);"	<line14>	"LOG.warn(""Could not find field or key field for field "" + field)"	"<line14> LOG.warn(""Could not find field or key field for field "" + field)"
task5	"<line2>      logger.trace(""setProtocolManagerFactoryStr("" + protocolManagerFactoryStr + "")"");"	<line2>	"logger.trace(""setProtocolManagerFactoryStr("" + protocolManagerFactoryStr + "")"")"	"<line2> logger.trace(""setProtocolManagerFactoryStr("" + protocolManagerFactoryStr + "")"")"
task5	<line15>      logger.warn(msg);	<line15>	logger.warn(msg)	<line15> logger.warn(msg)
task5	"<line1>    LOG.debug(""Granting all permissions to user {} on instance '{}'."",user.getName(),mInstanceUri.toOrderedString());"	<line1>	"LOG.info(""Granting all permissions to user '{}'."", user.getUserId())"	"<line1> LOG.info(""Granting all permissions to user '{}'."", user.getUserId())"
task5	"<line34>      logger.error(""Unable to create MemcachedCache instance."", e);"	<line27>	"log.info(""Creating client for Memcached server(s): {}"", hostsStr)"	"<line27> log.info(""Creating client for Memcached server(s): {}"", hostsStr)"
task5	"<line36>      LOG.debug(""found {} for select: {}"", resultSeq.getItemCount(), selectStmt);"	<line36>	"LOG.debug(""select expression is {}"", resultSeq)"	"<line36> LOG.debug(""select expression is {}"", resultSeq)"
task5	"<line1>    logger.debug(""validateCloudResponseDTO started..."");"	<line1>	"logger.debug(""validateCloud started..."")"	"<line1> logger.debug(""validateCloud started..."")"
task5	<line8>        log.debug(noSuchFolderException, noSuchFolderException);	<line8>	log.debug(noSuchFolderException, noSuchFolderException)	<line8> log.debug(noSuchFolderException, noSuchFolderException)
task5	"<line2>      log.error(""Sorry, {} is an unknown filter."", filter);"	<line2>	"log.error(""filter {} does not exist"", filter)"	"<line2> log.error(""filter {} does not exist"", filter)"
task5	"<line2>      LOGGER.info(""Plugin cache miss, reload"");"	<line4>	"logger.debug(""getPlugins({})"", viewName)"	"<line4> logger.debug(""getPlugins({})"", viewName)"
task5	"<line2>    logger.warn(""Error instantiating revocation registry class - using default registry"");"	<line2>	"log.error(""STS revocation registry instantiation error"")"	"<line2> log.error(""STS revocation registry instantiation error"")"
task5	"<line31>      log.error(""Cannot write license info into release "" + releaseId + ""."", e);"	<line31>	"log.error(""Cannot write license info into release {}"", releaseId, e)"	"<line31> log.error(""Cannot write license info into release {}"", releaseId, e)"
task5	<line11>      LOGGER.error(e.getMessage());	<line9>	"LOGGER.info(""getFAQSByWidget for widgetId {}"", widgetId)"	"<line9> LOGGER.info(""getFAQSByWidget for widgetId {}"", widgetId)"
task5	"<line3>      logger.trace(""addDoubleField fieldName: {}; value: {}"", fieldName, value);"	<line3>	"logger.trace(""addDoubleField fieldName: {}; value: {}"", fieldName, value)"	"<line3> logger.trace(""addDoubleField fieldName: {}; value: {}"", fieldName, value)"
task5	"<line11>      LOGGER.warn(""Component Id not found from disk component metadata"");"	<line11>	"LOGGER.warn(""Component id was null"")"	"<line11> LOGGER.warn(""Component id was null"")"
task5	"<line15>    log.info(""Clearing DB took {"" + duration + ""} ms."");"	<line15>	"log.info(""Database cleared in {"" + duration + ""} ms"")"	"<line15> log.info(""Database cleared in {"" + duration + ""} ms"")"
task5	<line2>    log.trace(XTCE_ARGUMENT);	<line2>	log.trace(XTCE_ARGUMENT)	<line2> log.trace(XTCE_ARGUMENT)
task5	"<line5>      LOG.debug(""Removed mapping to term "" + pm.getTerm().qualifiedName());"	<line5>	"LOG.info(""Removed property mapping: "" + qualifiedName)"	"<line5> LOG.info(""Removed property mapping: "" + qualifiedName)"
task5	"<line8>          LOG.debug(""InvocationType property: {}"", invocationType);"	<line8>	"logger.debug(""InvocationType: {}"", invocationType)"	"<line8> logger.debug(""InvocationType: {}"", invocationType)"
task5	"<line1>    logger.debug(""checkSystemRequestDTO started..."");"	<line1>	"logger.debug(""checkSystemRequestDTO started..."")"	"<line1> logger.debug(""checkSystemRequestDTO started..."")"
task5	"<line2>    LOGGER.debug(""Dh Modulus: "" + tlsContext.getServerDhModulus());"	<line2>	"LOGGER.debug(""DhModulus: "" + tlsContext.getServerDhModulus())"	"<line2> LOGGER.debug(""DhModulus: "" + tlsContext.getServerDhModulus())"
task5	"<line6>      log.info(""message version {} =================== "", version);"	<line14>	log.error(strResponse)	<line14> log.error(strResponse)
task5	<line29>          LOG.warn(ioe.getMessage(), ioe);	<line29>	"LOG.warn(""Failed to close content stream: {}"", ioe.getMessage(), ioe)"	"<line29> LOG.warn(""Failed to close content stream: {}"", ioe.getMessage(), ioe)"
task5	"<line2>    logger.info(""No metadata connection"");"	<line2>	"logger.debug(""isDuplicateFile()"")"	"<line2> logger.debug(""isDuplicateFile()"")"
task5	"<line16>        log.debug(""Error while evaluating service expression. Thread got interrupted."");"	<line16>	"log.error(""Interrupted while waiting for service"", e)"	"<line16> log.error(""Interrupted while waiting for service"", e)"
task5	"<line3>      LOGGER.info(""Teardown shared!"");"	<line5>	"log.info(""AddressSpace {} will not be deleted. Skipping deletion of shared resources."",sharedResourcesManager.getSharedAddressSpace())"	"<line5> log.info(""AddressSpace {} will not be deleted. Skipping deletion of shared resources."",sharedResourcesManager.getSharedAddressSpace())"
task5	"<line7>      logger.warn(""New Node {} was registered for this cluster, but this Node Identifier conflicts with {}""+ "" others: {}; each of these conflicting Node Identifiers will be removed from the""+ "" cluster"",nodeIdentifier.getFullDescription(),fullNodeIdDescriptions.size(),fullNodeIdDescriptions);"	<line7>	"logger.warn(""The node identifier {} is conflicting with the following node identifiers: {}"",nodeIdentifier,fullNodeIdDescriptions)"	"<line7> logger.warn(""The node identifier {} is conflicting with the following node identifiers: {}"",nodeIdentifier,fullNodeIdDescriptions)"
task5	"<line52>              log.warn(""CPOptionValuePersistenceImpl.fetchByC_ERC(long, String, boolean) with parameters""+ "" (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."");"	<line52>	"log.warn(""CPOptionValuePersistenceImpl.fetchByC_ERC(long, String, boolean) with parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."")"	"<line52> log.warn(""CPOptionValuePersistenceImpl.fetchByC_ERC(long, String, boolean) with parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."")"
task5	"<line6>        LOG.error(""Failed to register in JMX bean "" + bean + "" at "" + objectName + "". "" + e, e);"	<line6>	"log.error(""register mbean error"", e)"	"<line6> log.error(""register mbean error"", e)"
task5	<line27>      log.error(systemException, systemException);	<line27>	log.error(systemException, systemException)	<line27> log.error(systemException, systemException)
task5	"<line45>          logger.warn(""The customer ({})'s dueTime ({}) was automatically reduced""+ "" to maximumDueTime ({}) because of the depot's dueTime ({})."",customer,dueTime,maximumDueTime,depot.getDueTime());"	<line45>	"logger.warn(""The due time of customer ("" + id + "") is greater than the maximum possible."")"	"<line45> logger.warn(""The due time of customer ("" + id + "") is greater than the maximum possible."")"
task5	<line10>      log.error(e.getMessage(), e);	<line10>	log.error(e.getMessage())	<line10> log.error(e.getMessage())
task5	"<line29>    LOG.info(""node: "" + msg);"	<line2>	"LOG.info(""Provisioned {} at {}"", machine, locationAddress)"	"<line2> LOG.info(""Provisioned {} at {}"", machine, locationAddress)"
task5	"<line24>        LOG.warn(""Deadlock detected. Starting over again. Docs: {}; locked: {}. Cause: {}"",docs.getDocumentCount(),lockedDocuments.size(),e.getMessage());"	<line24>	"LOG.warn(""LockException while beginning protected: {}"", e.getMessage(), e)"	"<line24> LOG.warn(""LockException while beginning protected: {}"", e.getMessage(), e)"
task5	"<line21>      LOGGER.error(""StudyMetaDataDao - isValidToken() :: ERROR"", e);"	<line21>	"LOGGER.error(""StudyDAOImpl isValidToken() :: ERROR"", e)"	"<line21> LOGGER.error(""StudyDAOImpl isValidToken() :: ERROR"", e)"
task5	"<line14>        log.debug(""Parameter '""+ paramName+ ""' rejected in component '""+ inputComponent.getClientId()+ ""' in ComponentValidator '""+ this.getClass()+ ""'"");"	<line14>	"log.debug(""Invalid parameter: "" + paramName)"	"<line14> log.debug(""Invalid parameter: "" + paramName)"
task5	"<line1>    log.debug(""update() - structure: {}"", structure);"	<line1>	"log.debug(""update() - structure: {}"", structure)"	"<line1> log.debug(""update() - structure: {}"", structure)"
task5	"<line12>    log.debug(this + "" set initial port to "" + portStartingPoint);"	<line12>	"log.info(""Port forwarding service initialized, starting at port: "" + portStartingPoint)"	"<line12> log.info(""Port forwarding service initialized, starting at port: "" + portStartingPoint)"
task5	"<line6>      LOG.warn(""Invalid protocol type {}."" + ""Avaiable proxy protocol type HTTP and HTTPS."", protocol);"	<line6>	"logger.error(""Invalid protocol: "" + protocol)"	"<line6> logger.error(""Invalid protocol: "" + protocol)"
task5	"<line9>    logger.info(""Creating new upload job: {}"", job);"	<line14>	"logger.debug(""Created job directory {}"", jobDir)"	"<line14> logger.debug(""Created job directory {}"", jobDir)"
task5	"<line8>        logger.debug(testName + "": status = "" + statusCode);"	<line8>	"logger.debug(testName + "": status = "" + statusCode)"	"<line8> logger.debug(testName + "": status = "" + statusCode)"
task5	"<line3>    LOGGER.debug(""get logbook for owner with id :{}"", id);"	<line3>	"LOGGER.debug(""get logbook history by owner's id : {}"", id)"	"<line3> LOGGER.debug(""get logbook history by owner's id : {}"", id)"
task5	"<line2>    log.debug(""find() - id: {}"", id);"	<line2>	"log.debug(""find() - id: {}"", id)"	"<line2> log.debug(""find() - id: {}"", id)"
task5	"<line10>        log.info(""Waiting for catalog service"");"	<line10>	"LOG.warn(""Failed to schedule upgrades due to "" + e.getMessage(), e)"	"<line10> LOG.warn(""Failed to schedule upgrades due to "" + e.getMessage(), e)"
task5	"<line7>      log.error(""The provided algorithm is not found "", e);"	<line7>	"logger.error(""No KeyPair Generator for algorithm: "" + alg)"	"<line7> logger.error(""No KeyPair Generator for algorithm: "" + alg)"
task5	"<line1>    LOG.debug(""parsing URL "" + url);"	<line1>	"LOG.debug(""Parsing {}"", url)"	"<line1> LOG.debug(""Parsing {}"", url)"
task5	"<line8>      log.debug(""Unable to deduce ContractUpdate usage for {}, using defaults"",txn.getTransactionID(),e);"	<line8>	"log.warn(""Unable to estimate usage for contract update transaction: {}"", txn, e)"	"<line8> log.warn(""Unable to estimate usage for contract update transaction: {}"", txn, e)"
task5	"<line6>      logger.error(""Error during MQTT message callback: "" + e.getMessage());"	<line6>	"logger.error(""Exception in message callback"", e)"	"<line6> logger.error(""Exception in message callback"", e)"
task5	"<line20>        log.warn(""Unhandled encryption level %s - assuming DISABLED."", encryptionLevel.name());"	<line24>	"log.info(""Bolt connector using encryption level: {}"", encryptionLevel)"	"<line24> log.info(""Bolt connector using encryption level: {}"", encryptionLevel)"
task5	<line8>      log.error(exception, exception);	<line8>	log.error(exception, exception)	<line8> log.error(exception, exception)
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line5>      log.error(""I have a null head"");"	<line5>	"Logger.error(this, ""head is null"")"	"<line5> Logger.error(this, ""head is null"")"
task5	"<line12>          logger.error(""Couldn't convert url '"" + url + ""' to a file"");"	<line12>	"LOGGER.warn(""Unable to convert URL to URI for "" + url + "". Ignoring."", e)"	"<line12> LOGGER.warn(""Unable to convert URL to URI for "" + url + "". Ignoring."", e)"
task5	"<line22>      LOG.debug(""Using authorization provider ""+ authProviderName+ "" with resource ""+ resourceName+ "", policy engine ""+ policyEngineName+ "", provider backend ""+ providerBackendName);"	<line22>	"LOG.debug(""Creating authorization provider: {} using resource: {}"", authProviderName, resourceName)"	"<line22> LOG.debug(""Creating authorization provider: {} using resource: {}"", authProviderName, resourceName)"
task5	"<line6>    logger.debug(""Create the target repository"");"	<line6>	"logger.debug(""Create the target repository"")"	"<line6> logger.debug(""Create the target repository"")"
task5	"<line8>        LOGGER.warn(""There was an error adding the temporaryFile to S3"");"	<line2>	"logger.info(""Closing file writer"")"	"<line2> logger.info(""Closing file writer"")"
task5	"<line30>        logger.debug(""Refreshing persistent login token for profile '""+ persistentLogin.getProfileId()+ ""', id '""+ persistentLogin.getId()+ ""'"");"	<line30>	"logger.debug(""Refreshed persistent login token for {}"", presentedId)"	"<line30> logger.debug(""Refreshed persistent login token for {}"", presentedId)"
task5	<line8>      log.fatal(e);	<line8>	log.error(e.getMessage(), e)	<line8> log.error(e.getMessage(), e)
task5	"<line8>      logger.debug(""REDIS INVOKE START: "" + targetURL + "" action: "" + redisAction, null);"	<line8>	"logger.debug(""Invoke START:"" + targetURL + "","" + redisAction + "","" + appid, null)"	"<line8> logger.debug(""Invoke START:"" + targetURL + "","" + redisAction + "","" + appid, null)"
task5	"<line5>        log.info(""Instance for ["" + lca.toString() + ""] is null, creating"");"	<line13>	"log.debug(""created new lateral cache manager "" + lca.toString())"	"<line13> log.debug(""created new lateral cache manager "" + lca.toString())"
task5	"<line5>        log.debug(""Closing JDBC Connection ["" + connection + ""]"");"	<line5>	"log.debug(""Connection closed"")"	"<line5> log.debug(""Connection closed"")"
task5	"<line4>      log.error(""Segment "" + segmentName + ""Not found."");"	<line4>	"log.error(""Segment "" + segmentName + ""Not found."")"	"<line4> log.error(""Segment "" + segmentName + ""Not found."")"
task5	"<line7>      logger.error(""Error deleting value"", e);"	<line7>	"LOG.error(""Error deleting key "" + key, e)"	"<line7> LOG.error(""Error deleting key "" + key, e)"
task5	"<line7>        LOGGER.debug(""ADDRESS :[{}] Address:[{}] Command : [{}] RetCode[{}] Response [{}]"",enhancedMessagingException.computeAction(),me,enhancedMessagingException.computeAddress(),enhancedMessagingException.computeCommand(),enhancedMessagingException.getReturnCode());"	<line7>	LOGGER.info(enhancedMessagingException.getMessage())	<line7> LOGGER.info(enhancedMessagingException.getMessage())
task5	"<line8>          log.warn(""ServletContext INI resource '""+ servletContextPath+ ""' exists, but it did not contain ""+ ""any data."");"	<line8>	"log.warn(""Empty Ini resource: "" + path)"	"<line8> log.warn(""Empty Ini resource: "" + path)"
task5	"<line6>        LOG.error(""Test case has exceeded the maximum allotted time to run of: ""+ getMaxTestTime()+ "" ms."");"	<line6>	"LOGGER.error(""Test failed to complete in max time of {} seconds. Test thread dump follows:"",getMaxTestTime() / 1000)"	"<line6> LOGGER.error(""Test failed to complete in max time of {} seconds. Test thread dump follows:"",getMaxTestTime() / 1000)"
task5	"<line7>      LOG.warn(""Container is not running. Connection is not created."");"	<line7>	"LOGGER.warn(""The JDBC connection could not be configured because ""+ PROPERTY_JDBC+ "" was not found. Any attempt to persist data will fail."")"	"<line7> LOGGER.warn(""The JDBC connection could not be configured because ""+ PROPERTY_JDBC+ "" was not found. Any attempt to persist data will fail."")"
task5	"<line4>      logger.warn(""Unable to load the current recording for agent '{}': no recording found"", agentId);"	<line2>	"logger.debug(""Get current recording for agent {}"", agentId)"	"<line2> logger.debug(""Get current recording for agent {}"", agentId)"
task5	"<line3>    LOGGER.debug(""Using agent stage dir: {}"", agentDir);"	<line2>	"LOG.debug(""Setting up agent.properties and spool dirs"")"	"<line2> LOG.debug(""Setting up agent.properties and spool dirs"")"
task5	<line14>      log.error(exception, exception);	<line14>	log.error(exception, exception)	<line14> log.error(exception, exception)
task5	"<line11>      LOG.info(""Cannot access SecurityEvents!"");"	<line11>	"LOG.debug(""No filters applied to find accessible IDs, returning empty list"")"	"<line11> LOG.debug(""No filters applied to find accessible IDs, returning empty list"")"
task5	"<line29>        log.debug(""Class not found for resolving from name as-is '"" + className + ""'"");"	<line29>	"log.debug(""Class not found: "" + className)"	"<line29> log.debug(""Class not found: "" + className)"
task5	"<line8>        Log.error(""An exception occurred while trying to configure caches for plugin '{}':"",pluginName,e);"	<line8>	"log.warn(""Unable to configure caches for plugin "" + pluginName, e)"	"<line8> log.warn(""Unable to configure caches for plugin "" + pluginName, e)"
task5	"<line6>      LOGGER.debug(""findSchemaForPositionSHA: found schema_id: {} for sha: {}"", id, sha);"	<line6>	"LOGGER.debug(""Found schema id {} for position SHA {}"", id, sha)"	"<line6> LOGGER.debug(""Found schema id {} for position SHA {}"", id, sha)"
task5	"<line13>    logger.info(""generated "" + target);"	<line13>	"logger.info(""generated "" + target)"	"<line13> logger.info(""generated "" + target)"
task5	"<line2>    logger.info(""initializing InternalDataSerializer with {} services"", services.size());"	<line2>	"logger.info(""initialize DistributionConfig with serializableObjectFilter: {}"",distributionConfig.getSerializableObjectFilter())"	"<line2> logger.info(""initialize DistributionConfig with serializableObjectFilter: {}"",distributionConfig.getSerializableObjectFilter())"
task5	"<line21>          logger.warn(""Unsupported method "" + method, e);"	<line21>	"logger.warn(""Failed to apply "" + this, e)"	"<line21> logger.warn(""Failed to apply "" + this, e)"
task5	"<line6>      logger.debug(""Set disposition as of date for next action '""+ nextAction.getName()+ ""' (""+ nextAction.getNodeRef()+ "") to: ""+ newAsOfDate);"	<line6>	"logger.debug(""Setting date for node ""+ nextAction.getNodeRef()+ "" to ""+ newAsOfDate+ "" based on disposition action ""+ dispositionActionDef)"	"<line6> logger.debug(""Setting date for node ""+ nextAction.getNodeRef()+ "" to ""+ newAsOfDate+ "" based on disposition action ""+ dispositionActionDef)"
task5	"<line3>    logger.debug(""hello"");"	<line4>	"logger.debug(""hello"")"	"<line4> logger.debug(""hello"")"
task5	"<line6>        log.debug(e, ""error printing status"");"	<line6>	"log.error(""Unexpected error while waiting for server to start"", e)"	"<line6> log.error(""Unexpected error while waiting for server to start"", e)"
task5	"<line6>      LOGGER.warn(""Player {} tried to reach {} blocks wide"", player.name(), dist);"	<line6>	"LOGGER.debug(""Block pick distance too high: {}"", dist)"	"<line6> LOGGER.debug(""Block pick distance too high: {}"", dist)"
task5	"<line2>    LOGGER.info(""Using database name: "" + dbName);"	<line1>	"log.debug(""db: {}"", dbName)"	"<line1> log.debug(""db: {}"", dbName)"
task5	"<line3>      log.debug(""Getting deployment policy: [deployment-policy_id] "" + deploymentPolicyID);"	<line3>	"log.debug(""getDeploymentPolicy("" + deploymentPolicyID + "")"")"	"<line3> log.debug(""getDeploymentPolicy("" + deploymentPolicyID + "")"")"
task5	<line4>      log.error(exception, exception);	<line4>	log.error(exception, exception)	<line4> log.error(exception, exception)
task5	"<line2>    log.info(""Elastic Job: Stop {}"", serviceName());"	<line2>	"LOG.info(""Stopping {}"", DelegatingHttpFilterHandler.class.getSimpleName())"	"<line2> LOG.info(""Stopping {}"", DelegatingHttpFilterHandler.class.getSimpleName())"
task5	"<line2>      LOG.debug(""start writing Solr Update XML for export"");"	<line6>	LOG.error(message, e)	<line6> LOG.error(message, e)
task5	"<line20>      LOG.info(""Reading data from {} between {} and {}"",new Object[] {topicPartition, startingOffset, endingOffset});"	<line20>	"LOG.info(""Initialized Kafka Record Reader for topic: ""+ kafkaConnectionProperties.getProperty(KAFKA_TOPIC_KEY)+ "" and partition: ""+ topicPartition.partition())"	"<line20> LOG.info(""Initialized Kafka Record Reader for topic: ""+ kafkaConnectionProperties.getProperty(KAFKA_TOPIC_KEY)+ "" and partition: ""+ topicPartition.partition())"
task5	"<line12>          LOGGER.error(""Register IoTDB schema failed because "", e);"	<line14>	"LOGGER.info(""Set storage group failed"", e)"	"<line14> LOGGER.info(""Set storage group failed"", e)"
task5	"<line33>        logger.error(""Error while saving the page metadata record for table {}"", tableName, t);"	<line33>	"logger.error(""Error while saving the page metadata record for table {}"", tableName, t)"	"<line33> logger.error(""Error while saving the page metadata record for table {}"", tableName, t)"
task5	"<line9>      log.debug(""Requesting unsubscribe: "" + topic);"	<line9>	"log.debug(""{}: Unsubscribe from topic: {}"", this, topic)"	"<line9> log.debug(""{}: Unsubscribe from topic: {}"", this, topic)"
task5	<line3>      logger.debug(format, arguments);	<line3>	logger.debug(format, arguments)	<line3> logger.debug(format, arguments)
task5	"<line11>    logger.debug(""DONE consuming"");"	<line11>	"LOG.info(""Shutting down now."")"	"<line11> LOG.info(""Shutting down now."")"
task5	"<line3>          LOG.trace(""setting connectTimeout: {}"", s);"	<line3>	"LOG.debug(""Connect timeout set to {} ms"", s)"	"<line3> LOG.debug(""Connect timeout set to {} ms"", s)"
task5	<line2>    logger.info(e.toString());	<line2>	logger.info(e)	<line2> logger.info(e)
task5	"<line11>        log.warn(""AddressbookDO with id '"" + id + ""' not found. abIds string was: "" + abIds);"	<line11>	"log.warn(""Addressbook with id ""+ id+ "" not found in addressbook list: ""+ abIds+ "". This may be a problem, but we continue."")"	"<line11> log.warn(""Addressbook with id ""+ id+ "" not found in addressbook list: ""+ abIds+ "". This may be a problem, but we continue."")"
task5	<line15>        log.debug(sb.toString());	<line15>	log.debug(sb.toString())	<line15> log.debug(sb.toString())
task5	"<line17>    logger.debug(""Succesfully connected to InfluxDB. Instance ready={}"", createdClient.ready());"	<line15>	"LOGGER.debug(""Connecting to InfluxDB: {} with org: {}, bucket: {}, retention policy: {}"",configuration.getUrl(),configuration.getDatabaseName(),configuration.getRetentionPolicy(),configuration.getTokenAsCharArray())"	"<line15> LOGGER.debug(""Connecting to InfluxDB: {} with org: {}, bucket: {}, retention policy: {}"",configuration.getUrl(),configuration.getDatabaseName(),configuration.getRetentionPolicy(),configuration.getTokenAsCharArray())"
task5	<line3>    LOGGER.warn(aMessage);	<line1>	log.error(aMessage)	<line1> log.error(aMessage)
task5	"<line16>          log.warn(""Unable to create DiscreteIndexType for class name: "" + typeClass);"	<line16>	"log.error(""Could not find discrete index type {}"", typeClass, e)"	"<line16> log.error(""Could not find discrete index type {}"", typeClass, e)"
task5	"<line15>        logger.debug(""Exception while interacting with APM Server, trying next one."");"	<line14>	"LOG.warn(""Failed to connect to any of the following Elasticsearch clusters: {}"",serverUrlList,e)"	"<line14> LOG.warn(""Failed to connect to any of the following Elasticsearch clusters: {}"",serverUrlList,e)"
task5	"<line21>      log.info(""Kubernetes API Server at '"" + masterURL + ""' successfully contacted."");"	<line23>	"log.info(""Kubernetes deployment has been enabled"")"	"<line23> log.info(""Kubernetes deployment has been enabled"")"
task5	"<line2>      log.error(""cannot remove VideoDisplayPanel "" + source);"	<line2>	"log.error(""Trying to remove unknown video display for source {}"", source)"	"<line2> log.error(""Trying to remove unknown video display for source {}"", source)"
task5	"<line17>    logger.debug(""Finished task for {}; next scheduled time is at {} after a delay of {} milliseconds"",connectable,nextSchedule,delay);"	<line17>	"logger.debug(""Scheduling task in {} ms"", delay)"	"<line17> logger.debug(""Scheduling task in {} ms"", delay)"
task5	"<line17>      log.warn(""Usage estimation unexpectedly failed for {}!"", txn, illegal);"	<line17>	log.warn(illegal.getMessage(), illegal)	<line17> log.warn(illegal.getMessage(), illegal)
task5	"<line3>    logger.info(""Add CustomizedStateConfig to cluster {}, CustomizedStateConfig is {}"",clusterName,customizedStateConfig.toString());"	<line9>	"LOG.info(""Updating customizedStateConfig for cluster {}"", clusterName)"	"<line9> LOG.info(""Updating customizedStateConfig for cluster {}"", clusterName)"
task5	"<line2>      log.debug(""Positive test:: area: {}, type: {} for user: {}"", area, type, user);"	<line10>	"log.info(""Correctly denied access to area "" + area + "" for type "" + type + "" by "" + user)"	"<line10> log.info(""Correctly denied access to area "" + area + "" for type "" + type + "" by "" + user)"
task5	<line10>      logger.error(String.format(msg, msgArg), ex);	<line10>	logger.warn(String.format(msg, msgArg), ex)	<line10> logger.warn(String.format(msg, msgArg), ex)
task5	"<line8>      LOG.info(""Shutting down ManagedChannel failed."", e);"	<line8>	"LOG.warn(""Failed to shutdown managed channel"", e)"	"<line8> LOG.warn(""Failed to shutdown managed channel"", e)"
task5	"<line5>      log.error(""Failed to log timeseries delete"", e);"	<line5>	"log.error(""Failed to log timeseries delete"", e)"	"<line5> log.error(""Failed to log timeseries delete"", e)"
task5	"<line6>      LOGGER.warn(""Large document detected (id: %s). Size in bytes: %d"",item.getVertexiumObjectId(), sizeInBytes);"	<line6>	"logger.info(""Request size {} exceeds logRequestSizeLimit {}"", sizeInBytes, logRequestSizeLimit)"	"<line6> logger.info(""Request size {} exceeds logRequestSizeLimit {}"", sizeInBytes, logRequestSizeLimit)"
task5	"<line2>    logger.trace(""WebSocketClient stopping"");"	<line2>	"logger.info(""Jetty server stopping..."")"	"<line2> logger.info(""Jetty server stopping..."")"
task5	"<line2>    log.debug(""running in TestTransactionUtil"");"	<line2>	"log.debug(""running in TestTransactionUtil"")"	"<line2> log.debug(""running in TestTransactionUtil"")"
task5	"<line2>    LOG.info(""NoopTask.TaskStopHandler.send() invoked."");"	<line2>	"log.debug(""Stopping task {}"", getTaskId())"	"<line2> log.debug(""Stopping task {}"", getTaskId())"
task5	<line7>      logger.error(e.getMessage(), e);	<line7>	"logger.error(""Cannot start embedded agent"", e)"	"<line7> logger.error(""Cannot start embedded agent"", e)"
task5	"<line6>      log.warn(""Expected plugin to have PluginClassLoader; instead found: {}"",plugin.classLoader.getClass().getName());"	<line6>	"log.warn(""PluginClassLoader is not used for creation of URLClassSpace. This might cause problems""+ "" with the plugin."")"	"<line6> log.warn(""PluginClassLoader is not used for creation of URLClassSpace. This might cause problems""+ "" with the plugin."")"
task5	"<line8>      logger.warn(""PDU String should be always valid"", e);"	<line8>	"logger.error(""Failed sending outbind"", e)"	"<line8> logger.error(""Failed sending outbind"", e)"
task5	<line2>    log.info(s);	<line1>	logger.info(s)	<line1> logger.info(s)
task5	"<line4>    LOGGER.debug(""auto-configures HybridJwtDecoder."");"	<line4>	"LOGGER.info(""auto-configures: sap.security.services.xsuaa.hybridJwtDecoder"")"	"<line4> LOGGER.info(""auto-configures: sap.security.services.xsuaa.hybridJwtDecoder"")"
task5	<line22>      logger.debug(CLASS_NAME + s);	<line22>	logger.debug(CLASS_NAME + s)	<line22> logger.debug(CLASS_NAME + s)
task5	"<line13>      LOG.error(""run trainOnLocalClusterTest failed "", x);"	<line13>	"LOG.error(""run trainOnLocalClusterTest failed "", x)"	"<line13> LOG.error(""run trainOnLocalClusterTest failed "", x)"
task5	"<line11>      LOG.error(""Failed to execute the command due the exception "" + e);"	<line11>	LOG.info(e.getMessage())	<line11> LOG.info(e.getMessage())
task5	"<line4>      LOGGER.info(""{} activated"", LogLevelOverrideExtension.class.getSimpleName());"	<line6>	"LOGGER.debug(""No LogLevelOverrideExtension found in servlet '"" + context.getId() + ""'"")"	"<line6> LOGGER.debug(""No LogLevelOverrideExtension found in servlet '"" + context.getId() + ""'"")"
task5	"<line6>        log.warn(""Exception while interrupting channel: "", ex);"	<line6>	"LOG.debug(""Could not close saved socket "" + ex.getMessage())"	"<line6> LOG.debug(""Could not close saved socket "" + ex.getMessage())"
task5	"<line6>      log.debug(""setStat({})[{}]: {}"", getClientChannel(), handle, attributes);"	<line6>	"log.debug(""setStat({})[{}] {}"", handle, attributes, this)"	"<line6> log.debug(""setStat({})[{}] {}"", handle, attributes, this)"
task5	"<line3>    logger.debug(""Added {} unique statements, deduped {}"", addedStmts.size(), dedupCount);"	<line2>	"logger.debug(""Commit called"")"	"<line2> logger.debug(""Commit called"")"
task5	<line7>      log.error(exception, exception);	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	"<line36>      LOGGER.error(""Unable to append message to mailbox {}"", mailboxPath, e);"	<line36>	"LOGGER.warn(""Error while saving message"", e)"	"<line36> LOGGER.warn(""Error while saving message"", e)"
task5	"<line6>    LOG.debug(""got {} rows"", rowsSize);"	<line23>	"LOG.debug(""hasMore="" + hasMore)"	"<line23> LOG.debug(""hasMore="" + hasMore)"
task5	"<line5>        LOGGER.debug(""File was unable to be deleted: {}"", file.getAbsolutePath());"	<line5>	"log.error(""Failed to delete file {}"", file.getAbsolutePath())"	"<line5> log.error(""Failed to delete file {}"", file.getAbsolutePath())"
task5	"<line5>    LOGGER.warn(""Asyncrequest: {} "", asyncRequest);"	<line6>	"LOGGER.info(""PeriodicMeterReadsGasResponse is {}"", response)"	"<line6> LOGGER.info(""PeriodicMeterReadsGasResponse is {}"", response)"
task5	"<line6>            logger.warn(""Cache is being evicted because it exceeded max capacity {}. Consider increasing""+ "" cache size with the {} system property, or using an unbound cache with the""+ "" {} system property"",upperBound,SystemProperties.BOUNDED_QUERY_CACHE_SIZE,SystemProperties.ENABLE_BOUNDED_QUERY_CACHE);"	<line6>	"log.warn(""Query cache is full, clearing it out"")"	"<line6> log.warn(""Query cache is full, clearing it out"")"
task5	<line23>      log.error(systemException, systemException);	<line23>	log.error(systemException, systemException)	<line23> log.error(systemException, systemException)
task5	"<line5>        log.warn(""{}: queue does not exist - creating queue: address = {}, name = {}"",this.getClass().getSimpleName(),queueName.toString(),queueName.toString());"	<line2>	"log.debug(""Creating consumer for queue {}"", queueName)"	"<line2> log.debug(""Creating consumer for queue {}"", queueName)"
task5	"<line1>    LOGGER.debug(""Searching Artifactory url {}"", url);"	<line1>	"LOGGER.debug(""Connecting to: {}"", url)"	"<line1> LOGGER.debug(""Connecting to: {}"", url)"
task5	"<line14>      logger.error(""INVALID configured test protocols [{}]."", protocols);"	<line14>	"LOGGER.error(""INVALID configured test protocols: "" + protocols, e)"	"<line14> LOGGER.error(""INVALID configured test protocols: "" + protocols, e)"
task5	"<line7>      logger.debug(""Cannot process audioStream. No coordinator has been initialized."");"	<line7>	"logger.warn(""Coordinator not available, so cannot process audio stream. Only valid for testing."")"	"<line7> logger.warn(""Coordinator not available, so cannot process audio stream. Only valid for testing."")"
task5	"<line10>      LOGGER.warn(""Exception while compressing security group rules"");"	<line10>	"LOGGER.error(""Error while compressing stringified rules."", e)"	"<line10> LOGGER.error(""Error while compressing stringified rules."", e)"
task5	"<line4>    LOGGER.info(""Last page HTML:\n"" + html);"	<line4>	LOGGER.info(html)	<line4> LOGGER.info(html)
task5	"<line18>        logger.error(""meet error when recover upgrade process, file path:{}"",UpgradeLog.getUpgradeLogPath(),e);"	<line18>	"LOGGER.error(""Failed to read upgrade log"", e)"	"<line18> LOGGER.error(""Failed to read upgrade log"", e)"
task5	"<line1>    logger.debug(""Getting clientID ["" + this.clientID + ""]"");"	<line1>	"logger.debug(""Getting Client ID"")"	"<line1> logger.debug(""Getting Client ID"")"
task5	"<line5>      log.error(""Failed to get host address"", e);"	<line5>	"log.error(""Error getting IP address"", e)"	"<line5> log.error(""Error getting IP address"", e)"
task5	"<line2>      logger.warn(""{} denies to handle request for {} since query is still undefined"", this, query);"	<line2>	"log.error(""No SOLR query was set for the filter"")"	"<line2> log.error(""No SOLR query was set for the filter"")"
task5	<line12>      log.error(portalException, portalException);	<line12>	log.error(portalException, portalException)	<line12> log.error(portalException, portalException)
task5	<line6>    LOG.info(LOG_MESSAGE_AUTH_INITIATING, new Object[] {request.getRemoteAddr()});	<line8>	"LOG.info(""Redirecting to authentication page: "" + authUrl)"	"<line8> LOG.info(""Redirecting to authentication page: "" + authUrl)"
task5	"<line3>    LOG.debug(""ise harvest finished, outcome: {}"", counter);"	<line3>	"logger.debug(""Successfully fetched {} SGTs"", counter)"	"<line3> logger.debug(""Successfully fetched {} SGTs"", counter)"
task5	"<line16>      logger.warn(""Could not parse '{}' to a valid date"", value);"	<line16>	"logger.error(""Failed to parse date: {}"", value, pe)"	"<line16> logger.error(""Failed to parse date: {}"", value, pe)"
task5	"<line3>    LOG.debug(""Starting..."");"	<line3>	"logger.debug(""Starting..."")"	"<line3> logger.debug(""Starting..."")"
task5	"<line4>      logger.error(""Failed to get buffered writer for {}. "", filePath, e);"	<line4>	"LOG.error(""Failed to create file {}"", filePath, e)"	"<line4> LOG.error(""Failed to create file {}"", filePath, e)"
task5	"<line2>    log.info(""Waiting until provisioned service will be completed"");"	<line1>	"log.info(""Waiting until service is provisioned"")"	"<line1> log.info(""Waiting until service is provisioned"")"
task5	<line3>      this.logger.debug(buildMessage(message), e);	<line3>	logger.debug(message, e)	<line3> logger.debug(message, e)
task5	"<line17>          log.info(String.format(""Cache distribution %s"", distribution));"	<line17>	"log.info(String.format(""Read distribution %s from %s"", distribution, container))"	"<line17> log.info(String.format(""Read distribution %s from %s"", distribution, container))"
task5	"<line12>    logger.warn(""Cannot convert object to long: {}"", possibleLong);"	<line12>	"logger.warn(""Unable to parse date {}"", possibleLong)"	"<line12> logger.warn(""Unable to parse date {}"", possibleLong)"
task5	"<line2>    logger.debug(""getUDR() user ="" + authorId + "", title="" + title);"	<line2>	"logger.info(""getUDR() - authorId: "" + authorId + "" title: "" + title)"	"<line2> logger.info(""getUDR() - authorId: "" + authorId + "" title: "" + title)"
task5	"<line3>    LOGGER.error(""captured error"");"	<line3>	"log.info(""captured error"")"	"<line3> log.info(""captured error"")"
task5	<line7>      logger.error(e, e);	<line7>	"log.error(""Exception during shutdown"", e)"	"<line7> log.error(""Exception during shutdown"", e)"
task5	"<line5>      LOG.error(""Exception in reading data sources file {}"", dataSourcesUrl, e);"	<line5>	"LOG.error(""Cannot read DataSources from URL: "" + dataSourcesUrl, e)"	"<line5> LOG.error(""Cannot read DataSources from URL: "" + dataSourcesUrl, e)"
task5	"<line12>    log.debug(String.format(""Split SDK ready in %d ms"", (System.currentTimeMillis() - startTime)));"	<line12>	"log.info(""Took "" + (System.currentTimeMillis() - startTime) + "" ms to load SDK"")"	"<line12> log.info(""Took "" + (System.currentTimeMillis() - startTime) + "" ms to load SDK"")"
task5	"<line17>      logger.error(""queryApis error:"", throwable);"	<line17>	"logger.error(""Error when querying apis"", throwable)"	"<line17> logger.error(""Error when querying apis"", throwable)"
task5	"<line3>      log.debug(""Read '{}'"", url.getFile());"	<line3>	"log.debug(""Read '{}'"", url)"	"<line3> log.debug(""Read '{}'"", url)"
task5	"<line6>      LOG.debug(""Ignored error: "", e);"	<line6>	"LOG.error(""Cannot get precision value of this field: "" + fieldNameNode.getIdentifier())"	"<line6> LOG.error(""Cannot get precision value of this field: "" + fieldNameNode.getIdentifier())"
task5	"<line8>    LOG.debug(""Received: {}"", message);"	<line2>	"LOG.info(""---- sending a text message ---"")"	"<line2> LOG.info(""---- sending a text message ---"")"
task5	<line10>      log.debug(line);	<line12>	log.info(content.toString())	<line12> log.info(content.toString())
task5	<line23>      LOG.debug(txt.toString());	<line23>	LOGGER.debug(txt.toString())	<line23> LOGGER.debug(txt.toString())
task5	"<line2>    LOG.debug(""Scheduler Info Result : {} "", jsonResult);"	<line2>	"LOG.info(""scheduler info json string: {}"", jsonResult)"	"<line2> LOG.info(""scheduler info json string: {}"", jsonResult)"
task5	"<line6>      LOG.warn(""Unable to load id {}"", id, e);"	<line6>	"LOG.error(""load sessionData from cache error,id is {}"", id, e)"	"<line6> LOG.error(""load sessionData from cache error,id is {}"", id, e)"
task5	"<line3>        log.warn(""Saw request to split root tablet, ignoring"");"	<line3>	"log.warn(""Refusing to split root tablet"")"	"<line3> log.warn(""Refusing to split root tablet"")"
task5	"<line6>      log.trace(""Could not find jar with key: "" + entryKey);"	<line6>	"LOG.warn(""could not find installed jar for key: {}"", entryKey)"	"<line6> LOG.warn(""could not find installed jar for key: {}"", entryKey)"
task5	"<line14>      logger.error(""error in get widgets"", t);"	<line14>	"logger.error(""error in get widgets"", t)"	"<line14> logger.error(""error in get widgets"", t)"
task5	"<line6>        Log.warn(""An exception occurred while dispatching a 'componentSecretUpdated' event!"", e);"	<line6>	"logger.error(""Could not update component secret in listener {}"", listener.getClass().getName(), e)"	"<line6> logger.error(""Could not update component secret in listener {}"", listener.getClass().getName(), e)"
task5	"<line2>      log.debug(""Page unload for request id: {}"", requestId);"	<line2>	"LOG.debug(""Removing from Explanator: {}"", requestId)"	"<line2> LOG.debug(""Removing from Explanator: {}"", requestId)"
task5	"<line19>        logger.warn("""", t);"	<line19>	"logger.error(""Unexpected error in outgoing message handler: {}"", t.toString())"	"<line19> logger.error(""Unexpected error in outgoing message handler: {}"", t.toString())"
task5	<line6>      log.error(exception, exception);	<line6>	log.error(exception, exception)	<line6> log.error(exception, exception)
task5	"<line5>        logger.warn(""while reloading configuration of "" + bean, e);"	<line5>	"log.warn(""Error while reloading configuration of bean '{}'"", bean, e)"	"<line5> log.warn(""Error while reloading configuration of bean '{}'"", bean, e)"
task5	"<line25>          LOG.warn(""Unable to parse pool size: "" + strId + "". Applying default value"");"	<line25>	"LOG.warn(""Unable to parse ID as integer: {}"", strId)"	"<line25> LOG.warn(""Unable to parse ID as integer: {}"", strId)"
task5	"<line23>    logger.debug(""child_ids :"" + res);"	<line23>	"logger.debug(""child_ids :"" + res)"	"<line23> logger.debug(""child_ids :"" + res)"
task5	"<line12>                    logger.warn(""Exception at showUser"", e);"	<line12>	"logger.warn(""Exception at showUser"", e)"	"<line12> logger.warn(""Exception at showUser"", e)"
task5	"<line2>    log.info(""Manager reports: I just got pinged!"");"	<line2>	"LOG.info(""Ping!"")"	"<line2> LOG.info(""Ping!"")"
task5	"<line10>      logger.error(""Could not compress sensei request "", e);"	<line10>	"log.error(""Error while compressing the request with snappy"", e)"	"<line10> log.error(""Error while compressing the request with snappy"", e)"
task5	<line10>                    logger.debug(ex, ex);	<line10>	LOGGER.debug(ex, ex)	<line10> LOGGER.debug(ex, ex)
task5	"<line11>    log.debug(""PUT SUCCESS: "" + resolvedPartUri);"	<line9>	"log.error(""Failed to put binary part"", e)"	"<line9> log.error(""Failed to put binary part"", e)"
task5	"<line1>    LOG.info(""Executing: "" + sql);"	<line1>	"LOGGER.info(""Executing statement {}"", sql)"	"<line1> LOGGER.info(""Executing statement {}"", sql)"
task5	"<line2>    LOG.info(""Subscription status changed {} : {}"", subscription.getSubscriptionId(), status);"	<line2>	"logger.debug(""Status changed for subscription {}: {}"", subscription.getId(), status)"	"<line2> logger.debug(""Status changed for subscription {}: {}"", subscription.getId(), status)"
task5	<line45>            logger.error(e.getMessage(), e);	<line45>	"logger.error(""process output log parse error"", e)"	"<line45> logger.error(""process output log parse error"", e)"
task5	<line13>      log.error(e);	<line13>	"logger.error(""Could not parse date"")"	"<line13> logger.error(""Could not parse date"")"
task5	"<line1>    LOG.info(""Connection {} leaked at:"", leakInfo.getResourceDescription(), leakInfo.getStackFrames());"	<line1>	"log.warn(""Leaked object: "" + leakInfo.getLeakedObjectDisplayString())"	"<line1> log.warn(""Leaked object: "" + leakInfo.getLeakedObjectDisplayString())"
task5	"<line2>    log.warn(""Exception caught while serving static files"", cause);"	<line3>	"log.error(""Exception in "" + this, cause)"	"<line3> log.error(""Exception in "" + this, cause)"
task5	"<line8>      LOGGER.error(""Could not find "" + RABBITMQ_CONFIGURATION_NAME + "" configuration file."");"	<line8>	"LOGGER.error(""Could not find {} configuration file: {}"",RABBITMQ_CONFIGURATION_NAME,e.getMessage())"	"<line8> LOGGER.error(""Could not find {} configuration file: {}"",RABBITMQ_CONFIGURATION_NAME,e.getMessage())"
task5	"<line13>      LOGGER.error(""Exception during sendMessage()"", e);"	<line13>	"LOGGER.error(""sendMessage() exception for ipAddress {}, oslpRequest {}"", ipAddress, oslpRequest, e)"	"<line13> LOGGER.error(""sendMessage() exception for ipAddress {}, oslpRequest {}"", ipAddress, oslpRequest, e)"
task5	"<line5>      log.warn(""getServiceIcon threw"", e);"	<line5>	"logger.warn(""Could not find service icon for {}"", serviceType)"	"<line5> logger.warn(""Could not find service icon for {}"", serviceType)"
task5	"<line2>    logger.debug(""Netatmo webhook servlet stopped"");"	<line1>	"logger.info(""Unregistering handler for path: {}"", path)"	"<line1> logger.info(""Unregistering handler for path: {}"", path)"
task5	"<line13>        logger.error(""unsupported arg scheme: {}"", argScheme);"	<line13>	"log.warn(""Unrecognized response type {}"", argScheme)"	"<line13> log.warn(""Unrecognized response type {}"", argScheme)"
task5	"<line8>      log.warn(""All attributes are selected !"");"	<line20>	"LOGGER.warn(""Cannot generate random attributes for selection, using all attributes."")"	"<line20> LOGGER.warn(""Cannot generate random attributes for selection, using all attributes."")"
task5	"<line3>    logger.debug(""Setting request in RequestInfo: {}"", requestInfo);"	<line3>	"logger.trace(""service()"")"	"<line3> logger.trace(""service()"")"
task5	"<line2>    log.debug(""findAllModules() - pageable: {}, moduleSearchForm: {}"", pageable, moduleSearchForm);"	<line2>	"log.debug(""findAllModules() - pageable: {}, moduleSearchForm: {}"", pageable, moduleSearchForm)"	"<line2> log.debug(""findAllModules() - pageable: {}, moduleSearchForm: {}"", pageable, moduleSearchForm)"
task5	"<line6>    LOG.trace(""Actions for Droplet {} : page {} / {} per page [{}] "",dropletId,configuration.getPage(),configuration.getPerPage(),actions.getActions());"	<line6>	"LOG.trace(""All Droplet Actions : page {} / {} per page [{}] "",configuration.getPage(),configuration.getPerPage(),actions.getActions())"	"<line6> LOG.trace(""All Droplet Actions : page {} / {} per page [{}] "",configuration.getPage(),configuration.getPerPage(),actions.getActions())"
task5	"<line8>      logger.warn(""Attempt to post slack message to invalid channel: "" + ex.getChannelName());"	<line8>	"LOG.warn(""Could not find channel for: "" + message.getChannelId())"	"<line8> LOG.warn(""Could not find channel for: "" + message.getChannelId())"
task5	"<line2>    logger.info(""CounterIT.testCounters"");"	<line20>	"log.info(""Flushing cache"")"	"<line20> log.info(""Flushing cache"")"
task5	"<line3>    logger.trace(""added entry {} originally aimed at time {}"", ne, String.format(""%tc"", new Date(time)));"	<line3>	"logger.debug(""Adding device {} to poll queue at {}"", d.getAddress(), texp)"	"<line3> logger.debug(""Adding device {} to poll queue at {}"", d.getAddress(), texp)"
task5	"<line3>    logger.info(""{} => local. onCompleted"", getAgentInfo().getAgentKey());"	<line3>	"logger.info(""connected onCompleted. agentInfo:{}"", agentInfo)"	"<line3> logger.info(""connected onCompleted. agentInfo:{}"", agentInfo)"
task5	"<line10>        Log.info(""Loaded "" + idCounter + "" documents from index at "" + indexKey());"	<line12>	"Log.error(""Error while loading index"", e)"	"<line12> Log.error(""Error while loading index"", e)"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line9>      logger.error(""Critical error: Study {} not found in catalog."", studyId);"	<line18>	"logger.debug(""Workspace path: {}"", workspace)"	"<line18> logger.debug(""Workspace path: {}"", workspace)"
task5	"<line1>    LOG.info(""Spell checking file: {}"", file);"	<line1>	"LOG.info(""Spell checking {}"", file)"	"<line1> LOG.info(""Spell checking {}"", file)"
task5	"<line6>    logger.debug(""Search for target assets that are already localized"");"	<line6>	"log.info(""Finding target files"")"	"<line6> log.info(""Finding target files"")"
task5	"<line18>    logger.debug("" {} account_quota of ContainerQuota have been updated."", updatedCounter);"	<line18>	"logger.debug("" {} quota have been updated."", updatedCounter)"	"<line18> logger.debug("" {} quota have been updated."", updatedCounter)"
task5	"<line6>          log.debug(String.format(""[one-after-another algorithm] [scale-up] [partition] %s has space to create ""+ ""members. [non terminated count] %s [max] %s"",partitionContext.getPartitionId(),partitionContext.getNonTerminatedMemberCount(),partitionContext.getMax()));"	<line6>	"log.debug(""[round-robin algorithm] [scale-up] [partition] "" + partitionContext)"	"<line6> log.debug(""[round-robin algorithm] [scale-up] [partition] "" + partitionContext)"
task5	"<line27>        log.warn(""unknown permission: "" + permission);"	<line27>	"log.warn(""unknown permission: "" + permission)"	"<line27> log.warn(""unknown permission: "" + permission)"
task5	"<line7>      log.debug(""= "" + value);"	<line9>	"log.debug(""No value found for DOCPROPERTY PAGES. This is probably ok."")"	"<line9> log.debug(""No value found for DOCPROPERTY PAGES. This is probably ok."")"
task5	"<line12>    LOG.info(""Succeeded after ... warning is expected..."");"	<line10>	"logger.debug(""Ignored InterruptedIOException"", ignored)"	"<line10> logger.debug(""Ignored InterruptedIOException"", ignored)"
task5	"<line10>        log.debug(""Cannot handle protected node ""+ protectedParent+ "". It nor one of its parents represent a valid Authorizable."");"	<line10>	"log.debug(""Authorizable {} does not exist. Cannot determine membership."", groupNode)"	"<line10> log.debug(""Authorizable {} does not exist. Cannot determine membership."", groupNode)"
task5	"<line11>      log.debug(""No file item was found"");"	<line7>	"log.debug(""newResourceResponse: {}"", file)"	"<line7> log.debug(""newResourceResponse: {}"", file)"
task5	"<line4>    logger.info(""{}"", JsonCodec.INSTANCE.encode(set));"	<line4>	log.info(set.toString())	<line4> log.info(set.toString())
task5	"<line2>      LOGGER.info(""Creating directory {}"", SAVE_DIRECTORY_PATH.toAbsolutePath());"	<line3>	"LOGGER.info(""Created save directory "" + SAVE_DIRECTORY_PATH)"	"<line3> LOGGER.info(""Created save directory "" + SAVE_DIRECTORY_PATH)"
task5	"<line5>    log.info(""Stopping pipelines-to-avro-from-dwca service"");"	<line2>	"log.info(""Stopping pipelines-hdfs-view service"")"	"<line2> log.info(""Stopping pipelines-hdfs-view service"")"
task5	"<line28>    LOG.info(""Init server info: {}"", serverInfo);"	<line28>	"LOG.info(""Init server info: {}"", serverInfo)"	"<line28> LOG.info(""Init server info: {}"", serverInfo)"
task5	"<line4>      logger.debug(""insert trace: {}"", spanBo);"	<line4>	"logger.debug(""Handle span:{}"", spanBo)"	"<line4> logger.debug(""Handle span:{}"", spanBo)"
task5	"<line3>    LOG.info(""Snapshot of counter "" + numElements + "" at checkpoint "" + checkpointId);"	<line3>	"LOG.debug(""Taking a new snapshot as per checkpoint {}."", checkpointId)"	"<line3> LOG.debug(""Taking a new snapshot as per checkpoint {}."", checkpointId)"
task5	"<line2>      logger.warn(""Request has not been sent for {}."", this);"	<line2>	"LOG.warn(""Abandoning request {}"", request, cause)"	"<line2> LOG.warn(""Abandoning request {}"", request, cause)"
task5	"<line2>    logger.info(""[update]{}"", args);"	<line2>	"log.info(""Updating ClusterServiceBroker because of changes in ClusterServiceClass {}"",this.currentState.getClusterServiceClass())"	"<line2> log.info(""Updating ClusterServiceBroker because of changes in ClusterServiceClass {}"",this.currentState.getClusterServiceClass())"
task5	"<line2>    logger.info(""Handling error: "" + e.getClass().getSimpleName() + "", "" + e.getMessage());"	<line2>	"logger.info(""A client attempted to exchange a token with an invalid signature."", e)"	"<line2> logger.info(""A client attempted to exchange a token with an invalid signature."", e)"
task5	<line11>    Log.info(listOutput);	<line11>	Log.info(listOutput)	<line11> Log.info(listOutput)
task5	"<line4>      logger.debug(""Enforcing emit on {}"", operatorThread.getName());"	<line3>	"LOG.debug(""The operator thread will not be disabled."")"	"<line3> LOG.debug(""The operator thread will not be disabled."")"
task5	"<line6>        LOGGER.debug(""Unregistering RESTEasy servlet with an alias '"" + _alias + ""'"");"	<line6>	"LOGGER.debug(""Unregistering RESTEasy servlet for alias "" + _alias)"	"<line6> LOGGER.debug(""Unregistering RESTEasy servlet for alias "" + _alias)"
task5	"<line6>        log.debug(""Blob s3://"" + bucketName + ""/"" + bucketKey + "" already exists"");"	<line6>	"log.debug(String.format(""exists %s %s"", bucketKey, metadata.getContentLength()))"	"<line6> log.debug(String.format(""exists %s %s"", bucketKey, metadata.getContentLength()))"
task5	"<line11>        log.info(""Skipping index settings contributor"");"	<line11>	"log.info(""Unable to create REST client for indexing"", elasticsearchConnectionNotInitializedException)"	"<line11> log.info(""Unable to create REST client for indexing"", elasticsearchConnectionNotInitializedException)"
task5	"<line11>          LOG.debug(""Created directory {}, options: {}"", path.getPath(), mergedOptions);"	<line10>	"LOG.debug(""Creating directory {} with options {}"", path.getPath(), mergedOptions)"	"<line10> LOG.debug(""Creating directory {} with options {}"", path.getPath(), mergedOptions)"
task5	<line5>    LOGGER.info(new JsonUtils().convertBandInfos(objects));	<line5>	LOGGER.info(JsonUtil.toJson(objects, true))	<line5> LOGGER.info(JsonUtil.toJson(objects, true))
task5	"<line7>      log.error(""Unable to get asset entries count"", exception);"	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	<line15>          log.error(e.getMessage(), e);	<line15>	log.error(e.getMessage(), e)	<line15> log.error(e.getMessage(), e)
task5	"<line4>      logger.info(""Terminating solver early."");"	<line4>	"log.info(""Termination early successful"")"	"<line4> log.info(""Termination early successful"")"
task5	"<line16>      LOG.fatal(""Fatal error in View Lifecycle worker"", t);"	<line16>	"LOG.error(""Error in KRAD lifecycle worker"", t)"	"<line16> LOG.error(""Error in KRAD lifecycle worker"", t)"
task5	"<line5>        logger.debug(""after comma: "" + tt);"	<line5>	"log.debug(""nextComma: ttype = ""+ tok.ttype+ "" ('""+ tok.sval+ ""')"")"	"<line5> log.debug(""nextComma: ttype = ""+ tok.ttype+ "" ('""+ tok.sval+ ""')"")"
task5	"<line11>        logger.error(""Python operation encountered an exception: "" + ex.toString());"	<line11>	log.error(ex.asString())	<line11> log.error(ex.asString())
task5	"<line3>    logger.trace(""    Shuffled cachedEntityList with size ({}) in entitySelector({})."",cachedEntityList.size(),this);"	<line2>	"LOGGER.debug(""Starting to iterate through cached entity list."")"	"<line2> LOGGER.debug(""Starting to iterate through cached entity list."")"
task5	<line13>        log.debug(sb.toString());	<line13>	log.debug(sb.toString())	<line13> log.debug(sb.toString())
task5	"<line4>    LOG.info(""Worker container: "" + connectWorkerContainer.getEndpointUrl() + "" was detected"");"	<line4>	"log.info(""Adding worker container: {}"", connectWorkerContainer)"	"<line4> log.info(""Adding worker container: {}"", connectWorkerContainer)"
task5	"<line8>      LOG.debug(""queued job "" + id + "" in "" + elapsed + "" ms"");"	<line8>	"LOG.info(""Elapsed time: "" + elapsed)"	"<line8> LOG.info(""Elapsed time: "" + elapsed)"
task5	"<line3>    LOGGER.trace(""PUT: {}"", id.getFullIdPath());"	<line3>	"LOGGER.debug(""PUT: {}"", id.getFullIdPath())"	"<line3> LOGGER.debug(""PUT: {}"", id.getFullIdPath())"
task5	"<line16>        logger.info(""rootBound = "" + M);"	<line16>	"logger.info(""rootBound = "" + M)"	"<line16> logger.info(""rootBound = "" + M)"
task5	"<line2>    LOGGER.info(""Save: "" + profile);"	<line2>	"LOG.info(""Save device: "" + profile)"	"<line2> LOG.info(""Save device: "" + profile)"
task5	"<line5>      log.error(""Failed to execute shutdown hook"", e);"	<line5>	"log.error(""Timer task failed"", e)"	"<line5> log.error(""Timer task failed"", e)"
task5	"<line1>    log.info(""config service override of configFile="" + file);"	<line1>	"logger.debug(""Setting config file to: {}"", file)"	"<line1> logger.debug(""Setting config file to: {}"", file)"
task5	"<line2>      LOG.debug(""Removing completion key: {}"", key);"	<line2>	"LOG.debug(""Erroring out completion key {} rc {}"", key, rc)"	"<line2> LOG.debug(""Erroring out completion key {} rc {}"", key, rc)"
task5	<line7>        log.debug(interruptedException, interruptedException);	<line7>	log.debug(interruptedException, interruptedException)	<line7> log.debug(interruptedException, interruptedException)
task5	"<line3>    logger.debug(""Received channel: {}, command: {}"", channelUID, command);"	<line43>	"logger.debug(""Command {} failed: connector is null"", command)"	"<line43> logger.debug(""Command {} failed: connector is null"", command)"
task5	"<line4>    log.trace(""{} {} {} {}"", isEnter ? "">>>>"" : ""<<<<"", description, method, transaction);"	<line4>	"log.trace(""{} reactor {} {}"", isEnter ? "">>"" : ""<<"", method, transaction)"	"<line4> log.trace(""{} reactor {} {}"", isEnter ? "">>"" : ""<<"", method, transaction)"
task5	<line7>      log.debug(error, e);	<line7>	log.error(error, e)	<line7> log.error(error, e)
task5	<line21>    logger.debug(exception.getErrorMessage());	<line21>	logger.debug(exception.getErrorMessage())	<line21> logger.debug(exception.getErrorMessage())
task5	"<line2>    log.info(""------ Test a*.* AND b ------"");"	<line2>	"log.info(""------ Test (a AND b), where all terms are un-fielded ------"")"	"<line2> log.info(""------ Test (a AND b), where all terms are un-fielded ------"")"
task5	"<line4>      logger.debug(""page complete: "" + complete);"	<line4>	"logger.debug(""isPageComplete()="" + complete)"	"<line4> logger.debug(""isPageComplete()="" + complete)"
task5	"<line4>      LOGGER.debug(format(""Preparing static statements for entity of type %s"", entityClass.getCanonicalName()));"	<line4>	"LOGGER.debug(format(""Prepare SELECT statement for version %s"", cassandraVersion))"	"<line4> LOGGER.debug(format(""Prepare SELECT statement for version %s"", cassandraVersion))"
task5	"<line17>      LOGGER.error(""Unexpected error on nestedForeach"", t);"	<line17>	"LOGGER.error(""Nested foreach failed"", t)"	"<line17> LOGGER.error(""Nested foreach failed"", t)"
task5	"<line11>        LOG.error(""Unable to find specified default adapter class: "" + className, cnfe);"	<line15>	"log.debug(""Using {} as the default adapter"", resolvedReference)"	"<line15> log.debug(""Using {} as the default adapter"", resolvedReference)"
task5	"<line5>    log.info(Color.BLUE + ""4-Network-1 pattern lowercase"" + Color.NORMAL);"	<line5>	"log.info(Color.BLUE + ""4-Network-1 pattern lowercase"" + Color.NORMAL)"	"<line5> log.info(Color.BLUE + ""4-Network-1 pattern lowercase"" + Color.NORMAL)"
task5	"<line8>      LOG.error(""Exception in flush - write/commit data to Hive"", e);"	<line7>	"LOG.debug(""Committed records batch to HCatalog"")"	"<line7> LOG.debug(""Committed records batch to HCatalog"")"
task5	"<line32>            log.error(e1, ""Exception thrown when closing maker.  Logging and ignoring."");"	<line32>	"log.error(e1, ""Exception thrown when closing maker.  Logging and ignoring."")"	"<line32> log.error(e1, ""Exception thrown when closing maker.  Logging and ignoring."")"
task5	"<line8>            LOGGER.error(""Unable to migrate input '{}' (keep previous value)."", s);"	<line8>	"log.error(""Error during migration of property '{}' : {}"", s, e.getMessage())"	"<line8> log.error(""Error during migration of property '{}' : {}"", s, e.getMessage())"
task5	"<line16>      logger.error(""create and mapped file error."", ex);"	<line16>	"logger.error(""newMappedRWFile error"", ex)"	"<line16> logger.error(""newMappedRWFile error"", ex)"
task5	"<line10>    LOG.debug(""model: {}"", changedModel);"	<line9>	"LOG.debug(""model: {}"", model)"	"<line9> LOG.debug(""model: {}"", model)"
task5	"<line28>        LOG.warn(""interrupted while waiting for journal stats thread to shut down."");"	<line27>	"LOG.warn(""Interrupted while waiting for journal checkpoint thread to terminate"", e)"	"<line27> LOG.warn(""Interrupted while waiting for journal checkpoint thread to terminate"", e)"
task5	"<line2>    LOGGER.info(""Destroying Web application"");"	<line2>	"LOGGER.info(""Destroying web application context"")"	"<line2> LOGGER.info(""Destroying web application context"")"
task5	"<line6>        log.warn(""Message could not be built. [exception=({})]"", e.getMessage(), e);"	<line6>	"log.warn(""Message could not be built."", e)"	"<line6> log.warn(""Message could not be built."", e)"
task5	"<line4>      LOG.error(""Exception when executing "" + r, t);"	<line4>	"LOG.error(""Error in pool task"", t)"	"<line4> LOG.error(""Error in pool task"", t)"
task5	"<line5>        log.info(""Load property {} with value {} from ENV."", key, value);"	<line5>	"LOG.info(""Setting property: {}={}"", key, value)"	"<line5> LOG.info(""Setting property: {}={}"", key, value)"
task5	"<line2>    LOGGER.debug(""Leaving legacy_change_substitution"");"	<line5>	"log.debug(""From {} to {} at {}"", from, to, location)"	"<line5> log.debug(""From {} to {} at {}"", from, to, location)"
task5	"<line2>      LOG.debug(""calling setuseWorkflowPessimisticLocking '"" + useWorkflowPessimisticLocking + ""'"");"	<line2>	"LOG.debug(""setUseWorkflowPessimisticLocking("" + useWorkflowPessimisticLocking + "")"")"	"<line2> LOG.debug(""setUseWorkflowPessimisticLocking("" + useWorkflowPessimisticLocking + "")"")"
task5	"<line13>      log.debug(""{}: Creating AdminClient for {}"", reconciliation, bootstrapHostnames);"	<line25>	"log.warn(""An error while try to create an admin client with bootstrap brokers {}"", podNames, e)"	"<line25> log.warn(""An error while try to create an admin client with bootstrap brokers {}"", podNames, e)"
task5	"<line5>        logger.error(""Could not register ConfigDescription: {}"", configDescription.getUID(), e);"	<line5>	"log.error(""Failed to add config description for bundle "" + bundle.getSymbolicName(), e)"	"<line5> log.error(""Failed to add config description for bundle "" + bundle.getSymbolicName(), e)"
task5	"<line22>    log.info(""Removed topic {} with ID {}."", topic.name, record.topicId());"	<line22>	"log.info(""Replayed topic {} with topic ID {}."", topic.name, topic.id)"	"<line22> log.info(""Replayed topic {} with topic ID {}."", topic.name, topic.id)"
task5	"<line11>    LOG.info(""Shutdown Hook Attached"");"	<line7>	"LOG.info(""Shutdown Hook Attached"")"	"<line7> LOG.info(""Shutdown Hook Attached"")"
task5	"<line2>    logger.info(""Failed connection: "" + address);"	<line2>	"logger.info(""Failed to connect to address {}, waiting for next attempt"", address)"	"<line2> logger.info(""Failed to connect to address {}, waiting for next attempt"", address)"
task5	<line9>      logger.warn(e.toString(), e);	<line8>	"LOG.warn(""IllegalStateException while removing shutdown hook"", e)"	"<line8> LOG.warn(""IllegalStateException while removing shutdown hook"", e)"
task5	"<line9>      LOGGER.debug(""There was a problem converting the input to ReferenceTermType"");"	<line9>	"log.error(""The input values are invalid"", e)"	"<line9> log.error(""The input values are invalid"", e)"
task5	<line41>                  LOG.error(cause.getMessage(), cause);	<line41>	LOG.error(cause.getMessage(), cause)	<line41> LOG.error(cause.getMessage(), cause)
task5	"<line10>      LOG.error(""run trainOnLocalClusterTest failed "", x);"	<line10>	"LOG.error(""run incTrainTest failed "", x)"	"<line10> LOG.error(""run incTrainTest failed "", x)"
task5	"<line5>      LOGGER.debug(""Deregistering of JDBC driver(s) is disabled!"");"	<line5>	"logger.warn(""The JDBC driver manager is not destroyed because you are using a provided driver."")"	"<line5> logger.warn(""The JDBC driver manager is not destroyed because you are using a provided driver."")"
task5	"<line1>    log.debug(""Setting sourceHelper on "" + this.name);"	<line1>	"LOG.debug(""Setting source helper"")"	"<line1> LOG.debug(""Setting source helper"")"
task5	"<line2>    LOG.debug(""Opening '{}' for reading."", f);"	<line6>	"LOG.debug(""bucket is "" + bucket)"	"<line6> LOG.debug(""bucket is "" + bucket)"
task5	"<line6>                log.trace(""Get fresh values of capacity limits"");"	<line6>	"LOG.debug(""Loading capacity limit for {}"", name)"	"<line6> LOG.debug(""Loading capacity limit for {}"", name)"
task5	"<line42>        LOGGER.error(""Error cleaning up policies after test due to: "" + e.getMessage(), e);"	<line42>	"LOG.error(""Could not delete access policy: {}"", policyToDelete.getIdentifier(), e)"	"<line42> LOG.error(""Could not delete access policy: {}"", policyToDelete.getIdentifier(), e)"
task5	"<line13>    log.trace(""Read negotiate response"");"	<line13>	"log.debug(""peeked: {}"", Encdec.toHexString(this.sbuf, 0, size))"	"<line13> log.debug(""peeked: {}"", Encdec.toHexString(this.sbuf, 0, size))"
task5	"<line2>    log.trace(""[{}][{}] Processing local rpc call to device actor [{}]"",request.getTenantId(),request.getId(),request.getDeviceId());"	<line2>	"log.trace(""[{}][{}] Forwarding RPC request to device actor"", request.getId(), request.getDeviceId())"	"<line2> log.trace(""[{}][{}] Forwarding RPC request to device actor"", request.getId(), request.getDeviceId())"
task5	"<line9>    log.info(""Interface class is undefined for the factory. Generated interface is used."");"	<line10>	"log.debug(""Using {} as interface class for {}"", generatedInterfaceClass, this)"	"<line10> log.debug(""Using {} as interface class for {}"", generatedInterfaceClass, this)"
task5	"<line3>      log.debug(""Loading database script from :"" + scriptName);"	<line3>	"log.debug(""Getting db setup script location for "" + databaseType)"	"<line3> log.debug(""Getting db setup script location for "" + databaseType)"
task5	"<line11>      log.info(""Start session result for '{}': '{}'"", userName, ""start"", externalResult);"	<line18>	"log.debug(""Generated new session {} for user {}"", sessionId, userName)"	"<line18> log.debug(""Generated new session {} for user {}"", sessionId, userName)"
task5	"<line1>    LOG.info(""Executing operation putView"");"	<line1>	"LOG.info(""Executing operation putView"")"	"<line1> LOG.info(""Executing operation putView"")"
task5	<line4>      LOGGER.error(e, WebJcrI18n.cannotLoadRepositoryNames.text());	<line4>	"log.error(""Error while getting JCR repository names"", e)"	"<line4> log.error(""Error while getting JCR repository names"", e)"
task5	"<line10>          logger.debug(""Request message validated"");"	<line10>	"logger.debug(""Request is valid"")"	"<line10> logger.debug(""Request is valid"")"
task5	"<line6>        logger.warn("""", t);"	<line6>	"LOG.error(""endTransaction: t"", t)"	"<line6> LOG.error(""endTransaction: t"", t)"
task5	<line5>      logger.error(e);	<line5>	"logger.warn(""Error during finalize"")"	"<line5> logger.warn(""Error during finalize"")"
task5	"<line9>              LOG.trace(""{}: running {}"", this, task);"	<line12>	"LOG.error(""task {} failed"", task, e)"	"<line12> LOG.error(""task {} failed"", task, e)"
task5	"<line18>        logger.debug(""An unexpected status code was returned: '{}'"", statusCode);"	<line18>	"logger.warn(""POST to "" + url + "" failed: status = "" + statusCode)"	"<line18> logger.warn(""POST to "" + url + "" failed: status = "" + statusCode)"
task5	"<line10>    logger.debug(""{} : {}"", configItemName, xml);"	<line10>	"logger.info(""Extracting entity type {} from XML {}"", typeCode, xml)"	"<line10> logger.info(""Extracting entity type {} from XML {}"", typeCode, xml)"
task5	"<line5>      LOG.error(""Can't close "" + this.getClass().getSimpleName(), ex);"	<line5>	"LOG.error(""Failed to close XceiverClientManager"", ex)"	"<line5> LOG.error(""Failed to close XceiverClientManager"", ex)"
task5	<line6>        log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line6>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line6> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line2>      LOGGER.info(""Skipping configure resources step"");"	<line4>	"LOG.info(""Configuring resources for {}"", tableName)"	"<line4> LOG.info(""Configuring resources for {}"", tableName)"
task5	"<line74>    logger.info(""Read {} HET_ALT variants from sample {}"", numVariants, sample);"	<line74>	"logger.info(""Read "" + numVariants + "" knockout HET_ALT variants"")"	"<line74> logger.info(""Read "" + numVariants + "" knockout HET_ALT variants"")"
task5	"<line12>        log.error(""Failed to write PEM"", e);"	<line12>	"log.warn(""Failed to write public key for host [{}]"", entry.getKey(), e)"	"<line12> log.warn(""Failed to write public key for host [{}]"", entry.getKey(), e)"
task5	"<line4>      logger.debug(""Successfully published message for token:"" + token);"	<line4>	"logger.debug(""{} done"", this)"	"<line4> logger.debug(""{} done"", this)"
task5	"<line14>          logger.warn(""{}: Could not parse string \""{}\"" with pattern {} in element \""{}\"". Parameters: {}"",new Object[] {getReplacement(),sources[0].toString(),""yyyy-MM-dd'T'HH:mm:ssZ"",caller,getParametersAsString(sources)});"	<line14>	"logger.warn(""{}: Could not parse string {} with pattern {} in element {}, returning null."",this.getClass().getSimpleName(),sources[0].toString(),""yyyy-MM-dd'T'HH:mm:ssZ"",caller)"	"<line14> logger.warn(""{}: Could not parse string {} with pattern {} in element {}, returning null."",this.getClass().getSimpleName(),sources[0].toString(),""yyyy-MM-dd'T'HH:mm:ssZ"",caller)"
task5	"<line1>    logger.debug(""removing mapping from key {} to websocket session {}"", key, session.getId());"	<line1>	"LOG.trace(""Remove mapping: {} for session: {}"", key, session.getId())"	"<line1> LOG.trace(""Remove mapping: {} for session: {}"", key, session.getId())"
task5	"<line2>    LOG.debug(""save note, note: {}"", note);"	<line2>	"LOGGER.info(""Save note {}"", note)"	"<line2> LOGGER.info(""Save note {}"", note)"
task5	"<line66>    logger.info(this.getClass().getSimpleName() + "" altered scores for "" + altered + "" documents"");"	<line63>	"logger.debug(""altered = "" + altered)"	"<line63> logger.debug(""altered = "" + altered)"
task5	"<line2>    LOGGER.debug(""SaltLength: "" + msg.getSaltLength().getValue());"	<line2>	"LOGGER.debug(""SaltLength: "" + msg.getSaltLength().getValue())"	"<line2> LOGGER.debug(""SaltLength: "" + msg.getSaltLength().getValue())"
task5	"<line17>    LOG.debug(""Log context is prepared: {}"", registered);"	<line16>	"LOG.info(""Logging context registered: "" + name + ""="" + value)"	"<line16> LOG.info(""Logging context registered: "" + name + ""="" + value)"
task5	"<line2>      _Employee.LOG.debug(""updating hireDate from "" + hireDate() + "" to "" + value);"	<line2>	"_Employee.LOG.debug(""updating hireDate from "" + hireDate() + "" to "" + value)"	"<line2> _Employee.LOG.debug(""updating hireDate from "" + hireDate() + "" to "" + value)"
task5	"<line5>        logger.warn(""A JSON metadata entry's size is not supposed to exceed""+ "" kylin.metadata.jdbc.small-cell-meta-size-warning-threshold({}), resPath: {},""+ "" actual size: {}"",smallCellMetadataWarningThreshold,resPath,content.length);"	<line5>	"logger.warn(""A JSON metadata entry's size is not supposed to exceed""+ "" kylin.metadata.jdbc.small-cell-meta-size-warning-threshold(""+ smallCellMetadataWarningThreshold+ ""), resPath: ""+ resPath+ "", actual size: ""+ content.length)"	"<line5> logger.warn(""A JSON metadata entry's size is not supposed to exceed""+ "" kylin.metadata.jdbc.small-cell-meta-size-warning-threshold(""+ smallCellMetadataWarningThreshold+ ""), resPath: ""+ resPath+ "", actual size: ""+ content.length)"
task5	"<line44>    log.error(""could not load Mat {}"", infile);"	<line44>	"log.error(""could not find any file matching "" + infile)"	"<line44> log.error(""could not find any file matching "" + infile)"
task5	"<line11>        logger.warn(""A non numeric hue ID '{}' was assigned. Ignoring!"", metadata.getValue());"	<line11>	"logger.debug(""Cannot parse metadata value {}"", metadata.getValue())"	"<line11> logger.debug(""Cannot parse metadata value {}"", metadata.getValue())"
task5	"<line6>          LOG.info(""IndexFileManager.getFirstWriteInProgressRecord(source={}): current file={}"",this.source,record.getPath());"	<line11>	"LOG.debug(""getFirstWriteInProgressRecord: returning {}"", ret)"	"<line11> LOG.debug(""getFirstWriteInProgressRecord: returning {}"", ret)"
task5	<line22>    log.debug(stacktrace.toString());	<line21>	log.debug(stacktrace.toString())	<line21> log.debug(stacktrace.toString())
task5	"<line3>    logger.info(""Unregistering Service {}@{} and cleaning its running jobs"", serviceType, baseUrl);"	<line3>	"logger.info(""Unregistering service: {}"", serviceType)"	"<line3> logger.info(""Unregistering service: {}"", serviceType)"
task5	"<line1>    logger.info(""Producers connected - {}"", (Object) wires);"	<line1>	"logger.info(""Producers connected: {}"", wires.length)"	"<line1> logger.info(""Producers connected: {}"", wires.length)"
task5	"<line11>    log.info(b.toString() + ""]"");"	<line11>	logger.debug(b.toString())	<line11> logger.debug(b.toString())
task5	"<line2>    LOG.info(""Loading resource. RelativePath = {}."", relativePath);"	<line2>	"log.debug(""loadResource: "" + relativePath)"	"<line2> log.debug(""loadResource: "" + relativePath)"
task5	"<line1>    LOG.trace(""converting homeCommunityId ["" + homeCommunityId + ""] to assigning authority"");"	<line1>	"logger.debug(""lookupAssigningAuthorities for homeCommunityId: "" + homeCommunityId)"	"<line1> logger.debug(""lookupAssigningAuthorities for homeCommunityId: "" + homeCommunityId)"
task5	"<line44>        logger.error(""Exception while invoking onAsCreated"", ee);"	<line44>	"logger.error(""Exception while invoking onAsCreated"", ee)"	"<line44> logger.error(""Exception while invoking onAsCreated"", ee)"
task5	"<line2>    LOG.info(""delete specific not existing user"");"	<line2>	"LOGGER.info(""deleteNotExistingUserExpectError"")"	"<line2> LOGGER.info(""deleteNotExistingUserExpectError"")"
task5	"<line8>      LOG.error(""MessageResourcesFactory.createFactory"", t);"	<line8>	"log.error(""Error creating MessageResourcesFactory"", t)"	"<line8> log.error(""Error creating MessageResourcesFactory"", t)"
task5	"<line6>        LOG.warn(""Exception while closing channel for log file:"" + logId);"	<line6>	"LOG.warn(""Exception while closing channel for log file:"" + logId)"	"<line6> LOG.warn(""Exception while closing channel for log file:"" + logId)"
task5	"<line3>      log.info(""clear all metaData cache"");"	<line3>	"log.debug(""Clearing local cache and refreshing subscribers"")"	"<line3> log.debug(""Clearing local cache and refreshing subscribers"")"
task5	"<line24>      LOG.warn(""Unable to find a ParamConverterProvider for type Date"");"	<line24>	"LOG.warn(""Unable to find a ParamConverterProvider for type Date"")"	"<line24> LOG.warn(""Unable to find a ParamConverterProvider for type Date"")"
task5	"<line17>      LOGGER.debug(""Recorded DDL statements for database '{}': {}"",schemaChange.getDatabase(),schemaChange.getDdl());"	<line11>	"LOGGER.warn(""Unsupported schema change type: {}"", schemaChange.getType())"	"<line11> LOGGER.warn(""Unsupported schema change type: {}"", schemaChange.getType())"
task5	<line7>        log.debug(exception, exception);	<line7>	log.debug(exception, exception)	<line7> log.debug(exception, exception)
task5	"<line6>      logger.warn(""Could not create a short from the string "" + value);"	<line6>	"logger.warn(""Must be of type short!"", e)"	"<line6> logger.warn(""Must be of type short!"", e)"
task5	"<line23>    logger.info(""Saving {}"", user);"	<line22>	"LOG.info(""User {} not found in LDAP. Skip update."", userName)"	"<line22> LOG.info(""User {} not found in LDAP. Skip update."", userName)"
task5	"<line5>    LOGGER.info(""{} ssl reloaders registered"", reloaders.size());"	<line2>	"log.info(""The reload task has started"")"	"<line2> log.info(""The reload task has started"")"
task5	"<line2>    logger.trace(""getHomeDirectory"");"	<line2>	"logger.info(""getHomeDirectory()"")"	"<line2> logger.info(""getHomeDirectory()"")"
task5	"<line2>    this.logger.debug(""ConnectGPRSRequest"");"	<line2>	"this.logger.debug(""ConnectGPRSRequest"")"	"<line2> this.logger.debug(""ConnectGPRSRequest"")"
task5	"<line16>            log.info(""Message {}"", i);"	<line11>	"log.info(""Hello world"")"	"<line11> log.info(""Hello world"")"
task5	"<line2>    logger.error(""Exception thrown while initializing consumers."", throwable);"	<line2>	"LOGGER.error(""Error while executing task"", throwable)"	"<line2> LOGGER.error(""Error while executing task"", throwable)"
task5	"<line6>      LOG.debug(String.format(""File '%s' can't be converted to URL"", file), e);"	<line6>	"logger.error(""Could not convert file to URL: "" + file, e)"	"<line6> logger.error(""Could not convert file to URL: "" + file, e)"
task5	"<line6>    logger.info(""{} try to add Node {} To ReplicaSet {}"", user, nodeID, replicaSetID);"	<line6>	"logger.info(""addNodeToReplicaSet invoked by user {}"", user)"	"<line6> logger.info(""addNodeToReplicaSet invoked by user {}"", user)"
task5	"<line14>        LOGGER.warn(""Multiple identifiers found for Person: "" + pTO.getId());"	<line14>	"LOGGER.warn(""Cannot handle more than one identifier for a person"")"	"<line14> LOGGER.warn(""Cannot handle more than one identifier for a person"")"
task5	"<line6>        logger.warn(""Can not load lang detector models"", e);"	<line6>	"log.error(""Exception while loading language detector"", e)"	"<line6> log.error(""Exception while loading language detector"", e)"
task5	"<line6>    LOG.info(""### closed down the test case: "" + getName());"	<line2>	"LOG.info(""Stopping embedded server"")"	"<line2> LOG.info(""Stopping embedded server"")"
task5	"<line9>    LOG.debug(""Init output for table '{}' with schema: {}"", tableName, tableSchema);"	<line15>	"LOG.info(""Writing to temporary GCS path: {}"", temporaryGcsPath)"	"<line15> LOG.info(""Writing to temporary GCS path: {}"", temporaryGcsPath)"
task5	<line10>      log.error(bundleException, bundleException);	<line10>	log.error(bundleException, bundleException)	<line10> log.error(bundleException, bundleException)
task5	"<line23>      LOG.info(""Authorization Response url is: "" + driver.getCurrentUrl());"	<line26>	"logger.debug(""The authorization response is: {}"", authorizationResponseStr)"	"<line26> logger.debug(""The authorization response is: {}"", authorizationResponseStr)"
task5	"<line12>        LOG.error(""Unable to obtain AtlasAuthorizer"", e);"	<line12>	"LOG.warn(""Exception in filterTypesDef"", e)"	"<line12> LOG.warn(""Exception in filterTypesDef"", e)"
task5	"<line21>      log.error(""Failed ({}) to send channel open packet for {}: {}"",e.getClass().getSimpleName(),channel,e.getMessage());"	<line6>	"logger.debug(""Failed to open channel"", t)"	"<line6> logger.debug(""Failed to open channel"", t)"
task5	"<line29>      logger.error(""Error generating new version type - {}"", formTypeCode, t);"	<line29>	"logger.error(""Error generating new version type - {}"", formTypeCode, t)"	"<line29> logger.error(""Error generating new version type - {}"", formTypeCode, t)"
task5	"<line11>            LOGGER.debug(""copying database {} to {}"", db.toPath(), temp.toPath());"	<line2>	"LOGGER.debug(""Opening database (read only = {}, lock required = {})"", readOnly, lockRequired)"	"<line2> LOGGER.debug(""Opening database (read only = {}, lock required = {})"", readOnly, lockRequired)"
task5	"<line12>              LOG.debug(""Closing cache for feneric compiler "" + compiler.getId());"	<line12>	"LOG.debug(""Disposing generic compiler cache for "" + compiler)"	"<line12> LOG.debug(""Disposing generic compiler cache for "" + compiler)"
task5	"<line14>                LOGGER.info(""Job stats: {} pending, {} finished, {} cancelled"",state.size() - done - cancelled,done,cancelled);"	<line19>	"log.info(""Progress: {} done, {} cancelled"", done, cancelled)"	"<line19> log.info(""Progress: {} done, {} cancelled"", done, cancelled)"
task5	"<line2>    logger.debug(""[scheduledRecoverAlertReport] unRecoveredAlerts: {}"", unRecoveredAlerts);"	<line7>	"logger.info(""Recovering unrecovered alerts: {}"", unRecoveredAlerts)"	"<line7> logger.info(""Recovering unrecovered alerts: {}"", unRecoveredAlerts)"
task5	"<line3>      this.logger.debug(""Finalized classloader "" + toString());"	<line3>	"this.logger.debug(""finalized "" + this)"	"<line3> this.logger.debug(""finalized "" + this)"
task5	"<line6>      log.error(""Bad record "" + input, e);"	<line6>	"log.error(""Bad record "" + input, e)"	"<line6> log.error(""Bad record "" + input, e)"
task5	<line18>      log.error(systemException, systemException);	<line18>	log.error(systemException, systemException)	<line18> log.error(systemException, systemException)
task5	"<line12>                    log.error(""Print error."", ex);"	<line12>	"log.error(""Print error."", ex)"	"<line12> log.error(""Print error."", ex)"
task5	"<line17>      logger.debug(""results of getAllAuthorities1(): "" + res);"	<line17>	"logger.debug(""rolesNames: "" + res)"	"<line17> logger.debug(""rolesNames: "" + res)"
task5	"<line1>    LOGGER.debug(""Checking if field {} is queried by value comparison {}"", field, q);"	<line1>	"log.debug(""Checking whether field {} is queried by comparison expression {}"", field, q)"	"<line1> log.debug(""Checking whether field {} is queried by comparison expression {}"", field, q)"
task5	"<line9>        LOG.warn(""stop: InvalidPathException resolving syncPoint {}, exception {}"", syncPoint, e);"	<line9>	"LOG.error(""Failed to stop syncing for path: {}"", syncPoint.getPath())"	"<line9> LOG.error(""Failed to stop syncing for path: {}"", syncPoint.getPath())"
task5	"<line17>      log.debug(""Determined user DN prefix [{}] and suffix [{}]"", prefix, suffix);"	<line17>	"log.debug(""User DN template prefix: ["" + prefix + ""], suffix: ["" + suffix + ""]"")"	"<line17> log.debug(""User DN template prefix: ["" + prefix + ""], suffix: ["" + suffix + ""]"")"
task5	"<line15>      logger.error(""Cannot find delivery Tag in path:"" + deliveryTagPath + "" for this experiment"");"	<line15>	"log.error(""Delivery Tag does not exist for experimentID: "" + experimentID)"	"<line15> log.error(""Delivery Tag does not exist for experimentID: "" + experimentID)"
task5	"<line1>    logger.debug(""Cancel all jobs."");"	<line1>	"LOGGER.debug(""Canceling all jobs"")"	"<line1> LOGGER.debug(""Canceling all jobs"")"
task5	"<line3>    LOGGER.debug(""get agency identifier={}"");"	<line3>	"LOGGER.debug(""Get agency {}"", identifier)"	"<line3> LOGGER.debug(""Get agency {}"", identifier)"
task5	"<line27>            LOGGER.warn(""Unable to process drop file"", mue);"	<line27>	log.error(mue.getMessage(), mue)	<line27> log.error(mue.getMessage(), mue)
task5	"<line23>              logger.error(""Authz policy file VFS read error: "" + file.getFileName(), e);"	<line23>	"logger.error(""Failed to read authorization policy file: "" + file, e)"	"<line23> logger.error(""Failed to read authorization policy file: "" + file, e)"
task5	<line1>    LOG.info(content);	<line1>	LOGGER.info(content)	<line1> LOGGER.info(content)
task5	"<line1>    LOG.info(""update broker state from {} to {}"", BrokerState.codeOf(brokerState), newState);"	<line2>	"log.info(""Broker state updated to {}"", newState.getName())"	"<line2> log.info(""Broker state updated to {}"", newState.getName())"
task5	"<line22>      logger.warn(String.format(""%s"", LogUtil.getStackTrace(e)));"	<line22>	"logger.warn(String.format(""%s"", LogUtil.getStackTrace(e)))"	"<line22> logger.warn(String.format(""%s"", LogUtil.getStackTrace(e)))"
task5	"<line6>      LOGGER.error(""Error while delete documents"", e);"	<line4>	"LOG.debug(""Delete {} documents"", response.getDeletedCount())"	"<line4> LOG.debug(""Delete {} documents"", response.getDeletedCount())"
task5	"<line1>    LOG.trace(""[{}][{}] bratRenderLaterCommand"", getMarkupId(), vis.getMarkupId());"	<line1>	"LOG.debug(""bratRenderLaterCommand"")"	"<line1> LOG.debug(""bratRenderLaterCommand"")"
task5	"<line3>      LOG.error(""A valid path is needed for config setting {}"", ScmConfigKeys.OZONE_SCM_DATANODE_ID_DIR);"	<line14>	"LOG.warn(""File {} does not exist. Generating a random UUID for the local node."", idFile)"	"<line14> LOG.warn(""File {} does not exist. Generating a random UUID for the local node."", idFile)"
task5	"<line4>    logger.debug(""About to skip task with id '{}' as user '{}'"", taskId, userId);"	<line4>	"logger.debug(""About to skip task with id '{}' as user '{}'"", taskId, userId)"	"<line4> logger.debug(""About to skip task with id '{}' as user '{}'"", taskId, userId)"
task5	"<line31>          LOG.warn(""Error generating json binary type from object."", e);"	<line31>	"LOG.debug(""Encoding exception for "" + s, e)"	"<line31> LOG.debug(""Encoding exception for "" + s, e)"
task5	"<line12>    LOGGER.info(""progress:"" + percent);"	<line2>	"LOG.info(""progress "" + percent)"	"<line2> LOG.info(""progress "" + percent)"
task5	"<line11>      log.error(""Failed to list hooks."", e);"	<line11>	"LOG.error(""Error loading hooks from {}"", subdir, e)"	"<line11> LOG.error(""Error loading hooks from {}"", subdir, e)"
task5	<line7>      log.error(exception, exception);	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	"<line10>      LOG.debug(""Closing connection: {} with timeout: {} ms."", conn, closeTimeout);"	<line1>	"LOG.debug(""Closing connection and channel"")"	"<line1> LOG.debug(""Closing connection and channel"")"
task5	<line20>      log.error(systemException, systemException);	<line20>	log.error(systemException, systemException)	<line20> log.error(systemException, systemException)
task5	"<line13>      log.debug(""#createGroup - Failed to create the group {}. The exception occure"",groupNameValue.getKey(),e);"	<line13>	"log.debug(""error when creating group, unexpected type for group template"", e)"	"<line13> log.debug(""error when creating group, unexpected type for group template"", e)"
task5	"<line2>    log.info(""Checking input file(s) is/are present..."");"	<line2>	"log.info(""testing setup worked"")"	"<line2> log.info(""testing setup worked"")"
task5	"<line18>        LOGGER.info(""Nothing to do since operation has not been configured yet"");"	<line18>	"log.error(""Invalid operation: "" + operation)"	"<line18> log.error(""Invalid operation: "" + operation)"
task5	"<line20>        log.info(""Instrumentation"", ""deploy /resource/bin/"" + srcName + "" to "" + trg);"	<line24>	"log.info(""Unable to write "" + trg, e)"	"<line24> log.info(""Unable to write "" + trg, e)"
task5	"<line2>    LOGGER.debug(""ServerNameListLength: "" + msg.getServerNameListLength().getValue());"	<line2>	"LOGGER.debug(""ServerNameListLength: "" + msg.getServerNameListLength().getValue())"	"<line2> LOGGER.debug(""ServerNameListLength: "" + msg.getServerNameListLength().getValue())"
task5	<line14>      logger.warn(t);	<line14>	"logger.info(""error"", t)"	"<line14> logger.info(""error"", t)"
task5	<line5>        log.info(Hex.toHexString(actual.getContractCallResult().toByteArray()));	<line5>	"log.info(""Comparing actual local call result to expectations: {}"", actual)"	"<line5> log.info(""Comparing actual local call result to expectations: {}"", actual)"
task5	"<line4>    logger.debug(""channel {} updated with {} ({})"",channel.getUID().getAsString(),value,channel.getAcceptedItemType());"	<line3>	"logger.debug(""Updating item state for channel: {} with property: {} and value: {}"",channel.getUID(),propertyName,value)"	"<line3> logger.debug(""Updating item state for channel: {} with property: {} and value: {}"",channel.getUID(),propertyName,value)"
task5	"<line6>        log.info(""Creating a new SAML keystore at "" + samlKeyStoreFile);"	<line6>	"log.info(""Creating keystore file: "" + samlKeyStoreFile.getAbsolutePath())"	"<line6> log.info(""Creating keystore file: "" + samlKeyStoreFile.getAbsolutePath())"
task5	"<line2>    log.debug(""teamExists: "" + exists);"	<line2>	"log.debug(""teamExists: "" + teamId + "" -> "" + exists)"	"<line2> log.debug(""teamExists: "" + teamId + "" -> "" + exists)"
task5	"<line2>    LOG.trace(""enter CookieSpecBase.parse("" + ""String, port, path, boolean, String)"");"	<line2>	"LOG.trace(""enter CookieSpecBase.parse(String, int, String, boolean, Header)"")"	"<line2> LOG.trace(""enter CookieSpecBase.parse(String, int, String, boolean, Header)"")"
task5	"<line15>      logger.debug(""Can't write file {}: {}"", currentLocalListingFile, e.getMessage());"	<line32>	"logger.debug(""Scheduling folder watcher to run in {} seconds"", config.pollIntervalLocal)"	"<line32> logger.debug(""Scheduling folder watcher to run in {} seconds"", config.pollIntervalLocal)"
task5	"<line6>        LOGGER.debug(""checking: %s"", element.getId());"	<line6>	"LOGGER.info(""Visited %d elements"", i)"	"<line6> LOGGER.info(""Visited %d elements"", i)"
task5	"<line6>    LOG.debug(""Audit: {}/{} performed request {} ({}) at time {}"",who,fromAddress,whatURL,whatAddrs,whenISO9601);"	<line6>	"LOG.debug(""Audit: {who: "" + who + "", fromAddress: "" + fromAddress + "", fromHost: "" + fromHost + "", whatURL: "" + whatURL + "", whatAddrs: "" + whatAddrs + "", whenISO9601: "" + whenISO9601 + ""}"")"	"<line6> LOG.debug(""Audit: {who: "" + who + "", fromAddress: "" + fromAddress + "", fromHost: "" + fromHost + "", whatURL: "" + whatURL + "", whatAddrs: "" + whatAddrs + "", whenISO9601: "" + whenISO9601 + ""}"")"
task5	"<line3>    LOG.debug(""Calling OpenstackSwiftContainerResource.getMetadataShouldSucceed()"");"	<line3>	"LOG.debug(""Calling OpenStackKeystoneSession.getMetadataShouldSucceed()"")"	"<line3> LOG.debug(""Calling OpenStackKeystoneSession.getMetadataShouldSucceed()"")"
task5	"<line6>      logger.error(""Failed to deserialize device {} from buffer"", pathString);"	<line6>	"logger.error(""Path descriptor failed to deserialize: {}"", pathString, e)"	"<line6> logger.error(""Path descriptor failed to deserialize: {}"", pathString, e)"
task5	"<line6>      log.error(""Error in checking Mongo config availability"", e);"	<line6>	"LOGGER.error(""Error in checking MongoDB connection"", e)"	"<line6> LOGGER.error(""Error in checking MongoDB connection"", e)"
task5	<line5>    log.info(new String(writer.getBody()));	<line5>	log.info(new String(writer.getBody()))	<line5> log.info(new String(writer.getBody()))
task5	"<line5>    LOGGER.debug(""Registering {} component IDs."", componentIds.size());"	<line13>	"log.debug(""registered components: {}"", availableOrReservedSctIds.keySet())"	"<line13> log.debug(""registered components: {}"", availableOrReservedSctIds.keySet())"
task5	"<line11>          LOGGER.warn(""Match all mapping ignored: {} doesn't match expected format of""+ "" metacardAttribute=userAttribute"",mapping);"	<line11>	"LOG.info(""Ignoring invalid configuration value '{}'"", mapping)"	"<line11> LOG.info(""Ignoring invalid configuration value '{}'"", mapping)"
task5	"<line12>      logger.error(""Order by and group by on different field are not supported simultaneously"");"	<line16>	"log.debug(""Ordering by {}"", orderByItems.getExpression())"	"<line16> log.debug(""Ordering by {}"", orderByItems.getExpression())"
task5	"<line10>    LOG.info(""Copy job progress: {}/{}"", progress.getProgress(), progress.getProgressMax());"	<line10>	"LOG.info(""copying entity types finished"")"	"<line10> LOG.info(""copying entity types finished"")"
task5	"<line12>                    logger.warn(""Exception at destroyFavorite"", e);"	<line12>	"logger.warn(""Exception at destroyFavorite"", e)"	"<line12> logger.warn(""Exception at destroyFavorite"", e)"
task5	"<line5>              LOG.info(""Exiting process now."");"	<line5>	"LOG.error(""Uncaught exception in Samza app"", new Throwable())"	"<line5> LOG.error(""Uncaught exception in Samza app"", new Throwable())"
task5	"<line1>    LOG.warn(""Lost a agent {}"", agentId);"	<line1>	"LOG.info(""Agent {} lost"", agentId)"	"<line1> LOG.info(""Agent {} lost"", agentId)"
task5	"<line5>    logger.debug(""Registering Channel Listener for monitoring..."");"	<line13>	"logger.warn(""Channel listener already registered for channel {}"", channelName)"	"<line13> logger.warn(""Channel listener already registered for channel {}"", channelName)"
task5	"<line3>      LOGGER.info(""process() event:{}"", watchedEvent);"	<line2>	"LOG.info(""Watcher: {}"", watchedEvent)"	"<line2> LOG.info(""Watcher: {}"", watchedEvent)"
task5	<line18>      LOG.warn(e.getLocalizedMessage());	<line1>	"LOG.debug(""Getting user by SSO token {}"", token)"	"<line1> LOG.debug(""Getting user by SSO token {}"", token)"
task5	"<line3>    LOGGER.debug(""get logbook for profile with id :{}"", id);"	<line3>	"LOGGER.debug(""get logbook history by profile id :{}"", id)"	"<line3> LOGGER.debug(""get logbook history by profile id :{}"", id)"
task5	"<line35>      logger.debug(""register command consumer [tenant-id: {}, device-id: {}, adapter-instance-id {},""+ "" lifespan: {}s]"",tenantId,deviceId,adapterInstanceId,lifespan.getSeconds());"	<line27>	"LOG.debug(""registering command consumer for tenant [{}], device [{}]"", tenantId, deviceId)"	"<line27> LOG.debug(""registering command consumer for tenant [{}], device [{}]"", tenantId, deviceId)"
task5	"<line16>    LOGGER.debug(type.getSimpleName() + ""-queryNames took "" + (System.currentTimeMillis() - start) + ""ms"");"	<line16>	"LOGGER.debug(""queryNames {} took {} ms"", type, System.currentTimeMillis() - start)"	"<line16> LOGGER.debug(""queryNames {} took {} ms"", type, System.currentTimeMillis() - start)"
task5	"<line30>    logger.debug(LoggingMarkers.PERFORMANCE,""Saving {} indexer search entities took {}ms"",countEntities,stopwatch.elapsed(TimeUnit.MILLISECONDS));"	<line30>	"logger.debug(""Create or update {} IndexerSearchEntities took {}"", countEntities, stopwatch.toString())"	"<line30> logger.debug(""Create or update {} IndexerSearchEntities took {}"", countEntities, stopwatch.toString())"
task5	<line33>        logger.error(message, e);	<line33>	logger.error(message, e)	<line33> logger.error(message, e)
task5	"<line28>        LOG.error(""Inconsistent ""+ fileElement.getElementType()+ "" tree in ""+ this+ ""; nodeLength=""+ nodeLength+ ""; fileLength=""+ fileLength,attachments.toArray(Attachment.EMPTY_ARRAY));"	<line28>	"LOG.error(""Length inconsistency found: ""+ nodeLength+ "" != ""+ fileLength+ "" for ""+ fileElement+ "". ""+ ""The PSI is inconsistent with the document: ""+ myContent.toString(),new PsiLengthInconsistencyAccessException(attachments))"	"<line28> LOG.error(""Length inconsistency found: ""+ nodeLength+ "" != ""+ fileLength+ "" for ""+ fileElement+ "". ""+ ""The PSI is inconsistent with the document: ""+ myContent.toString(),new PsiLengthInconsistencyAccessException(attachments))"
task5	"<line5>      LOG.warn(""Unable to determine local hostname "" + ""-falling back to \"""" + LOCALHOST + ""\"""", e);"	<line6>	"log.warn(""Unable to resolve localhostname. Defaulting to '{}'"", LOCALHOST)"	"<line6> log.warn(""Unable to resolve localhostname. Defaulting to '{}'"", LOCALHOST)"
task5	"<line2>    LOGGER.debug(""Setting cipher for client to use "" + keySetType);"	<line1>	"LOGGER.debug(""Set Client KeySet: "" + keySetType)"	"<line1> LOGGER.debug(""Set Client KeySet: "" + keySetType)"
task5	"<line2>    LOGGER.debug(""SessionIdHit: "" + message.getSessionIdHit().getValue());"	<line2>	"LOGGER.debug(""SessionIdHit: "" + message.getSessionIdHit().getValue())"	"<line2> LOGGER.debug(""SessionIdHit: "" + message.getSessionIdHit().getValue())"
task5	"<line10>      log.warn(""Unable to send notification using template "" + templateId + "" to entity "" + entityId, e);"	<line10>	"log.error(""Error sending notification for entity {} with template {}"", entityId, templateId, e)"	"<line10> log.error(""Error sending notification for entity {} with template {}"", entityId, templateId, e)"
task5	"<line8>      logger.error(""Error in searchIdeas"", t);"	<line8>	"logger.error(""Error in searchIdeas"", t)"	"<line8> logger.error(""Error in searchIdeas"", t)"
task5	"<line13>      LOG.warn(String.format(""Failed to resolve endpoint builder from resource '%s/%s'"", RESOURCE_PATH, builder));"	<line13>	"LOG.warn(""Failed to lookup endpoint builder instance"", e)"	"<line13> LOG.warn(""Failed to lookup endpoint builder instance"", e)"
task5	"<line15>        LOG.info(""download file:{} to local:{}"", filePathOnSftp, fileLocalPath);"	<line18>	"logger.error(""load file from sftp error"", e)"	"<line18> logger.error(""load file from sftp error"", e)"
task5	<line18>                log.error(portalException, portalException);	<line18>	log.error(portalException, portalException)	<line18> log.error(portalException, portalException)
task5	"<line4>      LOG.trace(""Checked if full and remaining capacity is {}"", remaining);"	<line4>	"LOG.debug(""Remaining capacity: {}"", remaining)"	"<line4> LOG.debug(""Remaining capacity: {}"", remaining)"
task5	"<line2>    log.info(""runTests{}"");"	<line9>	"log.info(""running testType: {}"", testType)"	"<line9> log.info(""running testType: {}"", testType)"
task5	"<line6>        Log.debug(""JDBCAuthProvider: Automatically creating new user account for "" + username);"	<line8>	"log.warn(""User already exists!"", uaee)"	"<line8> log.warn(""User already exists!"", uaee)"
task5	"<line16>    LOG.info(""Scanner running with "" + connectionPoolForThreads.size() + "" kudu connections"");"	<line13>	"LOG.info(""All partitions to scan {}"", allPartitionsThatNeedScan)"	"<line13> LOG.info(""All partitions to scan {}"", allPartitionsThatNeedScan)"
task5	<line13>      LOGGER.error(e.getMessage());	<line13>	"LOGGER.error(""Error while creating voucher from pre approved voucher"", e)"	"<line13> LOGGER.error(""Error while creating voucher from pre approved voucher"", e)"
task5	"<line7>      log.info(""Restart node [node="" + nodeIdx + "", client="" + clientMode + ']');"	<line4>	"log.info(""Started node: "" + nodeIdx)"	"<line4> log.info(""Started node: "" + nodeIdx)"
task5	"<line4>      LOG.debug(""Opened database from '{}'."", runtimeDirectory);"	<line3>	"LOG.info(""Opening ZeebeDb in: {}"", runtimeDirectory)"	"<line3> LOG.info(""Opening ZeebeDb in: {}"", runtimeDirectory)"
task5	"<line13>        LOG.info(""wrong csrf"");"	<line13>	"log.debug(""CSRF check failed: {}"", res.right.right)"	"<line13> log.debug(""CSRF check failed: {}"", res.right.right)"
task5	"<line15>      LOG.error(""Fatal error while running command line interface."", strippedThrowable);"	<line13>	"LOG.error(""Error while parsing command line arguments: "" + Arrays.toString(args), t)"	"<line13> LOG.error(""Error while parsing command line arguments: "" + Arrays.toString(args), t)"
task5	"<line12>      LOG.warn(""Unable to read property: {})"", propertyName, ex);"	<line12>	"LOG.error(""Error: Failed to retrieve {} from property file {}: {}"",propertyName,NhincConstants.GATEWAY_PROPERTY_FILE,ex.getLocalizedMessage(),ex)"	"<line12> LOG.error(""Error: Failed to retrieve {} from property file {}: {}"",propertyName,NhincConstants.GATEWAY_PROPERTY_FILE,ex.getLocalizedMessage(),ex)"
task5	"<line16>      LOG.debug(""Transform value to ODocument (UNION), type:{}, storeType:{}"",new Object[] {innerSchema.getType(), type1, storeType});"	<line18>	"LOG.debug(""Union field converted to {}."", result)"	"<line18> LOG.debug(""Union field converted to {}."", result)"
task5	"<line18>      LOG.error(""Error finding objects"", th);"	<line18>	"LOG.error(""Error finding objects"", th)"	"<line18> LOG.error(""Error finding objects"", th)"
task5	"<line11>        logger.error(""Failed to perform tasks when enumerator was finished"", e);"	<line11>	"logger.error(""Error when finishing retrieving metrics"", e)"	"<line11> logger.error(""Error when finishing retrieving metrics"", e)"
task5	"<line5>      LOG.debug(""{}: No encoding parameter using default charset: {}"", type, encoding);"	<line6>	"logger.info(""{} using encoding: {}"", type, encoding)"	"<line6> logger.info(""{} using encoding: {}"", type, encoding)"
task5	"<line6>      logger.info(""Member {} is {}equivalent or in the same redundancy zone."", member, relationship);"	<line6>	"logger.info(""Redundancy zone relationship between the two members is: {}"", relationship)"	"<line6> logger.info(""Redundancy zone relationship between the two members is: {}"", relationship)"
task5	"<line21>      LOG.info(""Unexpected error during container creation"", e);"	<line21>	"LOG.info(""Disk is full. Exception during create container."", e)"	"<line21> LOG.info(""Disk is full. Exception during create container."", e)"
task5	"<line3>    LOG.debug(""Retrieving communication channels for user id "" + userId);"	<line3>	"LOG.debug(""listing communication channels for the user"")"	"<line3> LOG.debug(""listing communication channels for the user"")"
task5	<line49>      log.debug(newConfig);	<line49>	logger.info(newConfig.toString())	<line49> logger.info(newConfig.toString())
task5	<line3>    LOGGER.info(MessageFormat.format(Messages.PURGE_DELETE_REQUEST_SPACE_FROM_CONFIGURATION_TABLES, result));	<line3>	"LOGGER.debug(""dateBeforeTwoDays: "" + result)"	"<line3> LOGGER.debug(""dateBeforeTwoDays: "" + result)"
task5	"<line2>    logger.warn(""Skipping URL: {}, StatusCode: {}, {}, {}"", urlStr, statusCode, contentType, description);"	<line2>	"LOG.warn(""Got unexpected status code from {}: {}"", urlStr, statusCode)"	"<line2> LOG.warn(""Got unexpected status code from {}: {}"", urlStr, statusCode)"
task5	"<line2>    LOG.info(""{}"", params);"	<line4>	"log.info(""Added key {} for user {}"", keyPairName, username)"	"<line4> log.info(""Added key {} for user {}"", keyPairName, username)"
task5	"<line7>        LOG.warn(""update clock to master failed. task=""+ request.getTaskIndex()+ "", matrix=""+ request.getMatrixId()+ "", clock=""+ request.getClock());"	<line7>	"LOG.warn(""update clock failed "", e)"	"<line7> LOG.warn(""update clock failed "", e)"
task5	"<line29>          logger.debug(""ActivityObject not valid"");"	<line29>	"log.warn(""Could not determine object type"", ex)"	"<line29> log.warn(""Could not determine object type"", ex)"
task5	<line29>            logger.error(e1, e1);	<line29>	logger.error(e1, e1)	<line29> logger.error(e1, e1)
task5	<line6>        log.debug(exception, exception);	<line6>	log.debug(exception, exception)	<line6> log.debug(exception, exception)
task5	"<line3>      LOG.debug(""Skip migration because migration source folder is not specified or otherwise invalid."");"	<line3>	"log.info(""No migration folder file found"")"	"<line3> log.info(""No migration folder file found"")"
task5	"<line26>      logger.error(""Exception occurred in SDNCActivateTasks activateVfModule process"", ex);"	<line1>	"logger.debug(""Activate VfModule"")"	"<line1> logger.debug(""Activate VfModule"")"
task5	<line16>        log.debug(layoutFriendlyURLException, layoutFriendlyURLException);	<line16>	log.debug(layoutFriendlyURLException, layoutFriendlyURLException)	<line16> log.debug(layoutFriendlyURLException, layoutFriendlyURLException)
task5	"<line3>      logger.warn(""no mapping for '"" + name + ""'"");"	<line1>	"if (debug) Log.debug(""writing element '"" + name + ""'"")"	"<line1> if (debug) Log.debug(""writing element '"" + name + ""'"")"
task5	"<line2>    logger.info(""No metadata connection"");"	<line2>	"logger.info(""No metadata connection"")"	"<line2> logger.info(""No metadata connection"")"
task5	"<line2>    log.debug(""Attempting to locate resource '{}' using classloader the servlet context"", path);"	<line14>	"log.debug(""using URL: {}"", url)"	"<line14> log.debug(""using URL: {}"", url)"
task5	<line7>      log.error(e.getMessage(), e);	<line7>	"log.error(""Error while adding life cycle"", e)"	"<line7> log.error(""Error while adding life cycle"", e)"
task5	"<line3>        logger.debug(""sendCommand getSerialNumber :: {}"", TelitModemAtCommands.getSerialNumber.getCommand());"	<line2>	"logger.debug(""sendCommand getSerialNumber :: {}"",TelitModemAtCommands.getSerialNumber.getCommand())"	"<line2> logger.debug(""sendCommand getSerialNumber :: {}"",TelitModemAtCommands.getSerialNumber.getCommand())"
task5	"<line21>          LOG.warn(""Unsupported qop detected: "" + variant);"	<line28>	"LOG.debug(""cnonce = "" + cnonce)"	"<line28> LOG.debug(""cnonce = "" + cnonce)"
task5	"<line7>      LOG.warn(""[onStart] Erreur de connexion au serveur {} ({})"",remoteWebResource.getUri(),c.getMessage());"	<line7>	"LOGGER.error(""Cannot put start event for work {}"", workId, c)"	"<line7> LOGGER.error(""Cannot put start event for work {}"", workId, c)"
task5	"<line14>        LOG.debug(""Initialized component "" + _component);"	<line2>	"LOG.info(""Starting component "" + _moduleId)"	"<line2> LOG.info(""Starting component "" + _moduleId)"
task5	"<line6>      log.trace(""Cannot find any classes in bundles, not trying regular classloaders scanning: {}"",packageName);"	<line5>	"log.debug(""found {} implementations in bundle {}"", classes.size(), packageName)"	"<line5> log.debug(""found {} implementations in bundle {}"", classes.size(), packageName)"
task5	<line14>      log.error(exception, exception);	<line14>	log.error(exception, exception)	<line14> log.error(exception, exception)
task5	<line22>      log.error(e);	<line22>	"log.error(""Error while saving content definition {}"", e)"	"<line22> log.error(""Error while saving content definition {}"", e)"
task5	"<line2>    log.debug(""Producing event for custom resource id: {}"", customResourceUid);"	<line2>	"LOGGER.debug(""Timer task for {} executed"", customResourceUid)"	"<line2> LOGGER.debug(""Timer task for {} executed"", customResourceUid)"
task5	"<line27>              LOG.error(""Failed to write file."", throwable);"	<line27>	"LOG.error(""Failed to write file."", throwable)"	"<line27> LOG.error(""Failed to write file."", throwable)"
task5	"<line7>      logger.info(""Creating project "" + projectName);"	<line15>	"log.info(""Creating project {}"", projectName)"	"<line15> log.info(""Creating project {}"", projectName)"
task5	"<line15>        logger.error(""Null content mapping by existed channel for content type {}"",currentContent.getTypeCode());"	<line15>	"logger.error(""Null content mapping found for content type {}"", currentContent.getTypeCode())"	"<line15> logger.error(""Null content mapping found for content type {}"", currentContent.getTypeCode())"
task5	"<line4>    log.info(""UserHostAndPort serialized as: "" + result);"	<line9>	"log.info(""Result: "" + result)"	"<line9> log.info(""Result: "" + result)"
task5	"<line23>        log.trace(""receive({}) check iteration #{} for id={} remain time={}"",this,count,id,idleTimeout);"	<line23>	"log.trace(""receive({})[{}]: {}"", this, count, buffer)"	"<line23> log.trace(""receive({})[{}]: {}"", this, count, buffer)"
task5	"<line7>      LOGGER.warn(""Job({},{}) does not exist."", jobKey.getGroup(), jobKey.getName());"	<line10>	"LOGGER.info(""Paused job - name: {}, group: {}"", name, group)"	"<line10> LOGGER.info(""Paused job - name: {}, group: {}"", name, group)"
task5	"<line3>      log.debug(""Generating CA with subject={}"", subject);"	<line43>	"log.error(""Error while generating CA key and certificate."", e)"	"<line43> log.error(""Error while generating CA key and certificate."", e)"
task5	<line6>        logger.error(e.getMessage(), e);	<line6>	LOG.error(e.getMessage(), e)	<line6> LOG.error(e.getMessage(), e)
task5	"<line9>      log.error(""main threw"", e);"	<line9>	"log.error(""main threw"", e)"	"<line9> log.error(""main threw"", e)"
task5	"<line2>    LOG.debug(""setWorkingDirectory({})"", path);"	<line7>	"LOG.info(""Set working directory "" + mWorkingDir)"	"<line7> LOG.info(""Set working directory "" + mWorkingDir)"
task5	"<line6>    log.info(""multimap serialized as: "" + result);"	<line6>	log.info(result)	<line6> log.info(result)
task5	"<line8>    LOG.info(""Logged into hdfs with principal {}"", configuration.get(STORM_USER_NAME_KEY));"	<line7>	"LOG.info(""Logging in as principal: {}"", configuration.get(STORM_USER_NAME_KEY))"	"<line7> LOG.info(""Logging in as principal: {}"", configuration.get(STORM_USER_NAME_KEY))"
task5	"<line5>      LOGGER.warn(""Could not close plugin classloader"", e);"	<line5>	"LOGGER.error(""Error closing loader"", e)"	"<line5> LOGGER.error(""Error closing loader"", e)"
task5	"<line1>    logger.debug(""getManagedConnectionFactory()..."");"	<line1>	"logger.debug(""getManagedConnectionFactory()"")"	"<line1> logger.debug(""getManagedConnectionFactory()"")"
task5	"<line4>      log.trace(""Changing device status. DeviceId {}, dashId {}"", device.id, dashBoard.id);"	<line4>	"log.debug(""Device [{}] is not connected to the dash board [{}]."", device.name, dashBoard.id)"	"<line4> log.debug(""Device [{}] is not connected to the dash board [{}]."", device.name, dashBoard.id)"
task5	"<line7>      LOG.error(""Failed to get response, Error is : "" + e.getMessage());"	<line7>	"LOG.error(""Failed to get response, Error is : "" + e.getMessage())"	"<line7> LOG.error(""Failed to get response, Error is : "" + e.getMessage())"
task5	"<line24>      LOG.error(""Update of user {} failed, trying to pull its status anyway (if configured)"",userUR.getKey(),ex);"	<line24>	"LOG.debug(""Error while updating user"", ex)"	"<line24> LOG.debug(""Error while updating user"", ex)"
task5	"<line15>    logger.info(""[doInsertInstances]{}"", toAdd);"	<line15>	"logger.info(""[doInsertInstances]{}, {}, {}, {}, {}"",dcClusterShardTbl.getDcClusterShardId(),role,toAdd.toArray(new Pair[0]))"	"<line15> logger.info(""[doInsertInstances]{}, {}, {}, {}, {}"",dcClusterShardTbl.getDcClusterShardId(),role,toAdd.toArray(new Pair[0]))"
task5	"<line14>      logger.warn(""{} encountered Exception when trying to set bypass period: {}"",HeliosEasyControlsHandler.class.getSimpleName(),e.getMessage());"	<line14>	"logger.error(""Failed to set bypass date"", e)"	"<line14> logger.error(""Failed to set bypass date"", e)"
task5	"<line7>    LOG.info(mMsg + mWorkerId + "" just finished."");"	<line3>	"logger.info(""running io"")"	"<line3> logger.info(""running io"")"
task5	"<line6>      LOG.info(""Dropping datagram with command: "" + commandId);"	<line5>	"logger.debug(""Drop strategy decided to drop command {} written to {}"", commandId, address)"	"<line5> logger.debug(""Drop strategy decided to drop command {} written to {}"", commandId, address)"
task5	"<line2>    LOG.debug(""undoSoftDeleteOnCascade: {id: {}}"", id);"	<line2>	"LOG.debug(""undoSoftDeleteOnCascade: {id: {}}"", id)"	"<line2> LOG.debug(""undoSoftDeleteOnCascade: {id: {}}"", id)"
task5	"<line7>      log.debug(sb.a("", after="" + toString() + ']').toString());"	<line7>	"if (LOG.isDebugEnabled()) LOG.debug(sb.a("", after="" + toString() + ']').toString())"	"<line7> if (LOG.isDebugEnabled()) LOG.debug(sb.a("", after="" + toString() + ']').toString())"
task5	"<line2>    LOG.info(""Running testUpdateParagraphConfig"");"	<line12>	"LOGGER.info(""testUpdateParagraphConfig: {}"", put)"	"<line12> LOGGER.info(""testUpdateParagraphConfig: {}"", put)"
task5	"<line1>    logger.debug(""Cleaning up temporary certificate file"");"	<line1>	"log.info(""Cleaning up temporary file "" + temporaryFile)"	"<line1> log.info(""Cleaning up temporary file "" + temporaryFile)"
task5	"<line8>      log.debug(""Init existing SHARD using db version'{}' in {} ms"",dbVersion,System.currentTimeMillis() - start);"	<line5>	"log.info(""ShardTransactionManager.createOrUpdateShard: ""+ shardId+ "" dbVersion: ""+ dbVersion.getVersionId()+ "" timeout: ""+ getTimeout()+ ""ms"")"	"<line5> log.info(""ShardTransactionManager.createOrUpdateShard: ""+ shardId+ "" dbVersion: ""+ dbVersion.getVersionId()+ "" timeout: ""+ getTimeout()+ ""ms"")"
task5	"<line31>      logger.info(""Index: {}, {}..."", index, Format.formatSize(index * 1024));"	<line23>	"logger.info(""repeat: {}, index: {}"", repeat, index)"	"<line23> logger.info(""repeat: {}, index: {}"", repeat, index)"
task5	"<line3>    LOG.info(""assign is a no-op"");"	<line3>	"LOG.info(""ignoring assign() call"")"	"<line3> LOG.info(""ignoring assign() call"")"
task5	<line11>      logger.debug(e.getMessage(), e);	<line11>	"LOG.debug(""UserConfig already exists"", e)"	"<line11> LOG.debug(""UserConfig already exists"", e)"
task5	"<line4>    LOGGER.trace(""openModule - set active module to "" + module);"	<line1>	"log.info(""Opening module {}"", module)"	"<line1> log.info(""Opening module {}"", module)"
task5	"<line6>    log.error(""Conditional '{}' has already been added to Logix '{}'"", systemName, getSystemName());"	<line6>	"log.error(""Additional conditional added with same name as existing conditional: {}"", systemName)"	"<line6> log.error(""Additional conditional added with same name as existing conditional: {}"", systemName)"
task5	"<line2>    log.trace(""WbListener::Add"");"	<line2>	"log.debug(""Adding whiteboard {} to onlineWbs"", event.getKey())"	"<line2> log.debug(""Adding whiteboard {} to onlineWbs"", event.getKey())"
task5	"<line6>      Logger.error(this, ""Failed to find farm repo: %[exception]s"", err);"	<line6>	"Logger.error(this, ""error: %s"", err.getMessage())"	"<line6> Logger.error(this, ""error: %s"", err.getMessage())"
task5	"<line2>      LOGGER.trace(""columnData from current stack: {}"", Arrays.toString(columnData));"	<line2>	"LOGGER.trace(""Creating key from column data: {}"", Arrays.toString(columnData))"	"<line2> LOGGER.trace(""Creating key from column data: {}"", Arrays.toString(columnData))"
task5	"<line2>    LOGGER.debug(""testFindUsersByBadHeaderValueThenReturnBadRequest"");"	<line2>	"logger.debug(""Testing find users by bad header value"")"	"<line2> logger.debug(""Testing find users by bad header value"")"
task5	"<line7>                  LOGGER.info(""succeed to close ""+ RegistrationManager.INSTANCE.getMicroservice().getServiceName());"	<line7>	"LOGGER.info(""ITestShutdownHook: stop, destroying SCBEngine"")"	"<line7> LOGGER.info(""ITestShutdownHook: stop, destroying SCBEngine"")"
task5	"<line18>      LOGGER.warn(""Exception happened after test case."", e);"	<line18>	"LOG.error(""ERROR: after() failed"", e)"	"<line18> LOG.error(""ERROR: after() failed"", e)"
task5	"<line1>    log.info(""Runtime exec {}"", Arrays.toString(cmd));"	<line2>	"log.info(""exec: "" + p)"	"<line2> log.info(""exec: "" + p)"
task5	"<line7>        LOGGER.info(""Failed to remove filterless subscription registered for id {} for csw source with id""+ "" of {}"",filterlessSubscriptionId,this.getId());"	<line7>	"log.info(""Failed to delete event subscription"", e)"	"<line7> log.info(""Failed to delete event subscription"", e)"
task5	"<line63>      logger.error(""error in searchIdeaInstances"", t);"	<line63>	"logger.error(""error in searchIdeaInstances"", t)"	"<line63> logger.error(""error in searchIdeaInstances"", t)"
task5	<line9>    logger.debug(result);	<line9>	logger.debug(result)	<line9> logger.debug(result)
task5	"<line6>    log.info(serviceCheckName + tagString + "" - "" + System.currentTimeMillis() / 1000 + "" = "" + status);"	<line6>	"log.info(""Sending service check: "" + serviceCheckName + "" - "" + status + "" : "" + message + "" - "" + tagString)"	"<line6> log.info(""Sending service check: "" + serviceCheckName + "" - "" + status + "" : "" + message + "" - "" + tagString)"
task5	<line19>      log.error(systemException, systemException);	<line19>	log.error(systemException, systemException)	<line19> log.error(systemException, systemException)
task5	"<line2>    logger.info(""Resetting local state of the client, because of a cluster change."");"	<line2>	"logger.info(""Clearing local state of the client, because of a cluster change."")"	"<line2> logger.info(""Clearing local state of the client, because of a cluster change."")"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line1>    LOGGER.trace(""Setting attribute mappings to: {}"", attributeMappingsList);"	<line9>	"log.info(""Adding attribute mapping: {}"", map.toString())"	"<line9> log.info(""Adding attribute mapping: {}"", map.toString())"
task5	"<line3>      LOG.error(""Error processing auth message, closing connection"");"	<line3>	"LOG.error(""Failed to get auth token"", BKException.create(rc))"	"<line3> LOG.error(""Failed to get auth token"", BKException.create(rc))"
task5	"<line29>      log.error(exception, ""Exception in unzip retry loop"");"	<line29>	"LOG.error(""Error while pushing zip file {} to {}"", zip, outDir, exception)"	"<line29> LOG.error(""Error while pushing zip file {} to {}"", zip, outDir, exception)"
task5	"<line14>      log.error(""Error calling Roller.release()"", e);"	<line14>	"log.error(""Error releasing managers"", e)"	"<line14> log.error(""Error releasing managers"", e)"
task5	"<line7>        LOG.info(""inactive durable subs on "" + broker + "" : "" + Arrays.asList(subs));"	<line8>	"LOG.info(""Expected durable topic subscriber count: "" + expectedCount + "" vs "" + subs.length)"	"<line8> LOG.info(""Expected durable topic subscriber count: "" + expectedCount + "" vs "" + subs.length)"
task5	"<line4>    logger.debug(""Invalid Search Param Exception: "", ex);"	<line4>	"logger.error(""Invalid search param error"", ex)"	"<line4> logger.error(""Invalid search param error"", ex)"
task5	"<line4>    logger.info(""[doMigrationPublish]Cluster:{}, Shard:{}, NewPrimaryDc:{}, NewMaster:{}"",clusterName,shardName,primaryDcName,newMaster);"	<line9>	"logger.info(""{} : {}"", startTime, endTime)"	"<line9> logger.info(""{} : {}"", startTime, endTime)"
task5	"<line4>      log.warn(""Failed to serialize exception "", e);"	<line4>	"log.error(""Error creating json string for message: "" + getMessage(), e)"	"<line4> log.error(""Error creating json string for message: "" + getMessage(), e)"
task5	"<line2>    LOGGER.debug(""SerializedPSKIdentityLength: "" + msg.getIdentityHintLength().getValue());"	<line2>	"LOGGER.debug(""SerializedPSKIdentityHintLength: "" + msg.getIdentityHintLength())"	"<line2> LOGGER.debug(""SerializedPSKIdentityHintLength: "" + msg.getIdentityHintLength())"
task5	"<line4>      LOGGER.warn(""Error occured while getting session"", e);"	<line4>	"logger.info(""Could not parse JSON from API: "" + e.getMessage())"	"<line4> logger.info(""Could not parse JSON from API: "" + e.getMessage())"
task5	"<line3>    LOGGER.debug(""get logbook for users with id :{}"", id);"	<line3>	"LOGGER.debug(""get logbook history by id :{}"", id)"	"<line3> LOGGER.debug(""get logbook history by id :{}"", id)"
task5	"<line3>    log.debug(""Processing REST method return value \"""" + returnType.getName() + ""\""."");"	<line3>	"LOGGER.debug(""Processing method return value of type {}"", returnType)"	"<line3> LOGGER.debug(""Processing method return value of type {}"", returnType)"
task5	"<line4>      LOGGER.warn(""Could not perform reverse DNS for \"""" + ip + ""\"""", ex);"	<line4>	"log.warn(""Could not resolve IP {} into hostname"", ip, ex)"	"<line4> log.warn(""Could not resolve IP {} into hostname"", ip, ex)"
task5	<line8>      log.error(msg, e);	<line8>	log.error(msg, e)	<line8> log.error(msg, e)
task5	"<line4>      LOGGER.warn(name + "" (reserved word) cannot be used as parameter name. Renamed to "" + name + ""_"");"	<line4>	"LOG.warn(name+ "" (reserved word) cannot be used in naming. Renamed to ""+ name+ ""_."")"	"<line4> LOG.warn(name+ "" (reserved word) cannot be used in naming. Renamed to ""+ name+ ""_."")"
task5	"<line6>      LOGGER.debug(""Desc2 "" + urlBase + e.select(""a"").first().attr(""href""));"	<line2>	"logger.debug(""Getting descriptions from page"")"	"<line2> logger.debug(""Getting descriptions from page"")"
task5	"<line6>      log.info(String.format(""RP Placement: Storage pool %s does not have connectivity to a protection system."",storagePool.getLabel()));"	<line6>	"log.info(""No protection systems found for storage pool {}"", storagePool.getId())"	"<line6> log.info(""No protection systems found for storage pool {}"", storagePool.getId())"
task5	"<line23>          LOG.debug(""Detected source to target format match for video"");"	<line23>	"LOG.debug(""Forcing transcoding to "" + transcoding.getTargetFormat())"	"<line23> LOG.debug(""Forcing transcoding to "" + transcoding.getTargetFormat())"
task5	"<line3>      LOG.info(""verinice runs in designer mode - retrieving server configuration from ODA driver."");"	<line3>	"LOG.info(""updating server URI to {}"", uri)"	"<line3> LOG.info(""updating server URI to {}"", uri)"
task5	"<line6>      LOGGER.trace(format(""Select async with execution info : %s"",statementWrapper.getBoundStatement().preparedStatement().getQueryString()));"	<line6>	"LOGGER.trace(String.format(""Get list of JSON strings with stats for query %s"", statementWrapper.preparedStatement().getQueryString()))"	"<line6> LOGGER.trace(String.format(""Get list of JSON strings with stats for query %s"", statementWrapper.preparedStatement().getQueryString()))"
task5	"<line11>    LOG.debug(""query: "" + result);"	<line10>	"LOG.debug(""query: "" + result)"	"<line10> LOG.debug(""query: "" + result)"
task5	"<line3>    logger.debug(""Processing affinity group "" + group.getName() + "" for VM Id: "" + vm.getId());"	<line7>	"logger.debug(""Affinity group preferred hosts: "" + preferredHosts)"	"<line7> logger.debug(""Affinity group preferred hosts: "" + preferredHosts)"
task5	"<line8>      logger.warn(String.format(""unable to add baremetal RCT[%s]"", getRctUrl()), e);"	<line8>	"logger.warn(""Exception: "", e)"	"<line8> logger.warn(""Exception: "", e)"
task5	"<line5>      LOGGER.error(""error trying to sleep waiting for external view to change : "", e);"	<line5>	"LOG.error(""Error in stopping Helix Manager"", e)"	"<line5> LOG.error(""Error in stopping Helix Manager"", e)"
task5	"<line10>      LOG.error(""Not all the new directories are empty. New directories that are not empty are: ""+ nonEmptyDirs);"	<line10>	"LOG.error(""Found non empty directories: "" + nonEmptyDirs)"	"<line10> LOG.error(""Found non empty directories: "" + nonEmptyDirs)"
task5	<line30>      log.warn(errMsg, e);	<line30>	log.warn(errMsg, e)	<line30> log.warn(errMsg, e)
task5	"<line28>        logger.warn(""Failed to delete: {}"", file);"	<line28>	"LOG.warn(""Failed to delete file: {}"", file)"	"<line28> LOG.warn(""Failed to delete file: {}"", file)"
task5	"<line8>      LOG.warn(""Could not load form XML [{}]"", getClass().getName(), e);"	<line8>	"LOG.warn(""Unable to set value from XML"", e)"	"<line8> LOG.warn(""Unable to set value from XML"", e)"
task5	<line8>      log.error(ex);	<line8>	log.error(ex)	<line8> log.error(ex)
task5	"<line5>      LOGGER.warn(""Exception validating metacard ID {}"", metacard.getId(), e);"	<line5>	"LOGGER.debug(""Could not validate metacard."", e)"	"<line5> LOGGER.debug(""Could not validate metacard."", e)"
task5	"<line4>      logger.info(""Removing groups {}"", navGroup.getName());"	<line5>	"log.debug(""removed empty group: {}"", navGroup.getId())"	"<line5> log.debug(""removed empty group: {}"", navGroup.getId())"
task5	"<line3>          logger.warn(""Checkout conflicts warning"");"	<line3>	"logger.warn(""Checkout conflicts warning"")"	"<line3> logger.warn(""Checkout conflicts warning"")"
task5	"<line2>    log.trace(""Processing ARCRecord with offset: {}"", sar.getMetaData().getOffset());"	<line2>	"log.debug(""Processing record "" + sar)"	"<line2> log.debug(""Processing record "" + sar)"
task5	"<line27>      LOGGER.warn(""The resolvedMoveThreadCount ({}) is higher ""+ ""than the availableProcessorCount ({}), which is counter-efficient."",resolvedMoveThreadCount,availableProcessorCount);"	<line27>	"log.warn(""The configured moveThreadCount (""+ moveThreadCount+ "") is higher than the maximum possible (""+ availableProcessorCount+ "").""+ "" The moveThreadCount will be reduced to the maximum possible."")"	"<line27> log.warn(""The configured moveThreadCount (""+ moveThreadCount+ "") is higher than the maximum possible (""+ availableProcessorCount+ "").""+ "" The moveThreadCount will be reduced to the maximum possible."")"
task5	<line16>      log.error(exception, exception);	<line16>	"log.error(""Unable to process message"", exception)"	"<line16> log.error(""Unable to process message"", exception)"
task5	"<line31>      log.info(""Created RDD {} for table {}"", rdd.name(), tempTableName);"	<line22>	"log.info(""Creating RDD for table "" + tempTableName)"	"<line22> log.info(""Creating RDD for table "" + tempTableName)"
task5	"<line25>      LOGGER.error(""Remote config center ["" + settings + ""] is not available."", e);"	<line25>	"log.error(""Failed to read config from consul: {}"", e.getMessage(), e)"	"<line25> log.error(""Failed to read config from consul: {}"", e.getMessage(), e)"
task5	"<line2>    log.info(""------  testRangeOpsInDiffSubTree  ------"");"	<line2>	"log.info(""------  testRangeOpsInDiffSubTree  ------"")"	"<line2> log.info(""------  testRangeOpsInDiffSubTree  ------"")"
task5	"<line2>      LOGGER.trace(String.format(""Is '%s' Update statement ? "", statement.toString()));"	<line2>	"LOGGER.trace(String.format(""Is statement of type %s"", statement.getClass()))"	"<line2> LOGGER.trace(String.format(""Is statement of type %s"", statement.getClass()))"
task5	"<line6>      logger.error(""Error resetting method status"", t);"	<line6>	"logger.error(""error in resetMethodStatus"", t)"	"<line6> logger.error(""error in resetMethodStatus"", t)"
task5	"<line9>        logger.warn(""job-""+ job.getId()+ "" is scheduled for wakeup run, but there is no joining info anymore"");"	<line9>	"logger.info(""Unable to find join record for job: "" + job.getId())"	"<line9> logger.info(""Unable to find join record for job: "" + job.getId())"
task5	"<line3>      LOGGER.debug(""Animation plan set to "" + plan);"	<line3>	"LOGGER.debug(""Setting plan "" + plan)"	"<line3> LOGGER.debug(""Setting plan "" + plan)"
task5	"<line1>    log.info(""Shutting down thread monitoring tables."");"	<line1>	"log.info(""Shutting down with shutdown latch count: {}"", shutdownLatch.getCount())"	"<line1> log.info(""Shutting down with shutdown latch count: {}"", shutdownLatch.getCount())"
task5	"<line4>    LOG.info(""Destroyed WebSocketServer."");"	<line2>	"log.info(""Destroying {}"", instance)"	"<line2> log.info(""Destroying {}"", instance)"
task5	"<line11>        log.debug(""Invoke a Change Listener"");"	<line3>	"log.debug(""Triggering partition change listeners"")"	"<line3> log.debug(""Triggering partition change listeners"")"
task5	<line12>        log.debug(sb.toString());	<line12>	log.debug(sb.toString())	<line12> log.debug(sb.toString())
task5	"<line23>      log.debug(""send {} to {}"", bundle, sb);"	<line25>	"log.error(""Unexpected exception: "" + ex.getMessage(), ex)"	"<line25> log.error(""Unexpected exception: "" + ex.getMessage(), ex)"
task5	"<line58>      logger.error(""Error updating page {} status"", pageCode, e);"	<line58>	"logger.error(""Error in update page status"", e)"	"<line58> logger.error(""Error in update page status"", e)"
task5	"<line18>        LOGGER.warn(MessageFormat.format(""Found multiple implementations for ActionTrace {0}. Returning first""+ "" implementation"",scriptParameterDesignTraceKey.toString()));"	<line18>	"LOGGER.info(MessageFormat.format(""Found multiple implementations for {0}. Returning first implementation"",scriptParameterDesignTraceKey.toString()))"	"<line18> LOGGER.info(MessageFormat.format(""Found multiple implementations for {0}. Returning first implementation"",scriptParameterDesignTraceKey.toString()))"
task5	<line9>      log.error(message);	<line9>	log.error(message, ex)	<line9> log.error(message, ex)
task5	"<line5>      log.error(""Failed to set uninstall commands"");"	<line5>	"log.error(""Failed to parse uninstall commands: "", e)"	"<line5> log.error(""Failed to parse uninstall commands: "", e)"
task5	<line9>      log.error(e);	<line9>	log.error(e)	<line9> log.error(e)
task5	"<line10>      LOG.warn(""exception while writing counters data to files"", e);"	<line10>	"log.error(""Error while trying to stop the metrics repository."", e)"	"<line10> log.error(""Error while trying to stop the metrics repository."", e)"
task5	"<line12>                    logger.warn(""Exception at getUserListMemberships"", e);"	<line12>	"logger.warn(""Exception at getUserListMemberships"", e)"	"<line12> logger.warn(""Exception at getUserListMemberships"", e)"
task5	"<line3>    LOG.debug(""Enable SQS RPC: {}"", enabled);"	<line3>	"LOG.info(""Enable SQS RPC: {}"", enabled)"	"<line3> LOG.info(""Enable SQS RPC: {}"", enabled)"
task5	"<line17>        LOGGER.warn(""Partition strategy is necessary when using more than 1 partition, defaulting to 'hash'""+ "" partitioning."");"	<line17>	"LOGGER.warn(""Unable to wrap index with partitioning options.  Returning unchanged index."")"	"<line17> LOGGER.warn(""Unable to wrap index with partitioning options.  Returning unchanged index."")"
task5	<line1>    log.trace(XTCE_POLYNOMIAL_CALIBRATOR);	<line1>	log.trace(XTCE_POLYNOMIAL_CALIBRATOR)	<line1> log.trace(XTCE_POLYNOMIAL_CALIBRATOR)
task5	"<line2>      logger.debug(""Searching index using custom query '"" + query + ""'"");"	<line4>	"logger.error(""Error retrieving results from SOLR"", e)"	"<line4> logger.error(""Error retrieving results from SOLR"", e)"
task5	"<line10>      logger.info(""query-{}: segment-{} memory store scan finished, take {} ms"",queryProfile.getQueryId(),segmentName,profileStep.getDuration());"	<line6>	"logger.debug(""{} end read, scan_count: {}, filter_count: {}"", stepName, scanCnt, filterCnt)"	"<line6> logger.debug(""{} end read, scan_count: {}, filter_count: {}"", stepName, scanCnt, filterCnt)"
task5	"<line27>      LOG.error(""Failed to get running instances"", e);"	<line27>	"LOG.error(""Failed to get running instances"", e)"	"<line27> LOG.error(""Failed to get running instances"", e)"
task5	<line19>      log.error(systemException, systemException);	<line19>	log.error(systemException, systemException)	<line19> log.error(systemException, systemException)
task5	"<line3>      ActiveMQRALogger.LOGGER.trace(""getBooleanProperty("" + name + "")"");"	<line3>	"ActiveMQRALogger.LOGGER.trace(""getBooleanProperty("" + name + "")"")"	"<line3> ActiveMQRALogger.LOGGER.trace(""getBooleanProperty("" + name + "")"")"
task5	<line17>      log.error(portalException, portalException);	<line17>	log.error(portalException, portalException)	<line17> log.error(portalException, portalException)
task5	"<line6>      LOGGER.warn(MessageFormat.format(this.getActionExecution().getAction().getType()+ "" does not accept {0} as type for iterationCondition"",iterationCondition.getClass()));"	<line6>	"log.warn(MessageFormat.format(""{0} does not accept {1} as type for iteration condition."",this.getActionExecution().getAction().getType(), iterationCondition.getClass()))"	"<line6> log.warn(MessageFormat.format(""{0} does not accept {1} as type for iteration condition."",this.getActionExecution().getAction().getType(), iterationCondition.getClass()))"
task5	"<line5>      logger.trace(""searching process list for pid{}"", pid);"	<line21>	"logger.error(""isProcessRunning() :: Failed to get output of command: "" + PS_COMMAND, e)"	"<line21> logger.error(""isProcessRunning() :: Failed to get output of command: "" + PS_COMMAND, e)"
task5	"<line6>    LOGGER.debug(""CompleteResultinMessage: ""+ ArrayConverter.bytesToHexString(msg.getCompleteResultingMessage().getValue()));"	<line1>	"LOG.debug(""Preparing complete resulting message. Length: {}"", msg.getCompleteResultingMessage().length)"	"<line1> LOG.debug(""Preparing complete resulting message. Length: {}"", msg.getCompleteResultingMessage().length)"
task5	<line24>      log.error(systemException, systemException);	<line24>	log.error(systemException, systemException)	<line24> log.error(systemException, systemException)
task5	<line11>          log.debug(portalException, portalException);	<line11>	log.debug(portalException, portalException)	<line11> log.debug(portalException, portalException)
task5	"<line8>      logger.warn("""", fex);"	<line8>	"logger.warn("""", fex)"	"<line8> logger.warn("""", fex)"
task5	"<line2>    logger.info(""GeoIT.testMovingTarget"");"	<line2>	"logger.debug(""testMovingTarget"")"	"<line2> logger.debug(""testMovingTarget"")"
task5	"<line1>    log.error(""The portlet could not be loaded. Check if properly deployed."",ExceptionUtil.getRootCause(e));"	<line1>	"log.error(""Portlet container exception"", e)"	"<line1> log.error(""Portlet container exception"", e)"
task5	"<line6>        logger.debug(""{} DECODE COMPLETE: {}"", context.channel(), response);"	<line3>	"logger.debug(""{} DECODE COMPLETE: {}"", context.channel(), in)"	"<line3> logger.debug(""{} DECODE COMPLETE: {}"", context.channel(), in)"
task5	"<line9>      log.debug(executionException.getCause(),""Error while caching all catalogs metadata. Falling back to default flow"");"	<line9>	"log.error(""Failed to access catalogs cache"", executionException)"	"<line9> log.error(""Failed to access catalogs cache"", executionException)"
task5	<line22>      log.error(systemException, systemException);	<line22>	log.error(systemException, systemException)	<line22> log.error(systemException, systemException)
task5	<line17>        log.debug(throwable, throwable);	<line17>	log.debug(throwable, throwable)	<line17> log.debug(throwable, throwable)
task5	"<line7>        logger.debug(""Failure trying to obtain (Terminal-Information) MEID AVP value"", ex);"	<line7>	"logger.debug(""Failure trying to obtain TGPP2_MEID AVP value"", ex)"	"<line7> logger.debug(""Failure trying to obtain TGPP2_MEID AVP value"", ex)"
task5	"<line6>        LOG.warn(""Configuration value overridden by system property: {}, with value: {}"",property,value);"	<line6>	"logger.info(""Using configuration property "" + property + ""="" + value)"	"<line6> logger.info(""Using configuration property "" + property + ""="" + value)"
task5	"<line3>      log.debug(""Synchronizing all folders for accountId "" + account.getAccountId());"	<line3>	"log.debug(""Synchronizing IMAP folders for user "" + user.getUserId())"	"<line3> log.debug(""Synchronizing IMAP folders for user "" + user.getUserId())"
task5	"<line11>    log.info(""No data for report for user {} and reportId {}."", key.user.email, report.id);"	<line9>	"log.info(""generated report {}"", output)"	"<line9> log.info(""generated report {}"", output)"
task5	"<line8>    LOG.debug(""Canonical path: {}"", fileName);"	<line11>	"log.debug(""expanded to: "" + Arrays.toString(scanner.getIncludedFiles()))"	"<line11> log.debug(""expanded to: "" + Arrays.toString(scanner.getIncludedFiles()))"
task5	"<line1>    logger.info(""executing test case testOrFilter2"");"	<line1>	"logger.info(""executing test case testOrFilter2"")"	"<line1> logger.info(""executing test case testOrFilter2"")"
task5	"<line2>    LOGGER.info(""Retrieving "" + this.url);"	<line2>	"logger.info(""    Retrieving "" + this.url)"	"<line2> logger.info(""    Retrieving "" + this.url)"
task5	"<line12>        LOGGER.info(""Skipping test: "" + tcCtx.toString());"	<line6>	"LOGGER.info(""Skipping test compilation unit ""+ cUnit.getCompilationUnitId()+ "" in test context ""+ tcCtx.toString())"	"<line6> LOGGER.info(""Skipping test compilation unit ""+ cUnit.getCompilationUnitId()+ "" in test context ""+ tcCtx.toString())"
task5	"<line3>      LOGGER.debug(""Data Groups Changed: Request Tree Rebuild"");"	<line3>	"LOGGER.debug(""Data groups changed"")"	"<line3> LOGGER.debug(""Data groups changed"")"
task5	"<line10>                  log.info(""Check failed, will retry: "" + e);"	<line10>	"log.error(""Failed to wait for node count, will check again."", e)"	"<line10> log.error(""Failed to wait for node count, will check again."", e)"
task5	<line16>      log.error(systemException, systemException);	<line16>	log.error(systemException, systemException)	<line16> log.error(systemException, systemException)
task5	"<line4>      log.info(""Iteration: "" + i);"	<line26>	"log.info(""Services were deployed, now cancel all."")"	"<line26> log.info(""Services were deployed, now cancel all."")"
task5	"<line5>      logger.warn(""Failed to stop web server"", ex);"	<line5>	"log.error(""Error stopping server"", ex)"	"<line5> log.error(""Error stopping server"", ex)"
task5	"<line5>      logger.warn(""Cannot load resource "" + resource + "" from classpath"");"	<line5>	"log.error(""Could not read content fromInputStream"", e)"	"<line5> log.error(""Could not read content fromInputStream"", e)"
task5	"<line14>        log.error(""Failed to create Publisher for the topic [{}]."", topic, e);"	<line12>	"logger.debug(""Created a Publisher for the topic: {}"", topic)"	"<line12> logger.debug(""Created a Publisher for the topic: {}"", topic)"
task5	<line11>      log.error(e.getMessage(), e);	<line11>	"LOG.error(""Failed to start {}"", this.getClass().getName(), e)"	"<line11> LOG.error(""Failed to start {}"", this.getClass().getName(), e)"
task5	"<line5>      log.info(""Skipping graceful shutdown call, because web-console not up for {}"", this);"	<line5>	"log.info(""Shutting down without web console"")"	"<line5> log.info(""Shutting down without web console"")"
task5	"<line1>    LOGGER.debug(""Do something thing by Sub Generic Controller"");"	<line1>	log.info(string)	<line1> log.info(string)
task5	"<line2>    log.info(""HANDLE: OpenAction for element: "" + action.getElementId());"	<line2>	"LOGGER.debug(""Element opened: {}"", action.getElement())"	"<line2> LOGGER.debug(""Element opened: {}"", action.getElement())"
task5	"<line4>      logger.trace(this + ""::Acking message "" + message);"	<line4>	"logger.trace(""ClientMessageInternal.doAck()"")"	"<line4> logger.trace(""ClientMessageInternal.doAck()"")"
task5	"<line8>        log.trace(""Resource ""+ name+ "" not found with classloader: ""+ delegate+ "". Trying other delegates"");"	<line8>	"log.trace(""getResourceAsStream("" + name + "") returning null from "" + delegate.getClass().toString())"	"<line8> log.trace(""getResourceAsStream("" + name + "") returning null from "" + delegate.getClass().toString())"
task5	"<line15>      log.error(""sizeof: Failed to compute function for "" + type + "": "", t);"	<line15>	"log.warn(t,""Failed to compute sizeof for %s due to %s. Assuming %d bytes."",genericType,t.getMessage(),objectHeaderSize)"	"<line15> log.warn(t,""Failed to compute sizeof for %s due to %s. Assuming %d bytes."",genericType,t.getMessage(),objectHeaderSize)"
task5	"<line1>    LOGGER.info(""Creating disambiguated org {}"", organization.name);"	<line23>	"LOG.info(""Created org disambiguated entity {}"", orgDisambiguatedEntity)"	"<line23> LOG.info(""Created org disambiguated entity {}"", orgDisambiguatedEntity)"
task5	"<line3>      logger.trace(""addLongField fieldName: {}; value: {}"", fieldName, value);"	<line3>	"logger.trace(""addLongField fieldName: {}; value: {}"", fieldName, value)"	"<line3> logger.trace(""addLongField fieldName: {}; value: {}"", fieldName, value)"
task5	"<line19>        LOG.debug(""Malformed URL from "" + pathName, e);"	<line19>	"log.warn(""Problem creating URL for {}"", pathElement, e)"	"<line19> log.warn(""Problem creating URL for {}"", pathElement, e)"
task5	"<line2>      logger.debug(""Stop periodic connection check"");"	<line2>	"logger.debug(""Reconnect task running. Stopping it"")"	"<line2> logger.debug(""Reconnect task running. Stopping it"")"
task5	"<line7>    logger.info(""taskAckCommand : {}"", taskAckCommand);"	<line10>	"log.debug(""task execute ack received, instance id: {}, status: {}"",taskAckCommand.getTaskInstanceId(),ackStatus)"	"<line10> log.debug(""task execute ack received, instance id: {}, status: {}"",taskAckCommand.getTaskInstanceId(),ackStatus)"
task5	<line10>      logger.error(msg, ex);	<line10>	logger.error(msg, ex)	<line10> logger.error(msg, ex)
task5	"<line10>    LOGGER.info(""Generating code for .NET Framework "" + this.targetFramework);"	<line8>	"log.info(""Targeting .NET framework version: "" + dotnetFramework)"	"<line8> log.info(""Targeting .NET framework version: "" + dotnetFramework)"
task5	"<line2>    LOGGER.info(""Connection ({}) closed."", this.connection, e);"	<line2>	"LOGGER.info(""Connection closed"", e)"	"<line2> LOGGER.info(""Connection closed"", e)"
task5	<line6>      log.error(e.getMessage(), e);	<line6>	"log.error(""Failed to add permission"", e)"	"<line6> log.error(""Failed to add permission"", e)"
task5	"<line27>      logger.error(""A Problem happened in the BalancerValve on response "" + response, e);"	<line27>	"logger.error(""Error processing response, dropping it"", e)"	"<line27> logger.error(""Error processing response, dropping it"", e)"
task5	"<line1>    logger.debug(""enforce(agreement={},since={})"", agreement.getAgreementId(), since);"	<line2>	"logger.debug(""Enforcing agreement: "" + agreement.getAgreementId())"	"<line2> logger.debug(""Enforcing agreement: "" + agreement.getAgreementId())"
task5	<line24>      log.error(systemException, systemException);	<line24>	log.error(systemException, systemException)	<line24> log.error(systemException, systemException)
task5	"<line2>    LOG.debug(""Disposing Model on CamelContext"");"	<line2>	"logger.debug(""disposeModel called"")"	"<line2> logger.debug(""disposeModel called"")"
task5	"<line7>      log.warn(""Both legacy {} and R7 {} properties are specified. Using R7 property: {}."",PaxWebConstants.SERVICE_PROPERTY_HTTP_CONTEXT_ID,HttpWhiteboardConstants.HTTP_WHITEBOARD_CONTEXT_SELECT,selector);"	<line7>	"LOG.warn(""Ignoring legacy context id \""{}\"" in HTTP whiteboard service reference \""{}\"". Use of the""+ "" deprecated \""legacyMapping\"" parameter is deprecated."",legacyId,serviceReference)"	"<line7> LOG.warn(""Ignoring legacy context id \""{}\"" in HTTP whiteboard service reference \""{}\"". Use of the""+ "" deprecated \""legacyMapping\"" parameter is deprecated."",legacyId,serviceReference)"
task5	"<line5>      LOGGER.error(""process sync timeout request error"", e);"	<line5>	"LOG.error(""process sync request error"", e)"	"<line5> LOG.error(""process sync request error"", e)"
task5	"<line12>      logger.error(""error in buildTree"", t);"	<line12>	"logger.error(""Error while checking target nodes"", t)"	"<line12> logger.error(""Error while checking target nodes"", t)"
task5	"<line3>      LOG.error(""Scope can't be null."");"	<line7>	"LOG.info(""cluster "" + clusterName + "" is not setup yet"")"	"<line7> LOG.info(""cluster "" + clusterName + "" is not setup yet"")"
task5	"<line1>    LOG.info(""calling inoutdemo: {}, {}"", inout1[0], out1[0]);"	<line1>	"logger.info(""inoutdemo(int, int[], int[])"")"	"<line1> logger.info(""inoutdemo(int, int[], int[])"")"
task5	"<line2>    logger.debug(""executing test testInsertEmptyWhere"");"	<line2>	"logger.debug(""executing testInsertEmptyWhere"")"	"<line2> logger.debug(""executing testInsertEmptyWhere"")"
task5	<line21>    logger.trace(txIntrospector.toString());	<line21>	logger.trace(txIntrospector.toString())	<line21> logger.trace(txIntrospector.toString())
task5	"<line5>          log.info(""Port "" + x + "" was marked as healthy"");"	<line2>	"log.info(""Setting all ports healthy"")"	"<line2> log.info(""Setting all ports healthy"")"
task5	"<line21>      LOGGER.info(brother.getName()+ "" output: \n""+ Util.prettyPrintXml(brother.getOutput().getMessage()));"	<line2>	"LOGGER.info(""Scheduling parallel processes"")"	"<line2> LOGGER.info(""Scheduling parallel processes"")"
task5	"<line9>                logger.debug(""Exception while cleaning up Lucene Index Repository"", e);"	<line9>	"LOGGER.debug(""Lucene index failed to update for bucket {} due to {}"", bucketId, e)"	"<line9> LOGGER.debug(""Lucene index failed to update for bucket {} due to {}"", bucketId, e)"
task5	"<line3>    log.debug(""Loading experiment info"");"	<line3>	"logger.debug(""experimentId = "" + idString)"	"<line3> logger.debug(""experimentId = "" + idString)"
task5	<line12>        log.debug(sb.toString());	<line12>	log.debug(sb.toString())	<line12> log.debug(sb.toString())
task5	<line18>      log.error(systemException, systemException);	<line18>	log.error(systemException, systemException)	<line18> log.error(systemException, systemException)
task5	"<line4>    LOGGER.info(""Bundle [{}] removed successfully"");"	<line3>	"log.info(""Uninstalling bundle "" + bundleId + "" with config"")"	"<line3> log.info(""Uninstalling bundle "" + bundleId + "" with config"")"
task5	"<line22>        log.error(""ClassNotFoundException exception occurred: "" + entry.getValue());"	<line20>	"log.info(""Configuring config provider: "" + entry.getKey() + "" using class: "" + entry.getValue())"	"<line20> log.info(""Configuring config provider: "" + entry.getKey() + "" using class: "" + entry.getValue())"
task5	"<line5>    logger.debug(""Created new freemarker template processor for DocUtils"");"	<line5>	"LOG.info(""Freemarker configuration reset"")"	"<line5> LOG.info(""Freemarker configuration reset"")"
task5	"<line2>    log.info(""------  testSingleValueAndMultiFieldNoParens  ------"");"	<line27>	"log.info(""Testing "" + query + "" for FullTableScansDisallowedException"")"	"<line27> log.info(""Testing "" + query + "" for FullTableScansDisallowedException"")"
task5	"<line10>      log.warn(""Unable to update service context properties."");"	<line10>	"log.warn(""updateServiceContexts() only accepts a Map as an argument"")"	"<line10> log.warn(""updateServiceContexts() only accepts a Map as an argument"")"
task5	"<line6>        logger.debug(""Assuming that domain_id field doesn't exist in account_vlan_map table, no need to""+ "" upgrade"");"	<line6>	"logger.debug(""Unable to select from account_vlan_map table due to:"", e)"	"<line6> logger.debug(""Unable to select from account_vlan_map table due to:"", e)"
task5	"<line2>    LOGGER.debug(""DistinguishedNames: ""+ ArrayConverter.bytesToHexString(msg.getDistinguishedNames().getValue()));"	<line2>	"LOGGER.debug(""DistinguishedNames: ""+ ArrayConverter.bytesToHexString(msg.getDistinguishedNames().getValue()))"	"<line2> LOGGER.debug(""DistinguishedNames: ""+ ArrayConverter.bytesToHexString(msg.getDistinguishedNames().getValue()))"
task5	"<line9>        log.error(""server path is not configured in database and not yet generated from Http request!!!.""+ "" Admin need to configure it in database"");"	<line9>	"log.debug(""No server path configured. Returning empty string."")"	"<line9> log.debug(""No server path configured. Returning empty string."")"
task5	"<line3>      logger.debug(""Initialize {}"", this.getClass().getSimpleName());"	<line3>	"logger.debug(""Initialize {}"", this.getClass().getSimpleName())"	"<line3> logger.debug(""Initialize {}"", this.getClass().getSimpleName())"
task5	"<line2>    LOG.info(""Tearing down OmidTestBase..."");"	<line2>	"LOG.info(""AfterGroups start"")"	"<line2> LOG.info(""AfterGroups start"")"
task5	"<line6>    LOGGER.info(""Configuring JDBC connection using data source: {}"", dataSource.toString());"	<line5>	"LOG.info(""Adding config for: "" + connectionConfig.getDbName())"	"<line5> LOG.info(""Adding config for: "" + connectionConfig.getDbName())"
task5	"<line2>      logger.debug(""Starting thread for "" + p2pReaderName());"	<line2>	"logger.debug(""Starting Reader"")"	"<line2> logger.debug(""Starting Reader"")"
task5	"<line47>            logger.debug(""Returning CREATED response for start case with content '{}'"", response);"	<line49>	logger.debug(MessageFormat.format(CASE_DEFINITION_NOT_FOUND, caseDefId, containerId))	<line49> logger.debug(MessageFormat.format(CASE_DEFINITION_NOT_FOUND, caseDefId, containerId))
task5	"<line5>      logger.debug(""Found custom marshaller builder {} that is going to be used instead of the default"",marshallerBuilder);"	<line5>	"LOGGER.debug(""Using marshaller builder: {}"", marshallerBuilder.getClass().getName())"	"<line5> LOGGER.debug(""Using marshaller builder: {}"", marshallerBuilder.getClass().getName())"
task5	"<line29>      log.error(""[{}] Error adding entry"", name, result.status);"	<line22>	"log.error(""addEntry failed"", exception)"	"<line22> log.error(""addEntry failed"", exception)"
task5	"<line14>      log.info(""Ignoring exception, likely coming from Hadoop 1"", e);"	<line14>	"LOG.error(""Exception adding token from user to job conf: "" + e.getMessage(), e)"	"<line14> LOG.error(""Exception adding token from user to job conf: "" + e.getMessage(), e)"
task5	"<line5>      log.error(""Failed to log timeseries delete"", e);"	<line5>	"log.error(""Failed to log timeseries delete"", e)"	"<line5> log.error(""Failed to log timeseries delete"", e)"
task5	<line14>      log.error(e.getMessage(), e);	<line14>	"LOGGER.error(""Error while creating cardinality configuration"", e)"	"<line14> LOGGER.error(""Error while creating cardinality configuration"", e)"
task5	"<line12>      LOG.info(""KVDiskStorage create a new file, filePath = "" + newPath);"	<line14>	"LOG.error(""task UnInitializtionException"", e)"	"<line14> LOG.error(""task UnInitializtionException"", e)"
task5	"<line2>    LOGGER.info(""  testStringResult"");"	<line2>	"LOGGER.info(""  testStringResult"")"	"<line2> LOGGER.info(""  testStringResult"")"
task5	"<line5>        log.error(""Empty partitions for topic {}"", topic);"	<line9>	"log.debug(""Maximum number of partitions is {}"", numPartitions)"	"<line9> log.debug(""Maximum number of partitions is {}"", numPartitions)"
task5	"<line16>          LOGGER.error(""Error validating preservation binary "" + binary.getStoragePath(), e);"	<line22>	"LOGGER.error(""Could not validate PREMIS file"", e)"	"<line22> LOGGER.error(""Could not validate PREMIS file"", e)"
task5	<line10>      LOGGER.error(e);	<line10>	"LOGGER.error(""Failed to parse object list: {}"", objectList, e)"	"<line10> LOGGER.error(""Failed to parse object list: {}"", objectList, e)"
task5	"<line16>          LOG.info(""Could not load factory due to missing dependencies."");"	<line16>	"LOG.info(""Could not load ClusterClientFactory for configuration {}"", configuration, e)"	"<line16> LOG.info(""Could not load ClusterClientFactory for configuration {}"", configuration, e)"
task5	"<line11>        LOG.trace(""Flushing entry {} ({})"", entry, message);"	<line2>	"LOG.debug(""Flushing journal writer {}"", this)"	"<line2> LOG.debug(""Flushing journal writer {}"", this)"
task5	<line12>        logger.warn(e.getLocalizedMessage());	<line14>	"LOGGER.error(""Error in SymjaMMACodeRunner"", e)"	"<line14> LOGGER.error(""Error in SymjaMMACodeRunner"", e)"
task5	"<line12>      logger.error(""failed to open eventhub receiver: "" + ex.getMessage());"	<line12>	"logger.error(""Failed to open Event Hub receiver"", ex)"	"<line12> logger.error(""Failed to open Event Hub receiver"", ex)"
task5	"<line3>      LOGGER.info(""Resizing node table from {} to {}"", oldsize, newsize);"	<line3>	"logger.info(""bdd_default_reshandler: oldsize="" + oldsize + "", newsize="" + newsize)"	"<line3> logger.info(""bdd_default_reshandler: oldsize="" + oldsize + "", newsize="" + newsize)"
task5	"<line22>          log.debug(""Found conflicting container with uuid {""+ conflictingContainer.getUuid()+ ""} of node {""+ conflictingNode.getUuid()+ ""}"");"	<line22>	"log.debug(""Node {""+ node.getUuid()+ ""} already exists in target language container with display field value {""+ conflictingContainer.getDisplayFieldValue()+ ""}."")"	"<line22> log.debug(""Node {""+ node.getUuid()+ ""} already exists in target language container with display field value {""+ conflictingContainer.getDisplayFieldValue()+ ""}."")"
task5	"<line13>    LOG.debug(""Graph [{}] get rays paths from '{}' with ""+ ""direction '{}', edge label '{}', max depth '{}', ""+ ""max degree '{}', capacity '{}' and limit '{}'"",graph,sourceV,direction,edgeLabel,depth,maxDegree,capacity,limit);"	<line13>	"LOG.debug(""Graph [{}] get rays with source vertex '{}', direction '{}', edge label '{}', ""+ ""max depth '{}', max degree '{}', capacity '{}' and limit '{}'"",graph,sourceV,direction,edgeLabel,depth,maxDegree,capacity,limit)"	"<line13> LOG.debug(""Graph [{}] get rays with source vertex '{}', direction '{}', edge label '{}', ""+ ""max depth '{}', max degree '{}', capacity '{}' and limit '{}'"",graph,sourceV,direction,edgeLabel,depth,maxDegree,capacity,limit)"
task5	<line32>      log.error(systemException, systemException);	<line32>	log.error(systemException, systemException)	<line32> log.error(systemException, systemException)
task5	<line27>            ActiveMQServerLogger.LOGGER.warn(e.getMessage());	<line27>	"logger.debug(""Queue already exists"", e)"	"<line27> logger.debug(""Queue already exists"", e)"
task5	"<line8>        log.debug(""Can not send message"", e);"	<line8>	"LOG.warn(""Message #"" + i + "" failed: "" + e.getMessage(), e)"	"<line8> LOG.warn(""Message #"" + i + "" failed: "" + e.getMessage(), e)"
task5	"<line5>      log.info(""...Locking the singleton world of the DB definition!"");"	<line5>	"log.info(""Locking {}"", this)"	"<line5> log.info(""Locking {}"", this)"
task5	"<line6>      LOG.debug(""{} search result(s) found for URL {}"", addresses.size(), url);"	<line7>	"LOGGER.error(""Error while searching for addresses in OSM"", e)"	"<line7> LOGGER.error(""Error while searching for addresses in OSM"", e)"
task5	"<line12>      logger.error(""Error creating ideainstance"", t);"	<line12>	"logger.error(""Error creating ideainstance"", t)"	"<line12> logger.error(""Error creating ideainstance"", t)"
task5	"<line3>      ActiveMQRALogger.LOGGER.trace(""getAcknowledgeMode()"");"	<line3>	"ActiveMQRALogger.LOGGER.trace(""getAcknowledgeMode()"")"	"<line3> ActiveMQRALogger.LOGGER.trace(""getAcknowledgeMode()"")"
task5	<line18>      log.error(systemException, systemException);	<line18>	log.error(systemException, systemException)	<line18> log.error(systemException, systemException)
task5	"<line6>    log.debug(""Running virt_limit post unbind."");"	<line23>	"log.info(""Unbinding virt limit for pool: "" + pool.getId())"	"<line23> log.info(""Unbinding virt limit for pool: "" + pool.getId())"
task5	"<line12>          logger.warn(""exception when close gtscanner"", e);"	<line12>	"LOG.error(""search result close error"", e)"	"<line12> LOG.error(""search result close error"", e)"
task5	<line6>    LOGGER.info(html);	<line6>	LOGGER.info(html)	<line6> LOGGER.info(html)
task5	"<line24>      LOGGER.error(""removeByFilter occur a exception"", e);"	<line24>	"log.error(""removeByFilter occur a exception"", e)"	"<line24> log.error(""removeByFilter occur a exception"", e)"
task5	"<line9>              LOGGER.debug(""Could not find a MetacardMapper for featureType {}."", featureType);"	<line9>	"LOGGER.debug(""Could not find a MetacardAttributeToFeatureProperty mapper for featureType {}."",featureType)"	"<line9> LOGGER.debug(""Could not find a MetacardAttributeToFeatureProperty mapper for featureType {}."",featureType)"
task5	"<line10>    log.info(""All volumes are of the same size. No need for capacity calculations."");"	<line6>	"LOGGER.info(""The following volumes have different sizes: "" + currentVolumeSizes)"	"<line6> LOGGER.info(""The following volumes have different sizes: "" + currentVolumeSizes)"
task5	"<line10>                log.info(""Publishing Cluster terminating event for [application] ""+ appId+ "" [cluster] ""+ getClusterId()+ "" [instance] ""+ instanceId);"	<line10>	"log.info(""Publishing cluster terminating event: [application] ""+ getAppId()+ "" [service] ""+ getServiceId()+ "" [cluster] ""+ getClusterId()+ "" [instance] ""+ instanceId)"	"<line10> log.info(""Publishing cluster terminating event: [application] ""+ getAppId()+ "" [service] ""+ getServiceId()+ "" [cluster] ""+ getClusterId()+ "" [instance] ""+ instanceId)"
task5	"<line14>      log.error(Util.getMessage(""FailedSubscribingTo"") + destination + "": "", ex);"	<line14>	"LOG.error(""Failed to send subscribe message to: "" + destination + "". Error: "" + ex.getMessage())"	"<line14> LOG.error(""Failed to send subscribe message to: "" + destination + "". Error: "" + ex.getMessage())"
task5	"<line11>        LOGGER.warn(""Invalid access on table, iterator has been closed"");"	<line23>	"LOGGER.warn(""auto generated key: "" + keyS)"	"<line23> LOGGER.warn(""auto generated key: "" + keyS)"
task5	<line12>      log.error(exception, exception);	<line12>	log.error(exception, exception)	<line12> log.error(exception, exception)
task5	"<line5>      LOG.warn(""Unexpected exception while handling framework message"", t);"	<line5>	"log.error(""Executor failed to handle message: {}"", t.getStackTrace())"	"<line5> log.error(""Executor failed to handle message: {}"", t.getStackTrace())"
task5	"<line7>        LOGGER.error(""Can not parse port from substring {}"", portSubstring);"	<line7>	"logger.debug(""Unable to parse stream port in answer: \"""" + answer + ""\"""")"	"<line7> logger.debug(""Unable to parse stream port in answer: \"""" + answer + ""\"""")"
task5	"<line6>    logger.debug(""checkSystemIfUniqueValidationNeeded started..."");"	<line6>	"log.debug(""checkSystemIfUniqueValidationNeeded started..."")"	"<line6> log.debug(""checkSystemIfUniqueValidationNeeded started..."")"
task5	"<line14>        LOG.error(""Error removing node"", t);"	<line14>	"log.error(""Error while notifying nodeRemoved on former tree"", t)"	"<line14> log.error(""Error while notifying nodeRemoved on former tree"", t)"
task5	"<line14>    LOG.debug(""Graph [{}] query vertices by label: {}, properties: {}, ""+ ""offset: {}, page: {}, limit: {}"",graph,label,properties,offset,page,limit);"	<line14>	"LOG.debug(""Graph [{}] list vertices with label {}, properties {}, keep_start_p {}, offset {}, ""+ ""page {}, limit {}"",graph,label,properties,keepStartP,offset,page,limit)"	"<line14> LOG.debug(""Graph [{}] list vertices with label {}, properties {}, keep_start_p {}, offset {}, ""+ ""page {}, limit {}"",graph,label,properties,keepStartP,offset,page,limit)"
task5	"<line12>      log.debug(""Created session for device authorization grant page, sessionId: {}"",deviceAuthzSession.getId());"	<line1>	"log.debug(""initializeSession()"")"	"<line1> log.debug(""initializeSession()"")"
task5	"<line16>      log.debug(""Failed to fetch the container component {}. "", componentUid);"	<line16>	"log.debug(""Failed to fetch component with uid {}"", componentUid, getContainerRes.right().value())"	"<line16> log.debug(""Failed to fetch component with uid {}"", componentUid, getContainerRes.right().value())"
task5	"<line6>        LOGGER.error(""Failed to initialise."", ex);"	<line6>	"logger.error(""Failed to setUpClass"", ex)"	"<line6> logger.error(""Failed to setUpClass"", ex)"
task5	"<line7>      LOGGER.error(""Error in ZigBeeConsole API execute command."", e);"	<line7>	"logger.error(""Error processing command: "" + command, e)"	"<line7> logger.error(""Error processing command: "" + command, e)"
task5	"<line1>    LOG.info(""Close connection {}"", s);"	<line1>	"LOG.debug(""close {}"", s)"	"<line1> LOG.debug(""close {}"", s)"
task5	"<line4>      LOGGER.debug(""unbind branch type {}"", unbindBranchType);"	<line4>	"LOGGER.debug(""Unbind branch type: {}"", unbindBranchType)"	"<line4> LOGGER.debug(""Unbind branch type: {}"", unbindBranchType)"
task5	"<line1>    LOG.info(""NoopTask.stopTask() invoked."");"	<line1>	"log.debug(""Stopping task {}"", this.getId())"	"<line1> log.debug(""Stopping task {}"", this.getId())"
task5	"<line2>    logger.trace(""Executing query: {0}"", query);"	<line2>	"log.debug(""Executing query {} in JCR"", query)"	"<line2> log.debug(""Executing query {} in JCR"", query)"
task5	"<line9>      logger.debug(""Spring Security setup complete."");"	<line9>	"logger.debug(""AuthZ init: "" + authZ)"	"<line9> logger.debug(""AuthZ init: "" + authZ)"
task5	"<line8>    logger.debug(""-----installProject--- , project name: {}, branch name: {}"", projectName, branchName);"	<line8>	"logger.debug(""-----installProject--- , space name: {}, project name: {}, branch name: {}"",spaceName,projectName,branchName)"	"<line8> logger.debug(""-----installProject--- , space name: {}, project name: {}, branch name: {}"",spaceName,projectName,branchName)"
task5	"<line5>    log.trace(""Reported device connection duration [tenant : {}, noOfDeviceConnections: {},""+ "" connectionDurationInMs: {}]."",tenantId,noOfDeviceConnections.get(),deviceConnectionDuration);"	<line4>	"logger.info(""Reporting device connection duration of {} ms"", deviceConnectionDuration)"	"<line4> logger.info(""Reporting device connection duration of {} ms"", deviceConnectionDuration)"
task5	"<line4>      log.error(""!!!!!!!ProvenanceEventJmsWriter is NULL !!!!!!"");"	<line4>	"log.error(""Provenance Event Jms Writer is null"")"	"<line4> log.error(""Provenance Event Jms Writer is null"")"
task5	"<line22>        log.warn(""No workflow definitions found for "" + workflowDefinitionName);"	<line22>	"log.warn(""Unable to find workflow definition "" + workflowDefinitionName)"	"<line22> log.warn(""Unable to find workflow definition "" + workflowDefinitionName)"
task5	"<line7>        LOGGER.error(""Failed at stopping KIE Server extension {}"", EXTENSION_NAME);"	<line7>	"LOGGER.error(""Error while stopping Camel Context"", e)"	"<line7> LOGGER.error(""Error while stopping Camel Context"", e)"
task5	"<line4>    log.info(""Starting up the default async job executor [{}]."", getClass().getName());"	<line21>	"log.info(""Starting the Job Executor"")"	"<line21> log.info(""Starting the Job Executor"")"
task5	"<line13>        LOGGER.warn(""namespace add for xml:lang attribute in {}"", datasubtag.getName());"	<line7>	"LOGGER.warn(""history date text is empty"")"	"<line7> LOGGER.warn(""history date text is empty"")"
task5	<line13>        log.debug(sb.toString());	<line13>	log.debug(sb.toString())	<line13> log.debug(sb.toString())
task5	"<line6>      LOG.error(""Error retrieving console layout info for role {}"", roleKey, e);"	<line6>	"LOG.error(""Unable to read any layout for role {}"", roleKey, e)"	"<line6> LOG.error(""Unable to read any layout for role {}"", roleKey, e)"
task5	"<line18>      log.error(""Error deleting element."", e);"	<line18>	"log.error(""Error deleting element"", e)"	"<line18> log.error(""Error deleting element"", e)"
task5	"<line11>      LOGGER.warn(""Could not generate Signature! Using empty one instead!"", E);"	<line11>	"LOGGER.warn(""Could not generate signature: "" + E.getLocalizedMessage())"	"<line11> LOGGER.warn(""Could not generate signature: "" + E.getLocalizedMessage())"
task5	"<line3>      LOG.debug(""Retriving classifications for entity={}"", guid);"	<line3>	"LOG.debug(""retrieveClassifications({})"", guid)"	"<line3> LOG.debug(""retrieveClassifications({})"", guid)"
task5	"<line9>        log.error("""", ex);"	<line9>	"log.error(""Failed to write task exit state to file `job.exit`"", ex)"	"<line9> log.error(""Failed to write task exit state to file `job.exit`"", ex)"
task5	"<line17>        LOGGER.info(MessageFormat.format(""Found multiple implementations for ScriptVersionTrace {0}. Returning first""+ "" implementation"",scriptVersionTraceKey.toString()));"	<line17>	"LOGGER.info(MessageFormat.format(""Found multiple implementations for {0}. Returning first implementation"",scriptVersionTraceKey.toString()))"	"<line17> LOGGER.info(MessageFormat.format(""Found multiple implementations for {0}. Returning first implementation"",scriptVersionTraceKey.toString()))"
task5	"<line16>      log.warn(""Got exception: "", e);"	<line7>	"log.debug(""Could not find identities for entity {}, returning empty"", entityId, e)"	"<line7> log.debug(""Could not find identities for entity {}, returning empty"", entityId, e)"
task5	"<line8>      Log.error("""", ex);"	<line8>	logger.error(ex)	<line8> logger.error(ex)
task5	<line11>        log.debug(portalException, portalException);	<line11>	"log.debug(""Unable to retrieve layout for group "" + groupId, portalException)"	"<line11> log.debug(""Unable to retrieve layout for group "" + groupId, portalException)"
task5	"<line8>    LOG.warn(""[{}] Metric {} does not support {}, it will always return 0"",context.getSessionName(),DefaultSessionMetric.THROTTLING_QUEUE_SIZE.getPath(),requestThrottler.getClass().getName());"	<line8>	"LOG.warn(""Failed to determine throttling queue size. Returning 0."")"	"<line8> LOG.warn(""Failed to determine throttling queue size. Returning 0."")"
task5	"<line2>    log.debug(""=========== test1() ================="");"	<line2>	"log.info(""Test1: DatesPage1"")"	"<line2> log.info(""Test1: DatesPage1"")"
task5	"<line7>      logger.error(""Errore loading categories"", t);"	<line7>	"logger.error(""Error loading categories"", t)"	"<line7> logger.error(""Error loading categories"", t)"
task5	"<line8>        LOG.debug(""Failed verifying signature of token {}"", token, e);"	<line8>	"LOG.debug(""Error verifying token"", e)"	"<line8> LOG.debug(""Error verifying token"", e)"
task5	"<line1>    logger.warn(""Checkout conflicts warning"");"	<line12>	"logger.error(""Checkout conflicts warning"")"	"<line12> logger.error(""Checkout conflicts warning"")"
task5	<line5>        log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line5>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line5> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line5>      logger.error(""Fail to get HDFS! "", e);"	<line5>	"log.error(""Got error while setting conf and getting fs."", e)"	"<line5> log.error(""Got error while setting conf and getting fs."", e)"
task5	"<line2>    log.info(""-----  testDateFolderDistributor  -----"");"	<line6>	"log.info(""Testing date folder distributor"")"	"<line6> log.info(""Testing date folder distributor"")"
task5	"<line13>      LOGGER.error(""Exception in vulnerabilitybyapplications "", e);"	<line13>	LOGGER.error(e.getMessage())	<line13> LOGGER.error(e.getMessage())
task5	<line29>      log.info(buffer.toString());	<line29>	log.info(buffer.toString())	<line29> log.info(buffer.toString())
task5	"<line2>      logger.error(""Null user"");"	<line2>	"logger.error(""Null user"")"	"<line2> logger.error(""Null user"")"
task5	"<line3>      LOG.debug(""Google Cloud Storage available: "" + gcsAvailable);"	<line3>	"LOG.debug(""GCS availability: {}"", gcsAvailable)"	"<line3> LOG.debug(""GCS availability: {}"", gcsAvailable)"
task5	"<line3>    log.debug(""Started to create crypto provider"");"	<line15>	"log.debug(""Initialized cryptoProvider: {}"", cryptoProvider)"	"<line15> log.debug(""Initialized cryptoProvider: {}"", cryptoProvider)"
task5	"<line24>    Log.debug(""NeoEMF Editor opened in {0}"", stopwatch.stop().elapsed());"	<line24>	"log.info(""Created pages in {}"", stopwatch.stop())"	"<line24> log.info(""Created pages in {}"", stopwatch.stop())"
task5	"<line2>    LOGGER.warn(""Executing: "" + unit);"	<line2>	"log.warn(""Executing person "" + unit.getId())"	"<line2> log.warn(""Executing person "" + unit.getId())"
task5	<line8>      log.error(exception, exception);	<line8>	log.error(exception, exception)	<line8> log.error(exception, exception)
task5	"<line4>      logger.warn(file.getPath() + "" getCanonicalPath() error. Error:"" + e.getMessage(), e);"	<line4>	LOG.warn(e, e)	<line4> LOG.warn(e, e)
task5	"<line18>        LOG.warn(""Interrupted while sleeping"", e);"	<line18>	"LOG.warn(""Sleep interrupted"", e)"	"<line18> LOG.warn(""Sleep interrupted"", e)"
task5	"<line2>      log.debug(""Ids message handling failed. [exception=({})]"", exception.getMessage(), exception);"	<line2>	"log.debug(""Ids message handling failed. [exception=({})]"", exception.getMessage(), exception)"	"<line2> log.debug(""Ids message handling failed. [exception=({})]"", exception.getMessage(), exception)"
task5	"<line12>    logger.debug(""Request to join tournament - response (status "" + response.getStatus() + ""): "" + status);"	<line8>	"logger.info(""Game status response: {}"", status)"	"<line8> logger.info(""Game status response: {}"", status)"
task5	"<line7>            log.warn(""Wrong result type: {}"", json.getNodeType());"	<line7>	"log.warn(""Wrong result type: {}"", json.getNodeType())"	"<line7> log.warn(""Wrong result type: {}"", json.getNodeType())"
task5	"<line7>      LOG.debug(""close result set error"", e);"	<line7>	logger.error(e.getMessage(), e)	<line7> logger.error(e.getMessage(), e)
task5	<line22>      log.error(portalException, portalException);	<line22>	log.error(portalException, portalException)	<line22> log.error(portalException, portalException)
task5	<line5>      log.error(exception, exception);	<line5>	log.error(exception, exception)	<line5> log.error(exception, exception)
task5	"<line3>      logger.debug(""Adding PhysicalNetworkServiceProvider VirtualRouter"");"	<line41>	"logger.warn(""Exception while adding PhysicalNetworks"", e)"	"<line41> logger.warn(""Exception while adding PhysicalNetworks"", e)"
task5	"<line2>    LOG.debug(""Getting Types: {}."", ManagementBusInvocationPluginRest.TYPES);"	<line6>	"LOG.debug(""SupportedTypes: {}"", types)"	"<line6> LOG.debug(""SupportedTypes: {}"", types)"
task5	"<line15>      logger.error(""exception"", e);"	<line15>	"logger.error(""exception"", e)"	"<line15> logger.error(""exception"", e)"
task5	"<line3>    Log.debug(""INI FILE:"" + commaSeparatedFilePaths);"	<line5>	"Log.info(""No metadata connection"")"	"<line5> Log.info(""No metadata connection"")"
task5	"<line6>      logger.warn(""Module[{}] Received command {} with illegal value {} on channel {}"",thing.getUID(),command,e.getMessage(),channelUID.getId());"	<line6>	"logger.debug(""Illegal property value"", e)"	"<line6> logger.debug(""Illegal property value"", e)"
task5	"<line1>    log.debug(""Copying local file: {} to remote file: {} (in host {})"", origFile, targetFile, host);"	<line1>	"log.debug(""SCP {} {}"", origFile, targetFile)"	"<line1> log.debug(""SCP {} {}"", origFile, targetFile)"
task5	<line13>        log.debug(exception, exception);	<line13>	log.debug(exception, exception)	<line13> log.debug(exception, exception)
task5	"<line12>      logger.error(""[closeAllConnections] {}"", e);"	<line12>	"LOG.error(""Cannot close all connections"", e)"	"<line12> LOG.error(""Cannot close all connections"", e)"
task5	"<line54>      logger.warn("""", ex);"	<line26>	"logger.debug(""testSearchWithOwnerAndEnum"")"	"<line26> logger.debug(""testSearchWithOwnerAndEnum"")"
task5	"<line20>          LOG.debug(""Matrix param {} :: {}"", entry.getKey(), entry.getValue());"	<line19>	"LOG.trace(""Setting matrix parameter: {}={}"", entry.getKey(), entry.getValue())"	"<line19> LOG.trace(""Setting matrix parameter: {}={}"", entry.getKey(), entry.getValue())"
task5	"<line9>      LOGGER.warn(""Could not cancel sync repl request"", e);"	<line9>	"LOG.debug(""Restart search failed"", e)"	"<line9> LOG.debug(""Restart search failed"", e)"
task5	"<line1>    logger.info(""Downloading genome info ..."");"	<line14>	"logger.info(""Genome info JSON files were created successfully."")"	"<line14> logger.info(""Genome info JSON files were created successfully."")"
task5	"<line11>    log.info(""User's info:\n"" + formatJson(contents));"	<line10>	log.info(contents)	<line10> log.info(contents)
task5	"<line5>        logger.error(""{}"", e.getLocalizedMessage(), e);"	<line5>	"logger.warn(""Could not disconnect from Elasticsearch cluster"", e)"	"<line5> logger.warn(""Could not disconnect from Elasticsearch cluster"", e)"
task5	<line6>      log.error(exception, exception);	<line6>	log.error(exception, exception)	<line6> log.error(exception, exception)
task5	"<line2>    logger.debug(""testRedefineTerms"");"	<line2>	"logger.debug(""testRedefineTerms"")"	"<line2> logger.debug(""testRedefineTerms"")"
task5	"<line2>    LOG.info(""Executing operation isItemModifiedByOther"");"	<line2>	"LOG.info(""Executing operation isItemModifiedByOther"")"	"<line2> LOG.info(""Executing operation isItemModifiedByOther"")"
task5	"<line2>    LOGGER.info(""Received request for number of active resources"");"	<line2>	"LOGGER.debug(""Number of resources: "" + ResourceManager.getTotalNumberOfWorkers())"	"<line2> LOGGER.debug(""Number of resources: "" + ResourceManager.getTotalNumberOfWorkers())"
task5	"<line23>          logger.error(""Unexpected interruption when waiting for next start up check"", e);"	<line22>	"logger.error(""Interrupted while waiting for seed nodes to start up."", e)"	"<line22> logger.error(""Interrupted while waiting for seed nodes to start up."", e)"
task5	"<line2>    logger.info(""Starting slave.. slaveId - {}, environmentIds - {}"",slaveId,apolloConfiguration.getSlave().getSlaveCsvEnvironments());"	<line3>	"logger.info(""cleanupUnusedSlaves task scheduled to run in {} minutes"",CLEANUP_SLAVES_INTERVAL_IN_MINUTES)"	"<line3> logger.info(""cleanupUnusedSlaves task scheduled to run in {} minutes"",CLEANUP_SLAVES_INTERVAL_IN_MINUTES)"
task5	"<line9>      log.debug(""Error generating export report {} for {}."", report, key.user.email, e);"	<line9>	"log.debug(""Error generating report"", e)"	"<line9> log.debug(""Error generating report"", e)"
task5	<line51>      LOG.error(new AuthenticationException(AuthenticationException.UNNOWN_EXCEPTION, ne.getMessage()));	<line51>	LOG.error(new AuthenticationException(AuthenticationException.UNNOWN_EXCEPTION, ne.getMessage()))	<line51> LOG.error(new AuthenticationException(AuthenticationException.UNNOWN_EXCEPTION, ne.getMessage()))
task5	"<line8>      logger.error(""Create topic:{} addr:{} failed"", addr, topic);"	<line8>	"logger.error(""create topic error."", e)"	"<line8> logger.error(""create topic error."", e)"
task5	"<line2>    log.info(""onJointAngles {}"", angleMap);"	<line2>	"log.info(""onJointAngles {}"", angleMap)"	"<line2> log.info(""onJointAngles {}"", angleMap)"
task5	"<line3>      log.error(""Buyer user email is required"");"	<line3>	"log.error(""Buyer user email is required"")"	"<line3> log.error(""Buyer user email is required"")"
task5	"<line22>      logger.debug(""Target ["" + title + ""] did not match the query SMARTS. Skipping constraints"");"	<line22>	"logger.info(""The target molecule has fewer atoms than the query: "" + title)"	"<line22> logger.info(""The target molecule has fewer atoms than the query: "" + title)"
task5	"<line6>      logger.info(""Using default value of "" + Arrays.toString(defaultValue) + "" for property "" + key);"	<line6>	log.debug(e.getMessage())	<line6> log.debug(e.getMessage())
task5	"<line7>    logger.debug(""Sending request %s: %s"", request.hashCode(), request.getRequestLine());"	<line9>	"log.debug(""Converting request to native: {}"", request)"	"<line9> log.debug(""Converting request to native: {}"", request)"
task5	<line16>        logger.debug(responseAsString);	<line19>	"logger.error(""IOException: "" + ioe.getMessage(), ioe)"	"<line19> logger.error(""IOException: "" + ioe.getMessage(), ioe)"
task5	"<line8>    LOGGER.error(""Failed to install style class : "" + cl.getName());"	<line5>	"LOGGER.debug(""Installing style {}"", cl.getName())"	"<line5> LOGGER.debug(""Installing style {}"", cl.getName())"
task5	"<line2>    logger.debug(""C --> P {}"", record);"	<line2>	"LOGGER.debug(""ReadFromClient: "" + record)"	"<line2> LOGGER.debug(""ReadFromClient: "" + record)"
task5	"<line7>      log.error(""Error while checking whether "" + _app + "" exists in backend: "" + e.getMessage());"	<line7>	"LOG.error(""Error while checking existence of app in backend"", e)"	"<line7> LOG.error(""Error while checking existence of app in backend"", e)"
task5	"<line29>            log.trace(""{},{} is not at the centre of {}!"",lr.getDecimalLatitude(),lr.getDecimalLongitude(),lr.getStateProvince());"	<line29>	"log.trace(""No state province centres check for occurrence {}"", lr.getKey())"	"<line29> log.trace(""No state province centres check for occurrence {}"", lr.getKey())"
task5	"<line4>      log.debug(""Subscribed to: "" + pattern);"	<line4>	"log.debug(""Subscribed to pattern: {}"", pattern)"	"<line4> log.debug(""Subscribed to pattern: {}"", pattern)"
task5	"<line11>          LOG.warn(""No test results were found in the report file:"" + "" "" + path);"	<line11>	"LOG.warn(""Unable to read json report: "" + path, e)"	"<line11> LOG.warn(""Unable to read json report: "" + path, e)"
task5	"<line12>      log.error(""You've specified an unsupported baud rate"");"	<line12>	"logger.warn(""Unsupported baud rate: {}"", baudRate)"	"<line12> logger.warn(""Unsupported baud rate: {}"", baudRate)"
task5	"<line10>      logger.debug(""Could not get appliance command"", e);"	<line10>	"logger.debug(""Failed to get appliance command."", e)"	"<line10> logger.debug(""Failed to get appliance command."", e)"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line9>      LOG.error(""Request failed: {}."", e.getMessage());"	<line9>	LOG.error(e.toString())	<line9> LOG.error(e.toString())
task5	"<line14>      log.info(""objStat indicates collection type that does not support this operation:{}"", objStat);"	<line12>	"log.info(""setAccessPermissionReadInAdminMode on absPath:{}"", absolutePath)"	"<line12> log.info(""setAccessPermissionReadInAdminMode on absPath:{}"", absolutePath)"
task5	"<line6>      logger.error(""Update alert rule last check time, "" + validAlertRuleList, e);"	<line6>	"log.error(""Update alert rule last check time failed."", e)"	"<line6> log.error(""Update alert rule last check time failed."", e)"
task5	"<line2>    logger.trace(""Firing Disconnected!"");"	<line2>	"logger.info(""Fire disconnected"")"	"<line2> logger.info(""Fire disconnected"")"
task5	"<line6>        logger.debug(""No '"" + paramOrCookieName + ""' request param or cookie found"");"	<line6>	"logger.debug(""No site name passed in as a parameter or in a cookie. Returning null."")"	"<line6> logger.debug(""No site name passed in as a parameter or in a cookie. Returning null."")"
task5	"<line1>    LOGGER.trace(""mainMenuPerformed: {}"", menu);"	<line1>	"log.debug(""Main menu item {} performed"", menu)"	"<line1> log.debug(""Main menu item {} performed"", menu)"
task5	"<line3>      LOGGER.trace(format(""Create typed query for SELECT : %s"", regularStatement.getQueryString()));"	<line3>	"LOGGER.trace(format(""Returning typed query for statement %s"", regularStatement.getQueryString()))"	"<line3> LOGGER.trace(format(""Returning typed query for statement %s"", regularStatement.getQueryString()))"
task5	"<line8>      logger.error(""[logTransaction]"" + type + "","" + name + "","" + task, th);"	<line7>	"LOG.error(""Exception: "", th)"	"<line7> LOG.error(""Exception: "", th)"
task5	"<line10>      LOGGER.info(""Unsubscribe failed for mailbox {}"", mailboxName, e);"	<line10>	LOGGER.warn(e.getMessage(), e)	<line10> LOGGER.warn(e.getMessage(), e)
task5	"<line20>    log.info(""init data source success"");"	<line1>	"LOG.info(""db.url: "" + config.getDbUrl())"	"<line1> LOG.info(""db.url: "" + config.getDbUrl())"
task5	"<line2>    LOGGER.info(""testvoidInRPC() is called!"");"	<line2>	"logger.info(""testvoidInRPC"")"	"<line2> logger.info(""testvoidInRPC"")"
task5	<line23>      logger.warn(sb.toString());	<line23>	logger.warn(sb.toString())	<line23> logger.warn(sb.toString())
task5	"<line1>    logger.debug(""Creating user..."");"	<line1>	"logger.debug(""Creating user"")"	"<line1> logger.debug(""Creating user"")"
task5	"<line2>    LOG.trace(""access to save"");"	<line10>	"LOG.error(""BAD_REQUEST"", e)"	"<line10> LOG.error(""BAD_REQUEST"", e)"
task5	"<line4>      logger.error(""could not create platform mbean server: {}"", t.getMessage(), t);"	<line4>	"logger.error(""Error accessing Platform MBean Server"", t)"	"<line4> logger.error(""Error accessing Platform MBean Server"", t)"
task5	"<line1>    logger.debug(""MetadataDB executeUpdate:"" + s);"	<line1>	"logger.debug(""JDBC::executeUpdate"")"	"<line1> logger.debug(""JDBC::executeUpdate"")"
task5	"<line4>        Logger.debug(this, ""attempting to lock"");"	<line4>	"Logger.debug(this, ""Failed to acquire lock: "" + this.toString())"	"<line4> Logger.debug(this, ""Failed to acquire lock: "" + this.toString())"
task5	"<line24>        LOGGER.info(""No model definition found in "" + submodel.getId() + ""."");"	<line24>	"logger.debug(""ModelDefinition \""{}\"" does not have a CompModelPlugin"",modelDefinition.getElementName())"	"<line24> logger.debug(""ModelDefinition \""{}\"" does not have a CompModelPlugin"",modelDefinition.getElementName())"
task5	"<line5>    LOGGER.debug(""Patch User {} with {}"", id, partialDto);"	<line5>	"LOGGER.debug(""Patch {} with {}"", id, partialDto)"	"<line5> LOGGER.debug(""Patch {} with {}"", id, partialDto)"
task5	"<line11>    LOG.info("">>> Model : "" + model.toString());"	<line12>	LOG.info(model.toString())	<line12> LOG.info(model.toString())
task5	"<line10>      LOG.debug(""Load from ODocument, field:{}, schemaType:{}, docField:{}, storeType:{}"",new Object[] {field.name(), fieldSchema.getType(), docf, storeType});"	<line8>	"LOG.debug(""Loading field: {} with type: {} from OrientDB"", docf, storeType)"	"<line8> LOG.debug(""Loading field: {} with type: {} from OrientDB"", docf, storeType)"
task5	"<line7>        LOG.error(""Unable to process "" + hostname + "" as a valid hostname"", e);"	<line7>	"LOG.error(""Error creating URL"", e)"	"<line7> LOG.error(""Error creating URL"", e)"
task5	"<line10>        LOGGER.warn(""Processing notifications for this run will be stopped, because the circuit breaker is""+ "" open."",exc);"	<line10>	"LOGGER.error(""Resend notifications failed due to circuit breaker open"", exc)"	"<line10> LOGGER.error(""Resend notifications failed due to circuit breaker open"", exc)"
task5	"<line1>    log.error(""poll invoked but consumer stopped for topic"" + topic, new RuntimeException(""stacktrace""));"	<line1>	"log.error(""An error has occurred while retrieving the configuration."")"	"<line1> log.error(""An error has occurred while retrieving the configuration."")"
task5	"<line8>        logger.error(""Failed to parse the value to get the parameter id."", e);"	<line8>	"log.error(""Can't parse param index: {}"", paramNodeValue)"	"<line8> log.error(""Can't parse param index: {}"", paramNodeValue)"
task5	"<line4>    logger.debug(""Compiling Groovy code:\n{}"", code);"	<line2>	"log.debug(""Initializing Groovy script"")"	"<line2> log.debug(""Initializing Groovy script"")"
task5	"<line3>    log.info(""ClientObserver -> onRegistrationSuccess...  EndpointName [{}] [{}]"",request.getEndpointName(),registrationID);"	<line3>	"log.info(""onRegistrationSuccess: server={}, request={}, registrationID={}"",server,request,registrationID)"	"<line3> log.info(""onRegistrationSuccess: server={}, request={}, registrationID={}"",server,request,registrationID)"
task5	"<line3>      log.debug(""Node {"" + nodeName + ""} joined the cluster."");"	<line3>	"log.debug(""Cluster node joined: {}"", nodeName)"	"<line3> log.debug(""Cluster node joined: {}"", nodeName)"
task5	"<line30>          LOG.warn(""Failed to choose a bookie from {} : ""+ ""excluded {}, fallback to choose bookie randomly from the cluster."",bookieNodeToReplace.getNetworkLocation(),excludeBookies);"	<line30>	"LOG.error(""Failed to select a bookie from region {} : "", regionForBookieToReplace, e)"	"<line30> LOG.error(""Failed to select a bookie from region {} : "", regionForBookieToReplace, e)"
task5	"<line18>    logger.debug(""Storage path updated to {}"", path);"	<line15>	"logger.warn(""The path '{}' does not exist, using the default path '{}' instead."", newPath, path)"	"<line15> logger.warn(""The path '{}' does not exist, using the default path '{}' instead."", newPath, path)"
task5	"<line3>      LOG.debug(""GetVertexStatus via AM for app: "" + appId + "" dag: "" + dagId + "" vertex: "" + vertexName);"	<line3>	"LOG.debug(""GetVertexStatus for vertex: "" + vertexName)"	"<line3> LOG.debug(""GetVertexStatus for vertex: "" + vertexName)"
task5	"<line3>      LOGGER.trace(""->COLLECTED POINT X VALUE(LON): "" + myCurrentLon);"	<line3>	"LOGGER.trace(""collectPointX: "" + myCurrentLon)"	"<line3> LOGGER.trace(""collectPointX: "" + myCurrentLon)"
task5	<line1>    log.warn(StringUtils.safeFormat(message, formatArgs), t);	<line1>	logger.warn(t, message, formatArgs)	<line1> logger.warn(t, message, formatArgs)
task5	"<line9>    logger.info(""Attempting to start the connector with an INVALID configuration, so MULTIPLE error""+ "" messages and exceptions will appear in the log"");"	<line15>	log.info(msg)	<line15> log.info(msg)
task5	<line4>      LOGGER.fatal(tcx.getMessageAndLocation());	<line4>	"LOG.warn(""Failed to create stylesheet with {}"", stylesheet, tcx)"	"<line4> LOG.warn(""Failed to create stylesheet with {}"", stylesheet, tcx)"
task5	"<line7>      logger.error(""Error updating configuration"", e);"	<line7>	"logger.error(""Error updating system configuration"", e)"	"<line7> logger.error(""Error updating system configuration"", e)"
task5	"<line12>    logger.info(""Creating entity in fabric {} at {}{}"",new Object[] {this,location,(creation != null && !creation.isEmpty() ? "", properties "" + creation : """")});"	<line1>	"log.debug(""Adding cluster {} at {}"", getEntityType().getSimpleName(), location)"	"<line1> log.debug(""Adding cluster {} at {}"", getEntityType().getSimpleName(), location)"
task5	"<line2>      LOGGER.warn(""Switching the order manager used by the ElevationManager."");"	<line2>	"LOGGER.error(""Order manager changed, but not correctly initialized before use."")"	"<line2> LOGGER.error(""Order manager changed, but not correctly initialized before use."")"
task5	<line23>      log.error(systemException, systemException);	<line23>	log.error(systemException, systemException)	<line23> log.error(systemException, systemException)
task5	<line23>      log.error(systemException, systemException);	<line23>	log.error(systemException, systemException)	<line23> log.error(systemException, systemException)
task5	"<line55>        log.info(""*** Starting test: "" + msg);"	<line55>	"log.info(""Starting: "" + msg)"	"<line55> log.info(""Starting: "" + msg)"
task5	"<line22>      LOGGER.warn(""Transformer {}. Regulating control forced to off. Only one control is supported"", id);"	<line17>	"LOGGER.info(""Defining active power control for winding {}"", winding.getWindingId())"	"<line17> LOGGER.info(""Defining active power control for winding {}"", winding.getWindingId())"
task5	"<line2>    log.info(""Service Started"");"	<line1>	"log.info(""Starting service "" + serviceName)"	"<line1> log.info(""Starting service "" + serviceName)"
task5	"<line8>        log.error(""Some processors are still active"");"	<line8>	"log.info(""Some thread pools didn't stop in the expected time, you might see increasing number of""+ "" threads"")"	"<line8> log.info(""Some thread pools didn't stop in the expected time, you might see increasing number of""+ "" threads"")"
task5	"<line1>    log.debug(""failed deposit: {}"", message);"	<line1>	"log.error(""Failing job: {}"", message)"	"<line1> log.error(""Failing job: {}"", message)"
task5	"<line9>        log.warn(Messages.getString(""TableViewerCreator.columnNoIBeanProperty"", column.getId(), column.getTitle()));"	<line9>	"LOG.warn(""CellEditor is defined but no bean property accessors are defined for the column. The""+ "" CellEditor will not be used."")"	"<line9> LOG.warn(""CellEditor is defined but no bean property accessors are defined for the column. The""+ "" CellEditor will not be used."")"
task5	"<line2>    logger.debug(""Getting product count: "", super.getProductCount());"	<line2>	"logger.debug(""Calling getProductCount()"")"	"<line2> logger.debug(""Calling getProductCount()"")"
task5	"<line10>      LOGGER.error(""Unable to perform aggregation on non-geotools feature adapter '""+ adapter.getTypeName()+ ""'"");"	<line10>	"LOGGER.error(""Unable to create aggregation using the provided DataTypeAdapter.  The DataTypeAdapter""+ "" must be of the correct type in order to use the common index aggregation."")"	"<line10> LOGGER.error(""Unable to create aggregation using the provided DataTypeAdapter.  The DataTypeAdapter""+ "" must be of the correct type in order to use the common index aggregation."")"
task5	"<line9>      logger.info(""Installing {}"", plugin.getClass().getName());"	<line9>	"LOG.info(""Installing plugin: {}"", plugin.getClass().getName())"	"<line9> LOG.info(""Installing plugin: {}"", plugin.getClass().getName())"
task5	<line3>    LOG.debug(QUERY_CONVERTED_QUERY, queryJsonNode);	<line2>	"LOG.debug(""Delete by query on type {}"", typeDescriptor.getType())"	"<line2> LOG.debug(""Delete by query on type {}"", typeDescriptor.getType())"
task5	"<line10>    LOGGER.info(""Certificate created (SHA-256 fingerprint: {})"", fingerprint);"	<line10>	"LOGGER.info(""Generated certificate with serial number {} and fingerprint {}"",certificate.getSerialNumber(),fingerprint)"	"<line10> LOGGER.info(""Generated certificate with serial number {} and fingerprint {}"",certificate.getSerialNumber(),fingerprint)"
task5	"<line4>      log.error(""invalid parameters for validator "" + abstractParameter.getClass().getName());"	<line4>	"log.error(""invalid parameters for validator "" + abstractParameter.getClass().getName())"	"<line4> log.error(""invalid parameters for validator "" + abstractParameter.getClass().getName())"
task5	"<line3>    log.debug(""updateContents:: npanels IS null ? {}, client IS null ? {}"",npanel == null,getClient() == null);"	<line7>	"log.info(""[updateContents] setting panel to ""+ npanel.getClass().getName()+ "" for fragment ""+ f)"	"<line7> log.info(""[updateContents] setting panel to ""+ npanel.getClass().getName()+ "" for fragment ""+ f)"
task5	<line20>      log.error(errmsg, e);	<line20>	log.error(errmsg, e)	<line20> log.error(errmsg, e)
task5	"<line8>        log.warn(""Unable to calculate installation path. setting to 'unknown'"");"	<line8>	"log.warn(""Package installation path is null for package {}. This is a deprecated way of storing""+ "" the installation path in the package metadata. The package content may not be available."",this)"	"<line8> log.warn(""Package installation path is null for package {}. This is a deprecated way of storing""+ "" the installation path in the package metadata. The package content may not be available."",this)"
task5	"<line7>        LOGGER.info(""Found vertex: "" + vertex);"	<line13>	"LOGGER.error(String.format(""Expected at least %d vertices of type %s. But found only %d"",minOccurrence, vertexType, occurrence))"	"<line13> LOGGER.error(String.format(""Expected at least %d vertices of type %s. But found only %d"",minOccurrence, vertexType, occurrence))"
task5	"<line4>    log.info(""Exporting the DwC Archive to Avro started {}"", inputPath);"	<line11>	"log.info(""Reading DwCA file from: {}"", inputPath)"	"<line11> log.info(""Reading DwCA file from: {}"", inputPath)"
task5	"<line10>      log.error(""Unable to handle unknown extensionPoint "" + extensionPoint);"	<line10>	"log.warn(""Unknown extension point: "" + extensionPoint)"	"<line10> log.warn(""Unknown extension point: "" + extensionPoint)"
task5	"<line10>      logger.warn(""failed while to convert message. applicationName:{}, original:{}, message:{}."",applicationName,resultMap,e.getMessage(),e);"	<line10>	logger.error(e.getMessage(), e)	<line10> logger.error(e.getMessage(), e)
task5	"<line9>        log.info(""No configuration supplied for table "" + table);"	<line9>	"log.warn(""No table config found for table "" + table)"	"<line9> log.warn(""No table config found for table "" + table)"
task5	"<line2>      ActiveMQRALogger.LOGGER.trace(""setRetryInterval("" + retryInterval + "")"");"	<line2>	"ActiveMQRALogger.LOGGER.trace(""setRetryInterval("" + retryInterval + "")"")"	"<line2> ActiveMQRALogger.LOGGER.trace(""setRetryInterval("" + retryInterval + "")"")"
task5	"<line19>      log.error(""Error while creating relation"", ce);"	<line19>	"log.error(""Error while checking relations for massnahme: "" + massnahme.getId(), ce)"	"<line19> log.error(""Error while checking relations for massnahme: "" + massnahme.getId(), ce)"
task5	<line5>        log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line5>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line5> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	"<line2>    logger.info(""Deleting host "" + fqdn + "" in cluster "" + clusterName);"	<line10>	"logger.info(""deleteHost() returned "" + deleteHostJson)"	"<line10> logger.info(""deleteHost() returned "" + deleteHostJson)"
task5	"<line20>    LOGGER.debug(""Creating new derivate with ID {}"", derivateID);"	<line22>	"LOGGER.debug(""Created new derivate with ID {}"", derivateID)"	"<line22> LOGGER.debug(""Created new derivate with ID {}"", derivateID)"
task5	"<line12>    log.info(""Pruned data for organisation unit: "" + organisationUnit);"	<line12>	"log.info(""Pruned data for organisation unit: "" + organisationUnit.getName())"	"<line12> log.info(""Pruned data for organisation unit: "" + organisationUnit.getName())"
task5	"<line1>    log.info(""...Deleting already-released AlterDDL in unreleased directory: ""+ unreleasedSqlFileList.size());"	<line3>	"log.info(""Deleting unreleased sql file: "" + unreleasedSqlFile.getAbsolutePath())"	"<line3> log.info(""Deleting unreleased sql file: "" + unreleasedSqlFile.getAbsolutePath())"
task5	"<line12>      log.error(""Error occured, Caused by {}."", e);"	<line12>	"log.error(""Error converting to UUID from byte array"", e)"	"<line12> log.error(""Error converting to UUID from byte array"", e)"
task5	"<line11>      LOGGER.error(""UTF-8 not supported?"", e);"	<line11>	"LOG.error(""Encountered error when trying to encode row and column family to UTF8 format."", e)"	"<line11> LOG.error(""Encountered error when trying to encode row and column family to UTF8 format."", e)"
task5	<line10>      logger.debug(e.getMessage(), e);	<line14>	"log.error(""Exception while running test {}"", testMethod, throwable)"	"<line14> log.error(""Exception while running test {}"", testMethod, throwable)"
task5	"<line7>      log.error(""Redis protocol error"", e);"	<line7>	"logger.error(""Protocol exception while trying to get the number of subscribers to a channel. ""+ ""This is a non-critical error, so it is ignored."",e)"	"<line7> logger.error(""Protocol exception while trying to get the number of subscribers to a channel. ""+ ""This is a non-critical error, so it is ignored."",e)"
task5	<line22>        logger.error(e1.getMessage(), e1);	<line39>	logger.error(e.getMessage(), e)	<line39> logger.error(e.getMessage(), e)
task5	"<line5>    log.info(""[{}] [{}] {} {}"",jobId.getName(),containerId.substring(0, Math.min(7, containerId.length())),stream.id(),stringBuilder.toString());"	<line6>	"log.debug(""Container [$containerId] for stream [$stream] with job [$jobId]"",stringBuilder.append(containerId).append(stream.getId()).append(jobId))"	"<line6> log.debug(""Container [$containerId] for stream [$stream] with job [$jobId]"",stringBuilder.append(containerId).append(stream.getId()).append(jobId))"
task5	<line13>      log.error(portalException, portalException);	<line13>	log.error(portalException, portalException)	<line13> log.error(portalException, portalException)
task5	"<line2>      log.debug(""{} moveTo {} {} {}"", getName(), topStom, midStom, lowStom);"	<line2>	"log.debug(""Move to "" + topStom + "" "" + midStom + "" "" + lowStom)"	"<line2> log.debug(""Move to "" + topStom + "" "" + midStom + "" "" + lowStom)"
task5	"<line3>    logger.warn(""{} for buffer with length {} was fragmented {} times (total fragmented operations: {})"",operation,buffer.limit(),iterations,total);"	<line3>	"logger.warn(""Fragmented {} operation: {} {}/{}"", operation, total, iterations)"	"<line3> logger.warn(""Fragmented {} operation: {} {}/{}"", operation, total, iterations)"
task5	"<line3>    log.debug(""Building command {} with arguments {}"", mc.getName(), argAssignmentList);"	<line11>	"log.debug(""{} preparing command {}"", this, cmdId)"	"<line11> log.debug(""{} preparing command {}"", this, cmdId)"
task5	"<line13>        logger.warn(""action=fetchWeather error date=""+ date+ "", lat=""+ latitude+ "", lon=""+ longitude+ "", city=""+ closestCity.geo_name);"	<line13>	"log.error(""Unable to fetch weather info"", e)"	"<line13> log.error(""Unable to fetch weather info"", e)"
task5	"<line10>        log.debug(String.format(""A cluster monitor is not found in autoscaler context "" + ""[cluster] %s"",clusterId));"	<line10>	"log.debug(String.format(""A cluster monitor is not found in autoscaler context "" + ""[cluster] %s"",clusterId))"	"<line10> log.debug(String.format(""A cluster monitor is not found in autoscaler context "" + ""[cluster] %s"",clusterId))"
task5	"<line1>    log.debug("""");"	<line1>	"log.debug("""")"	"<line1> log.debug("""")"
task5	"<line4>      Log.error(""Cannot create stable ID: No class specified! Will return generated ID: "" + id);"	<line4>	"Log.error(""No class name for the element id - using DOM.createUniqueId()"")"	"<line4> Log.error(""No class name for the element id - using DOM.createUniqueId()"")"
task5	"<line7>      LOGGER.debug(""Comparing '"" + lastActTZ + ""' with '"" + lastTimeZoneTZ + ""'."");"	<line3>	"logger.info(""The actual time zone is not the expected time zone. Actual: ""+ actualTZ+ "" Expected: ""+ expextedTZ)"	"<line3> logger.info(""The actual time zone is not the expected time zone. Actual: ""+ actualTZ+ "" Expected: ""+ expextedTZ)"
task5	"<line10>        logger.warn(""error while deleting remote repository"", e);"	<line9>	"logger.info(""repository deleted"")"	"<line9> logger.info(""repository deleted"")"
task5	"<line13>      log.error(""Unable to get asset entries"", exception);"	<line13>	log.error(exception, exception)	<line13> log.error(exception, exception)
task5	"<line2>    LOG.debug(""retrieving page "" + pageUrl + "" for group "" + groupId);"	<line2>	"LOG.debug(""retrieving page "" + pageUrl + "" for group "" + groupId)"	"<line2> LOG.debug(""retrieving page "" + pageUrl + "" for group "" + groupId)"
task5	"<line13>          LOG.info(""Failed to send audit message:"", e);"	<line2>	"LOG.debug(""Sending message: {} to: {}"", msg.getLength(), msg.getAddress())"	"<line2> LOG.debug(""Sending message: {} to: {}"", msg.getLength(), msg.getAddress())"
task5	"<line6>    log.info(""Inited ML service"");"	<line4>	"log.info(""Creating a new Session"")"	"<line4> log.info(""Creating a new Session"")"
task5	"<line13>        logger.debug(""Unable to get Cqs. Error: {}"", cqe.getMessage(), cqe);"	<line13>	"logger.debug(""Unable to retrieve the CQs."", cqe)"	"<line13> logger.debug(""Unable to retrieve the CQs."", cqe)"
task5	"<line6>      log.error(""session was null"");"	<line6>	"LOG.warn(""session is null"")"	"<line6> LOG.warn(""session is null"")"
task5	"<line32>          LOG.warn(String.format(""Can't deserialize matching rule order type for id '%s'. Falling back to default""+ "" (%s)"",orderTypeId, ArrangementMatchRule.DEFAULT_ORDER_TYPE.getId()));"	<line32>	"LOG.info(""Unknown order type '""+ orderTypeId+ ""', using default order type for matching rule."")"	"<line32> LOG.info(""Unknown order type '""+ orderTypeId+ ""', using default order type for matching rule."")"
task5	"<line4>      log.warn(""unable to request host state update: "", e);"	<line4>	"log.error(""Error sending control message to host state topic"", e)"	"<line4> log.error(""Error sending control message to host state topic"", e)"
task5	"<line3>        logger.debug(""abortTest: Disconnecting from distributed system and sending null chunk to abort"");"	<line3>	"logger.debug(""Aborting cache close by initiating local abort"")"	"<line3> logger.debug(""Aborting cache close by initiating local abort"")"
task5	"<line3>      LOG.warn(""Failed to locate region in '""+ tableName+ ""', row='""+ Bytes.toStringBinary(req.row)+ ""', locateType=""+ req.locateType,error);"	<line3>	"LOG.warn(""Locate request failed"", error)"	"<line3> LOG.warn(""Locate request failed"", error)"
task5	<line7>      log.error(exception, exception);	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	"<line19>      log.debug(""Failed to find radius clients"", e);"	<line19>	"log.error(""Failed to search radius clients"", e)"	"<line19> log.error(""Failed to search radius clients"", e)"
task5	"<line12>                    logger.warn(""Exception at getOAuthAccessTokenAsync"", e);"	<line12>	"logger.warn(""Exception at getOAuthRequestTokenAsync"", e)"	"<line12> logger.warn(""Exception at getOAuthRequestTokenAsync"", e)"
task5	"<line9>      LOG.error(""Error for model: {} and context: {}"", model, dataObject, e);"	<line9>	"LOG.error(""Can't get display object model"", e)"	"<line9> LOG.error(""Can't get display object model"", e)"
task5	"<line9>      logger.error(""Failed to obtain WifiInterfaceMode"", e);"	<line9>	"logger.error(""Failed to get WiFi interface mode"", e)"	"<line9> logger.error(""Failed to get WiFi interface mode"", e)"
task5	<line19>      LOG.error(message, e);	<line19>	logger.error(message, e)	<line19> logger.error(message, e)
task5	"<line1>    logger.trace(""setting passivator: {}"", p);"	<line1>	"logger.trace(""setting passivator: {}"", p)"	"<line1> logger.trace(""setting passivator: {}"", p)"
task5	"<line3>      logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Writing Boolean {}"", value);"	<line3>	"logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Writing boolean {}"", value)"	"<line3> logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Writing boolean {}"", value)"
task5	"<line6>      LOG.error(""Unable to get List of Trust Bundles: "", ex);"	<line6>	"LOG.error(""Unable to get Trust Bundles from Direct Config Service: "", ex)"	"<line6> LOG.error(""Unable to get Trust Bundles from Direct Config Service: "", ex)"
task5	"<line4>      logger.error(LoggingAnchor.THREE,MessageEnum.RA_GENERAL_EXCEPTION.toString(),ErrorCode.BusinessProcessError.getValue(),""Exception in encryptPassword "",e);"	<line4>	"log.error(""Security exception"", e)"	"<line4> log.error(""Security exception"", e)"
task5	"<line9>    LOGGER.info(""Logging EMR cluster definition being deleted. emrClusterDefinition={}"",xmlHelper.objectToXml(createEmrClusterDefinitionFromEntity(emrClusterDefinitionEntity), true));"	<line10>	"LOGGER.info(""Deleted EMR cluster definition with key {}"", emrClusterDefinitionKey)"	"<line10> LOGGER.info(""Deleted EMR cluster definition with key {}"", emrClusterDefinitionKey)"
task5	"<line5>      logger.error(""Test error"", e);"	<line5>	"logger.error(""Test error"", e)"	"<line5> logger.error(""Test error"", e)"
task5	<line38>      log.error(systemException, systemException);	<line38>	log.error(systemException, systemException)	<line38> log.error(systemException, systemException)
task5	"<line1>    logger.debug(""Deactivating ExampleComponent"");"	<line1>	"logger.info(""Deactivating {}"", this.properties.get(ConfigurationService.KURA_SERVICE_PID))"	"<line1> logger.info(""Deactivating {}"", this.properties.get(ConfigurationService.KURA_SERVICE_PID))"
task5	"<line10>      logger.error(""invokeInFxThreadAndWait() failed"", e);"	<line10>	"LOG.error(""Error waiting from fx thread"", e)"	"<line10> LOG.error(""Error waiting from fx thread"", e)"
task5	"<line10>    LOG.info(""Copy job progress: {}/{}"", progress.getProgress(), progress.getProgressMax());"	<line4>	"LOG.info(""Copying package A to target package"")"	"<line4> LOG.info(""Copying package A to target package"")"
task5	"<line22>          logger.error(method + "": bad or missing specifier!"");"	<line27>	"logger.error(op + "" failed on bad or missing Authority specifier"")"	"<line27> logger.error(op + "" failed on bad or missing Authority specifier"")"
task5	"<line2>    LOG.info(""-- Loading Hetu Metastore --"");"	<line3>	"LOG.info(""Load hetu metastore config file: {}"", HETUMETASTORE_CONFIG_FILE.getAbsolutePath())"	"<line3> LOG.info(""Load hetu metastore config file: {}"", HETUMETASTORE_CONFIG_FILE.getAbsolutePath())"
task5	<line2>    logger.info(string, o);	<line2>	logger.info(string, o)	<line2> logger.info(string, o)
task5	"<line26>      logger.warn(String.format(""Failed to dispatch event %s : Input must have a pluginName or a valid pluginKey""+ "" specified json=%s"",commandType, metadata.getEventJson()));"	<line28>	"logger.info(""Received plugin command {}"", commandType)"	"<line28> logger.info(""Received plugin command {}"", commandType)"
task5	"<line2>    logger.debug(""KHD start of testDispatchingJobsHigherMaxLoad"");"	<line2>	"log.info(""testDispatchingJobsHigherMaxLoad"")"	"<line2> log.info(""testDispatchingJobsHigherMaxLoad"")"
task5	"<line3>      log.debug(String.format(""Cancel action %s"", action));"	<line3>	"log.debug(String.format(""Cancel action %s"", action))"	"<line3> log.debug(String.format(""Cancel action %s"", action))"
task5	"<line6>                log.info(""JMXFetch is closing"");"	<line9>	"log.info(""Shutdown Hook Attached"")"	"<line9> log.info(""Shutdown Hook Attached"")"
task5	<line7>      log.error(e, e);	<line7>	log.error(e, e)	<line7> log.error(e, e)
task5	"<line4>    log.info(""creating work directory {}"", location);"	<line6>	"log.info(""Created work directory "" + location)"	"<line6> log.info(""Created work directory "" + location)"
task5	<line17>      log.error(UNEXPECTED_ERROR_OCCURRED, exception);	<line17>	log.error(UNEXPECTED_ERROR_OCCURRED, exception)	<line17> log.error(UNEXPECTED_ERROR_OCCURRED, exception)
task5	"<line3>      logger.info(""SegmentAppendTrieDict needn't to copy"");"	<line15>	"logger.warn(""No version exists in this dictionary"")"	"<line15> logger.warn(""No version exists in this dictionary"")"
task5	"<line9>      LOGGER.debug(""Error while loading internals: "" + e.getMessage());"	<line9>	"LOGGER.warn(""Error loading saved internals: "" + e.getMessage(), e)"	"<line9> LOGGER.warn(""Error loading saved internals: "" + e.getMessage(), e)"
task5	"<line5>        LOGGER.info(""PURGE ACTION - Purged nodeId {}"", nodeId);"	<line4>	"logger.info(""Purging node {}"", nodeId)"	"<line4> logger.info(""Purging node {}"", nodeId)"
task5	"<line2>    logger.info(""Downloading gene Ensembl data (gtf, pep, cdna, motifs) ..."");"	<line2>	"logger.info(""Downloading gene information ..."")"	"<line2> logger.info(""Downloading gene information ..."")"
task5	"<line2>    LOG.info(""Executing operation putTransformer"");"	<line2>	"LOG.info(""Executing operation putTransformer"")"	"<line2> LOG.info(""Executing operation putTransformer"")"
task5	"<line5>    LOG.debug(""Closing reader on path:{}"", path);"	<line3>	"LOG.debug(""Reader is not in the open state. Closing immediately."")"	"<line3> LOG.debug(""Reader is not in the open state. Closing immediately."")"
task5	<line53>      LOG.info(msgForLog);	<line22>	"LOG.debug(""No privileges were found for the current query. ""+ ""Subject: ""+ subject.getPrincipals().iterator().next().getName())"	"<line22> LOG.debug(""No privileges were found for the current query. ""+ ""Subject: ""+ subject.getPrincipals().iterator().next().getName())"
task5	"<line7>              log.error(""Failed to execute shutdownhook"", e);"	<line7>	"log.error(""unable to run shutdown hook"", e)"	"<line7> log.error(""unable to run shutdown hook"", e)"
task5	"<line50>      logger.error(""Start RocketMQ consumer error"", ex);"	<line50>	"LOG.error(""RocketMQ consumer start error."", ex)"	"<line50> LOG.error(""RocketMQ consumer start error."", ex)"
task5	"<line4>    LOGGER.debug(""getById {} / {}"",identifier,URLEncoder.encode(identifier, StandardCharsets.UTF_8.toString()));"	<line4>	"LOGGER.debug(""getById {} / {}"",identifier,URLEncoder.encode(identifier, StandardCharsets.UTF_8.toString()))"	"<line4> LOGGER.debug(""getById {} / {}"",identifier,URLEncoder.encode(identifier, StandardCharsets.UTF_8.toString()))"
task5	"<line1>    LOG.trace(""removeTableFromGroup: "" + groupName + "": "" + schemaName + ""."" + tableName);"	<line1>	"log.debug(""Removing table {} from group {}"", concat(schemaName, tableName), groupName)"	"<line1> log.debug(""Removing table {} from group {}"", concat(schemaName, tableName), groupName)"
task5	<line16>      log.error(systemException, systemException);	<line16>	log.error(systemException, systemException)	<line16> log.error(systemException, systemException)
task5	"<line3>    LOG.info(""Styx REST Interface incoming request uri={}, method={}"",request.getRequestURI(),request.getMethod());"	<line3>	"log.debug(""Request initialized: "" + request.getRequestURI())"	"<line3> log.debug(""Request initialized: "" + request.getRequestURI())"
task5	"<line4>        logger.debug(""String already represents JSON. Skipping conversion in favor of""+ "" 'getBytes(StandardCharsets.UTF_8'."");"	<line4>	"logger.debug(""Json string value is: "" + value)"	"<line4> logger.debug(""Json string value is: "" + value)"
task5	"<line13>      logger.warn(""failed to parse expiration date on SSR DOCS"");"	<line13>	"LOG.warn(""Invalid date format for travel document expiration date"")"	"<line13> LOG.warn(""Invalid date format for travel document expiration date"")"
task5	"<line32>      logger.error(""getByCriteriaWithAliasByOrder failed, criteria = "" + criterion.toString(), e);"	<line32>	"logger.error(""getByCriteriaWithAliasByOrder failed, criteria = "" + criterion.toString(), e)"	"<line32> logger.error(""getByCriteriaWithAliasByOrder failed, criteria = "" + criterion.toString(), e)"
task5	"<line1>    logger.trace(""supported identifiers: {}, searching for objects {}"", supportedIdentifiers, cosemObjects);"	<line8>	"logger.debug(""filtered {} to {}"", cosemObjects, filteredValues)"	"<line8> logger.debug(""filtered {} to {}"", cosemObjects, filteredValues)"
task5	"<line6>        log.debug(""Fill "" + filler.fillerId + "": Creating "" + query.getLanguage() + "" query executer"");"	<line6>	"log.debug(""query language="" + query.getLanguage())"	"<line6> log.debug(""query language="" + query.getLanguage())"
task5	"<line2>    LOG.info(""Finished rollback on [{0}/{1}]"", _shard, _table);"	<line4>	"log.info(""Renaming {} to {}"", name, rename(name, BADROWIDS))"	"<line4> log.info(""Renaming {} to {}"", name, rename(name, BADROWIDS))"
task5	"<line6>      LOG.debug(""While reading schema on connector {}"", connector, e);"	<line6>	"log.error(""Failed to get object class info"", e)"	"<line6> log.error(""Failed to get object class info"", e)"
task5	"<line3>    LOGGER.debug(""clientNonce: ""+ ArrayConverter.bytesToHexString(clientEsniInne.getClientNonce().getValue()));"	<line3>	"LOGGER.debug(""ClientNonce: "" + ArrayConverter.bytesToHexString(clientNonce))"	"<line3> LOGGER.debug(""ClientNonce: "" + ArrayConverter.bytesToHexString(clientNonce))"
task5	<line6>      LOG.error(e.getLocalizedMessage());	<line6>	"LOG.error(""Unable to create SubjectConfirmationData"", e)"	"<line6> LOG.error(""Unable to create SubjectConfirmationData"", e)"
task5	"<line21>          logger.debug(""Issuing consumed until request to persistence manager for topic: {} with min-id: {}"",topic.toStringUtf8(),minConsumedMessage);"	<line21>	"logger.debug(""Updating min consumed message for topic: {} to: {}"", topic, minConsumedMessage)"	"<line21> logger.debug(""Updating min consumed message for topic: {} to: {}"", topic, minConsumedMessage)"
task5	"<line13>      logger.error(""Error while deleting attributeId: "" + id, e);"	<line13>	"logger.error(""Error while deleting attribute in Tagger"", e)"	"<line13> logger.error(""Error while deleting attribute in Tagger"", e)"
task5	"<line3>    log.info(""Found: "" + context);"	<line3>	"log.info(""jaxb context: {}"", context)"	"<line3> log.info(""jaxb context: {}"", context)"
task5	"<line10>      LOGGER.error(""Could not invoke configuration listeners."", e);"	<line10>	"log.error(""Could not invoke configuration listeners"", e)"	"<line10> log.error(""Could not invoke configuration listeners"", e)"
task5	"<line13>      log.error(""Shutdown failed: {}"", e.getMessage(), e);"	<line13>	"LOG.error(""Error during close: {}"", e.getMessage())"	"<line13> LOG.error(""Error during close: {}"", e.getMessage())"
task5	"<line4>      log.warn(""Invalid HTTP header specified in ""+ ACCESS_CONTROL_REQUEST_HEADERS+ "" '""+ headerName+ ""'. ""+ ""It will be ignored and not attached to the ""+ ACCESS_CONTROL_ALLOW_HEADERS+ "" response header"");"	<line4>	"LOG.warn(""The '{}' header is not allowed to be added to the response."", headerName)"	"<line4> LOG.warn(""The '{}' header is not allowed to be added to the response."", headerName)"
task5	"<line1>    LOG.info(""Disconnecting from broker {} on user {}"", config.url(), config.username());"	<line1>	"log.debug(""Disconnecting from JMS server"")"	"<line1> log.debug(""Disconnecting from JMS server"")"
task5	"<line11>      logger.error(""Study ID is null"");"	<line11>	"logger.debug(""No metadata found for study {}"", studyId)"	"<line11> logger.debug(""No metadata found for study {}"", studyId)"
task5	<line30>      LOG.error(e.getMessage(), e);	<line30>	"LOGGER.error(""Error while bundling visualization packages"", e)"	"<line30> LOGGER.error(""Error while bundling visualization packages"", e)"
task5	<line16>      LOGGER.warn(PROBLEM_GETTING_COMMITTEE_PROPOSAL_FOR_ID_S_FROM_DATA_RIKSDAGEN_SE, id);	<line16>	LOGGER.warn(PROBLEM_GETTING_DATA_FROM_RIKSDAGEN_SE, e)	<line16> LOGGER.warn(PROBLEM_GETTING_DATA_FROM_RIKSDAGEN_SE, e)
task5	"<line5>        log.debug(""found Slave DataSource name="" + slaveName);"	<line10>	"logger.info(""created slave datasource: "" + slaveName)"	"<line10> logger.info(""created slave datasource: "" + slaveName)"
task5	<line8>      log.error(exception, exception);	<line8>	log.error(exception, exception)	<line8> log.error(exception, exception)
task5	"<line1>    logger.trace(""{}: ZclCluster.addAttributeListener adding {}"",zigbeeEndpoint.getEndpointAddress(),listener);"	<line1>	"logger.trace(""Adding attribute listener {}"", listener)"	"<line1> logger.trace(""Adding attribute listener {}"", listener)"
task5	"<line11>        logger.warn(""Unable to copy relationship property {} of relationship {} to {}: {}"",new Object[] {sourcePropertyKey, rel.getUuid(), destPropertyKey, fex.getMessage()});"	<line11>	"logger.warn("""", fex)"	"<line11> logger.warn("""", fex)"
task5	"<line6>        LOGGER.debug(""error when trying to instal artifacts"", e);"	<line6>	"LOGGER.debug(""error when trying to instal artifacts"", e)"	"<line6> LOGGER.debug(""error when trying to instal artifacts"", e)"
task5	"<line2>    logger.debug(""bridgeStatusChanged {} for thing {}"", bridgeStatusInfo, getThing().getUID());"	<line2>	"logger.debug(""Z-Way bridge status changed: {}"", bridgeStatusInfo)"	"<line2> logger.debug(""Z-Way bridge status changed: {}"", bridgeStatusInfo)"
task5	<line22>      log.error(systemException, systemException);	<line22>	log.error(systemException, systemException)	<line22> log.error(systemException, systemException)
task5	"<line6>        log.info(""Delete existing log (lastIndex '{}') and replace with received snapshot (index '{}')"",lastIndex,index);"	<line6>	"log.info(""Resetting log to snapshot index {}"", index)"	"<line6> log.info(""Resetting log to snapshot index {}"", index)"
task5	"<line2>    logger.info(""[testTokenCleanup] vm1 tests recursion"");"	<line2>	"logger.info(""[testTokenCleanup] vmGrantor creates grantor"")"	"<line2> logger.info(""[testTokenCleanup] vmGrantor creates grantor"")"
task5	"<line5>      logger.error(""event=failed_to_get_number_of_not_visible_messages queue_url="" + queueUrl);"	<line5>	"logger.error(""Unable to get queue not visible message count for queue: "" + queueUrl, ex)"	"<line5> logger.error(""Unable to get queue not visible message count for queue: "" + queueUrl, ex)"
task5	"<line26>          LOG.error(""Unable to encode parameter name or value: "" + paramName + ""="" + paramValue, ex);"	<line32>	"LOG.trace(""parameterized URL: {}"", ret.toString())"	"<line32> LOG.trace(""parameterized URL: {}"", ret.toString())"
task5	"<line38>          LOG.error(""failed to build BigtableAsyncAdmin"", e);"	<line2>	"LOG.info(""getAdminBuilder()"")"	"<line2> LOG.info(""getAdminBuilder()"")"
task5	"<line3>    LOG.debug(""Runtime context is prepared: {}"", RuntimeContext.get());"	<line3>	"LOG.info(""WindGate scripting API prepared"")"	"<line3> LOG.info(""WindGate scripting API prepared"")"
task5	"<line21>      log.error(""{}"", e.getMessage(), e);"	<line21>	"log.error(""Exception keeping 3 versions"", e)"	"<line21> log.error(""Exception keeping 3 versions"", e)"
task5	"<line2>    LOGGER.debug(""Stopping lock service"");"	<line2>	"logger.debug(""Stopping {}"", this.getClass().getName())"	"<line2> logger.debug(""Stopping {}"", this.getClass().getName())"
task5	"<line26>        logger.info(String.format(""Excpetion  in bucket index creation : %s"", ignor.getLocalizedMessage()),ignor);"	<line26>	"logger.info(""IndexMananger::getIndexes: Exception in getting indexes from "" + this.partitionedRegion,ignor)"	"<line26> logger.info(""IndexMananger::getIndexes: Exception in getting indexes from "" + this.partitionedRegion,ignor)"
task5	"<line2>      log.error(""unrecoverable error in task feeder or one of its mapper threads. immediately halting""+ "" jvm"",t);"	<line2>	"log.error(""unrecoverable error in task feeder or one of its mapper threads. immediately halting""+ "" jvm"",t)"	"<line2> log.error(""unrecoverable error in task feeder or one of its mapper threads. immediately halting""+ "" jvm"",t)"
task5	<line12>        logger.warn(JSONObjectUtil.toJsonString(statistic));	<line11>	"logger.debug(""Get sync task statistic: {}"", statistic)"	"<line11> logger.debug(""Get sync task statistic: {}"", statistic)"
task5	"<line3>    LOG.info(""Executing operation receiveMeshInterfaceObjects"");"	<line3>	"LOG.info(""receiveMeshInterfaceObjects"")"	"<line3> LOG.info(""receiveMeshInterfaceObjects"")"
task5	"<line3>    logger.debug(""List to delete: "" + uuid);"	<line4>	"logger.debug(""list deleted : "" + uuid)"	"<line4> logger.debug(""list deleted : "" + uuid)"
task5	"<line12>                    logger.warn(""Exception at getGeoDetails"", e);"	<line12>	"logger.warn(""Exception at getGeoDetails"", e)"	"<line12> logger.warn(""Exception at getGeoDetails"", e)"
task5	"<line18>      logger.info(e.getKey() + "" = "" + e.getValue());"	<line18>	"logger.info(""key: "" + e.getKey() + "" value: "" + e.getValue())"	"<line18> logger.info(""key: "" + e.getKey() + "" value: "" + e.getValue())"
task5	"<line6>      log.error(""Exception thrown"", e);"	<line6>	"log.error(""Error creating color scale "" + name, e)"	"<line6> log.error(""Error creating color scale "" + name, e)"
task5	"<line7>            LOG.debug(""{} cookie has been found and is being processed"", cookieName);"	<line7>	"LOG.debug(""Found JWT in cookie: "" + cookie.getValue())"	"<line7> LOG.debug(""Found JWT in cookie: "" + cookie.getValue())"
task5	"<line4>      LOG.error(""Unable to read {} from file {}: {}"",key,NhincConstants.MESSAGES_PROPERTY_FILE,ex.getLocalizedMessage(),ex);"	<line4>	"LOG.warn(""Failed to retrieve message for key "" + key, ex)"	"<line4> LOG.warn(""Failed to retrieve message for key "" + key, ex)"
task5	"<line2>    LOGGER.debug(""Parsing HelloRetryRequestMessage"");"	<line2>	"LOGGER.debug(""Parsing HelloRetryRequestMessage"")"	"<line2> LOGGER.debug(""Parsing HelloRetryRequestMessage"")"
task5	"<line9>      log.error(""Failed to start CloudStack"", e);"	<line15>	"logger.info(""Parent context initialized: "" + configuredParentName)"	"<line15> logger.info(""Parent context initialized: "" + configuredParentName)"
task5	"<line1>    log.info(""Truncating file [{0}] to {1}"", filepath, length);"	<line1>	"logger.trace(""truncate({})"", length)"	"<line1> logger.trace(""truncate({})"", length)"
task5	"<line3>      this.logger.error(""Invalid trace: {}"", invalidTrace);"	<line3>	"this.logger.error(""Invalid trace: {}"", invalidTrace)"	"<line3> this.logger.error(""Invalid trace: {}"", invalidTrace)"
task5	"<line6>        log.debug(""Cannot process event: {} as its class type: {} is not assignable with: {}"",new Object[] {event, event.getClass().getName(), eventClass.getName()});"	<line6>	"log.debug(""Ignoring event of wrong type {}"", event.getClass())"	"<line6> log.debug(""Ignoring event of wrong type {}"", event.getClass())"
task5	"<line3>      LOG.debug(""Switch idle"");"	<line2>	"LOG.info(""Read timed out"")"	"<line2> LOG.info(""Read timed out"")"
task5	"<line6>      LOG.trace(""Expanding envelope {} for offering {} to include {}"",offeringEnvelope,offering,envelope);"	<line4>	"LOG.trace(""Expanding envelope {} for offering {}"", envelope, offering)"	"<line4> LOG.trace(""Expanding envelope {} for offering {}"", envelope, offering)"
task5	"<line3>      logger.debug(""Failed to send a 413 Request Entity Too Large."", future.cause());"	<line2>	"log.info(""[doExecute] success: {}"", future.isSuccess())"	"<line2> log.info(""[doExecute] success: {}"", future.isSuccess())"
task5	"<line3>      log.info(""Found MagicAnnotation on field "" + field + "" of class "" + bean.getClass());"	<line3>	"log.debug(""Injecting magic value {} into field {} of bean {}"",annotation.value(),field.getName(),bean)"	"<line3> log.debug(""Injecting magic value {} into field {} of bean {}"",annotation.value(),field.getName(),bean)"
task5	<line10>      log.error(portalException, portalException);	<line10>	log.error(portalException, portalException)	<line10> log.error(portalException, portalException)
task5	<line18>      log.error(e.getMessage());	<line16>	"logger.error(""Exception: "", e)"	"<line16> logger.error(""Exception: "", e)"
task5	<line15>      LOGGER.info(new String(IOUtils.toByteArray(p.getInputStream())));	<line22>	"LOGGER.info(""Interrupted while waiting for preparation script"", e)"	"<line22> LOGGER.info(""Interrupted while waiting for preparation script"", e)"
task5	"<line1>    LOGGER.info(""attempt to migrate navigation"");"	<line1>	"log.info(""Migrating navigation files"")"	"<line1> log.info(""Migrating navigation files"")"
task5	"<line7>      log.error(""Failed to delete file: {}"", file, e);"	<line7>	"LOG.warn(""Could not delete file: "" + file, e)"	"<line7> LOG.warn(""Could not delete file: "" + file, e)"
task5	"<line15>      LOG.error(""error during save patient: {}"", e.getLocalizedMessage(), e);"	<line15>	"LOG.error(""error during save patient: {}"", e.getLocalizedMessage(), e)"	"<line15> LOG.error(""error during save patient: {}"", e.getLocalizedMessage(), e)"
task5	"<line3>    logger.trace(""bridgeDirectCommunicate(BCP: {},{}authenticated) called."",communication.name(),useAuthentication ? """" : ""un"");"	<line3>	"logger.debug(""Communication protocol: {}"", communication.name())"	"<line3> logger.debug(""Communication protocol: {}"", communication.name())"
task5	"<line16>    logger.info(""generated "" + target);"	<line16>	"logger.info(""generated "" + target)"	"<line16> logger.info(""generated "" + target)"
task5	"<line9>      LOG.trace(""New classifier created: {}\n{}"", classifierEntry.getKey(), classifierEntry.getValue());"	<line4>	"LOG.trace(""Pulled stats for policy {}"", rootIdentifier)"	"<line4> LOG.trace(""Pulled stats for policy {}"", rootIdentifier)"
task5	"<line3>      LOGGER.debug(""clients size: {}"", clients.size());"	<line3>	"LOGGER.debug(""Selecting first client"")"	"<line3> LOGGER.debug(""Selecting first client"")"
task5	<line2>    LOGGER.info(JSON.toJSONString(jobLogPo));	<line2>	"logger.info("">>>>>>>>> jobLogPo:{}"", jobLogPo)"	"<line2> logger.info("">>>>>>>>> jobLogPo:{}"", jobLogPo)"
task5	"<line28>      logger.warn(""Unable to create image reference for container {} due to {}"", id, e.getMessage(), e);"	<line5>	"logger.warn(""Extension is not initialized"")"	"<line5> logger.warn(""Extension is not initialized"")"
task5	"<line3>    logger.warn(""Invoking unimplemented method build"");"	<line3>	"log.info(""build()"")"	"<line3> log.info(""build()"")"
task5	"<line6>      log.warn(""Warning"", e);"	<line6>	"log.error(""loadClass"", e)"	"<line6> log.error(""loadClass"", e)"
task5	"<line2>    logger.debug(""{} stopped"", this);"	<line1>	"log.info(""Stopping {}"", this)"	"<line1> log.info(""Stopping {}"", this)"
task5	"<line1>    LOGGER.info(""Unblocked messages to "" + address);"	<line2>	"log.info(""Unblocking outgoing traffic to: "" + address)"	"<line2> log.info(""Unblocking outgoing traffic to: "" + address)"
task5	"<line11>          log.warn(""Unable to parse date "" + value, exception);"	<line11>	log.warn(exception, exception)	<line11> log.warn(exception, exception)
task5	"<line4>      log.error(""Cannot get home path"");"	<line4>	"log.warn(""Failed to get home path"", e)"	"<line4> log.warn(""Failed to get home path"", e)"
task5	"<line19>            Log.info(""Successfully executed flush operation ':"" + flushOp + ""'"");"	<line19>	"Log.debug(""Flush {} failed {}"", name, failure)"	"<line19> Log.debug(""Flush {} failed {}"", name, failure)"
task5	"<line22>      logger.warn(""Unable to extract the version of Restcomm Load Balancer currently running"", e);"	<line22>	"log.warn(""Unable to load release.properties"", e)"	"<line22> log.warn(""Unable to load release.properties"", e)"
task5	<line7>      LOGGER.error(t.getLocalizedMessage(), t);	<line7>	"logger.error(""Error while initializing keystore"", t)"	"<line7> logger.error(""Error while initializing keystore"", t)"
task5	"<line6>      LOG.debug(""Workflow {} does not exist possibly due to stale workflow cache"",state.workflowInstance().workflowId().toKey());"	<line6>	"log.warn(""Could not find workflow configuration for workflow instance {}"",state.workflowInstance())"	"<line6> log.warn(""Could not find workflow configuration for workflow instance {}"",state.workflowInstance())"
task5	"<line7>      LOGGER.warn(""Caught exception while closing result set '"" + resultSet + ""', ignoring."", e);"	<line7>	"logger.error(""Error closing result set"", e)"	"<line7> logger.error(""Error closing result set"", e)"
task5	"<line3>    LOG.debug(""Starting testKerbFileAccess() ..."");"	<line23>	"LOG.debug(""Expected exception: "" + expected)"	"<line23> LOG.debug(""Expected exception: "" + expected)"
task5	"<line2>    LOG.info(""\n===RunDaoTest.get===\n"");"	<line2>	"LOG.info(""\n===RunDaoTest.get===\n"")"	"<line2> LOG.info(""\n===RunDaoTest.get===\n"")"
task5	<line19>    LOG.error(message);	<line19>	LOG.warn(message, failures.get(0))	<line19> LOG.warn(message, failures.get(0))
task5	"<line2>    logger.trace(""refining "" + concept);"	<line8>	"logger.info(""Refinement set for concept "" + concept + "": "" + refinements)"	"<line8> logger.info(""Refinement set for concept "" + concept + "": "" + refinements)"
task5	"<line4>    LOGGER.trace(""QUERY getFeature(identifier): {}"", HibernateHelper.getSqlString(criteria));"	<line4>	"LOGGER.trace(""QUERY getFeature(identifier): {}"", HibernateHelper.getSqlString(criteria))"	"<line4> LOGGER.trace(""QUERY getFeature(identifier): {}"", HibernateHelper.getSqlString(criteria))"
task5	"<line2>    log.info(""Publish {}: Prepare target store for uploaded datasets"", jobId);"	<line2>	"log.info(""Start preparing target store for job: {}"", jobId)"	"<line2> log.info(""Start preparing target store for job: {}"", jobId)"
task5	"<line7>              LOGGER.info(""Processing message {}"", exchange.getIn().getBody());"	<line2>	"LOGGER.info(""Building routes..."")"	"<line2> LOGGER.info(""Building routes..."")"
task5	"<line7>      logger.info(""This contact has not been found by obm-sync"", e);"	<line7>	"logger.debug(""Error while checking for existing contact"", e)"	"<line7> logger.debug(""Error while checking for existing contact"", e)"
task5	"<line3>      logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Writing Long {}"", value);"	<line3>	"logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Writing Long {}"", value)"	"<line3> logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Writing Long {}"", value)"
task5	"<line8>    log.debug(""Creating server in port: "" + port);"	<line8>	"log.info(""Properties: {}"", properties)"	"<line8> log.info(""Properties: {}"", properties)"
task5	"<line12>      logger.debug(""Adding AWS {} mapping to database: {} points to {}, object version {}"",getStoreType(),storagePath,objectName,objectVersion);"	<line9>	"logger.error(""Error uploading object "" + objectName, e)"	"<line9> logger.error(""Error uploading object "" + objectName, e)"
task5	<line12>        log.debug(sb.toString());	<line12>	log.debug(sb.toString())	<line12> log.debug(sb.toString())
task5	"<line4>    log.debug(""Authenticating user '{}' through LDAP"", principal);"	<line7>	"log.debug(""Authenticating {}"", principal)"	"<line7> log.debug(""Authenticating {}"", principal)"
task5	"<line3>    LOG.info(""Fixed: "" + orcid + "" "" + correctedEmailHash);"	<line2>	"LOG.info(""Correcting email hash for "" + email)"	"<line2> LOG.info(""Correcting email hash for "" + email)"
task5	<line9>          log.debug(noSuchFileShortcutException, noSuchFileShortcutException);	<line9>	log.debug(noSuchFileShortcutException, noSuchFileShortcutException)	<line9> log.debug(noSuchFileShortcutException, noSuchFileShortcutException)
task5	"<line6>      log.debug(""Missing requested artifact. [artifact=({}), contract=({}), ""+ ""issuer=({}), messageId=({})]"",requestedArtifact,transferContract,issuerConnector,messageId);"	<line6>	"log.debug(""Missing requested artifact. [requestedArtifact=({})]"", requestedArtifact)"	"<line6> log.debug(""Missing requested artifact. [requestedArtifact=({})]"", requestedArtifact)"
task5	<line10>        LOGGER.error(t.toString(), t);	<line10>	"logger.error(""Error while notifying listener {}"", listener, t)"	"<line10> logger.error(""Error while notifying listener {}"", listener, t)"
task5	"<line12>      log.debug(""{} was redirected to {}"", redirectTarget, destinationUrl);"	<line2>	"log.info(""Starting up test client"")"	"<line2> log.info(""Starting up test client"")"
task5	"<line9>      LOG.fatal(""Error starting TajoMaster"", t);"	<line9>	"LOG.error(""Uncaught exception in Tajo Master main thread"", t)"	"<line9> LOG.error(""Uncaught exception in Tajo Master main thread"", t)"
task5	<line7>      log.error(exception, exception);	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	"<line6>      LOGGER.debug(""Received a [{}] operation, but no mapped metacardIds were available for product [{}]."",catalogOperation,referenceKey);"	<line6>	"LOGGER.info(MessageFormat.format(""Could not find metacard id for product reference {0}. No metacard was created for this""+ "" product in the {1} catalog."",referenceKey,catalogOperation))"	"<line6> LOGGER.info(MessageFormat.format(""Could not find metacard id for product reference {0}. No metacard was created for this""+ "" product in the {1} catalog."",referenceKey,catalogOperation))"
task5	"<line4>      LOG.info(""Stopping Vertx {}"", vertx);"	<line3>	"LOGGER.debug(""Stopping Vert.x event bus handler ..."")"	"<line3> LOGGER.debug(""Stopping Vert.x event bus handler ..."")"
task5	"<line11>    log.debug(""User "" + personDao.getLoggedPerson().getEmail() + "" retrieved list of education levels."");"	<line2>	"LOG.debug(""getEducationLevelList"")"	"<line2> LOG.debug(""getEducationLevelList"")"
task5	"<line3>      logger.error(""Usage: <node>"");"	<line3>	LOG.info(Messages.ARGS_LENGTH_ERROR)	<line3> LOG.info(Messages.ARGS_LENGTH_ERROR)
task5	"<line14>    logger.info(""Configuration updated"");"	<line14>	"logger.info(""openhab.rootUrl: {}"", rootUrl)"	"<line14> logger.info(""openhab.rootUrl: {}"", rootUrl)"
task5	"<line18>    logger.debug(""Start fetching pom!"");"	<line21>	"log.info(""Downloaded content: "" + downloaded)"	"<line21> log.info(""Downloaded content: "" + downloaded)"
task5	"<line9>      LOGGER.debug(""did store last authenticated timestamp for user [{}]"", user.getNickname());"	<line7>	"log.info(""Updating last authentication timestamp for user {} to {}"",user.getId(),millisNow)"	"<line7> log.info(""Updating last authentication timestamp for user {} to {}"",user.getId(),millisNow)"
task5	"<line29>      logger.error(""Error creating url"", e);"	<line29>	"logger.error(""Error creating url"", e)"	"<line29> logger.error(""Error creating url"", e)"
task5	"<line11>        log.debug(""Discarding service-provider={}, consumer={}"",entry.getServiceProperties(),serviceConsumer);"	<line15>	"log.debug(""getServiceProvidersForConsumer: activeServices={}"", activeServices)"	"<line15> log.debug(""getServiceProvidersForConsumer: activeServices={}"", activeServices)"
task5	"<line2>    LOG.debug(""fetching all pages for course "" + courseId);"	<line2>	"LOG.debug(""Retrieving list of pages in course "" + courseId)"	"<line2> LOG.debug(""Retrieving list of pages in course "" + courseId)"
task5	<line8>      logger.error(request.getRequestContext(), ex.getMessage(), ex);	<line9>	"log.error(""Error while searching location"", ex)"	"<line9> log.error(""Error while searching location"", ex)"
task5	"<line17>              log.debug(""Timed out waiting for rebalancing status from coordinator, trying again"");"	<line17>	"log.warn(""Error reading rebalancing status from coordinator {}, will retry"", coordinator, throwable)"	"<line17> log.warn(""Error reading rebalancing status from coordinator {}, will retry"", coordinator, throwable)"
task5	"<line11>      logger.error(""Unable to get user by its name"", fex);"	<line11>	"logger.error(""Error while checking user"", fex)"	"<line11> logger.error(""Error while checking user"", fex)"
task5	"<line5>        logger.debug(""The name of the queue region is {} and the size is {}. keyset size is {}"",prQ.getName(),prQ.size(),prQ.keys().size());"	<line5>	"logger.debug(""ShadowPRQueue size: {}"", prQ.size())"	"<line5> logger.debug(""ShadowPRQueue size: {}"", prQ.size())"
task5	"<line19>      log.debug(""Change detected: {}"", entry);"	<line17>	"LOG.debug(""Filtering out audit entry {} because it does not impact the current user"", entry)"	"<line17> LOG.debug(""Filtering out audit entry {} because it does not impact the current user"", entry)"
task5	<line7>        log.warn(exception, exception);	<line7>	log.warn(exception, exception)	<line7> log.warn(exception, exception)
task5	"<line2>    LOG.error(""Only self managed allowed!"", exception);"	<line2>	"LOG.error(""SelfManagedOnlyException: "" + exception.getMessage())"	"<line2> LOG.error(""SelfManagedOnlyException: "" + exception.getMessage())"
task5	"<line2>    log.info(""Closing MiniTrogdorCluster."");"	<line14>	"LOG.info(""Stopped"")"	"<line14> LOG.info(""Stopped"")"
task5	"<line5>      log.info(""adjusting paths in entry to reflect linked collection info"");"	<line5>	"log.info(""under a linked collection, put out the entry as if it were at the collection level"")"	"<line5> log.info(""under a linked collection, put out the entry as if it were at the collection level"")"
task5	"<line6>      LOGGER.error(""Failed to transform JSON: "" + e, e);"	<line6>	"log.error(""Error while formatting JSON"", e)"	"<line6> log.error(""Error while formatting JSON"", e)"
task5	"<line7>      log.trace(""testFolderishCollection2():\n""+ ""Create a folder with the Collection facet (\""collectionFolder\"") inside a folder""+ "" (\""folder1\"");\n""+ ""Add \""folder1\"" to the \""collectionFolder\"" collection;\n""+ ""Register \""folder1\"" as a synchronization root;\n""+ ""Create a collection \""collectionSyncRoot\"" and register it as a synchronization""+ "" root;\n""+ ""Create a document \""testDoc\"" and add it to both collections \""collectionFolder\""""+ "" and \""collectionSyncRoot\"".\n"");"	<line2>	"log.debug(""Create a folderish collection, with a folder in it"")"	"<line2> log.debug(""Create a folderish collection, with a folder in it"")"
task5	"<line12>    log.debug(""User info={}"", json);"	<line12>	"log.debug(""Received auth info: {}"", json)"	"<line12> log.debug(""Received auth info: {}"", json)"
task5	"<line40>      logger.error(""NotificationController - viewNotificationList() - ERROR "", e);"	<line40>	"logger.error(""NotificationController - viewNotificationList() - ERROR"", e)"	"<line40> logger.error(""NotificationController - viewNotificationList() - ERROR"", e)"
task5	<line2>    logger.debug(Messages.GETTING_INSTANCES_OF_APPLICATION_0, app.getName());	<line2>	logger.debug(Messages.GETTING_APPLICATION_INSTANCES_0, app.getUniqueIdentifier())	<line2> logger.debug(Messages.GETTING_APPLICATION_INSTANCES_0, app.getUniqueIdentifier())
task5	"<line7>      LOGGER.debug(""Registering module state with id ["" + id + ""]"");"	<line7>	"LOGGER.debug(""Registering state: "" + id)"	"<line7> LOGGER.debug(""Registering state: "" + id)"
task5	"<line3>      LOG.trace(""Channel open: {}"", ctx.channel());"	<line3>	"LOG.trace(""Channel activated: {}"", ctx.channel())"	"<line3> LOG.trace(""Channel activated: {}"", ctx.channel())"
task5	"<line10>      logger.info(""Trying to cancel job {} with savepoint, but no savepoint directory configured."", jobId);"	<line10>	"logger.info(""No savepoint directory configured. You can either specify a directory ""+ ""while cancelling via -s :targetDirectory or configure a cluster-wide ""+ ""default via key '{}'."",CheckpointingOptions.SAVEPOINT_DIRECTORY.key())"	"<line10> logger.info(""No savepoint directory configured. You can either specify a directory ""+ ""while cancelling via -s :targetDirectory or configure a cluster-wide ""+ ""default via key '{}'."",CheckpointingOptions.SAVEPOINT_DIRECTORY.key())"
task5	"<line52>    LOG.debug(""TaskManager start command: "" + startCommand);"	<line52>	"log.debug(""TaskExecutor start command: {}"", startCommand)"	"<line52> log.debug(""TaskExecutor start command: {}"", startCommand)"
task5	<line1>    logger.debug(message);	<line3>	log.info(message)	<line3> log.info(message)
task5	"<line6>      logger.error(""unable to translate "" + netexSourceType + "" as PTNetworkSourceType"");"	<line6>	"log.error(""unable to read PTNetworkSourceType for type : "" + netexSourceType)"	"<line6> log.error(""unable to read PTNetworkSourceType for type : "" + netexSourceType)"
task5	"<line4>      log.error(""Got IOException while reading delimited file: "" + lineProducer);"	<line4>	"LOGGER.error(""Error while reading next line."", e1)"	"<line4> LOGGER.error(""Error while reading next line."", e1)"
task5	"<line20>        Log.debug(""Adds a monitored point '""+ point.getLabel()+ ""' to container with id #""+ containerId+ ""."");"	<line20>	"Log.debug(""onUploadSuccess: "" + point)"	"<line20> Log.debug(""onUploadSuccess: "" + point)"
task5	"<line17>      LOGGER.error(""Error in getAppsBySeverity from ES"", e);"	<line17>	"logger.error(""Error in getAppsBySeverity"", e)"	"<line17> logger.error(""Error in getAppsBySeverity"", e)"
task5	"<line16>        LOG.warn(""Incorrect {} configuration - missing {} selector"", pid, KEY_BUNDLE_SN);"	<line16>	"LOG.warn(""{} is not a valid configuration for {}"", props, this)"	"<line16> LOG.warn(""{} is not a valid configuration for {}"", props, this)"
task5	"<line2>    log.error(""getModulesConfigurationPropertiesFallback: "" + serviceName);"	<line3>	"logger.warn(""Could not get modules configuration properties for service: "" + serviceName)"	"<line3> logger.warn(""Could not get modules configuration properties for service: "" + serviceName)"
task5	"<line4>          log.debug(""Setting autocommit to ""+ desiredAutoCommit+ "" on JDBC Connection [""+ connection+ ""]"");"	<line4>	"log.debug(""Setting AutoCommit to "" + desiredAutoCommit)"	"<line4> log.debug(""Setting AutoCommit to "" + desiredAutoCommit)"
task5	"<line18>      logger.error(""Error while extracting Allowed Nested Types"", t);"	<line18>	"logger.error(""Error while extracting Allowed Nested Types"", t)"	"<line18> logger.error(""Error while extracting Allowed Nested Types"", t)"
task5	"<line18>        LOGGER.debug(""Unable to build query. Unknown sort order of [{}]."",sortOrder == null ? null : sortOrder.identifier());"	<line18>	"LOGGER.info(""Unsupported sort order: "" + sortOrder)"	"<line18> LOGGER.info(""Unsupported sort order: "" + sortOrder)"
task5	<line14>      LOGGER.error(e, e);	<line14>	"LOGGER.error(""Unable to decode video"", e)"	"<line14> LOGGER.error(""Unable to decode video"", e)"
task5	"<line28>      logger.info(""SpringSocialSecurity sign in details not found in session"");"	<line17>	"logger.debug(""Authentication of user {}"", user)"	"<line17> logger.debug(""Authentication of user {}"", user)"
task5	"<line2>    log.debug(""Starting up test server"");"	<line2>	"log.debug(""Starting up test server"")"	"<line2> log.debug(""Starting up test server"")"
task5	"<line17>      logger.debug(""More than one element builder plugin claims responsibilty for ""+ flavor+ "": ""+ buf.toString());"	<line17>	"logger.warn(""Found more than one plugin for building new element of type {} with flavor {}: {}"",type,flavor,buf.toString())"	"<line17> logger.warn(""Found more than one plugin for building new element of type {} with flavor {}: {}"",type,flavor,buf.toString())"
task5	"<line41>    log.info(""PageMemory tracker started, ""+ U.readableSize(maxMemorySize, false)+ "" offheap memory allocated."");"	<line41>	"if (log.isInfoEnabled()) log.info(""PageMemory tracker started."")"	"<line41> if (log.isInfoEnabled()) log.info(""PageMemory tracker started."")"
task5	"<line2>    LOGGER.info(""MQTT Message received {}"", new String(message.getPayload()));"	<line2>	"log.info(""Received message {}"", message.getPayloadAsString())"	"<line2> log.info(""Received message {}"", message.getPayloadAsString())"
task5	"<line5>        LOG.error(""Failed to transform String to URI: {} "", string);"	<line5>	"LOGGER.error(""Unable to convert {}"", string, e)"	"<line5> LOGGER.error(""Unable to convert {}"", string, e)"
task5	"<line2>    log.debug("""");"	<line2>	"log.debug("""")"	"<line2> log.debug("""")"
task5	<line20>              LOG.error(STD_ERR_MSG, e);	<line20>	"log.error(""Error while resolving urls"", e)"	"<line20> log.error(""Error while resolving urls"", e)"
task5	"<line2>    log.debug(""Monitoring condition with specified checkInterval of {}, timeout of {}, timeUnit {}"",checkInterval,timeout,timeUnit);"	<line2>	"log.debug(""Monitoring condition until timeout [{}]ms"", timeout)"	"<line2> log.debug(""Monitoring condition until timeout [{}]ms"", timeout)"
task5	"<line7>      logger.error(""Unable to move file '"" + file.getName() + ""' to directory: "" + destinationDir, ex);"	<line7>	"log.error(""Cannot move file "" + file.getAbsolutePath() + "" to directory "" + destinationDir, ex)"	"<line7> log.error(""Cannot move file "" + file.getAbsolutePath() + "" to directory "" + destinationDir, ex)"
task5	"<line2>    LOGGER.debug(""HeartbeatMode: "" + ArrayConverter.bytesToHexString(msg.getHeartbeatMode().getValue()));"	<line2>	"LOGGER.debug(""HeartbeatMode: "" + ArrayConverter.bytesToHexString(msg.getHeartbeatMode().getValue()))"	"<line2> LOGGER.debug(""HeartbeatMode: "" + ArrayConverter.bytesToHexString(msg.getHeartbeatMode().getValue()))"
task5	"<line2>    LOGGER.debug(""Get levels with criteria={}"", criteria);"	<line2>	"LOGGER.debug(""getLevels criteria={}"", criteria)"	"<line2> LOGGER.debug(""getLevels criteria={}"", criteria)"
task5	"<line16>        LOGGER.warn(""Unable to add file '{}' because cannot find corresponding group  with @USE='{}'. ""+ ""Ignore file and continue."",ref.toFileId(),use);"	<line16>	"LOGGER.warn(""Could not find matching FileGrp for {}"", ref.getPath())"	"<line16> LOGGER.warn(""Could not find matching FileGrp for {}"", ref.getPath())"
task5	"<line22>              LOG.error(""While updating console layout for role {}"", wrapper.getKey(), e);"	<line22>	"LOG.error(""While updating any layout for role {}"", model.getObject().getKey(), e)"	"<line22> LOG.error(""While updating any layout for role {}"", model.getObject().getKey(), e)"
task5	"<line11>        LOGGER.error(""Failed to parse state interval: "" + e, e);"	<line11>	"LOGGER.warn(""Unable to set current time to ISO8601 string: "" + time.getCurrent(), e)"	"<line11> LOGGER.warn(""Unable to set current time to ISO8601 string: "" + time.getCurrent(), e)"
task5	"<line15>        log.error(""Error cloning Managed block disk '{}': {}"", managedBlockDisk.getDiskAlias());"	<line15>	"log.error(""Failed to clone managed block disk"")"	"<line15> log.error(""Failed to clone managed block disk"")"
task5	"<line9>      logger.warn(""Unable to collect a list of wiki objects components: %s"", e);"	<line9>	"this.logger.error(""Failed to lookup wiki objects for the page."", e)"	"<line9> this.logger.error(""Failed to lookup wiki objects for the page."", e)"
task5	"<line6>      logger.error(""fail to unMarshal json {}"", e.getMessage());"	<line6>	"logger.error(""error to parse jsonstr:{}"", jsonstr, e)"	"<line6> logger.error(""error to parse jsonstr:{}"", jsonstr, e)"
task5	"<line5>    logger.debug(""About to marshal case file data (name = {}) for case with id '{}' {}"",name,caseId,caseFileData);"	<line3>	"logger.debug(""Getting data {} for case {}"", name, caseId)"	"<line3> logger.debug(""Getting data {} for case {}"", name, caseId)"
task5	"<line21>                    LOG.warn(""Unable to fetch system jobs from node {}:"", entry.getKey(), e);"	<line21>	"LOG.error(""Could not cancel job {} on node {}"", jobId, entry.getKey(), e)"	"<line21> LOG.error(""Could not cancel job {} on node {}"", jobId, entry.getKey(), e)"
task5	"<line9>      LOG.debug(""Reading checkpoint for {} to {}"", entry.getName(), checkpointPath);"	<line9>	"LOG.info(""Reading checkpoint {}"", checkpointPath)"	"<line9> LOG.info(""Reading checkpoint {}"", checkpointPath)"
task5	"<line4>      log.trace(""deleteIfExists({}): {}"", path, r);"	<line4>	"log.trace(""deleteIfExists({})"", r)"	"<line4> log.trace(""deleteIfExists({})"", r)"
task5	<line5>      log.warn(missingMessage(key));	<line2>	"log.debug(""getting long value for key: {}"", key)"	"<line2> log.debug(""getting long value for key: {}"", key)"
task5	"<line7>      LOGGER.warn(""Could not resolve Inbox mailbox"", e);"	<line7>	"LOGGER.warn(""Could not find inbox for user "" + addedEvent.getUsername(), e)"	"<line7> LOGGER.warn(""Could not find inbox for user "" + addedEvent.getUsername(), e)"
task5	"<line2>    LOGGER.error(""Exception:"", exception);"	<line2>	"logger.error(""MQTT connect failed"", exception)"	"<line2> logger.error(""MQTT connect failed"", exception)"
task5	"<line3>    logger.debug(""Committing XA TX. {}, One Face: {}"", xid, b);"	<line2>	"logger.info(""commit invoked"")"	"<line2> logger.info(""commit invoked"")"
task5	"<line1>    logger.info(""test-auth: Auth accept OK"");"	<line1>	"log.info(""accept"")"	"<line1> log.info(""accept"")"
task5	<line11>      LOGGER.warn(ex);	<line11>	"LOGGER.debug(""Invalid TransportHandler State"", ex)"	"<line11> LOGGER.debug(""Invalid TransportHandler State"", ex)"
task5	"<line11>    logger.info(""query list queue return result:{}"", mvcResult.getResponse().getContentAsString());"	<line11>	logger.info(mvcResult.getResponse().getContentAsString())	<line11> logger.info(mvcResult.getResponse().getContentAsString())
task5	"<line3>      LOGGER.debug(""Nothing to commit. Transaction branch is null"");"	<line5>	"logger.debug(""rollback: {}"", branch)"	"<line5> logger.debug(""rollback: {}"", branch)"
task5	"<line29>      LOGGER.debug(format(""Injecting read/write/serial consistency levels %s/%s/%s into entity meta of %s"",readConsistencyLevel.name(),writeConsistencyLevel.name(),serialConsistencyLevel.name(),entityClass.getCanonicalName()));"	<line29>	"LOGGER.debug(format(""Determining read consistency level for entity of type %s : %s"",this.entityClass.getCanonicalName(), this.readConsistencyLevel))"	"<line29> LOGGER.debug(format(""Determining read consistency level for entity of type %s : %s"",this.entityClass.getCanonicalName(), this.readConsistencyLevel))"
task5	"<line12>      LOG.info(""No service configuration given and no ConfigurationProviders set."");"	<line12>	"LOG.debug(""Using the ConfigurationProviders as no ServiceConfiguration was provided."")"	"<line12> LOG.debug(""Using the ConfigurationProviders as no ServiceConfiguration was provided."")"
task5	"<line2>    log.info(t + """");"	<line2>	"logger.info(""{} next: {}"", this, t)"	"<line2> logger.info(""{} next: {}"", this, t)"
task5	"<line5>      log.error(""RemoteException"", e);"	<line5>	"log.error(""RemoteException"", e)"	"<line5> log.error(""RemoteException"", e)"
task5	"<line18>      LOG.error(""Error stopping plugin \"""" + getName() + ""\"": "" + e.getLocalizedMessage(), e);"	<line16>	"LOG.error(""Error while stopping plugin {"" + getName() + ""}"", e)"	"<line16> LOG.error(""Error while stopping plugin {"" + getName() + ""}"", e)"
task5	"<line9>        LOG.info(""Copying jarFile = "" + jarPath);"	<line5>	"LOG.info(""Copying jar files to temp dir "" + localPath)"	"<line5> LOG.info(""Copying jar files to temp dir "" + localPath)"
task5	"<line1>    logger.debug(""Product service returning list of products"");"	<line1>	"LOGGER.info(""Fetching products..."")"	"<line1> LOGGER.info(""Fetching products..."")"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line2>    logger.debug(""Device item {} state changed to {}"", item, newState);"	<line6>	"logger.debug(""Updating state of item {} to {}"", item.getName(), isOn)"	"<line6> logger.debug(""Updating state of item {} to {}"", item.getName(), isOn)"
task5	<line6>      Log.error(e.getMessage());	<line6>	"logger.error(""Error creating decrypt cipher"", e)"	"<line6> logger.error(""Error creating decrypt cipher"", e)"
task5	"<line11>      LOG.info(""Adaptive Scheduler configured, but Batch job detected. Changing scheduler type to NG /""+ "" DefaultScheduler."");"	<line11>	"LOG.info(""The Adaptive scheduler is not supported with job type [{}]. Falling back to the default""+ "" scheduler."",jobType)"	"<line11> LOG.info(""The Adaptive scheduler is not supported with job type [{}]. Falling back to the default""+ "" scheduler."",jobType)"
task5	"<line2>      log.warn(""Bad checksum at "" + getPosition() + "". Skipping entries."");"	<line2>	"LOG.info(""Skipping checksum error at position "" + getPosition(), e)"	"<line2> LOG.info(""Skipping checksum error at position "" + getPosition(), e)"
task5	"<line8>                    LOG.error(""Failed to stop process"", t);"	<line8>	"LOG.error(""Error when stopping process on shutdown: "", t)"	"<line8> LOG.error(""Error when stopping process on shutdown: "", t)"
task5	<line9>      logger.error(e);	<line9>	"logger.error(""Error while initialzing Redis client."", e)"	"<line9> logger.error(""Error while initialzing Redis client."", e)"
task5	"<line9>      log.debug(""Deleting not activated user {}"", user.getLogin());"	<line9>	"log.debug(""Removing not activated user: {}"", user.getId())"	"<line9> log.debug(""Removing not activated user: {}"", user.getId())"
task5	"<line21>          LOGGER.info(""Ignoring unregistered zero byte S3 file. s3Key=\""{}\"" storageName=\""{}\""""+ "" businessObjectDataKey={}"",s3ObjectSummary.getKey(),storageName,businessObjectDataKeyAsJson);"	<line21>	"LOGGER.info(""Found unregistered S3 file \""{}\"" in \""{}\"" storage. Business object data {}"",s3ObjectSummary.getKey(),storageName,businessObjectDataKeyAsJson)"	"<line21> LOGGER.info(""Found unregistered S3 file \""{}\"" in \""{}\"" storage. Business object data {}"",s3ObjectSummary.getKey(),storageName,businessObjectDataKeyAsJson)"
task5	"<line31>      logger.error(""Unable to get user settings:"", e);"	<line31>	"logger.error(""Unable to get user settings"", e)"	"<line31> logger.error(""Unable to get user settings"", e)"
task5	"<line12>          log.info(""Initialization completed after {} ms"",ManagementFactory.getRuntimeMXBean().getUptime());"	<line10>	"log.info(""Registering workspace folders capability"")"	"<line10> log.info(""Registering workspace folders capability"")"
task5	"<line2>      logger.warn(""error accessing mbean: {}"", mbeanObjectName, e);"	<line2>	"log.warn(e, ""Failed to retrieve gauge values from MBean: %s"", mbeanObjectName)"	"<line2> log.warn(e, ""Failed to retrieve gauge values from MBean: %s"", mbeanObjectName)"
task5	"<line29>    LOGGER.info(""Rolling to new images has finished!"");"	<line3>	"LOGGER.info(""Starting testUpgradeAcrossVersionsWithNoKafkaVersion"")"	"<line3> LOGGER.info(""Starting testUpgradeAcrossVersionsWithNoKafkaVersion"")"
task5	"<line4>    logger.debug(""{} ready: initialized"", this.getClass().getName());"	<line2>	"logger.debug(""Initializing language service"")"	"<line2> logger.debug(""Initializing language service"")"
task5	"<line25>        logger.debug(""Thing {}: unexpected command {} from channel {}"",getThing().getUID(),command,channelUID.getId());"	<line15>	"logger.debug(""BridgeHandler not available. Only RefreshType commands are supported."")"	"<line15> logger.debug(""BridgeHandler not available. Only RefreshType commands are supported."")"
task5	"<line22>        LOGGER.debug(""Group {} doesn't exist"", groupDN);"	<line22>	"LOGGER.debug(""Group '{}' does not exist, skipping add member to group"", groupDN)"	"<line22> LOGGER.debug(""Group '{}' does not exist, skipping add member to group"", groupDN)"
task5	"<line7>      logger.error(""Error updating jpavatar config"", t);"	<line7>	"logger.error(""Error updating jpavatar config"", t)"	"<line7> logger.error(""Error updating jpavatar config"", t)"
task5	"<line2>    logger.debug(""Setting valency: "", valency);"	<line2>	"logger.debug(""Setting valency: "", valency)"	"<line2> logger.debug(""Setting valency: "", valency)"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	<line19>      log.error(systemException, systemException);	<line19>	log.error(systemException, systemException)	<line19> log.error(systemException, systemException)
task5	"<line4>    logger.debug(""registerUuid result: {}"", response);"	<line4>	"logger.debug(""registerUuid(): response={}"", response)"	"<line4> logger.debug(""registerUuid(): response={}"", response)"
task5	"<line1>    logger.info(""Obtained session"");"	<line1>	"if (LOGGER.isDebugEnabled()) LOGGER.debug(""isFinancialYearActiveForPosting"")"	"<line1> if (LOGGER.isDebugEnabled()) LOGGER.debug(""isFinancialYearActiveForPosting"")"
task5	"<line4>    log.debug(""env for channel {}: {} = {}"", new Object[] {id, name, value});"	<line3>	"log.info(""Environment variable: name="" + name + "", value="" + value)"	"<line3> log.info(""Environment variable: name="" + name + "", value="" + value)"
task5	<line17>      LOG.warn(exception.toString());	<line17>	LOG.warn(exception)	<line17> LOG.warn(exception)
task5	"<line41>              LOG.warn(""Failed to build sorted map from state, this may result in wrong result. ""+ ""The sort key is {}, partition key is {}, ""+ ""treeMap is {}. The expected inner rank is {}, but current size is {}."",sortKey,partitionKey,treeMap,innerRank,size);"	<line41>	"LOG.info(""The inner rank of the record is not the same as the size of the buffer. The record is""+ "" {} with inner rank {} but the size of the buffer is {}."",recordRowKey,innerRank,size)"	"<line41> LOG.info(""The inner rank of the record is not the same as the size of the buffer. The record is""+ "" {} with inner rank {} but the size of the buffer is {}."",recordRowKey,innerRank,size)"
task5	<line7>        log.debug(exception, exception);	<line7>	log.debug(exception, exception)	<line7> log.debug(exception, exception)
task5	"<line5>        LOGGER.warn(""cannot find event handler by class: "" + context.getClass());"	<line5>	"LOGGER.warn(""No event handlers registered for context {}"", context.getClass())"	"<line5> LOGGER.warn(""No event handlers registered for context {}"", context.getClass())"
task5	"<line3>      LOG.info(""*** server shut down"");"	<line3>	"log.info(""OrientDB Embedded Server terminated successfully."")"	"<line3> log.info(""OrientDB Embedded Server terminated successfully."")"
task5	"<line7>      logger.error(""Error when setting the database driver "" + driver + ""{}"", ex.getMessage());"	<line7>	"logger.error(""Could not set driver class"", ex)"	"<line7> logger.error(""Could not set driver class"", ex)"
task5	"<line3>    LOG.info(""Killing "" + ensemble + "" from ensemble="" + firstEnsemble);"	<line3>	"LOG.info(""Killing bookie {} which is in ensemble {}"", ensemble, firstEnsemble)"	"<line3> LOG.info(""Killing bookie {} which is in ensemble {}"", ensemble, firstEnsemble)"
task5	"<line5>      logger.error(""save command history failed"", e);"	<line5>	"log.error(""Failed to save command history to file "" + Constants.CMD_HISTORY_FILE, e)"	"<line5> log.error(""Failed to save command history to file "" + Constants.CMD_HISTORY_FILE, e)"
task5	"<line4>    LOG.debug(""getRootFolder: "" + result);"	<line4>	"LOG.debug(""getRootFolder: "" + result)"	"<line4> LOG.debug(""getRootFolder: "" + result)"
task5	"<line23>      log.error(""Unable to render journal articles list"", exception);"	<line23>	"log.error(""Unable to render journal articles list"", exception)"	"<line23> log.error(""Unable to render journal articles list"", exception)"
task5	"<line2>    log.info(""...Checking previous resources by replacing"");"	<line15>	"log.info(""...Checked previous schema: previous resource saved!"")"	"<line15> log.info(""...Checked previous schema: previous resource saved!"")"
task5	"<line5>      log.error(""eval expression {} error"", expression, e);"	<line5>	"log.error(""Error evaluating expression: "" + expression, e)"	"<line5> log.error(""Error evaluating expression: "" + expression, e)"
task5	"<line17>    logger.trace(format(""Register QueuedBlockEvent listener %s"", handle));"	<line17>	"logger.trace(""registerBlockListener: {}"", handle)"	"<line17> logger.trace(""registerBlockListener: {}"", handle)"
task5	<line18>      logger.info(e.getMessage(), e);	<line18>	logger.info(e.getMessage(), e)	<line18> logger.info(e.getMessage(), e)
task5	"<line13>    logger.info(""CoachShuttleGathering {} has {} road locations, {} coaches, {} shuttles and {} bus stops""+ "" with a search space of {}."",getInputId(),solution.getLocationList().size(),solution.getCoachList().size(),solution.getShuttleList().size(),solution.getStopList().size(),getFlooredPossibleSolutionSize(possibleSolutionSize));"	<line13>	"logger.info(""The possible solution size is "" + possibleSolutionSize)"	"<line13> logger.info(""The possible solution size is "" + possibleSolutionSize)"
task5	"<line17>        LOG.debug(""Unresolved reference"", ignore);"	<line17>	"LOGGER.debug(""Unresolved reference"", ignore)"	"<line17> LOGGER.debug(""Unresolved reference"", ignore)"
task5	<line14>    logger.info(mvcResult.getResponse().getContentAsString());	<line14>	logger.info(mvcResult.getResponse().getContentAsString())	<line14> logger.info(mvcResult.getResponse().getContentAsString())
task5	"<line1>    log.debug(""find() - id: {}"", id);"	<line1>	"log.debug(""find() - id: {}"", id)"	"<line1> log.debug(""find() - id: {}"", id)"
task5	"<line3>    log.info(""loading from table properties: {}"", storageTableName);"	<line7>	"log.info(""Loaded timelines from table properties: {}"", getTimePartColNamesOfTable(storageTableName))"	"<line7> log.info(""Loaded timelines from table properties: {}"", getTimePartColNamesOfTable(storageTableName))"
task5	"<line6>      LOGGER.debug(""Calling after() for '{}' in processor '{}'..."",interceptor,component.getLocation().getLocation());"	<line18>	"LOG.warn(""Exception while invoking interceptor {}"", interceptor, e)"	"<line18> LOG.warn(""Exception while invoking interceptor {}"", interceptor, e)"
task5	<line5>      LOG.warn(e.getMessage(), e);	<line5>	"log.error(""Error in initial sleep"", e)"	"<line5> log.error(""Error in initial sleep"", e)"
task5	"<line4>      log.error(""failed to convert {} to a JCR path"", path);"	<line4>	"log.warn(""Failed to determine JCR path for (safe) {}"", path)"	"<line4> log.warn(""Failed to determine JCR path for (safe) {}"", path)"
task5	"<line13>    logger.info(""Created column '""+ col.REGISTRATION_DATE+ ""' and set the current timestamp, ""+ currentTimestamp+ "", to all ""+ updatedRows+ "" rows"");"	<line13>	"log.info(""Created column '""+ col.REGISTRATION_DATE+ ""' and set the current timestamp, ""+ currentTimestamp+ "", to all ""+ updatedRows+ "" rows"")"	"<line13> log.info(""Created column '""+ col.REGISTRATION_DATE+ ""' and set the current timestamp, ""+ currentTimestamp+ "", to all ""+ updatedRows+ "" rows"")"
task5	"<line3>      LOG.error(""createBalanceObject unexpected record size={}, record={}"",balance.size(),balance.toString());"	<line3>	"LOG.error(""createBalanceObject unexpected record size={}, record={}"", balance.size(), balance.toString())"	"<line3> LOG.error(""createBalanceObject unexpected record size={}, record={}"", balance.size(), balance.toString())"
task5	<line26>      LOGGER.error(e.getMessage(), e);	<line26>	"logger.error(""Error while retrieving list of data viewer formats"", e)"	"<line26> logger.error(""Error while retrieving list of data viewer formats"", e)"
task5	"<line12>        LOGGER.info(""No queries were found"");"	<line12>	"LOGGER.warn(""No queries found to register."")"	"<line12> LOGGER.warn(""No queries found to register."")"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line2>    LOGGER.debug(""testGetPaginatedGroup"");"	<line2>	"log.debug(""testing get paginated group"")"	"<line2> log.debug(""testing get paginated group"")"
task5	"<line5>      log.error(""Error performing heartbeat: "" + e.getMessage());"	<line5>	"logger.error(""Error sending heartbeat"", e)"	"<line5> logger.error(""Error sending heartbeat"", e)"
task5	"<line8>        log.error(""Failed to delete secret from storage [{}]"", secret.getId(), e);"	<line8>	"log.error(""Could not delete secret value for secret {}"", secret.getName(), e)"	"<line8> log.error(""Could not delete secret value for secret {}"", secret.getName(), e)"
task5	"<line7>        logger.warn(""Exception at updateProfileImage"", e);"	<line7>	"logger.warn(""Exception at updateProfileImage"", e)"	"<line7> logger.warn(""Exception at updateProfileImage"", e)"
task5	<line11>    logger.debug(url);	<line11>	"logger.debug(""remote BSS ws url: {}"", url)"	"<line11> logger.debug(""remote BSS ws url: {}"", url)"
task5	"<line5>        logger.warn(""Playlist failed to remove entries from start, check all cameras in groups use the same""+ "" HLS settings."");"	<line5>	"logger.error(""Error removing from start of string"")"	"<line5> logger.error(""Error removing from start of string"")"
task5	"<line8>        LOGGER.warn(""Project {1} does not exist."", project.getName());"	<line8>	"LOGGER.warn(""Tried to delete the project named \""{}\"" but no project with that name was""+ "" found."",project.getName())"	"<line8> LOGGER.warn(""Tried to delete the project named \""{}\"" but no project with that name was""+ "" found."",project.getName())"
task5	"<line11>      log.error(""Failed to report active user."", e);"	<line11>	"log.error(""Error adding user "" + id, e)"	"<line11> log.error(""Error adding user "" + id, e)"
task5	"<line7>          LOGGER.debug(""Can't parse the matched number."", ex);"	<line7>	"LOG.debug(""Error index could not be parsed from message: {}"", message, ex)"	"<line7> LOG.debug(""Error index could not be parsed from message: {}"", message, ex)"
task5	<line5>    log.info(json);	<line5>	LOG.info(json)	<line5> LOG.info(json)
task5	"<line10>      LOGGER.error(""Exception:"", ex);"	<line10>	"LOGGER.error(""Exception:"", ex)"	"<line10> LOGGER.error(""Exception:"", ex)"
task5	<line22>      log.error(systemException, systemException);	<line22>	log.error(systemException, systemException)	<line22> log.error(systemException, systemException)
task5	"<line9>        LOG.warn(""Encountered error {} while recovering transaction {}. ""+ ""Presumably this transaction has been already committed before"",ex,transaction);"	<line9>	"LOG.warn(""Could not commit transaction"", ex)"	"<line9> LOG.warn(""Could not commit transaction"", ex)"
task5	"<line10>        LOG.error(""Unknown role "" + role);"	<line10>	"LOG.error(""Unexpected role: "" + role)"	"<line10> LOG.error(""Unexpected role: "" + role)"
task5	"<line8>    LOG.debug(""Entering AdapterPatientDiscoveryProxyNoOpImpl.respondingGatewayPRPAIN201305UV02"");"	<line8>	"LOG.debug(""Using NoOp Implementation for Adapter Patient Discovery Service"")"	"<line8> LOG.debug(""Using NoOp Implementation for Adapter Patient Discovery Service"")"
task5	"<line25>    LOGGER.info(""WFS filter GetFeature response:\n"" + prettyString(doc));"	<line25>	"LOGGER.info(""WFS filter GetFeature response:\n"" + prettyString(doc))"	"<line25> LOGGER.info(""WFS filter GetFeature response:\n"" + prettyString(doc))"
task5	"<line46>              log.warn(""HtmlPreviewEntryPersistenceImpl.fetchByG_C_C(long, long, long, boolean) with""+ "" parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."");"	<line46>	"log.warn(""HtmlPreviewEntryPersistenceImpl.fetchByG_C_C(long, long, long, boolean) with more than one result: ""+ ""group=""+ groupId+ "", classNameId=""+ classNameId+ "", classPK=""+ classPK)"	"<line46> log.warn(""HtmlPreviewEntryPersistenceImpl.fetchByG_C_C(long, long, long, boolean) with more than one result: ""+ ""group=""+ groupId+ "", classNameId=""+ classNameId+ "", classPK=""+ classPK)"
task5	<line22>      log.debug(q.toString());	<line22>	"log.info(""Active query: "" + q.toString())"	"<line22> log.info(""Active query: "" + q.toString())"
task5	"<line7>            log.debug(""Ignoring put(). New entry is not from a newer reader. ""+ ""existing: ""+ e.creationTick+ "", new: ""+ reader.getCreationTick());"	<line7>	"log.debug(""Segment "" + uuid + "" not cached because index was created later"")"	"<line7> log.debug(""Segment "" + uuid + "" not cached because index was created later"")"
task5	"<line16>        log.warn(""Invalid schema version for release: "" + release, illegalArgumentException);"	<line16>	"log.warn(""Unable to register Release service with schema version "" + release.getSchemaVersion(),illegalArgumentException)"	"<line16> log.warn(""Unable to register Release service with schema version "" + release.getSchemaVersion(),illegalArgumentException)"
task5	"<line15>    logger.debug(""About to marshal process variable with name '{}' {}"", varName, variable);"	<line2>	"logger.debug(""About to get process instance variable {}"", varName)"	"<line2> logger.debug(""About to get process instance variable {}"", varName)"
task5	"<line2>    LOGGER.debug(""create context={}"", contextDto);"	<line2>	"LOGGER.debug(""create {}"", contextDto)"	"<line2> LOGGER.debug(""create {}"", contextDto)"
task5	"<line5>      logger.error(""Encountered an error: "", e);"	<line5>	"log.error(""Error extracting root key from bootstrap file"", e)"	"<line5> log.error(""Error extracting root key from bootstrap file"", e)"
task5	"<line25>        logger.debug(""Definita dimensione di resize: {}"", dimension.getIdDim());"	<line1>	"log.info(""Getting dimensions..."")"	"<line1> log.info(""Getting dimensions..."")"
task5	<line8>    LOGGER.error(String.format(Messages.Log.ERROR_WHILE_ATTACHING_VOLUME_GENERAL_S, errorText));	<line8>	logger.error(errorText)	<line8> logger.error(errorText)
task5	"<line8>      logger.error(""Document creation failed."");"	<line8>	"LOGGER.error(""Error while exporting docket data to XML."", e)"	"<line8> LOGGER.error(""Error while exporting docket data to XML."", e)"
task5	"<line2>    log.trace(""Read {}  byte, val is {}"", context, ByteUtils.formatByte(b));"	<line2>	"logger.debug(""read()="" + b + "" "" + context)"	"<line2> logger.debug(""read()="" + b + "" "" + context)"
task5	"<line7>        log.error(""Invalid setting for "" + prop + "" value="" + sPoolSize + "" using defaults."");"	<line7>	"log.warn(""Invalid value for property "" + prop + "" - using default value"")"	"<line7> log.warn(""Invalid value for property "" + prop + "" - using default value"")"
task5	"<line2>    logger.info(""Retrieving "" + this.url);"	<line2>	"logger.info(""    Retrieving "" + this.url)"	"<line2> logger.info(""    Retrieving "" + this.url)"
task5	"<line3>      log.trace(""Creating a new custom container builder"");"	<line3>	"log.trace(""Creating a new custom container builder"")"	"<line3> log.trace(""Creating a new custom container builder"")"
task5	"<line3>    logger.debug(""{} ready. Initialized"", this.getClass().getName());"	<line3>	"logger.debug(""{} ready. Initialized"", this.getClass().getName())"	"<line3> logger.debug(""{} ready. Initialized"", this.getClass().getName())"
task5	"<line2>      logger.debug(""Cancelling query {}"", QueryIdHelper.getQueryId(id));"	<line2>	"logger.debug(""Canceling query {}"", id)"	"<line2> logger.debug(""Canceling query {}"", id)"
task5	"<line20>        LOGGER.warn(""Node instance with url "" + ref.getUrl() + "" not found"");"	<line20>	"LOGGER.warn(""Could not find node library reference for instance node: "" + ref.getUrl())"	"<line20> LOGGER.warn(""Could not find node library reference for instance node: "" + ref.getUrl())"
task5	"<line1>    LOGGER.info(""Get the Object Group with Identifier {}"", id);"	<line1>	"log.debug(""Find object by id: {}"", id)"	"<line1> log.debug(""Find object by id: {}"", id)"
task5	"<line8>      logger.trace(""Value '{}' for {} hasn't changed, ignoring update"", value, variable);"	<line4>	"logger.debug(""onValueReceived(): argument 'variable' must be non-null"")"	"<line4> logger.debug(""onValueReceived(): argument 'variable' must be non-null"")"
task5	"<line41>      LOG.info(""Published [%d] segments"", newSegments.size());"	<line41>	"log.info(""Published [%,d] sinks."", segmentsToPublish.size())"	"<line41> log.info(""Published [%,d] sinks."", segmentsToPublish.size())"
task5	"<line2>      LOG.info(""Validation of Timestamp: The message was created in the future!"");"	<line2>	"LOG.info(""The invocation could not be verified because the creation date is in the future"")"	"<line2> LOG.info(""The invocation could not be verified because the creation date is in the future"")"
task5	"<line18>        logger.debug(debugger,"">>>>>>>>>>create a new schedule setting for unit [""+ topUnitName+ ""][""+ unitName+ ""]......"");"	<line23>	"logger.warn(""system get schedule setting by unit name got an exception!"")"	"<line23> logger.warn(""system get schedule setting by unit name got an exception!"")"
task5	"<line5>      LOGGER.info(""Got app ID: {}"", appId);"	<line6>	"logger.info(""Generated new app id: "" + appId)"	"<line6> logger.info(""Generated new app id: "" + appId)"
task5	"<line4>      LOG.info(""Found scheduled, but not in database {}"", configId);"	<line4>	"log.info(""Alert config ID {} not found. Stop the job {}"", configId, scheduledJobKey)"	"<line4> log.info(""Alert config ID {} not found. Stop the job {}"", configId, scheduledJobKey)"
task5	"<line2>    LOG.trace(""Starting {}"", this);"	<line3>	"LOG.info(""{} starting at {}"", this, locs)"	"<line3> LOG.info(""{} starting at {}"", this, locs)"
task5	"<line27>        log.warn(""Failed to disconnect transport"", e);"	<line21>	"log.debug(""Tree connected"")"	"<line21> log.debug(""Tree connected"")"
task5	"<line20>      log.error(""InterruptedException in receiver "" + i, e);"	<line20>	"log.error(""Exception in receiver "" + i, e)"	"<line20> log.error(""Exception in receiver "" + i, e)"
task5	"<line8>        logger.info(""Join check from ""+ getCallerAddress()+ "" failed validation due to incompatible version,""+ ""remote cluster version is ""+ request.getClusterVersion()+ "", this cluster is ""+ service.getClusterVersion());"	<line16>	"logger.info(""Could not validate split-brain join message! -> "" + e.getMessage())"	"<line16> logger.info(""Could not validate split-brain join message! -> "" + e.getMessage())"
task5	<line11>      LOG.error(myDiff.toString());	<line11>	"LOG.error(""XML files are not the same: "" + myDiff.toString())"	"<line11> LOG.error(""XML files are not the same: "" + myDiff.toString())"
task5	"<line13>    logger.info(""[testDeleted] {}"", needDeletedHello);"	<line13>	"logger.info(""{}"", needDeletedHello)"	"<line13> logger.info(""{}"", needDeletedHello)"
task5	"<line6>      log.info(""Test cache [mode=""+ ccfg.getCacheMode()+ "", atomicity=""+ ccfg.getAtomicityMode()+ "", backups=""+ ccfg.getBackups()+ "", near=""+ near+ ""]"");"	<line11>	"log.info(""Destroyed cache: "" + ccfg.getName())"	"<line11> log.info(""Destroyed cache: "" + ccfg.getName())"
task5	"<line2>    LOGGER.info(""TestJDBCInterface setup"");"	<line2>	"LOGGER.info(""Setting up for test"")"	"<line2> LOGGER.info(""Setting up for test"")"
task5	"<line3>      logger.error(""Resource not found: "" + path);"	<line3>	"logger.error(""Could not find image "" + path)"	"<line3> logger.error(""Could not find image "" + path)"
task5	"<line10>      LOG.info(""Failed to resolve the network location"", exc);"	<line10>	"LOG.error(""Failed to resolve network location for {}"", address, exc)"	"<line10> LOG.error(""Failed to resolve network location for {}"", address, exc)"
task5	"<line6>    log.info(""CAMP created '{}'"", instance);"	<line2>	"log.debug(""Creating application instance for {} ({})"", template.getId(), template)"	"<line2> log.debug(""Creating application instance for {} ({})"", template.getId(), template)"
task5	"<line2>      log.warn(""Detected that shutdown was requested. ""+ ""All clients in this app will now begin to shutdown"");"	<line2>	"log.info(""Group {} received SHUTDOWN, rebalance to trigger"", groupId)"	"<line2> log.info(""Group {} received SHUTDOWN, rebalance to trigger"", groupId)"
task5	<line10>        LOG.error(SshdText.get().sessionCloseFailed, e);	<line10>	"LOG.warn(""Failed to close Cassandra connection"", e)"	"<line10> LOG.warn(""Failed to close Cassandra connection"", e)"
task5	<line4>      LOG.info(json);	<line5>	LOG.info(json)	<line5> LOG.info(json)
task5	"<line5>        log.debug(""Unable to get file entry "" + fileEntryId, portalException);"	<line5>	log.debug(portalException, portalException)	<line5> log.debug(portalException, portalException)
task5	"<line15>    LOG.info(""initializeUI took "" + watch.taken());"	<line3>	"log.info(""Initialize UI took "" + watch.taken())"	"<line3> log.info(""Initialize UI took "" + watch.taken())"
task5	"<line11>        log.warn(""Cannot find host ip"", e);"	<line11>	"LOGGER.error(""Cannot run /sbin/ip route|awk '/default/ { print $3 }' in container"", e)"	"<line11> LOGGER.error(""Cannot run /sbin/ip route|awk '/default/ { print $3 }' in container"", e)"
task5	"<line2>    log.debug(""onEndRequest"");"	<line2>	"log.debug(""Ending request cycle for {}"", this)"	"<line2> log.debug(""Ending request cycle for {}"", this)"
task5	"<line2>    Log.debug(""Test"");"	<line2>	"logger.warn(""Test"")"	"<line2> logger.warn(""Test"")"
task5	"<line29>      logger.error(""move processDefinition error: {}"", e.getMessage(), e);"	<line27>	"logger.error(""Move process definition error."", e)"	"<line27> logger.error(""Move process definition error."", e)"
task5	"<line4>    LOGGER.info(""Checking url: "" + url);"	<line8>	"LOGGER.warn(""Could not determine final URL for "" + url)"	"<line8> LOGGER.warn(""Could not determine final URL for "" + url)"
task5	"<line2>    LOG.debug(""Destroying scout server scoutSessionId={}"", session.getId());"	<line3>	"LOG.info(""Destroying session {}"", session.getId())"	"<line3> LOG.info(""Destroying session {}"", session.getId())"
task5	"<line13>    LOGGER.warn(""Could not cast preference value for key [""+ key+ ""] from [""+ pref.getValueType()+ ""] to [""+ type+ ""]"");"	<line13>	"LOG.warn(""JAXB object for key "" + key + "" not of type "" + type)"	"<line13> LOG.warn(""JAXB object for key "" + key + "" not of type "" + type)"
task5	"<line3>    log.debug(""Output from command: [{}]"", baos.toString().replaceAll(""\n"", ""\\\\n""));"	<line3>	"logger.info(""Command returned: "" + ret)"	"<line3> logger.info(""Command returned: "" + ret)"
task5	"<line6>    log.info(""started ""+ app+ "" containing ""+ brooklynNode+ "" for ""+ JavaClassNames.niceClassAndMethod());"	<line18>	"log.info(""started "" + app + "" containing "" + brooklynNode)"	"<line18> log.info(""started "" + app + "" containing "" + brooklynNode)"
task5	"<line4>    LOG.error(String.format(""A channel exception set on %s"", toString()));"	<line2>	"logger.debug(""Channel already has an error. Not overwriting it with {}"", cause)"	"<line2> logger.debug(""Channel already has an error. Not overwriting it with {}"", cause)"
task5	<line17>      log.error(systemException, systemException);	<line17>	log.error(systemException, systemException)	<line17> log.error(systemException, systemException)
task5	"<line7>        logger.warn(StringMessageUtils.getBoilerPlate(newArrayList(""WARNING:"","" "",""Class: '""+ name+ ""' is NOT exposed by the plugin but it will be visible ""+ ""due to it was manually forced to be exported for testing purposes."","" "",""Check if this is really necessary, this class won't be visible in standalone""+ "" mode.""),'*',DEFAULT_MESSAGE_WIDTH));"	<line7>	"logger.debug(""Exported class: {} from {}"", name, classLoaderFilter)"	"<line7> logger.debug(""Exported class: {} from {}"", name, classLoaderFilter)"
task5	"<line11>      LOG.error(""Unknown error during processing of [mutations={0}]"", e, mutations);"	<line11>	"LOG.error(""Unknown error while trying to enqueue mutation batch [{}]."", mutations, e)"	"<line11> LOG.error(""Unknown error while trying to enqueue mutation batch [{}]."", mutations, e)"
task5	"<line6>      LOGGER.warn(""Error upon {} mapping resolution for {}. You might want to audit mapping content for""+ "" this mapping entry. "",fromUser.asString(),connectedUser.asString());"	<line6>	"LOGGER.warn(""Error while checking if a user can send an email using one of his aliases"", e)"	"<line6> LOGGER.warn(""Error while checking if a user can send an email using one of his aliases"", e)"
task5	"<line4>      LOGGER.warn(MessageFormat.format(this.getActionExecution().getAction().getType()+ "" does not accept {0} as type for check name"",checkName.getClass()));"	<line4>	"LOGGER.warn(MessageFormat.format(this.getActionExecution().getAction().getType()+ "" does not accept {0} as type for check name"",checkName.getClass()))"	"<line4> LOGGER.warn(MessageFormat.format(this.getActionExecution().getAction().getType()+ "" does not accept {0} as type for check name"",checkName.getClass()))"
task5	"<line2>      log.warn(""Global FacesMessage to user (wid: {}): {})"",windowContext.getCurrentWindowId(),msg.getSummary());"	<line2>	log.warn(msg.getMessage())	<line2> log.warn(msg.getMessage())
task5	<line18>      logger.info(s);	<line18>	LOG.info(s)	<line18> LOG.info(s)
task5	"<line43>      logger.error(""Error occurred while executing 'describe disk-store': {}!"", e.getMessage(), e);"	<line43>	logger.error(e.getMessage(), e)	<line43> logger.error(e.getMessage(), e)
task5	"<line37>      logger.trace(String.format(""FCM Notification Response status=%d, response=%s"",conn.getResponseCode(), response));"	<line33>	"logger.debug(""FCM response : "" + response)"	"<line33> logger.debug(""FCM response : "" + response)"
task5	"<line1>    log.debug(""validRequestorForSendType_returnType:"" + sendType + "","" + returnType);"	<line9>	"log.warn(String.format(""No valid requestor found for sendType %s, returnType %s"", sendType, returnType))"	"<line9> log.warn(String.format(""No valid requestor found for sendType %s, returnType %s"", sendType, returnType))"
task5	"<line47>      logger.debug(""SEARCHING FOR NOTES WITH CRITERIA: "" + criteria);"	<line47>	"logger.debug(""SEARCHING FOR NOTES WITH CRITERIA: "" + criteria)"	"<line47> logger.debug(""SEARCHING FOR NOTES WITH CRITERIA: "" + criteria)"
task5	<line16>      log.error(systemException, systemException);	<line16>	log.error(systemException, systemException)	<line16> log.error(systemException, systemException)
task5	"<line7>    LOG.info(""Total number of created elements: "" + uuidList.size());"	<line15>	"logger.debug(""Test create and remove element, total number of elements: "" + uuidList.size())"	"<line15> logger.debug(""Test create and remove element, total number of elements: "" + uuidList.size())"
task5	"<line10>        logger.error(""Failed to read response from remote service: "", e);"	<line10>	"logger.error(""Error publishing to streaming"", e)"	"<line10> logger.error(""Error publishing to streaming"", e)"
task5	"<line5>      this.logger.info(""Root context already created (using as parent)."");"	<line1>	"log.info(""Creating root application context"")"	"<line1> log.info(""Creating root application context"")"
task5	"<line3>      logger.info(""TimeSeries list to be deleted is empty."");"	<line3>	"logger.warn(""delete plan has no path"")"	"<line3> logger.warn(""delete plan has no path"")"
task5	<line12>      LOGGER.error(e);	<line12>	"LOGGER.info(""Could not delete model with pretty format: "" + modelId, e)"	"<line12> LOGGER.info(""Could not delete model with pretty format: "" + modelId, e)"
task5	"<line19>      LOG.info(String.format(""Padding ORC by %d bytes while merging.."", availBlockSpace));"	<line26>	"LOG.debug(""Writing stripe at offset {}"", start)"	"<line26> LOG.debug(""Writing stripe at offset {}"", start)"
task5	"<line26>      log.error(""Error while storing: "" + e.toString());"	<line26>	"log.error(""Error while deleting activity node. ItemStateException"", e)"	"<line26> log.error(""Error while deleting activity node. ItemStateException"", e)"
task5	"<line24>      LOG.debug(""Error occurred: "", e);"	<line37>	"LOG.debug(""Can't find single parameter method caller for {}"", methodName)"	"<line37> LOG.debug(""Can't find single parameter method caller for {}"", methodName)"
task5	"<line44>        LOGGER.debug(""Cannot match record: merged record has a too low confidence value (""+ normalizedConfidence+ "" < ""+ minConfidenceValue+ "")"");"	<line44>	"LOGGER.debug(""Confidence is below threshold for matcher "" + matchIndex)"	"<line44> LOGGER.debug(""Confidence is below threshold for matcher "" + matchIndex)"
task5	<line10>        LOG.warn(e1.getMessage(), e1);	<line10>	"LOG.debug(""Method '{}' not found for step '{}'."", setterName, step.getClass().getName())"	"<line10> LOG.debug(""Method '{}' not found for step '{}'."", setterName, step.getClass().getName())"
task5	"<line6>      log.debug(count+ "" ""+ uids.size()+ "" ""+ uidsToRemove.size()+ "" ""+ uidsCopy.size()+ "" removing ""+ (count == 0 && uidsCopy.isEmpty()));"	<line6>	"log.debug(""propogateKey uids {0} to {1}"", uids, uidsCopy)"	"<line6> log.debug(""propogateKey uids {0} to {1}"", uids, uidsCopy)"
task5	<line56>      log.error(e.getMessage(), e);	<line3>	"LOG.info(""Received message ["" + count + ""]: "" + tm.getText())"	"<line3> LOG.info(""Received message ["" + count + ""]: "" + tm.getText())"
task5	<line7>      log.debug(e.getMessage(), e);	<line7>	"log.error(""Failed to check if person is contained"", e)"	"<line7> log.error(""Failed to check if person is contained"", e)"
task5	"<line7>    log.debug(""usersPage.getTotalElements(): {}"", usersPage.getTotalElements());"	<line7>	"log.debug(""usersPage: "" + usersPage)"	"<line7> log.debug(""usersPage: "" + usersPage)"
task5	"<line2>    Log.debug(""Test"");"	<line2>	"Log.debug(""Test"")"	"<line2> Log.debug(""Test"")"
task5	"<line2>    logger.error(""Filter get error"", t);"	<line2>	"logger.error(""Error from invocation of "" + invocation.getMethodName(), t)"	"<line2> logger.error(""Error from invocation of "" + invocation.getMethodName(), t)"
task5	"<line4>      logger.trace(""Service already unregistered."");"	<line4>	"log.trace(""unregisterCommand: already unregistered"", ex)"	"<line4> log.trace(""unregisterCommand: already unregistered"", ex)"
task5	"<line6>          LOG.warn(""Could not find key {} in message"", mConfig.getMessageTimestampName());"	<line6>	"LOG.info(""Field not found: {}"", mNestedFields[i])"	"<line6> LOG.info(""Field not found: {}"", mNestedFields[i])"
task5	"<line15>    LOGGER.debug(""Projects size is {}"", projectPaginationDTO.getProjects().size());"	<line3>	"log.debug(""GetProjects"")"	"<line3> log.debug(""GetProjects"")"
task5	<line9>          LOG.error(ex.getLocalizedMessage());	<line9>	LOG.error(ex.getLocalizedMessage(), ex)	<line9> LOG.error(ex.getLocalizedMessage(), ex)
task5	"<line22>      log.error(""Error destroying prepared queries"", e);"	<line22>	"log.error(""Failed to destroy all prepared queries."", e)"	"<line22> log.error(""Failed to destroy all prepared queries."", e)"
task5	"<line13>      logger.error("""", fex);"	<line13>	"logger.error("""", fex)"	"<line13> logger.error("""", fex)"
task5	"<line3>      logger.trace(""The value {} ({}) is considered a byte because only the 8 least significant bits are set""+ "", but its value is outside signed byte that is between -128 and 127"",b,Integer.toHexString(b));"	<line3>	"logger.trace(""isByteValue: {}"", valid)"	"<line3> logger.trace(""isByteValue: {}"", valid)"
task5	<line13>        log.info(msg);	<line13>	log.warn(msg)	<line13> log.warn(msg)
task5	"<line7>      log.debug(""Open file: {}"", fileChooser.getSelectedFile().getPath());"	<line7>	"log.debug(""getFileCustom: "" + fileChooser.getSelectedFile())"	"<line7> log.debug(""getFileCustom: "" + fileChooser.getSelectedFile())"
task5	"<line4>    LOGGER.debug(""Patch {} with {}"", id, partialDto);"	<line4>	"LOGGER.debug(""Patch {} with {}"", id, partialDto)"	"<line4> LOGGER.debug(""Patch {} with {}"", id, partialDto)"
task5	<line13>      LOG.error(e.toString(), e);	<line13>	"logger.error(""Failed to create query for keyword: {}"", keyword, e)"	"<line13> logger.error(""Failed to create query for keyword: {}"", keyword, e)"
task5	<line5>        log.debug(exception, exception);	<line5>	log.debug(exception, exception)	<line5> log.debug(exception, exception)
task5	<line3>    log.error(msg);	<line3>	log.warn(msg)	<line3> log.warn(msg)
task5	"<line22>                    LOGGER.debug(""Using the configured proxy username and password"");"	<line41>	"LOGGER.warn(""Error getting connection."", ex)"	"<line41> LOGGER.warn(""Error getting connection."", ex)"
task5	"<line7>        logger.warn(""Unable to publish updated App Certificate"");"	<line7>	"logger.error(""Failed to publish certificate for appId: {}"", appId, e)"	"<line7> logger.error(""Failed to publish certificate for appId: {}"", appId, e)"
task5	"<line11>        logger.info(""Failed to add index for "" + value + "" due to "" + e.getMessage());"	<line11>	"logger.info(""Failed to update index for "" + value + "" due to "" + e.getMessage())"	"<line11> logger.info(""Failed to update index for "" + value + "" due to "" + e.getMessage())"
task5	"<line2>      LOG.trace(""Resource attempted to schedule a null task."");"	<line2>	"LOG.warn(""Scheduling a null task for delay {}ms"", delay)"	"<line2> LOG.warn(""Scheduling a null task for delay {}ms"", delay)"
task5	"<line19>        logger.info(""Transaction execution failed (service={}, txId={}, txMessageHash={})"",service.getName(),txId,context.getTransactionMessageHash(),e);"	<line19>	"logger.error(""Service {} threw exception on transaction {}"",service.getName(),txMessageHash,e)"	"<line19> logger.error(""Service {} threw exception on transaction {}"",service.getName(),txMessageHash,e)"
task5	"<line32>      logger.warn(""unexpected table: {}"", tableName);"	<line32>	"logger.warn(""Unknown table: "" + tableName)"	"<line32> logger.warn(""Unknown table: "" + tableName)"
task5	"<line9>      logger.error(""meet error when create upgrade log, file path:{}"", upgradeLogPath, e);"	<line9>	"logger.error(""Unable to create upgrade log file"", e)"	"<line9> logger.error(""Unable to create upgrade log file"", e)"
task5	"<line3>      logger.trace(""Adding pageTransaction "" + pageTransaction.getTransactionID());"	<line3>	"logger.trace(""addTransaction("" + pageTransaction + "")"")"	"<line3> logger.trace(""addTransaction("" + pageTransaction + "")"")"
task5	"<line2>    LOG.info(""Executing operation getTransformerPluginV2Configuration"");"	<line2>	"LOG.info(""Executing operation getTransformerPluginV2Configuration"")"	"<line2> LOG.info(""Executing operation getTransformerPluginV2Configuration"")"
task5	"<line35>        log.error(""Cannot create new id token"", e);"	<line35>	"log.error(""Failed to create ID Token"", e)"	"<line35> log.error(""Failed to create ID Token"", e)"
task5	"<line7>          log.warn(""{} was deprecated and will be removed in a future release; assuming user meant""+ "" its replacement {} and will remove that instead"",property,replacement);"	<line7>	"log.warn(""Deprecated system property {} will be ignored in future versions. ""+ ""Please use the replacement property {} instead."",property,replacement)"	"<line7> log.warn(""Deprecated system property {} will be ignored in future versions. ""+ ""Please use the replacement property {} instead."",property,replacement)"
task5	<line3>      logger.warn(marker, format, arguments);	<line3>	logger.warn(marker, format, arguments)	<line3> logger.warn(marker, format, arguments)
task5	"<line8>      logger.error(""getBrokerByRetryType error request {},response {}"", request, response);"	<line8>	"logger.error(""getBrokerByRetryType error request {},response {}"", request, response)"	"<line8> logger.error(""getBrokerByRetryType error request {},response {}"", request, response)"
task5	"<line3>    LOG.debug(""listing a migration issue for a content migration for the course"");"	<line3>	"LOG.debug(""listing a migration issue"")"	"<line3> LOG.debug(""listing a migration issue"")"
task5	"<line8>        log.error(""Error writing to network port"");"	<line8>	"log.error(""Could not send error status to {} because of IO error"", l)"	"<line8> log.error(""Could not send error status to {} because of IO error"", l)"
task5	"<line4>      LOGGER.warn(""Language classification {} not found"", classification.getRootID());"	<line4>	"log.error(""Unable to find classification root category"")"	"<line4> log.error(""Unable to find classification root category"")"
task5	"<line12>      LOGGER.warn(""Could not find language resources \""""+ fileName+ ""\"" for SiteReportRater. Using default (english)."");"	<line12>	"LOG.info(""Could not find the "" + recommendationLanguage + "" recommendations file. Using the default file."")"	"<line12> LOG.info(""Could not find the "" + recommendationLanguage + "" recommendations file. Using the default file."")"
task5	"<line14>      LOG.warn(""Exception occurred during done UnitOfWork for Exchange: {}. This exception will be""+ "" ignored."",exchange,e);"	<line14>	"LOG.debug(""Error doneUoW"", e)"	"<line14> LOG.debug(""Error doneUoW"", e)"
task5	"<line67>      LOG.error(""Category Code cannot be found from the category list during recalculation of account""+ "" object code for Contracts & Grants Invoice Document."");"	<line67>	"LOG.warn(""Cost Category does not exist for the given category code ""+ categoryCode+ "" - assignCurrentExpenditureToNonExistingAccountObjectCode()"")"	"<line67> LOG.warn(""Cost Category does not exist for the given category code ""+ categoryCode+ "" - assignCurrentExpenditureToNonExistingAccountObjectCode()"")"
task5	"<line5>        log.trace(""no store found for "" + o.getUID() + "" for disposal"");"	<line5>	"log.trace(""Virtualizer store not found for object "" + o)"	"<line5> log.trace(""Virtualizer store not found for object "" + o)"
task5	"<line11>        logger.trace(""Assertion from where roles will be sought = "" + AssertionUtil.asString(assertion));"	<line11>	"logger.trace(""SAML Assertion: "" + assertion.toString())"	"<line11> logger.trace(""SAML Assertion: "" + assertion.toString())"
task5	"<line59>      LOG.error("""", e);"	<line59>	"LOG.error(""Error in posting "" + entity, e)"	"<line59> LOG.error(""Error in posting "" + entity, e)"
task5	<line27>      LOGGER.debug(e);	<line27>	LOGGER.error(e.getMessage(), e)	<line27> LOGGER.error(e.getMessage(), e)
task5	"<line3>    log.info(""Finding document by employee name {} ."", employeeName);"	<line10>	"LOGGER.info(""Found document with id : "" + documentInfo.getId())"	"<line10> LOGGER.info(""Found document with id : "" + documentInfo.getId())"
task5	<line13>      log.info(message);	<line13>	log.info(message)	<line13> log.info(message)
task5	"<line12>              LOGGER.debug(""Loading roles which the current user has right to assign"");"	<line2>	"LOGGER.debug(""Creating list panel for type {}"", type)"	"<line2> LOGGER.debug(""Creating list panel for type {}"", type)"
task5	"<line2>      LOGGER.error(""Expected {}, but got {}"", targetClass, entity);"	<line2>	"log.debug(""Expected type "" + targetClass + "" got "" + entity)"	"<line2> log.debug(""Expected type "" + targetClass + "" got "" + entity)"
task5	"<line7>    LOG.debug(""Creating security event with targetEdOrgList determined from entities of type ""+ entityType);"	<line7>	"LOG.debug(""Using entity type {} as the target for the security event"", entityType)"	"<line7> LOG.debug(""Using entity type {} as the target for the security event"", entityType)"
task5	"<line13>      LOGGER.error(""Streaming for replica set {} failed"", replicaSet.replicaSetName(), t);"	<line13>	"LOGGER.error(""Error reading oplog from primary on replicaSet: "" + replicaSet, t)"	"<line13> LOGGER.error(""Error reading oplog from primary on replicaSet: "" + replicaSet, t)"
task5	"<line4>        LOG.info(""Writing person: "" + person);"	<line4>	"LOG.info(""Writing "" + person)"	"<line4> LOG.info(""Writing "" + person)"
task5	<line13>        log.debug(exception, exception);	<line13>	log.debug(exception, exception)	<line13> log.debug(exception, exception)
task5	"<line1>    log.info(""buildOuputZip called with id="" + id);"	<line7>	"log.error(""Zip file not found: "" + e.getMessage())"	"<line7> log.error(""Zip file not found: "" + e.getMessage())"
task5	"<line3>    LOGGER.info(""Loaded segment metadata for segment : "" + segmentMetadata.getName());"	<line3>	"log.debug(""Loaded segment metadata {}"", segmentMetadata)"	"<line3> log.debug(""Loaded segment metadata {}"", segmentMetadata)"
task5	"<line7>      log.trace(""%s: rejected connection from %s %s"",local_addr, peer_addr, explanation(conn_exists, replace));"	<line7>	"log.trace(""%s: connection to %s already exists, closing"", name, peer_addr)"	"<line7> log.trace(""%s: connection to %s already exists, closing"", name, peer_addr)"
task5	"<line12>        LOGGER.warn(""Plugin provider for ingest type '""+ formatPlugin.getIngestFormatName()+ ""' does not support hdfs ingest"",e);"	<line12>	"LOGGER.info(""IngestFormatPluginProviderSpi.createIngestFromHdfsPlugin() returned null for format""+ "" options {}"",formatOptions)"	"<line12> LOGGER.info(""IngestFormatPluginProviderSpi.createIngestFromHdfsPlugin() returned null for format""+ "" options {}"",formatOptions)"
task5	"<line2>    LOG.info(""Executing operation putTransformerV2"");"	<line2>	"LOG.info(""Executing operation putTransformerV2"")"	"<line2> LOG.info(""Executing operation putTransformerV2"")"
task5	"<line3>    LOG.info(""Error in pingAsyncAsync() {}"", t.getMessage());"	<line2>	"logger.error(""Error while finishing stream request"", t)"	"<line2> logger.error(""Error while finishing stream request"", t)"
task5	"<line2>      logger.debug(""{} Stopping leadership election..."", logPrefix());"	<line2>	"logger.debug(""Stopping serialized executor..."")"	"<line2> logger.debug(""Stopping serialized executor..."")"
task5	"<line18>            LOG.error(""Failed while processing event"", ex);"	<line18>	"LOG.error(""Error during timer push event handling"", ex)"	"<line18> LOG.error(""Error during timer push event handling"", ex)"
task5	<line9>      LOG.error(ERROR_TRANSLATING_POSTGRES_EXC_MSG, pSqlException);	<line2>	LOGGER.error(ERROR_TRANSLATING_EXCEPTION_MSG, pSqlException)	<line2> LOGGER.error(ERROR_TRANSLATING_EXCEPTION_MSG, pSqlException)
task5	"<line11>          logger.info(""Access point reachable? {}"", ret);"	<line12>	"logger.error(""Exception :: isAccessPointReachable() :: failed to determine reachability of {}"",ipAddress.getHostAddress(),e)"	"<line12> logger.error(""Exception :: isAccessPointReachable() :: failed to determine reachability of {}"",ipAddress.getHostAddress(),e)"
task5	<line5>            logger.info(dialog.getTitle());	<line5>	"logger.info(""Showing dialog later"")"	"<line5> logger.info(""Showing dialog later"")"
task5	"<line2>    log.info(""{0}: Cache file root directory: {1}"", logCacheName, rafDir);"	<line2>	"log.info(""{0}: Initialized rafDir to {1}"", this.logCacheName, this.rafDir)"	"<line2> log.info(""{0}: Initialized rafDir to {1}"", this.logCacheName, this.rafDir)"
task5	"<line2>    LOG.info(""Deleting topic {}"", topic);"	<line10>	"log.error(""Delete test topic : {} failed, {}"", topic, e.getMessage())"	"<line10> log.error(""Delete test topic : {} failed, {}"", topic, e.getMessage())"
task5	"<line49>      logger.error(""Ip Assoc failure on applying one ip due to exception:  "", e);"	<line51>	"logger.error(""Exception: "", e)"	"<line51> logger.error(""Exception: "", e)"
task5	"<line19>      logger.debug(""findAcceptApplicationName result:{}"", resultSet);"	<line3>	"logger.debug(""findAcceptApplicationName fromApplication:{}"", fromApplication)"	"<line3> logger.debug(""findAcceptApplicationName fromApplication:{}"", fromApplication)"
task5	"<line3>      logger.debug(""Note: Empty AI platform is being mapped."");"	<line3>	"logger.warn(""AIPlatformValue is null"")"	"<line3> logger.warn(""AIPlatformValue is null"")"
task5	"<line2>    logger.warn(String.format(""Communication channel lost for AspFactroy=%s Association=%s"",this.name, association.getName()));"	<line2>	"logger.info(""Communication lost for association: {}"", association.getId())"	"<line2> logger.info(""Communication lost for association: {}"", association.getId())"
task5	"<line5>      log.error(""RemoteException"", e);"	<line5>	"log.error(""RemoteException"", e)"	"<line5> log.error(""RemoteException"", e)"
task5	"<line10>        LOG.error(""Exception in flush thread"", e);"	<line10>	"LOG.error(""Exception while flushing ledgers"", e)"	"<line10> LOG.error(""Exception while flushing ledgers"", e)"
task5	"<line55>        logger.error(""Unsupported feature type in Describe Platform M1_0: ""+ this.getDatasetFeatureType().toString());"	<line55>	"log.error(""Unsupported feature type for DS response"")"	"<line55> log.error(""Unsupported feature type for DS response"")"
task5	"<line5>      log.debug(""Result in "" + this.getClass().getCanonicalName() + "" injected from cache"");"	<line5>	"log.debug(""cache result injected: "" + result)"	"<line5> log.debug(""cache result injected: "" + result)"
task5	<line7>        LOG.warn(ex.toString());	<line7>	LOG.warn(ex.toString())	<line7> LOG.warn(ex.toString())
task5	"<line9>          LOGGER.warn(""UNKNOWN COMMAND RECEIVED TRHOUGH PIPE ""+ pipe.getInboundPipe()+ "": ""+ uce.getMessage());"	<line21>	"log.error(""External executor exception"", eee)"	"<line21> log.error(""External executor exception"", eee)"
task5	"<line13>      LOG.debug(""Dereferencing {} for {}"", contextReference, bundleContext);"	<line4>	"LOG.debug(""httpContext is null, using Bundle.getBundleContext() to resolve"")"	"<line4> LOG.debug(""httpContext is null, using Bundle.getBundleContext() to resolve"")"
task5	"<line11>      LOGGER.trace(StringUtilities.formatTimingMessage(""Added/Remove Geometries to registry[""+ newVisibleGeomSet.size()+ ""/""+ newHiddenGeomSet.size()+ ""] in "",System.nanoTime() - start));"	<line11>	"LOGGER.trace(""publishToRegistry took "" + ((System.nanoTime() - start) / 1000000) + "" ms"")"	"<line11> LOGGER.trace(""publishToRegistry took "" + ((System.nanoTime() - start) / 1000000) + "" ms"")"
task5	"<line3>      logger.trace(""Failed to notify success ({}) to a promise: {}"", result, promise);"	<line3>	"logger.error(""trySuccess() failed for promise {}"", promise)"	"<line3> logger.error(""trySuccess() failed for promise {}"", promise)"
task5	<line5>      LOG.debug(message);	<line5>	LOG.error(message)	<line5> LOG.error(message)
task5	"<line2>    logger.info(""Filter get the value: "" + appResponse.getValue());"	<line2>	"LOGGER.debug(""Application {} responded to {} with status {} and data '{}'"",getApplicationName(),invocation,appResponse.getStatus(),appResponse.getData())"	"<line2> LOGGER.debug(""Application {} responded to {} with status {} and data '{}'"",getApplicationName(),invocation,appResponse.getStatus(),appResponse.getData())"
task5	"<line10>        LOG.error(""Unrecognized search sql: "" + searchSql);"	<line10>	"LOG.warn(""Cannot use custom search SQL for class {} because it is not valid SQL. SQL=""+ searchSql+ "" CLASS=""+ oClass.getName())"	"<line10> LOG.warn(""Cannot use custom search SQL for class {} because it is not valid SQL. SQL=""+ searchSql+ "" CLASS=""+ oClass.getName())"
task5	"<line13>                LOG.warn(""Deleting stale registration request {} : {}"",requestedHost.getHostname(),requestedHost.getAddress());"	<line13>	"logger.info(""Cleaning up requested host"")"	"<line13> logger.info(""Cleaning up requested host"")"
task5	<line6>      log.error(exception, exception);	<line6>	log.error(exception, exception)	<line6> log.error(exception, exception)
task5	"<line5>      logger.trace(LogMarker.VERSIONED_OBJECT_LIST_VERBOSE,""reading object {} of type {}"",index,objectTypeArray[index]);"	<line5>	"logger.trace(LogMarker.VERSIONED_OBJECT_LIST_VERBOSE, ""Reading a versioned object at index {}"", index)"	"<line5> logger.trace(LogMarker.VERSIONED_OBJECT_LIST_VERBOSE, ""Reading a versioned object at index {}"", index)"
task5	"<line2>    LOG.trace(""PersonnameDAO.create() - Begin"");"	<line2>	"LOGGER.warn(""The personname record to create is null!"")"	"<line2> LOGGER.warn(""The personname record to create is null!"")"
task5	"<line15>      logger.warn(""BBSConfigSetting update/ got a error!"");"	<line15>	"logger.warn(""system get setting by id got an exception!"")"	"<line15> logger.warn(""system get setting by id got an exception!"")"
task5	"<line6>    log.info(""unmarshalling fonts.substitutions"");"	<line16>	"log.debug(""fonts.substitutions map populated"")"	"<line16> log.debug(""fonts.substitutions map populated"")"
task5	<line10>        log.debug(configurationException, configurationException);	<line10>	log.debug(configurationException, configurationException)	<line10> log.debug(configurationException, configurationException)
task5	"<line19>        logger.debug(""user=""+ userName+ "" password=""+ passwd+ "" password length=""+ passwd.getBytes().length);"	<line19>	"logger.debug(""setPassword(String)"")"	"<line19> logger.debug(""setPassword(String)"")"
task5	<line3>      log.info(bom.toString());	<line3>	"log.info(""Platform: ""+ bom.toString()+ "" from ""+ o.getSource().getName()+ "" (""+ o.getSource().getUrl()+ "")"")"	"<line3> log.info(""Platform: ""+ bom.toString()+ "" from ""+ o.getSource().getName()+ "" (""+ o.getSource().getUrl()+ "")"")"
task5	"<line5>      log.warn(""Exception closing webSocket session"", e);"	<line5>	"LOG.warn(""IO Error during closing native WebSocket session"", e)"	"<line5> LOG.warn(""IO Error during closing native WebSocket session"", e)"
task5	"<line8>      LOG.info(""Error adding metadata record. metadataName={} length={}"", name, recordLength, e);"	<line2>	"LOG.debug(""Adding metadata record {}"", name)"	"<line2> LOG.debug(""Adding metadata record {}"", name)"
task5	"<line53>      LOG.debug(""Second connection with same container Id failed as expected."");"	<line53>	"LOG.debug(""Caught expected exception on connect: {}"", ex.getMessage())"	"<line53> LOG.debug(""Caught expected exception on connect: {}"", ex.getMessage())"
task5	"<line27>      LOG.debug(""Configuring HTTP client to use HTTP proxy {}:{}"", proxyAuthHost, proxyAuthPort);"	<line34>	"LOG.debug(""Configuring HTTP proxy: {} : {}"", proxyAuthHost, proxyAuthPort)"	"<line34> LOG.debug(""Configuring HTTP proxy: {} : {}"", proxyAuthHost, proxyAuthPort)"
task5	"<line10>    LOG.info(""Session "" + sessionId + "" is created."");"	<line10>	"logger.info(""Created new session: "" + sessionId)"	"<line10> logger.info(""Created new session: "" + sessionId)"
task5	"<line7>      LOGGER.error(""Error on sending registry entry."", e);"	<line7>	"LOG.error(""Failed to send data on the socket."", e)"	"<line7> LOG.error(""Failed to send data on the socket."", e)"
task5	"<line5>      LOG.debug(""Finished split source: %s (%s)"", splitSource.getCatalogName(), splitSource.toString());"	<line1>	"log.debug(""Deactivating split source %s"", splitSource.getMarker())"	"<line1> log.debug(""Deactivating split source %s"", splitSource.getMarker())"
task5	"<line59>        LOG.warn(""Unable to read {}"", docf);"	<line59>	"LOG.debug(""Unknown Avro field type: "" + fieldSchema.getType())"	"<line59> LOG.debug(""Unknown Avro field type: "" + fieldSchema.getType())"
task5	"<line11>      LOG.warn(""Failed to take over file access count for all tables, ""+ ""which may make the measurement for data temperature inaccurate!"",e.getMessage());"	<line11>	"LOG.error(""takeOverAccessCount error"", e)"	"<line11> LOG.error(""takeOverAccessCount error"", e)"
task5	"<line2>    log.info(""Removing user {}"", user);"	<line2>	"log.info(""Deleting user {}"", username)"	"<line2> log.info(""Deleting user {}"", username)"
task5	"<line1>    LOGGER.info(String.format(""Executing: %s from %s"",command,pathToWorkingDirectory != null? pathToWorkingDirectory.getAbsolutePath(): System.getProperty(""user.dir"")));"	<line38>	"log.debug(""{}"", output.toString())"	"<line38> log.debug(""{}"", output.toString())"
task5	"<line6>            LOGGER.warn(""Ignoring failing MappingSource to MailAddress conversion for user {}"", user, e);"	<line6>	"LOGGER.warn(""Error while parsing mail address for user {}"", user.asString(), e)"	"<line6> LOGGER.warn(""Error while parsing mail address for user {}"", user.asString(), e)"
task5	"<line2>      LOG.warn(""it can't be updated because the critical path provided is empty"");"	<line2>	"LOG.debug(""No critical path found, so no need to calculate theoretical advance"")"	"<line2> LOG.debug(""No critical path found, so no need to calculate theoretical advance"")"
task5	<line23>      log.error(systemException, systemException);	<line23>	log.error(systemException, systemException)	<line23> log.error(systemException, systemException)
task5	"<line3>    LOGGER.debug(""get One Ingest id={}"", id);"	<line3>	"LOGGER.debug(""Get logbook operation {}"", id)"	"<line3> LOGGER.debug(""Get logbook operation {}"", id)"
task5	"<line6>      LOG.error(""Op {} threw an exception during processing watermark"", this.getClass().getName(), e);"	<line4>	"LOG.debug(""Processing watermark {}"", time)"	"<line4> LOG.debug(""Processing watermark {}"", time)"
task5	"<line9>      log.warn(""Compaction failed for {} on {}"", compactable.getExtent(), getJob(), e);"	<line9>	"LOG.error(""Failed to compact chunk store ID "" + compactable.getId(), e)"	"<line9> LOG.error(""Failed to compact chunk store ID "" + compactable.getId(), e)"
task5	"<line1>    log.info(""Configuration resource: "" + resource);"	<line1>	"log.debug(""config.resource: "" + resource)"	"<line1> log.debug(""config.resource: "" + resource)"
task5	"<line2>      LOG.info(""Getting Hive Connection to "" + config.hiveJDBCUrl);"	<line2>	"LOG.info(""Creating connection to Hive"")"	"<line2> LOG.info(""Creating connection to Hive"")"
task5	"<line2>    logger.debug(""Getting index of single electron: "", electron);"	<line2>	"logger.debug(""Getting index of single electron: "", electron)"	"<line2> logger.debug(""Getting index of single electron: "", electron)"
task5	"<line6>      LOGGER.error(""Error writing uploaded File in temp file"", e);"	<line6>	"log.error(""Cannot write in tmp file"", e)"	"<line6> log.error(""Cannot write in tmp file"", e)"
task5	"<line2>    LOG.debug(""Creating a wired context to local LDAP server on port {}"", ldapServer.getPort());"	<line2>	"LOG.info(""Creating context for Dn: {}"", principalDn)"	"<line2> LOG.info(""Creating context for Dn: {}"", principalDn)"
task5	<line16>      log.error(systemException, systemException);	<line16>	log.error(systemException, systemException)	<line16> log.error(systemException, systemException)
task5	"<line8>    LOG.debug(""Graph [{}] get edges by ids: {}"", graph, stringIds);"	<line8>	"LOG.debug(""Graph [{}] list edges by ids: {}"", graph, stringIds)"	"<line8> LOG.debug(""Graph [{}] list edges by ids: {}"", graph, stringIds)"
task5	"<line3>        LOGGER.debug(""Stopping periodic Server Refreshes."");"	<line3>	"LOGGER.debug(""Stopping timer..."")"	"<line3> LOGGER.debug(""Stopping timer..."")"
task5	<line14>      log.error(jsonProcessingException, jsonProcessingException);	<line14>	log.error(jsonProcessingException, jsonProcessingException)	<line14> log.error(jsonProcessingException, jsonProcessingException)
task5	"<line11>        logger.debug(""Received an exception getting pdx type from pool {}, {}"", pool, e.getMessage(), e);"	<line11>	"logger.debug(""Received an exception getting pdx type from pool {}, {}"", pool, e.getMessage(), e)"	"<line11> logger.debug(""Received an exception getting pdx type from pool {}, {}"", pool, e.getMessage(), e)"
task5	"<line15>      log.error(""Failure to validate path "" + path, e);"	<line15>	"LOG.warn(""Got error while testing writability of path {}, so skipping it."", path, e)"	"<line15> LOG.warn(""Got error while testing writability of path {}, so skipping it."", path, e)"
task5	"<line22>                logger.warn(""Could not delete from index series {}: {}"", id, e.getMessage());"	<line22>	"logger.error(""Error indexing series {}: {}"", id, e.getMessage())"	"<line22> logger.error(""Error indexing series {}: {}"", id, e.getMessage())"
task5	"<line7>        logger.error(""map entry wrong "" + e + "" to "" + c + "" old "" + b);"	<line7>	"LOG.error(""Removed from map: "" + e + "" -> "" + b + ""!="" + c)"	"<line7> LOG.error(""Removed from map: "" + e + "" -> "" + b + ""!="" + c)"
task5	"<line14>      LOG.info(""Result: "" + counter + "" = "" + row);"	<line16>	"LOG.info(""Result: "" + data)"	"<line16> LOG.info(""Result: "" + data)"
task5	"<line1>    log.debug(""Setting scanner factory on ShardQueryLogic: ""+ System.identityHashCode(this)+ "".setScannerFactory(""+ System.identityHashCode(scannerFactory)+ ')');"	<line1>	"LOG.info(""setting scannerFactory to {}"", scannerFactory)"	"<line1> LOG.info(""setting scannerFactory to {}"", scannerFactory)"
task5	"<line7>      log.info(""setting documents similarity exporter threshold to: "" + similarityThreshold);"	<line7>	"log.info(""Set document similarity threshold to "" + similarityThreshold)"	"<line7> log.info(""Set document similarity threshold to "" + similarityThreshold)"
task5	"<line8>      LOG.debug(String.format(""table : %s, UUID: %s, commit-ts: %d, seq-no: %d, micro-ts: %d"",ar.getTableName(),ar.getTransactionUUID(),commitTimestamp,transactionSequenceNumber,microsOverride));"	<line8>	"LOG.debug(""Override row commit time to {} and set the microsecond timestamp to {}"",commitTimestamp,microsOverride)"	"<line8> LOG.debug(""Override row commit time to {} and set the microsecond timestamp to {}"",commitTimestamp,microsOverride)"
task5	<line3>      this.logger.info(fmt, i, i * 7L, i / 16.0);	<line3>	"logger.info(""Hello World"")"	"<line3> logger.info(""Hello World"")"
task5	"<line21>                    log.warn(""[{}] Failed to mark delete while trimming data ledgers: {}"",name,exception.getMessage());"	<line21>	"log.error(""[{}] Failed to markdelete position {} in cursor {}"", name, highestPositionToDelete, cursorName, exception)"	"<line21> log.error(""[{}] Failed to markdelete position {} in cursor {}"", name, highestPositionToDelete, cursorName, exception)"
task5	"<line14>    logger.info(""HTTP server stoped : "" + node);"	<line1>	"log.info(""Shutting down secure server"")"	"<line1> log.info(""Shutting down secure server"")"
task5	"<line1>    log.info(""released {}"", serviceName);"	<line1>	"LOGGER.info(""{} has been released."", serviceName)"	"<line1> LOGGER.info(""{} has been released."", serviceName)"
task5	"<line3>      log.info(""Iteration: "" + i);"	<line3>	"log.info(""Iteration: "" + i)"	"<line3> log.info(""Iteration: "" + i)"
task5	"<line3>      LOGGER.debug(""Admin supplied distance tolerance is too low. Defaulting to the minimum of {} meter"",MIN_DISTANCE_TOLERANCE_IN_METERS);"	<line4>	"logger.warn(""The distance tolerance cannot be set to a value lower than {} meters. It has been clamped to""+ "" this value."",MIN_DISTANCE_TOLERANCE_IN_METERS)"	"<line4> logger.warn(""The distance tolerance cannot be set to a value lower than {} meters. It has been clamped to""+ "" this value."",MIN_DISTANCE_TOLERANCE_IN_METERS)"
task5	"<line7>      logger.warn(""Warning! duplication nominal label"");"	<line7>	"logger.error(""Error in finding duplicate document nominal label with id : "" + documentNominalLabel.getIdDTO())"	"<line7> logger.error(""Error in finding duplicate document nominal label with id : "" + documentNominalLabel.getIdDTO())"
task5	"<line20>        log.warn(""Error updating JoalAudioSource ({})"", this.getSystemName());"	<line20>	"log.warn(""Error updating JoalAudioSource ({})"", this.getSystemName())"	"<line20> log.warn(""Error updating JoalAudioSource ({})"", this.getSystemName())"
task5	"<line18>      LOGGER.error(""StudyMetaDataService - termsPolicy() :: ERROR"", e);"	<line18>	"LOGGER.error(""StudyMetaDataService - termsPolicy() :: ERROR"", e)"	"<line18> LOGGER.error(""StudyMetaDataService - termsPolicy() :: ERROR"", e)"
task5	<line25>        Log.fatal(ex);	<line25>	"logger.error(""Error waiting for workflow run to transition"", ex)"	"<line25> logger.error(""Error waiting for workflow run to transition"", ex)"
task5	"<line14>      logger.info(""Correctly failed to send event"", ex);"	<line14>	"logger.debug(""Expected exception"", ex)"	"<line14> logger.debug(""Expected exception"", ex)"
task5	"<line4>      ActiveMQRALogger.LOGGER.trace(""createTextMessage"" + session);"	<line4>	"ActiveMQRALogger.LOGGER.trace(""createTextMessage()"")"	"<line4> ActiveMQRALogger.LOGGER.trace(""createTextMessage()"")"
task5	"<line2>    log.info(""Watch closed"");"	<line2>	"log.debug(""onClose {}"", this)"	"<line2> log.debug(""onClose {}"", this)"
task5	"<line1>    log.debug("""");"	<line1>	"log.debug("""")"	"<line1> log.debug("""")"
task5	"<line12>      LOGGER.debug(""Capturing structure of table {}"", tableId);"	<line13>	"LOGGER.debug(""Capturing schema changes of table {}"", tableId)"	"<line13> LOGGER.debug(""Capturing schema changes of table {}"", tableId)"
task5	"<line8>      LOG.error("""", e);"	<line8>	"LOG.error("""", e)"	"<line8> LOG.error("""", e)"
task5	"<line2>    log.info(""-----  testProcessFlagsOrder  -----"");"	<line4>	"log.info(""Created test files"")"	"<line4> log.info(""Created test files"")"
task5	"<line13>    log.debug(""Creating new tag {}."", newTag);"	<line27>	"log.debug(""Created tag {}."", newTag.name)"	"<line27> log.debug(""Created tag {}."", newTag.name)"
task5	"<line3>      logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Writing Class {}"", c);"	<line3>	"logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Writing class {}"", c.getName())"	"<line3> logger.trace(LogMarker.SERIALIZER_VERBOSE, ""Writing class {}"", c.getName())"
task5	<line22>      logger.error(ex);	<line22>	"logger.error(""Email client not present"", ex)"	"<line22> logger.error(""Email client not present"", ex)"
task5	<line5>      log.error(exception, exception);	<line5>	log.error(exception, exception)	<line5> log.error(exception, exception)
task5	"<line9>      LOGGER.warn(""Cannot read GeoWave build properties to show version information"", e);"	<line10>	"console.warn(""Cannot read GeoWave build properties to show version information: "" + e.getMessage())"	"<line10> console.warn(""Cannot read GeoWave build properties to show version information: "" + e.getMessage())"
task5	"<line12>      LOGGER.error(""Error creating transfer thread"", ex);"	<line12>	"LOGGER.error(""Error while indexing file {}"", file, ex)"	"<line12> LOGGER.error(""Error while indexing file {}"", file, ex)"
task5	"<line3>    LOGGER.info(""Dumping the content of the caches.\nCurrent counters:\n{}\n"", cacheInformation);"	<line3>	"LOGGER.debug(""Dumping cache registry content{}"", cacheInformation)"	"<line3> LOGGER.debug(""Dumping cache registry content{}"", cacheInformation)"
task5	"<line6>      log.debug(""entering 'save' method..."");"	<line6>	"log.debug(""save"")"	"<line6> log.debug(""save"")"
task5	"<line2>    LOG.info(""foo() method called with: "" + bar);"	<line2>	"logger.info(""bar = "" + bar)"	"<line2> logger.info(""bar = "" + bar)"
task5	"<line7>        logger.error(String.format(Locale.ROOT,""Convert %s to immutable for node %s failed."",cubeName,node.toNormalizeString()),ioe);"	<line7>	"logger.error(""Fail to make cube immutable for node "" + node, ioe)"	"<line7> logger.error(""Fail to make cube immutable for node "" + node, ioe)"
task5	"<line2>    log.debug(""start"");"	<line3>	"log.info(""Starting the update thread"")"	"<line3> log.info(""Starting the update thread"")"
task5	<line3>      LOG.error(e.getMessage());	<line3>	"logger.error(""Error while fetching STCC list"", e)"	"<line3> logger.error(""Error while fetching STCC list"", e)"
task5	"<line5>        logger.error(""Error stopping socket "" + socketDescription, e);"	<line5>	"logger.debug(""Failed to shutdown event executor group"", e)"	"<line5> logger.debug(""Failed to shutdown event executor group"", e)"
task5	<line3>      LOGGER.info(task);	<line3>	"LOGGER.info(""Task updated to '"" + task + ""'"")"	"<line3> LOGGER.info(""Task updated to '"" + task + ""'"")"
task5	"<line2>    log.warn(""disconnected"");"	<line5>	"logger.info(""PubSub client disconnected. Mode: {}"", mode)"	"<line5> logger.info(""PubSub client disconnected. Mode: {}"", mode)"
task5	"<line3>    logger.trace(""Read {}  byte, val is {}"", context, ByteUtils.formatByte(b));"	<line3>	"logger.debug(""read('{}') -> {}"", context, b)"	"<line3> logger.debug(""read('{}') -> {}"", context, b)"
task5	"<line15>          logger.error(String.format(""Cannot delete authority item CSID='%s' because it still has records in the""+ "" system that are referencing it."",docModel.getName()));"	<line4>	"logger.debug(""Handling workflow transition for document ('{}')"", wrapDoc.getTitle())"	"<line4> logger.debug(""Handling workflow transition for document ('{}')"", wrapDoc.getTitle())"
task5	"<line7>        log.info(""Score at iteration {} is {}"", iteration, score);"	<line7>	"log.info(""Iteration: "" + iteration + "" Score: "" + score)"	"<line7> log.info(""Iteration: "" + iteration + "" Score: "" + score)"
task5	"<line45>          logger.debug(""Returning CREATED response for reopen case {}"", caseId);"	<line39>	"logger.debug(""About to reopen case instance {} on container {}"", caseId, containerId)"	"<line39> logger.debug(""About to reopen case instance {} on container {}"", caseId, containerId)"
task5	<line17>      log.error(exception, exception);	<line17>	log.error(exception, exception)	<line17> log.error(exception, exception)
task5	"<line4>      log.error(""Local trip update buffer full!  Clearing!  Dropping "" + tripUpdate.getId() + "" record"");"	<line4>	"log.error(""Could not persist trip update, dropping it"")"	"<line4> log.error(""Could not persist trip update, dropping it"")"
task5	"<line3>      logger.trace(""addObjectField fieldName: {}"", fieldName);"	<line3>	"logger.trace(""addObjectField fieldName:{} member:{}"", fieldName, member)"	"<line3> logger.trace(""addObjectField fieldName:{} member:{}"", fieldName, member)"
task5	"<line4>      log.info(""Iteration: "" + i);"	<line4>	"log.info(""Start iteration: "" + i)"	"<line4> log.info(""Start iteration: "" + i)"
task5	"<line10>      log.error(""Exception in startHandshake"", e);"	<line13>	"LOG.debug(""{} sending handshake to {}"", this, resourceDescriptor.getServerUri())"	"<line13> LOG.debug(""{} sending handshake to {}"", this, resourceDescriptor.getServerUri())"
task5	"<line10>        logger.warn(""{}: No session available to remvoe session attribute! (this can happen in""+ "" onStructrLogin/onStructrLogout)"",getReplacement());"	<line10>	"logger.warn(""Unable to remove session attribute. Session is null."")"	"<line10> logger.warn(""Unable to remove session attribute. Session is null."")"
task5	"<line14>        logger.warn(""Failed to create account servlet"", e);"	<line3>	"logger.debug(""Initialize account handler."")"	"<line3> logger.debug(""Initialize account handler."")"
task5	"<line2>    logger.trace(""Submitting schema refresh"");"	<line6>	"logger.debug(""[{}] Refreshing schema for {} {}"", logPrefix, targetType, targetName)"	"<line6> logger.debug(""[{}] Refreshing schema for {} {}"", logPrefix, targetType, targetName)"
task5	"<line17>      LOGGER.error(""Unable to find OSLP device: {}"", deviceIdentification);"	<line17>	"LOGGER.info(""No oslp device found for device: {}"", deviceIdentification)"	"<line17> LOGGER.info(""No oslp device found for device: {}"", deviceIdentification)"
task5	"<line5>    logger.debug(""Session '{}' added to Web Socket manager"", session.getId());"	<line1>	"LOGGER.debug(""Adding new session to the Web Socket session pool: {}"", session)"	"<line1> LOGGER.debug(""Adding new session to the Web Socket session pool: {}"", session)"
task5	"<line5>      LOG.error(""Error loading config from storm conf {}"", topoConf);"	<line5>	"LOG.error(""Error creating new Redis Key Value state. Exiting..."")"	"<line5> LOG.error(""Error creating new Redis Key Value state. Exiting..."")"
task5	"<line11>      logger.error(""Failed to set DEBUG log level due to ISolutionEngine not being available in""+ "" MicroPlatform"");"	<line11>	"Logger.error(this, ""Error during start"", e)"	"<line11> Logger.error(this, ""Error during start"", e)"
task5	"<line4>      log.warn(this.getClass().getName() + ""."" + methodName + ""() test took "" + runtime + ""ms"");"	<line4>	"LOG.warn(""Test has been running for {} seconds"", runtime / 1000)"	"<line4> LOG.warn(""Test has been running for {} seconds"", runtime / 1000)"
task5	"<line2>      log.debug(""fetching calendar configurations for "" + subscribeId);"	<line2>	"logger.debug(""fetching calendar configurations for "" + subscribeId)"	"<line2> logger.debug(""fetching calendar configurations for "" + subscribeId)"
task5	"<line11>      LOG.error(""Unknown error while trying to fetch index readers."", e);"	<line11>	"LOG.error(""Unknown error while trying to get indexes for table ["" + table + ""]"", e)"	"<line11> LOG.error(""Unknown error while trying to get indexes for table ["" + table + ""]"", e)"
task5	"<line1>    log.info(""Enter project description {}"", projectDescription);"	<line1>	"log.info(""Enter project description {}"", projectDescription)"	"<line1> log.info(""Enter project description {}"", projectDescription)"
task5	<line8>        LOG.info(dataExample.getAbsolutePath());	<line11>	"LOGGER.error(""Unable to copy data folder, please check configuration"", e)"	"<line11> LOGGER.error(""Unable to copy data folder, please check configuration"", e)"
task5	"<line11>      logger.error(""Error closing tag"", t);"	<line11>	"logger.error(""error in end tag"", t)"	"<line11> logger.error(""error in end tag"", t)"
task5	"<line7>          logger.error(""Object validation error "" + reader.GetObjectPID() + "": "" + e.getMessage());"	<line7>	"LOGGER.error(""Object validation failed: {}"", e.getMessage())"	"<line7> LOGGER.error(""Object validation failed: {}"", e.getMessage())"
task5	"<line9>        LOGGER.error(""Only HLS 5, LLS 1 and public (LLS 0) connections are currently supported"");"	<line9>	"LOGGER.error(""Unsupported security level: {}"", securityLevel)"	"<line9> LOGGER.error(""Unsupported security level: {}"", securityLevel)"
task5	"<line7>      LOG.warn(""Exception checking for exists on: "" + key);"	<line7>	"LOG.error(""Got error while testing existence of dir "" + dir, e)"	"<line7> LOG.error(""Got error while testing existence of dir "" + dir, e)"
task5	"<line3>      LOG.warn(""{}: Ignoring {}"", server.getId(), reply);"	<line7>	"LOG.info(""Inconsistency detected. Local node should have index {}, but it has {},""+ "" which is greater than the upper bound {}. Clearing pending requests."",reply.getNextIndex(),request.getPreviousLog().getIndex(),reply.getNextIndex())"	"<line7> LOG.info(""Inconsistency detected. Local node should have index {}, but it has {},""+ "" which is greater than the upper bound {}. Clearing pending requests."",reply.getNextIndex(),request.getPreviousLog().getIndex(),reply.getNextIndex())"
task5	"<line1>    LOG.debug(""{}: {}"", FileUtils.fileName(getFile()), freeList.toString());"	<line1>	"LOG.debug(""Freelist: "" + _freelist)"	"<line1> LOG.debug(""Freelist: "" + _freelist)"
task5	"<line3>    LOG.debug(""SuggestComponent prepare with : "" + params);"	<line2>	"log.debug(""prepare for build or reload"")"	"<line2> log.debug(""prepare for build or reload"")"
task5	"<line6>      LOGGER.error(""Unable to deserialize '{}'"", message, e);"	<line6>	"logger.error(""Failed to deserialize message: \""{}\"""", message, e)"	"<line6> logger.error(""Failed to deserialize message: \""{}\"""", message, e)"
task5	"<line4>      LOGGER.error(getChosenSQLDriver() + "" class not found."", e);"	<line4>	"log.error(""The chosen SQL driver class could not be loaded."", e)"	"<line4> log.error(""The chosen SQL driver class could not be loaded."", e)"
task5	"<line4>    log.info(""startFolderEvent({})[{}] {}"", session, op, file);"	<line4>	"logger.info(""Start folder event: {} {}"", op, file)"	"<line4> logger.info(""Start folder event: {} {}"", op, file)"
task5	"<line63>      log.debug(""Failed to launch process used to create '"" + CLASSES_LIST_FILE_NAME + ""'."", e);"	<line63>	"log.debug(""Failed to create '"" + CLASSES_LIST_FILE_NAME + ""' file."", e)"	"<line63> log.debug(""Failed to create '"" + CLASSES_LIST_FILE_NAME + ""' file."", e)"
task5	"<line4>        log.debug(""unmapSession(id={}): {}"", sessionId, ioSession);"	<line4>	"log.debug(""Unmapped session "" + sessionId + "" ("" + ioSession + "")"")"	"<line4> log.debug(""Unmapped session "" + sessionId + "" ("" + ioSession + "")"")"
task5	"<line1>    logger.debug(""Groups"");"	<line1>	"logger.debug(""groups"")"	"<line1> logger.debug(""groups"")"
task5	"<line2>    LOG.info(""Clone existing project {} to a new project."", idProject);"	<line10>	"log.info(""cloneProject: idProject="" + idProject + "" not cloned because it doesn't belong to the""+ "" current user"")"	"<line10> log.info(""cloneProject: idProject="" + idProject + "" not cloned because it doesn't belong to the""+ "" current user"")"
task5	"<line53>      logger.info(""Forwarded the prediction model of ""+ numForwarded+ "" rows. [totalErrors=""+ cvState.getTotalErrors()+ "", lastLosses=""+ cvState.getCumulativeLoss()+ "", #trainingExamples=""+ count+ ""]"");"	<line52>	"LOG.info(""Forwarded "" + numForwarded + "" ratings."")"	"<line52> LOG.info(""Forwarded "" + numForwarded + "" ratings."")"
task5	"<line2>    log.info(""Starting JDBC Sink task"");"	<line9>	"LOG.warn(""Errant record reporter is not defined in the context"", e)"	"<line9> LOG.warn(""Errant record reporter is not defined in the context"", e)"
task5	<line10>      LOG.info(entityInfo.toString());	<line10>	LOG.info(entityInfo.toString())	<line10> LOG.info(entityInfo.toString())
task5	"<line38>      LOG.debug(""certificate validation failed"", e);"	<line38>	"LOGGER.debug(""Could not verify certificate"", e)"	"<line38> LOGGER.debug(""Could not verify certificate"", e)"
task5	"<line2>    LOGGER.debug(""Start"");"	<line9>	"LOGGER.info(""Saut = "" + sautCourant)"	"<line9> LOGGER.info(""Saut = "" + sautCourant)"
task5	"<line3>      LOGGER.debug(""Writing: {}"", outputPath);"	<line5>	"log.info(""Wrote {}"", outputPath)"	"<line5> log.info(""Wrote {}"", outputPath)"
task5	"<line15>        log.info(""detach {}"", controllerList.getSelectedItem());"	<line2>	"log.info(""refreshing"")"	"<line2> log.info(""refreshing"")"
task5	"<line2>    LOG.info(""Worker "" + name + "" was interrupted..."");"	<line2>	"logger.info(""Transport interrupted"")"	"<line2> logger.info(""Transport interrupted"")"
task5	"<line11>      LOG.error("""", e);"	<line11>	"log.error(""Error in parsing partition field values"", e)"	"<line11> log.error(""Error in parsing partition field values"", e)"
task5	<line5>    logger.info(Messages.STAGING_APP, app.getName());	<line3>	LOGGER.debug(MessageFormat.format(Messages.SKIPPING_STAGE_BECAUSE_PACKAGE_0_IS_ALREADY_UPLOADED,app.getPackageGuid()))	<line3> LOGGER.debug(MessageFormat.format(Messages.SKIPPING_STAGE_BECAUSE_PACKAGE_0_IS_ALREADY_UPLOADED,app.getPackageGuid()))
task5	"<line3>      LOG.debug(""Extra value is null, throw away it."");"	<line3>	"log.warn(""Value for key "" + key + "" is null."")"	"<line3> log.warn(""Value for key "" + key + "" is null."")"
task5	"<line44>        logger.warn(""No message integrity check"");"	<line44>	"LOGGER.debug(""Encrypted data was not integrity protected"")"	"<line44> LOGGER.debug(""Encrypted data was not integrity protected"")"
task5	"<line4>    LOG.debug(""[{}] Creating new schedule for the control connection"", logPrefix);"	<line4>	"logger.info(""Creating new reconnection schedule. isInitialConnection: {}"", isInitialConnection)"	"<line4> logger.info(""Creating new reconnection schedule. isInitialConnection: {}"", isInitialConnection)"
task5	"<line3>      logger.error(""getListProperty(): argument 'name' must be non-null"");"	<line3>	"logger.warn(""getListProperty(): argument 'name' must be non-null"")"	"<line3> logger.warn(""getListProperty(): argument 'name' must be non-null"")"
task5	"<line9>      logger.error(""Error on creating column family, ignoring"", e);"	<line9>	"logger.error(""Create column family error"", e)"	"<line9> logger.error(""Create column family error"", e)"
task5	"<line42>                LOG.debug(""Successfully wrote request to fence ledger and read entry: ""+ entryId+ "" ledger-id: ""+ ledgerId+ "" bookie: ""+ channel.getRemoteAddress());"	<line42>	"LOG.debug(""Sent request to read entry and fence ledger {} : {}"", ledgerId, entryId)"	"<line42> LOG.debug(""Sent request to read entry and fence ledger {} : {}"", ledgerId, entryId)"
task5	<line9>      Logger.error(this.getClass().getName(), ex.getMessage(), ex);	<line9>	"logger.error(""Failed to retrieve the table columns metadata"", ex)"	"<line9> logger.error(""Failed to retrieve the table columns metadata"", ex)"
task5	"<line29>          logger.warn(""***** "" + e.getMessage() + "" *****"");"	<line2>	"logger.info(""Traversal done, result size="" + result.size())"	"<line2> logger.info(""Traversal done, result size="" + result.size())"
task5	"<line4>      this.logger.warn(""level.dat for world '{}' could not be saved: "", this.levelName, cause);"	<line4>	log.error(cause.getMessage(), cause)	<line4> log.error(cause.getMessage(), cause)
task5	"<line17>        LOGGER.error(""Enclosing trace does not match split point. Found: {} expected: {}"",enclosingTrace.getTraceId(),enclosingTrace.getTraceId());"	<line17>	"logger.warn(""Detected a mismatch of trace IDs: the trace ID generated from the parent thread does not""+ "" match the trace ID implied by the monitored method's @Trace annotation: @Trace(traceId = ""+ tp.traceId+ "", orderId = ""+ tp.orderId+ ""). This may be a result of manually setting the""+ "" thread's trace ID to a value other than zero. If this is the case, the trace ID""+ "" generated from the parent thread will be used."")"	"<line17> logger.warn(""Detected a mismatch of trace IDs: the trace ID generated from the parent thread does not""+ "" match the trace ID implied by the monitored method's @Trace annotation: @Trace(traceId = ""+ tp.traceId+ "", orderId = ""+ tp.orderId+ ""). This may be a result of manually setting the""+ "" thread's trace ID to a value other than zero. If this is the case, the trace ID""+ "" generated from the parent thread will be used."")"
task5	"<line5>    log.debug("""");"	<line2>	"log.debug("""")"	"<line2> log.debug("""")"
task5	"<line36>        LOGGER.debug(""Unable to get X500 Name"", e);"	<line36>	"log.debug(""Invalid X500 name: {}"", curPermValue, e)"	"<line36> log.debug(""Invalid X500 name: {}"", curPermValue, e)"
task5	"<line13>    LOG.debug(""Processing {}"", cmd);"	<line48>	"LOG.debug(""Not connected to ZK"")"	"<line48> LOG.debug(""Not connected to ZK"")"
task5	"<line3>    log.info(""Subscribing to notifications: {}"", nfConsumer.getTopic());"	<line3>	"log.info(""Application is ready!"")"	"<line3> log.info(""Application is ready!"")"
task5	"<line4>      logger.error(""Received publication for not existing subscription callback with subscriptionId {}"",subscriptionId);"	<line4>	"logger.error(""Subscription State for subscriptionId: "" + subscriptionId + "" not found"")"	"<line4> logger.error(""Subscription State for subscriptionId: "" + subscriptionId + "" not found"")"
task5	"<line5>      LOG.error(""add SERVER_FAILED event for request failed, "", e);"	<line5>	"LOG.error(""Failed to notify other servers of ps failed, psLoc="" + server.psLoc, e)"	"<line5> LOG.error(""Failed to notify other servers of ps failed, psLoc="" + server.psLoc, e)"
task5	"<line27>    LOGGER.trace(""updateTextSections fertig nach {} ms. Entfernte/Neue TextSections: {} / {}"",Integer.valueOf((int) (System.currentTimeMillis() - startTime)),invalidTextSections.size(),newTextSections.size());"	<line27>	"LOGGER.info(L.m(""Update of text sections took %1%s ms.""),System.currentTimeMillis() - startTime)"	"<line27> LOGGER.info(L.m(""Update of text sections took %1%s ms.""),System.currentTimeMillis() - startTime)"
task5	"<line70>      log.error(""Error while communicating with the ForgeAPI"", t);"	<line71>	"log.error(""Error while communicating with the ForgeAPI"", t)"	"<line71> log.error(""Error while communicating with the ForgeAPI"", t)"
task5	"<line9>    LOGGER.info(""Set Device Verification Key Request received from organisation: {} for device: {} with""+ "" message priority: {}."",organisationIdentification,request.getDeviceIdentification(),messagePriority);"	<line9>	"LOGGER.info(""Set Device Verification Key Request received from organisation: {} for device: {} with""+ "" verification key: {}."",organisationIdentification,request.getDeviceIdentification(),request.getVerificationKey())"	"<line9> LOGGER.info(""Set Device Verification Key Request received from organisation: {} for device: {} with""+ "" verification key: {}."",organisationIdentification,request.getDeviceIdentification(),request.getVerificationKey())"
task5	"<line3>    log.debug(""Build scroll with query: {}"", query);"	<line1>	"log.debug(""Building the scroll"")"	"<line1> log.debug(""Building the scroll"")"
task5	"<line40>    LOG.debug(""{}"", sink.collectedTuples);"	<line40>	"LOG.debug(""{}"", sink.collectedTuples)"	"<line40> LOG.debug(""{}"", sink.collectedTuples)"
task5	"<line1>    log.error(""{}: could not find readable resource {} for the Menubars-Layout."",WebAppContextPath.class.getName(),menubarsLayoutXmlResource,cause);"	<line1>	"LOGGER.error(""Cannot load menubars layout resource: "" + menubarsLayoutXmlResource, cause)"	"<line1> LOGGER.error(""Cannot load menubars layout resource: "" + menubarsLayoutXmlResource, cause)"
task5	<line13>      logger.debug(e.getMessage());	<line13>	"logger.error(""Error"", e)"	"<line13> logger.error(""Error"", e)"
task5	<line10>        log.debug(portalException, portalException);	<line10>	log.debug(portalException, portalException)	<line10> log.debug(portalException, portalException)
task5	"<line3>    logger.debug(""Send CEA message"");"	<line3>	"logger.debug(""Send CEA message"")"	"<line3> logger.debug(""Send CEA message"")"
task5	"<line45>      logger.debug(""The command '{}' is not supported by this handler."", command.getClass());"	<line45>	"logger.warn(""Unsupported command: {} Class: {}"", command, command.getClass())"	"<line45> logger.warn(""Unsupported command: {} Class: {}"", command, command.getClass())"
task5	"<line7>        LOG.warn(""Dataset homepageURL was invalid: {}"", Strings.nullToEmpty(homepageUrl));"	<line7>	"log.info(""Invalid URL for dataset homepage: {}"", homepageUrl, e)"	"<line7> log.info(""Invalid URL for dataset homepage: {}"", homepageUrl, e)"
task5	<line33>      log.error(systemException, systemException);	<line33>	log.error(systemException, systemException)	<line33> log.error(systemException, systemException)
task5	"<line5>      log.error(""Could no de-serialize the following json "" + json, e);"	<line5>	"logger.error(""Error fromJson: "" + json, e)"	"<line5> logger.error(""Error fromJson: "" + json, e)"
task5	"<line1>    LOG.debug(""reading tenant info [id: {}]"", tenantId);"	<line3>	"LOG.info(""tenant not found: {}"", tenantId)"	"<line3> LOG.info(""tenant not found: {}"", tenantId)"
task5	"<line6>        LOG.error(""Unable to determine host name for IP: "" + host + "", setting to default pool"", e1);"	<line6>	"log.warn(""Could not resolve host \"""" + host + ""\"" returning the default pool"", e1)"	"<line6> log.warn(""Could not resolve host \"""" + host + ""\"" returning the default pool"", e1)"
task5	<line56>      log.error(e.getMessage(), e);	<line56>	log.error(e.getMessage(), e)	<line56> log.error(e.getMessage(), e)
task5	<line33>      log.error(e.getMessage());	<line33>	log.error(e.getMessage(), e)	<line33> log.error(e.getMessage(), e)
task5	"<line2>    LOG.info(""Getting all"");"	<line2>	"LOG.info(""Getting all countries"")"	"<line2> LOG.info(""Getting all countries"")"
task5	"<line16>    logger.debug(String.format(""vm[uuid:%s] is started .."", self.getUuid()));"	<line17>	"logger.debug(String.format(""afterStartNewCreatedVm[vm:%s]"", inv.getName()))"	"<line17> logger.debug(String.format(""afterStartNewCreatedVm[vm:%s]"", inv.getName()))"
task5	"<line5>    log.info(Color.GREEN + ""Stop_2 : empty column stop_id"" + Color.NORMAL);"	<line5>	"log.info(Color.GREEN + ""Stop_3_1 : empty column stop_id"" + Color.NORMAL)"	"<line5> log.info(Color.GREEN + ""Stop_3_1 : empty column stop_id"" + Color.NORMAL)"
task5	"<line2>      logger.debug(""Failed to cleanup the input "" + origInput);"	<line2>	"logger.warn(""Result string is empty. This indicates that the analysis could not be""+ "" performed on the input. The input string was: ""+ origInput)"	"<line2> logger.warn(""Result string is empty. This indicates that the analysis could not be""+ "" performed on the input. The input string was: ""+ origInput)"
task5	"<line6>      logger.debug(""Failed to parse path '{}', returning null"", path, e);"	<line6>	"LOG.warn(""Failed to parse path: "" + path, e)"	"<line6> LOG.warn(""Failed to parse path: "" + path, e)"
task5	"<line8>      logger.debug(""Channel {} unable to process command {}"", CHANNEL_BRIGHTNESS, command);"	<line8>	"logger.warn(""Brightness command '{}' not supported. Supported command: '{}'"",command,PercentType.class.getSimpleName())"	"<line8> logger.warn(""Brightness command '{}' not supported. Supported command: '{}'"",command,PercentType.class.getSimpleName())"
task5	"<line5>    LOGGER.debug(""Trying to acquire token for table: {}"", tableName);"	<line3>	"LOGGER.info(""Query rate limit is disabled"")"	"<line3> LOGGER.info(""Query rate limit is disabled"")"
task5	"<line55>              log.warn(""KBFolderPersistenceImpl.fetchByG_P_UT(long, long, String, boolean) with""+ "" parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."");"	<line55>	"log.warn(""fetchByG_P_UT(long, long, String, boolean) with parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."")"	"<line55> log.warn(""fetchByG_P_UT(long, long, String, boolean) with parameters (""+ StringUtil.merge(finderArgs)+ "") yields a result set with more than 1 result. This violates the logical""+ "" unique restriction. There is no order guarantee on which result is""+ "" returned by this finder."")"
task5	<line3>      logger.debug(objToLog);	<line3>	logger.debug(objToLog)	<line3> logger.debug(objToLog)
task5	"<line17>          LOGGER.debug(""Executed clear datasource SQL statement: {}"", sql);"	<line17>	LOG.debug(sql)	<line17> LOG.debug(sql)
task5	"<line5>    log.info(Color.GREEN + ""Stop_2_3 : missing column stop_lat"" + Color.NORMAL);"	<line5>	"log.info(Color.GREEN + ""Stop_2_3 : missing column stop_lat"" + Color.NORMAL)"	"<line5> log.info(Color.GREEN + ""Stop_2_3 : missing column stop_lat"" + Color.NORMAL)"
task5	"<line5>      log.debug(""Received activation response [requestId=""+ msg.getRequestId()+ "", nodeId=""+ nodeId+ ""]"");"	<line5>	"log.debug(""Process change global state response [nodeId="" + nodeId + "", msg="" + msg + ']')"	"<line5> log.debug(""Process change global state response [nodeId="" + nodeId + "", msg="" + msg + ']')"
task5	"<line2>      logger.trace(""Executing refresh job"");"	<line1>	"logger.debug(""Refreshing Plugwise Home Automation handler."")"	"<line1> logger.debug(""Refreshing Plugwise Home Automation handler."")"
task5	"<line2>    LOG.debug(""Providing password for ssh authentication of user '{}'"", config.getUsername());"	<line2>	"LOGGER.debug(""Retrieving password from configuration file"")"	"<line2> LOGGER.debug(""Retrieving password from configuration file"")"
task5	"<line5>        logger.error(""Error in closing data source "" + sourceHolder, e);"	<line5>	"log.error(""Failed to close data source: "" + sourceHolder.getName(), e)"	"<line5> log.error(""Failed to close data source: "" + sourceHolder.getName(), e)"
task5	"<line3>      ActiveMQRALogger.LOGGER.trace(""getMapNames()"");"	<line3>	"ActiveMQRALogger.LOGGER.trace(""getMapNames()"")"	"<line3> ActiveMQRALogger.LOGGER.trace(""getMapNames()"")"
task5	"<line5>        LOG.debug(""Failed to close ledger {} : "", ledgerId, re);"	<line5>	"LOG.debug(""Failed to close ledger for addition - ledger: {} : "", ledgerId, re)"	"<line5> LOG.debug(""Failed to close ledger for addition - ledger: {} : "", ledgerId, re)"
task5	"<line35>      log.error(""query table error,{}"", e);"	<line35>	"log.error(""Cannot get identity value from "" + tableName + "" after update operation."", e)"	"<line35> log.error(""Cannot get identity value from "" + tableName + "" after update operation."", e)"
task5	"<line5>    log.info(Color.GREEN + ""Route_8 : route_long_name includes route_short_name"" + Color.NORMAL);"	<line5>	"log.info(Color.GREEN + ""Route_8 : route_long_name includes route_short_name"" + Color.NORMAL)"	"<line5> log.info(Color.GREEN + ""Route_8 : route_long_name includes route_short_name"" + Color.NORMAL)"
task5	<line4>      logger.warn(e.getMessage());	<line4>	"LOG.error(""Got Exception while cleaning helper files"", e)"	"<line4> LOG.error(""Got Exception while cleaning helper files"", e)"
task5	"<line7>      logger.debug(""Got response mana type from player: "" + getId());"	<line2>	"logger.debug(""Setting response mana type to {} for player {}"", manaType, manaTypePlayerId)"	"<line2> logger.debug(""Setting response mana type to {} for player {}"", manaType, manaTypePlayerId)"
task5	"<line2>    log.info(""Reloading configuration"");"	<line9>	"log.info(""Loading configuration store {}"", sysPropConfigStore.getConfigLocation())"	"<line9> log.info(""Loading configuration store {}"", sysPropConfigStore.getConfigLocation())"
task5	"<line5>      LOGGER.error(""Could not read skin from input: "", e);"	<line5>	"log.error(""Error creating player skin from input stream"", e)"	"<line5> log.error(""Error creating player skin from input stream"", e)"
task5	"<line3>      log.debug(""writeBuffer({}) writing {} bytes"", this, buffer.available());"	<line3>	"log.debug(""writeBuffer({}) {}"", this, buffer)"	"<line3> log.debug(""writeBuffer({}) {}"", this, buffer)"
task5	"<line50>      log.error(""Error while fetching column by id {}, Caused by {}."", pKeyColumnValue, e);"	<line50>	"logger.error(""Error while finding the foreign keys for the entity {}."", entityClass, e)"	"<line50> logger.error(""Error while finding the foreign keys for the entity {}."", entityClass, e)"
task5	"<line2>    LOG.info(""Starting Server using kerberos credential"");"	<line2>	"log.info(""Starting server {}."", server.getName())"	"<line2> log.info(""Starting server {}."", server.getName())"
task5	"<line41>            log.warn(Messages.getString(""ProcessorUtilities.nullProcess""));"	<line41>	"log.error(""Can't find process for item: "" + testItem.getProcessItem())"	"<line41> log.error(""Can't find process for item: "" + testItem.getProcessItem())"
task5	<line10>      log.error(exception, exception);	<line10>	log.error(exception, exception)	<line10> log.error(exception, exception)
task5	"<line18>        logger.error(String.format(""Error while adding key=%s to As list=%s"", key, Arrays.toString(asList)));"	<line18>	logger.error(ex.getMessage())	<line18> logger.error(ex.getMessage())
task5	"<line43>          LOG.error(""impossible to create a java object from Bin:""+ field.getName()+ "" and type:""+ field.getType()+ "" and value:""+ t+ ""; recordReceived:""+ currentBin);"	<line43>	"LOG.error(""Error while casting number type for field [""+ field.getName()+ ""] in Aerospike entity extractor"",e)"	"<line43> LOG.error(""Error while casting number type for field [""+ field.getName()+ ""] in Aerospike entity extractor"",e)"
task5	"<line11>    log.info(""Join query returned: ""+ sampleListener.getLastEvent().get(""key1"")+ "" and ""+ sampleListener.getLastEvent().get(""key2""));"	<line1>	"log.info(""Running join sample"")"	"<line1> log.info(""Running join sample"")"
task5	<line12>        logger.info(query);	<line2>	"LOGGER.info(""Attempting to write file: {}"", fileName)"	"<line2> LOGGER.info(""Attempting to write file: {}"", fileName)"
task5	<line15>      log.error(systemException, systemException);	<line15>	log.error(systemException, systemException)	<line15> log.error(systemException, systemException)
task5	"<line1>    LOG.debug(""setPrimaryFieldPos()"");"	<line1>	"log.debug(""Setting primary field position to: "" + p)"	"<line1> log.debug(""Setting primary field position to: "" + p)"
task5	"<line27>      LOGGER.debug(""Temporary file deleted: {}"", tempDir.delete());"	<line27>	"LOGGER.debug(""Temporary file deleted: {}"", tempDir.delete())"	"<line27> LOGGER.debug(""Temporary file deleted: {}"", tempDir.delete())"
task5	"<line13>        LOG.error(""Error deleting user "" + username, e);"	<line13>	"LOG.error(""Error removing user from properties file"", e)"	"<line13> LOG.error(""Error removing user from properties file"", e)"
task5	"<line2>    logger.info(""SchedulerManager:schedule: Started scheduler job for cache refresh with ttl in sec =""+ TTL);"	<line1>	"log.info(""Scheduling data cache handler to run every {} seconds"", TTL)"	"<line1> log.info(""Scheduling data cache handler to run every {} seconds"", TTL)"
task5	<line26>            log.warn(sb.toString());	<line26>	log.warn(sb.toString())	<line26> log.warn(sb.toString())
task5	"<line25>          log.info(""closed the moved namespace info, namespace is {}, old zkClusterKey is {}"",namespace,zkClusterKey);"	<line22>	"LOG.info(""Close move out namespace: {}"", nns)"	"<line22> LOG.info(""Close move out namespace: {}"", nns)"
task5	"<line5>      logger.error(""Error while loading content vo : id {}"", id, t);"	<line5>	"logger.error(""Error while loading content vo : id {}"", id, t)"	"<line5> logger.error(""Error while loading content vo : id {}"", id, t)"
task5	"<line14>      LOGGER.info(""Caught exception while initializing caches"", e);"	<line14>	"LOG.error(""Error while creating data sources from path '{}'"", thirdeyeConfig.getDataSourcesPath(), e)"	"<line14> LOG.error(""Error while creating data sources from path '{}'"", thirdeyeConfig.getDataSourcesPath(), e)"
task5	"<line13>      log.warn(""[ClusterStatusHolder-{}] receive the expired heartbeat from {}, serverTime: {},""+ "" heartTime: {}"",appName,heartbeat.getWorkerAddress(),System.currentTimeMillis(),heartbeat.getHeartbeatTime());"	<line13>	"log.warn(""heartbeat time {} is older than last active time {}, maybe the worker is dead"",heartbeatTime,oldTime)"	"<line13> log.warn(""heartbeat time {} is older than last active time {}, maybe the worker is dead"",heartbeatTime,oldTime)"
task5	"<line10>        log.debug(""Metric=[%s] has not been configured to be emitted to opentsdb"",((ServiceMetricEvent) event).getMetric());"	<line10>	"log.info(""Ignoring event [%s] because it didn't match any metrics"", event)"	"<line10> log.info(""Ignoring event [%s] because it didn't match any metrics"", event)"
task5	<line9>          log.debug(noSuchFolderException, noSuchFolderException);	<line9>	log.debug(noSuchFolderException, noSuchFolderException)	<line9> log.debug(noSuchFolderException, noSuchFolderException)
task5	<line24>    LOGGER.info(ArrayConverter.bytesToHexString(message.getRandom().getValue()));	<line22>	"LOGGER.debug(""Random: "" + ArrayConverter.bytesToHexString(message.getRandom().getValue()))"	"<line22> LOGGER.debug(""Random: "" + ArrayConverter.bytesToHexString(message.getRandom().getValue()))"
task5	"<line5>    LOGGER.info(""Rack object returned to client : "" + updatedRack.toJsonString());"	<line5>	"LOGGER.info(""Rack object returned to client: {}"", updatedRack.toJsonString())"	"<line5> LOGGER.info(""Rack object returned to client: {}"", updatedRack.toJsonString())"
task5	"<line18>        LOG.trace(""Found {} in cache for {}, row='{}', locateType={}, replicaId={}"",loc,tableName,Bytes.toStringBinary(row),RegionLocateType.BEFORE,replicaId);"	<line18>	"LOG.trace(""cache hit for row before start of target region: ""+ Bytes.toStringBinary(loc.getRegion().getStartKey()))"	"<line18> LOG.trace(""cache hit for row before start of target region: ""+ Bytes.toStringBinary(loc.getRegion().getStartKey()))"
task5	"<line1>    LOG.debug(""Start new backup exclusive operation"");"	<line13>	"LOG.debug(""Failed to start backup operation because another backup is running"")"	"<line13> LOG.debug(""Failed to start backup operation because another backup is running"")"
task5	"<line5>      log.debug("".sendEventJson Processing event "" + json);"	<line5>	"log.debug("".sendEventJson JSON="" + json)"	"<line5> log.debug("".sendEventJson JSON="" + json)"
task5	"<line2>    LOGGER.debug(""Serializing RSAClientKeyExchangeMessage"");"	<line2>	"LOGGER.debug(""Serializing RSAClientKeyExchangeMessage"")"	"<line2> LOGGER.debug(""Serializing RSAClientKeyExchangeMessage"")"
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	"<line2>    Log.debug(""Test"");"	<line2>	"Log.debug(""Test"")"	"<line2> Log.debug(""Test"")"
task5	"<line1>    LOG.info(""Task '"" + taskid.getTaskID().toString() + ""' has failed."");"	<line2>	"LOG.info(""Task: "" + taskid + "" + terminated with state: "" + status.getRunState())"	"<line2> LOG.info(""Task: "" + taskid + "" + terminated with state: "" + status.getRunState())"
task5	"<line6>      log.warn(""Unexpected authorizable or definition for property rep:impersonators"");"	<line8>	"log.debug(""Importing impersonators: {}"", propInfo.getTextValues())"	"<line8> log.debug(""Importing impersonators: {}"", propInfo.getTextValues())"
task5	<line15>      log.error(exception, exception);	<line15>	log.error(exception, exception)	<line15> log.error(exception, exception)
task5	<line4>      LOG.debug(validationResult.get());	<line4>	LOG.warn(validationResult.get())	<line4> LOG.warn(validationResult.get())
task5	<line7>      logger.error(e, true);	<line7>	"logger.error(""InflateException when inflating fragment_authenticated_webview"", e)"	"<line7> logger.error(""InflateException when inflating fragment_authenticated_webview"", e)"
task5	"<line7>      LOG.debug(""Updated layout ID for table {} to {}."", tableURI, layoutID);"	<line7>	"LOG.info(""Updated table layout for {}: {}"", tableURI, layoutID)"	"<line7> LOG.info(""Updated table layout for {}: {}"", tableURI, layoutID)"
task5	"<line9>            logger.debug(""Current position saved: "" + pos);"	<line2>	"logger.debug(""handleMessage: {}"", msg.what)"	"<line2> logger.debug(""handleMessage: {}"", msg.what)"
task5	"<line6>      LOGGER.warn(""{} Error exporting {} \t{}"",Thread.currentThread().getName(),evidence.getPath(),e.toString());"	<line6>	"logger.warn(""Error extracting file"", e)"	"<line6> logger.warn(""Error extracting file"", e)"
task5	"<line26>      log.info(""PageMemory tracking enabled by system property."");"	<line27>	"if (log.isInfoEnabled()) log.info(""Page memory tracker plugin initialized: "" + plugin)"	"<line27> if (log.isInfoEnabled()) log.info(""Page memory tracker plugin initialized: "" + plugin)"
task5	"<line12>      LOG.error(""ProviderException requesting version history for "" + pageName, e);"	<line12>	"log.error(""Unable to get version history for page "" + pageName, e)"	"<line12> log.error(""Unable to get version history for page "" + pageName, e)"
task5	"<line1>    logger.debug(""build"");"	<line1>	"LOG.debug(""building form"")"	"<line1> LOG.debug(""building form"")"
task5	"<line14>        logger.error(""Failed to perform tasks when enumerator was finished"", e);"	<line14>	"logger.error(""Failed to perform tasks when enumerator was finished"", e)"	"<line14> logger.error(""Failed to perform tasks when enumerator was finished"", e)"
task5	"<line11>        log.warn(""Unexpected uiSource type '"" + child.getClass().getName() + ""'."");"	<line14>	"log.error(""Cannot determine parent container for component "" + child.getClass().getName())"	"<line14> log.error(""Cannot determine parent container for component "" + child.getClass().getName())"
task5	"<line3>          LOG.warn(""Failover triggered by {}"", user.getId());"	<line3>	"LOG.info(""Aborting due to manual failover by {}"", user.getId())"	"<line3> LOG.info(""Aborting due to manual failover by {}"", user.getId())"
task5	"<line6>      log.warn(""Error occurred while sleeping"", e);"	<line5>	"logger.error(""Interrupted while sleeping"", e)"	"<line5> logger.error(""Interrupted while sleeping"", e)"
task5	"<line4>      LOGGER.warn(MessageFormat.format(this.getActionExecution().getAction().getType()+ "" does not accept {0} as type for sourceFileName"",sourceFileName.getClass()));"	<line4>	"LOGGER.warn(MessageFormat.format(this.getActionExecution().getAction().getType()+ "" does not accept {0} as type for source file name"",sourceFileName.getClass()))"	"<line4> LOGGER.warn(MessageFormat.format(this.getActionExecution().getAction().getType()+ "" does not accept {0} as type for source file name"",sourceFileName.getClass()))"
task5	"<line8>      LOG.error(""exception while shutting down ldap"", e);"	<line8>	"LOGGER.error(""Failed to stop LDAP service."", e)"	"<line8> LOGGER.error(""Failed to stop LDAP service."", e)"
task5	"<line14>      log.error(""Error handling url: "" + urlString, e);"	<line14>	"log.error(""Error handling url: "" + urlString, e)"	"<line14> log.error(""Error handling url: "" + urlString, e)"
task5	"<line23>    LOG.info(""Command to launch container for PS is : "" + mergedCommand);"	<line5>	"LOG.info(""java options: "" + javaOpts)"	"<line5> LOG.info(""java options: "" + javaOpts)"
task5	"<line12>    LOG.error(""submitAndSchedule is not supported on Server.Please run your operation on Prism "");"	<line12>	"LOG.error(""submitAndSchedule is not supported on Server.Please run your operation on Prism "")"	"<line12> LOG.error(""submitAndSchedule is not supported on Server.Please run your operation on Prism "")"
task5	"<line7>      LOG.warn(""Interrupted while setting up mocks"", e);"	<line7>	"LOG.warn(""Interrupted while setting up mocks"", e)"	"<line7> LOG.warn(""Interrupted while setting up mocks"", e)"
task5	"<line7>      LOG.error(""Error while removing object"", t);"	<line7>	"logger.error(""Error while removing element"", t)"	"<line7> logger.error(""Error while removing element"", t)"
task5	"<line6>      logger.debug(""Path: "" + path + "" is already relative path."");"	<line6>	logger.debug(e, e)	<line6> logger.debug(e, e)
task5	<line2>    LOG.info()	<line2>	nan	<line2> nan
task5	"<line48>      LOGGER.error(""Error accessing database"", sqle);"	<line48>	"LOGGER.error(""Exception thrown"", sqle)"	"<line48> LOGGER.error(""Exception thrown"", sqle)"
task5	"<line15>      logger.debug(""New application orgName {} orgAppName {} id {} "",orgName,name,applicationId.toString());"	<line15>	"logger.debug(""Creating application "" + appName)"	"<line15> logger.debug(""Creating application "" + appName)"
task5	"<line2>    LOG.warn(""Exception raised when handling request to {}"", url, cause);"	<line2>	"logger.debug(requestInfo + "" received error response: "" + cause)"	"<line2> logger.debug(requestInfo + "" received error response: "" + cause)"
task5	"<line5>    log.info(""{}: Deactivating ConsumeBenchWorker."", id);"	<line9>	"log.info(""{}: Deactivated {}"", id, platform)"	"<line9> log.info(""{}: Deactivated {}"", id, platform)"
task5	<line6>      LOGGER.error(ex.getMessage(), ex);	<line6>	"log.error(""Error while getting operations list"", ex)"	"<line6> log.error(""Error while getting operations list"", ex)"
task5	"<line2>    log.error(""Error during report execution"", t);"	<line2>	"log.warn(""Fill handle error"", t)"	"<line2> log.warn(""Fill handle error"", t)"
task5	"<line6>    LOG.info(""Configuring CommitProcessor with {} worker threads."",numWorkerThreads > 0 ? numWorkerThreads : ""no"");"	<line12>	"LOG.info(""CommitProcessor started"")"	"<line12> LOG.info(""CommitProcessor started"")"
task5	"<line6>      logger.debug(MessageFormat.format(""Added message: {0}"", auditMessage));"	<line7>	"LOG.trace(""Audit message added: {}"", auditMessage)"	"<line7> LOG.trace(""Audit message added: {}"", auditMessage)"
task5	"<line2>      logger.debug(""Removing execution id: {}"", event.getExecId());"	<line1>	"logger.debug(""processExecutionChangedEvent {}"", event)"	"<line1> logger.debug(""processExecutionChangedEvent {}"", event)"
task5	"<line6>      logger.debug(""Executing SQL batch update of {} statements"", sql.length);"	<line6>	"logger.debug(""Executing batch SQL statements"")"	"<line6> logger.debug(""Executing batch SQL statements"")"
task5	"<line14>      log.trace(""IOException while creating jmxremote.access file:"", e);"	<line14>	"log.warn(""Cannot create jmxremote.access file."", e)"	"<line14> log.warn(""Cannot create jmxremote.access file."", e)"
task5	"<line46>        LOG.debug(ignore, ""Cannot close columns result set"");"	<line46>	"LOG.debug(""Failed to close column result set: {}"", ignore)"	"<line46> LOG.debug(""Failed to close column result set: {}"", ignore)"
task5	"<line1>    LOGGER.debug(""Updating Expansion Properties."");"	<line9>	"LOGGER.debug(""Updated with properties: {}"", properties)"	"<line9> LOGGER.debug(""Updated with properties: {}"", properties)"
task5	<line38>      logger.warn(errMsg, e);	<line38>	logger.error(errMsg, e)	<line38> logger.error(errMsg, e)
task5	"<line7>        LOGGER.info(""User group with uri "" + uri + "" not found."");"	<line7>	"LOGGER.error(""Error while reading group"", e)"	"<line7> LOGGER.error(""Error while reading group"", e)"
task5	"<line16>        logger.warn(""Query {} interrupted"", sourceInfo);"	<line16>	"logger.warn(""Query {} interrupted"", sourceInfo)"	"<line16> logger.warn(""Query {} interrupted"", sourceInfo)"
task5	"<line10>    log.info(""test entity child group id gives: "" + result);"	<line10>	log.info(result)	<line10> log.info(result)
task5	"<line7>      LOG.error(""Some of the fields in the query {} are not one of the valid fields {}."",fields,gdqt.getFields().getFields());"	<line7>	"log.info(""Fields in the snapshot are not valid for the schema"")"	"<line7> log.info(""Fields in the snapshot are not valid for the schema"")"
task5	"<line3>      LOGGER.debug(""Implicit declaration of property {}."", key);"	<line1>	"log.debug(""Setting property: {} = {}"", key, value)"	"<line1> log.debug(""Setting property: {} = {}"", key, value)"
task5	"<line3>    log.info(""Role  {} dropped successfully "", roleName);"	<line2>	LOGGER.debug(dropRoleStmt)	<line2> LOGGER.debug(dropRoleStmt)
task5	"<line25>      LOGGER.error(""An exception occurred publishing metrics to Parfait"", ex);"	<line25>	"log.error(""Error publishing metrics"", ex)"	"<line25> log.error(""Error publishing metrics"", ex)"
task5	"<line1>    logger.debug(""Create copy of track {}"", track);"	<line16>	"logger.info(""Copied track {} to {}"", track.getIdentifier(), copiedTrack.getIdentifier())"	"<line16> logger.info(""Copied track {} to {}"", track.getIdentifier(), copiedTrack.getIdentifier())"
task5	"<line13>    logger.debug(""oxAuth redirection Url: '{}'"", redirectionUrl);"	<line7>	"LOG.warn(""No ID Token found in the session. Logout will not be enforced."")"	"<line7> LOG.warn(""No ID Token found in the session. Logout will not be enforced."")"
task5	"<line21>      LOG.error(""Unable to retrieve results"", e);"	<line21>	"log.error(""Error while caching search results"", e)"	"<line21> log.error(""Error while caching search results"", e)"
task5	"<line4>      LOGGER.error(""Exception creating JAXBContext for templates: {}"", e.getLocalizedMessage(), e);"	<line4>	"logger.error(""Failed to initialize JAXBContext for templates"", e)"	"<line4> logger.error(""Failed to initialize JAXBContext for templates"", e)"
task5	"<line9>                  LOG.trace(""build image callback {}"", item);"	<line9>	"LOG.trace(""build image callback {}"", item)"	"<line9> LOG.trace(""build image callback {}"", item)"
task5	<line13>      logger.error(e.getMessage(), e);	<line13>	"logger.error(""Failed to parse date"", e)"	"<line13> logger.error(""Failed to parse date"", e)"
task5	<line4>    logger.warn(format, param);	<line9>	logger.warn(format, param)	<line9> logger.warn(format, param)
task5	<line6>      log.warn(ade.getMessage());	<line24>	"log.error(""Could not send signup email"", me)"	"<line24> log.error(""Could not send signup email"", me)"
task5	"<line7>      LOG.trace(""failed to activate method: {}#{}"", className, methodName, e);"	<line7>	"log.warn(""Failed to lookup method \"""" + methodName + ""\"" on class \"""" + className + ""\"""", e)"	"<line7> log.warn(""Failed to lookup method \"""" + methodName + ""\"" on class \"""" + className + ""\"""", e)"
task5	"<line7>          logger.debug(""Removing publish in progress marker from updated node, because update was not""+ "" successful. (node=""+ nodeRef.toString()+ "")"");"	<line7>	"logger.debug(""Setting publish in progress to false on nodeRef "" + nodeRef)"	"<line7> logger.debug(""Setting publish in progress to false on nodeRef "" + nodeRef)"
task5	"<line25>    LOG.info(""Caught script exception"", scriptException);"	<line12>	"LOG.error(""Exception while triggering onerror event"", e)"	"<line12> LOG.error(""Exception while triggering onerror event"", e)"
task5	"<line3>    LOGGER.info(""    Retrieving "" + url);"	<line3>	"logger.debug(""Getting tweets from URL: "" + url)"	"<line3> logger.debug(""Getting tweets from URL: "" + url)"
task5	<line27>      log.error(exception, exception);	<line27>	log.error(exception, exception)	<line27> log.error(exception, exception)
task5	"<line3>    log.debug(""Loading values..."");"	<line3>	"log.debug(""Loading values..."")"	"<line3> log.debug(""Loading values..."")"
task5	"<line8>        LOG.info(""Caught ObjectNotActive exception: ""+ ona+ "" during deactivate_object() call on POA: ""+ bindingPOA);"	<line8>	"log.info(""The object is not active, so deactivate_object threw an exception"", ona)"	"<line8> log.info(""The object is not active, so deactivate_object threw an exception"", ona)"
task5	"<line2>      ActiveMQRALogger.LOGGER.trace(""isEnable1xPrefixes()"");"	<line2>	"logger.trace(""isEnable1xPrefixes()"")"	"<line2> logger.trace(""isEnable1xPrefixes()"")"
task5	"<line3>      log.info(""...Setting queryLogLevelInfo: "" + queryLogLevelInfo);"	<line3>	"log.info(""Query log level set to info"")"	"<line3> log.info(""Query log level set to info"")"
task5	"<line2>    log.info(""Starting an EBInMemoryRegistry on UUID {0}"", registryUuid);"	<line2>	"logger.info(""Initializing EBRegistryProxyHandler"")"	"<line2> logger.info(""Initializing EBRegistryProxyHandler"")"
task5	"<line6>    LOG.info(""Pushing changes: {}"", commitComment);"	<line2>	"log.info(""Attempting to commit new components: {}"", newComponents.size())"	"<line2> log.info(""Attempting to commit new components: {}"", newComponents.size())"
task5	"<line21>      logger.debug(""Node to bucketId map: {}"", ret);"	<line21>	"logger.debug(""Bucket ownership changed to match the dataset. [dataset/bucket ids:{}][nodes:{}]{}"",bucketIdsToConsider,ret)"	"<line21> logger.debug(""Bucket ownership changed to match the dataset. [dataset/bucket ids:{}][nodes:{}]{}"",bucketIdsToConsider,ret)"
task5	"<line28>      log.debug(""Validating attachment contentType: ""+ receivedAttachment.getContentType()+ ""='""+ controlAttachment.getContentType()+ ""': OK."");"	<line28>	"log.debug(""validateAttachmentContentType: contentType match for index ""+ getAttachmentIndex(receivedAttachment)+ "" and ""+ getAttachmentIndex(controlAttachment))"	"<line28> log.debug(""validateAttachmentContentType: contentType match for index ""+ getAttachmentIndex(receivedAttachment)+ "" and ""+ getAttachmentIndex(controlAttachment))"
task5	<line15>      log.error(systemException, systemException);	<line15>	log.error(systemException, systemException)	<line15> log.error(systemException, systemException)
task5	<line1>    Logger.trace(id, message, error);	<line1>	logger.trace(message, error)	<line1> logger.trace(message, error)
task5	"<line2>    log.info(context.getVariable(""index""));"	<line2>	"LOGGER.debug(""Success!"")"	"<line2> LOGGER.debug(""Success!"")"
task5	"<line2>    log.trace(MessageFormat.format(""Deleting script {0}"", scriptKey.toString()));"	<line2>	"LOGGER.trace(MessageFormat.format(""Deleting Script {0}.{1}."", scriptKey.getScriptId(), scriptKey.getScriptVersion()))"	"<line2> LOGGER.trace(MessageFormat.format(""Deleting Script {0}.{1}."", scriptKey.getScriptId(), scriptKey.getScriptVersion()))"
task5	<line7>      logger.debug(e.getMessage(), e);	<line7>	logger.debug(e.getMessage(), e)	<line7> logger.debug(e.getMessage(), e)
task5	<line16>      LOG.error(msg, e);	<line16>	LOGGER.error(msg, e)	<line16> LOGGER.error(msg, e)
task5	"<line7>      logger.error(""Exception thrown from crucial Journal Transport: '"" + transportName + ""'"", e);"	<line7>	"logger.error(""Exception thrown from crucial journal transport: "" + transportName, e)"	"<line7> logger.error(""Exception thrown from crucial journal transport: "" + transportName, e)"
task5	<line22>        log.debug(portalException, portalException);	<line22>	log.debug(portalException, portalException)	<line22> log.debug(portalException, portalException)
task5	"<line12>            logger.info(""Unsupported encoding"", e);"	<line12>	"logger.error(""Query map failed to decode value"", e)"	"<line12> logger.error(""Query map failed to decode value"", e)"
task5	"<line38>    logger.info(""Update fixed_date to {} on ci [{}:{}]"", fixedDate, ciTypeId, guid);"	<line38>	"logger.info(""[Dynamically] Update the CI [{}], in state [{}], to state [{}]"",guid,ciHolder.get(CmdbConstants.DEFAULT_FIELD_STATE),targetState)"	"<line38> logger.info(""[Dynamically] Update the CI [{}], in state [{}], to state [{}]"",guid,ciHolder.get(CmdbConstants.DEFAULT_FIELD_STATE),targetState)"
task5	"<line2>      LOGGER.info(""Creating VirtualBox port forward for "" + port);"	<line2>	"LOGGER.info(""Creating port forward for "" + port)"	"<line2> LOGGER.info(""Creating port forward for "" + port)"
task5	"<line5>      log.info(""Test zero duration on update, key: "" + key);"	<line2>	"log.info(""Test zero on update."")"	"<line2> log.info(""Test zero on update."")"
task5	"<line3>      log.info(""setting up class"");"	<line2>	"log.info(""setUpClass called"")"	"<line2> log.info(""setUpClass called"")"
task5	"<line9>      LOGGER.error(""Could not download result: {}"", e.getMessage(), e);"	<line9>	"LOGGER.error(""Unable to write result file: {}"", e.getMessage(), e)"	"<line9> LOGGER.error(""Unable to write result file: {}"", e.getMessage(), e)"
task5	"<line3>        logger.debug(""Fail to update the ""+ _containerName+ "" container XML file for ""+ spaceName+ "" space; the DOM element for spaces is null"");"	<line3>	"logger.debug(""m_rootSpaceElement is null, cannot update XML tree"")"	"<line3> logger.debug(""m_rootSpaceElement is null, cannot update XML tree"")"
task5	"<line6>      logger.error(""BulkMigrationUser:encryptData:error occurred while encrypting data"", e);"	<line6>	"logger.error(""UserDataService:encryptData: Exception occurred with error messgae = ""+ e.getMessage(),e)"	"<line6> logger.error(""UserDataService:encryptData: Exception occurred with error messgae = ""+ e.getMessage(),e)"
task5	"<line2>    log.debug(""Connection established with sessionId: "" + session.getSessionId());"	<line2>	"LOG.info(""After connection established"")"	"<line2> LOG.info(""After connection established"")"
task5	"<line14>      log.error(""Unable to get blogs portlet instance configuration"", configurationException);"	<line14>	log.error(configurationException, configurationException)	<line14> log.error(configurationException, configurationException)
task5	"<line14>        logger.debug(""intersect contract m = "" + m);"	<line14>	"logger.debug(""contracted p="" + p + "" to "" + m)"	"<line14> logger.debug(""contracted p="" + p + "" to "" + m)"
task5	"<line7>      logger.error(""Error in Kafka iterator wrapper"", e);"	<line7>	"logger.error(""Failed to end messaging transaction"", e)"	"<line7> logger.error(""Failed to end messaging transaction"", e)"
task5	"<line3>    logger.debug(""Converting  response to "" + clazz);"	<line6>	"logger.debug(""Writing remote file ["" + fileName + ""] to path ["" + tempFile + ""]"")"	"<line6> logger.debug(""Writing remote file ["" + fileName + ""] to path ["" + tempFile + ""]"")"
task5	"<line13>      this.logger.warn(""Unexpected buffer underflow. Resetting and compacting buffer."", ex);"	<line13>	"this.logger.warn(""Unexpected buffer underflow. Resetting and compacting buffer."", ex)"	"<line13> this.logger.warn(""Unexpected buffer underflow. Resetting and compacting buffer."", ex)"
task5	"<line7>      log.fatal(""Unable to process audit message "" + auditMessage, exception);"	<line7>	log.error(exception, exception)	<line7> log.error(exception, exception)
task5	<line11>        log.debug(exception, exception);	<line11>	log.debug(exception, exception)	<line11> log.debug(exception, exception)
task5	"<line26>      log.warn(""Error while initializing cug importer"", e);"	<line26>	"log.warn(""Error while initializing the CugImporter"", e)"	"<line26> log.warn(""Error while initializing the CugImporter"", e)"
task5	<line13>    log.warn(sb.toString());	<line13>	log.warn(sb.toString())	<line13> log.warn(sb.toString())
task5	<line5>      logger.error(e);	<line5>	"logger.error(""loadModelFromFilename() :: failed to create URL from filename {}"", file, e)"	"<line5> logger.error(""loadModelFromFilename() :: failed to create URL from filename {}"", file, e)"
task5	"<line3>    logger.debug(""createServiceDefinitionResponse started..."");"	<line3>	"logger.debug(""createServiceDefinitionResponse started..."")"	"<line3> logger.debug(""createServiceDefinitionResponse started..."")"
task5	"<line2>    LOGGER.info(""CredentialService: received kapua event from {}, operation {}"",kapuaEvent.getService(),kapuaEvent.getOperation());"	<line2>	"LOG.info(""Received kapua event: {}"", kapuaEvent)"	"<line2> LOG.info(""Received kapua event: {}"", kapuaEvent)"
task5	"<line6>      LOGGER.error(""error printing message"", ioe);"	<line6>	"LOGGER.info(""exception while processing mail"", ioe)"	"<line6> LOGGER.info(""exception while processing mail"", ioe)"
task5	<line12>        log.debug(sb.toString());	<line12>	log.debug(sb.toString())	<line12> log.debug(sb.toString())
task5	"<line2>      LOG.info(""MiniHBaseCluster stopped"");"	<line2>	"LOG.info(""Shutting down HBase cluster"")"	"<line2> LOG.info(""Shutting down HBase cluster"")"
task5	<line21>    logger.info(sizeInfo);	<line21>	logger.info(sizeInfo)	<line21> logger.info(sizeInfo)
task5	"<line1>    Log.warn(""Autocreating jiveID row for type '"" + type + ""'"");"	<line6>	"LOG.debug(""ID table created"")"	"<line6> LOG.debug(""ID table created"")"
task5	"<line36>      LOGGER.error(""Error while mapping to MysqlBinLogEvent . Exception : ""+ e.getMessage()+ "" Cause: ""+ e.getCause(),e);"	<line36>	"LOG.error(""Error in mapping binlog event to a SourceEvent"", e)"	"<line36> LOG.error(""Error in mapping binlog event to a SourceEvent"", e)"
task5	<line4>      log.error(exception, exception);	<line4>	log.error(exception, exception)	<line4> log.error(exception, exception)
task5	"<line32>        LOG.info(""preprocess: ignored entities={}; pruned entities={}. topic-offset={}, partition={}"",ignoredEntities,prunedEntities,context.getKafkaMessageOffset(),context.getKafkaPartition());"	<line32>	"LOG.info(""Ignored {} entities, pruned {} entities"", ignoredEntities, prunedEntities)"	"<line32> LOG.info(""Ignored {} entities, pruned {} entities"", ignoredEntities, prunedEntities)"
task5	"<line4>      logger.debug(""Endpoint missing. Component is disabled."");"	<line4>	"LOG.debug(""No endpoint specified, ignoring receive event"")"	"<line4> LOG.debug(""No endpoint specified, ignoring receive event"")"
task5	<line8>          log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey);	<line8>	log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)	<line8> log.debug(_NO_SUCH_ENTITY_WITH_PRIMARY_KEY + primaryKey)
task5	<line21>      log.error(systemException, systemException);	<line21>	log.error(systemException, systemException)	<line21> log.error(systemException, systemException)
task5	<line18>      log.error(systemException, systemException);	<line18>	log.error(systemException, systemException)	<line18> log.error(systemException, systemException)
task5	<line11>    logger.debug(dbInfo.toString());	<line5>	"LOGGER.info(""Testing mysqlParse6"")"	"<line5> LOGGER.info(""Testing mysqlParse6"")"
task5	"<line4>    logger.warn(""Unable to write trace to disk"", e);"	<line5>	"LOG.error(""Error while flushing cache entry with key {}"", cacheKey, e)"	"<line5> LOG.error(""Error while flushing cache entry with key {}"", cacheKey, e)"
task5	"<line5>      LOG.debug(""Exception as expected when testing sshable "" + machineConfig);"	<line5>	"LOG.info(""expected exception "" + e + "" from "" + machineConfig)"	"<line5> LOG.info(""expected exception "" + e + "" from "" + machineConfig)"
task5	"<line7>    LOGGER.info(""Cluster: "" + getName() + "" locationType: "" + locationType + "" value:"" + value);"	<line7>	"LOGGER.info(""getLocation: locationType="" + locationType + "", value="" + value)"	"<line7> LOGGER.info(""getLocation: locationType="" + locationType + "", value="" + value)"
task5	"<line1>    logger.trace(""Setting occupancy groups list"");"	<line1>	"log.debug(""Setting occupancy groups: "" + oGroupList.size())"	"<line1> log.debug(""Setting occupancy groups: "" + oGroupList.size())"
task5	"<line6>        logger.debug(""Failure handling failure message for Event ""+ event+ "" (""+ eventType+ "") and Request ""+ request,e);"	<line6>	"logger.debug(""Failed to set session state to IDLE. Event type: {}, App request ID: {}, Error: {}"",eventType,request.getAppRequestId(),e.getMessage())"	"<line6> logger.debug(""Failed to set session state to IDLE. Event type: {}, App request ID: {}, Error: {}"",eventType,request.getAppRequestId(),e.getMessage())"
task5	"<line9>      logger.warn(""Target tag doesn't exist"");"	<line9>	"logger.warn(""Target document doesn't have an active tag - nothing to edit"")"	"<line9> logger.warn(""Target document doesn't have an active tag - nothing to edit"")"
task5	<line9>      LOGGER.error(e);	<line9>	"LOGGER.error(""Error starting transfer reply workflow."", e)"	"<line9> LOGGER.error(""Error starting transfer reply workflow."", e)"
task5	"<line5>      LOGGER.info(""Cannot retrieve space: "" + id);"	<line5>	"LOGGER.error(""Error retrieving space "" + id, e)"	"<line5> LOGGER.error(""Error retrieving space "" + id, e)"
task5	<line10>        LOGGER.error(e);	<line9>	"LOG.info(""Hive Meta Store Client created"")"	"<line9> LOG.info(""Hive Meta Store Client created"")"
task5	"<line6>      logger.info(""total: count: {}; time: {}; average: {}; period: count: {}; time: {}; average: {}"",totalCount,endTime - totalBeginTime,totalCount * 1000 / (endTime - totalBeginTime),tupleCount,endTime - beginTime,tupleCount * 1000 / (endTime - beginTime));"	<line5>	"logger.debug(""{} Total Count: {}"", this, totalCount)"	"<line5> logger.debug(""{} Total Count: {}"", this, totalCount)"
task5	"<line9>        logger.error(""count down is null, returning generic countdown vo!"");"	<line9>	"logger.error(""Error, no date provided (it is null) for flight: "" + f.getId())"	"<line9> logger.error(""Error, no date provided (it is null) for flight: "" + f.getId())"
task5	"<line4>        log.info(""Key is locked [key="" + key + "", node="" + ignite.name() + ']');"	<line4>	"log.error(""Key is locked: "" + key)"	"<line4> log.error(""Key is locked: "" + key)"
task5	<line9>      LOG.error(ex.toString(), ex);	<line9>	logger.info(ex.toString())	<line9> logger.info(ex.toString())
task5	"<line5>        LOGGER.warn(""Unable to check partial result of scanner context"", e);"	<line5>	"LOGGER.error(""Failed to get scanner state for instance {}. This may be a sign of a""+ "" malicious client."",instance,e)"	"<line5> LOGGER.error(""Failed to get scanner state for instance {}. This may be a sign of a""+ "" malicious client."",instance,e)"
task5	"<line7>    LOGGER.info(""DayProfileTablePassive to set is: {}"", this.dlmsHelper.getDebugInfo(dayArray));"	<line7>	"LOGGER.info(""DayProfileTablePassive to set is: {}"", this.dlmsHelper.getDebugInfo(dayArray))"	"<line7> LOGGER.info(""DayProfileTablePassive to set is: {}"", this.dlmsHelper.getDebugInfo(dayArray))"
task5	"<line13>      LOG.debug(""Inventory node connector key is null. Data can't be written to topology termination""+ "" point"");"	<line13>	"LOG.debug(""TerminationPoint is not present in topology. Skipping it."")"	"<line13> LOG.debug(""TerminationPoint is not present in topology. Skipping it."")"
task5	"<line9>      logger.error(""**** Error in UserTokenDAO:"", e);"	<line9>	"logger.error(""**** Error in find: {}"", e.getMessage())"	"<line9> logger.error(""**** Error in find: {}"", e.getMessage())"
task5	<line48>          log.warn(exception, exception);	<line48>	"log.warn(""Unable to add field "" + field.getName(), exception)"	"<line48> log.warn(""Unable to add field "" + field.getName(), exception)"
task5	"<line12>      logger.error(""Error while updating isMicromapperEnabled flag for crisis: "" + code, e);"	<line12>	"logger.error(""Unable to update micromapperEnabled for collection, code = "" + code, e)"	"<line12> logger.error(""Unable to update micromapperEnabled for collection, code = "" + code, e)"
task5	"<line8>        logger.error(""Exception initializing JdbcAsyncWriter"", ex);"	<line7>	"logger.error(""Exception occurred while checking for initialization."", ex)"	"<line7> logger.error(""Exception occurred while checking for initialization."", ex)"
task5	"<line6>      logger.warn(""{}: No preset found at id: {}"", handler.getDeviceName(), command.intValue());"	<line6>	"logger.debug(""No preset found for value {}"", command.toFullString())"	"<line6> logger.debug(""No preset found for value {}"", command.toFullString())"
task5	"<line2>    Log.debug(""Test"");"	<line3>	"Log.debug(""Test"")"	"<line3> Log.debug(""Test"")"
task5	"<line6>          LOG.info(""Dropping bootstrap index. Deleting file : "" + indexPath);"	<line7>	"LOG.info(""Deleted index path="" + indexPath)"	"<line7> LOG.info(""Deleted index path="" + indexPath)"
task5	"<line6>    LOG.info(""Property (set to default) {} = {}"", keyValueDefault.getKey(), keyValueDefault.getValue());"	<line2>	"log.info(""Setting property: {} -> {}"", keyValueDefault.getKey(), currentValue)"	"<line2> log.info(""Setting property: {} -> {}"", keyValueDefault.getKey(), currentValue)"
task5	"<line3>      LOG.debug(""["" + id_ + ""] setGlobalAlpha("" + globalAlpha + "")"");"	<line3>	"LOG.debug(""["" + id_ + ""] setGlobalAlpha("" + globalAlpha + "")"")"	"<line3> LOG.debug(""["" + id_ + ""] setGlobalAlpha("" + globalAlpha + "")"")"
task5	"<line9>      this.logger.error(""Error loading server handler jar"", e);"	<line9>	"logger.error(""Unable to load server handler "" + ""jar: "" + e.getMessage())"	"<line9> logger.error(""Unable to load server handler "" + ""jar: "" + e.getMessage())"
task5	"<line13>    LOGGER.info(""add rows in %.3fs"", (endTime - startTime) / 1000);"	<line13>	"LOGGER.info(""Added %d extended data rows in %d ms"", extendedDataRowCount, endTime - startTime)"	"<line13> LOGGER.info(""Added %d extended data rows in %d ms"", extendedDataRowCount, endTime - startTime)"
task5	"<line10>      log.error(""Unable to authenticate client against Kerberos"", e);"	<line10>	"LOG.warn(""Could not establish GSSContext"", e)"	"<line10> LOG.warn(""Could not establish GSSContext"", e)"
task5	"<line14>    LOG.warn(policy.toString() + "" is not supported by ByChar comparison"");"	<line14>	"LOG.warn(""Unknown comparison policy: "" + policy)"	"<line14> LOG.warn(""Unknown comparison policy: "" + policy)"
task5	"<line6>      LOG.error(""Failed to parse IP address {}"", e);"	<line6>	"LOG.debug(""Could not resolve endpoint address {}"", rendEp.getAddress())"	"<line6> LOG.debug(""Could not resolve endpoint address {}"", rendEp.getAddress())"
task5	"<line8>          BPELRESTLightElement.LOG.error(""Internal Error: Stored URI was invalid"", e);"	<line8>	"LOG.error(""Could not create URI from URI part: {}"", this.getURIPart(), e)"	"<line8> LOG.error(""Could not create URI from URI part: {}"", this.getURIPart(), e)"
task5	"<line6>      logger.debug(""Can not handle timeout event"", e);"	<line6>	"log.error(""Failed to handle timeout for request {}"", request, e)"	"<line6> log.error(""Failed to handle timeout for request {}"", request, e)"
task5	"<line10>                LOGGER.debug(""Failed getting {} resource bundle, using default \""{}\"""",INTRIGUE_BASE_NAME,DEFAULT_MESSAGE_FORMAT);"	<line10>	"LOGGER.error(""Could not find message format for attribute validation."", e)"	"<line10> LOGGER.error(""Could not find message format for attribute validation."", e)"
task5	"<line14>      logger.debug(""invalid syntax"", e);"	<line14>	"LOG.debug(""Failed to find configuration for factoryPid: {} identifier: {}. Creating one."",factoryPid,identifier)"	"<line14> LOG.debug(""Failed to find configuration for factoryPid: {} identifier: {}. Creating one."",factoryPid,identifier)"
task5	"<line5>        logger.debug(""MembershipViewReplyProcessor received {}"", view);"	<line5>	"logger.debug(""Received new view: {}"", view)"	"<line5> logger.debug(""Received new view: {}"", view)"
task5	"<line4>        LOG.debug(""Setting custom LocaleResolver of type "" + localeResolver.getClass().getName());"	<line4>	"LOG.debug(""LocaleResolver: "" + localeResolver)"	"<line4> LOG.debug(""LocaleResolver: "" + localeResolver)"
task5	"<line1>    log.info(""controller.policyFlags()"");"	<line1>	"LOGGER.info(""Current policy: "" + policy)"	"<line1> LOGGER.info(""Current policy: "" + policy)"
task5	"<line23>      logger.error(""Error while loading username for control uuid: "" + uuid, t);"	<line23>	"log.error(""Error while finding assignee for task/control "" + uuid, t)"	"<line23> log.error(""Error while finding assignee for task/control "" + uuid, t)"
task5	"<line7>      log.debug(""finished"");"	<line7>	"log.debug(""finished indexing {}"", tuple)"	"<line7> log.debug(""finished indexing {}"", tuple)"
task5	"<line8>      LOG.debug(""Obtaining active resource claims, will NOT consider {} because its parent is not the""+ "" current section"",file);"	<line11>	"logger.debug(""Visited file "" + path + "" and created resource claim "" + identifier)"	"<line11> logger.debug(""Visited file "" + path + "" and created resource claim "" + identifier)"
task5	"<line3>      LOGGER.error(""Unable to delete the following file: "" + filename);"	<line1>	"logger.debug(""Deleting file: {}"", filename)"	"<line1> logger.debug(""Deleting file: {}"", filename)"
